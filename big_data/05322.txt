6
1
0
2

 
r
a

 

M
7
1

 
 
]

.

R
P
h
t
a
m

[
 
 

1
v
2
2
3
5
0

.

3
0
6
1
:
v
i
X
r
a

Stein’s method for positively associated random

variables with applications to Ising, percolation and

voter models

Larry Goldstein∗ and Nathakhun Wiroonsri

University of Southern California

March 18, 2016

Abstract

We provide non-asymptotic L1 bounds to the normal for three well-known models
in statistical physics in Zd; the ferromagnetic nearest-neighbor Ising model, the super-
critical bond percolation model, and the voter model. In the Ising model, we obtain
an L1 distance bound between the total magnetization and the normal distribution at
temperatures below critical. In the percolation model, we obtain such a bound for the
total number of points in a ﬁnite region belonging to an inﬁnite cluster in dimensions
d ≥ 2, and in the voter model for the occupation time in dimensions d ≥ 7.
The tool developed for these purposes is a version of Stein’s method adapted to
positively associated random variables. In one dimension, letting ξ = (ξ1, . . . , ξm) be a
positively associated mean zero random vector with components that obey the bound

i=1 ξi has variance 1, it holds that

|ξi| ≤ B, i = 1, . . . , m, and whose sum W =Pm
d1(cid:0)L(W ),L(Z)(cid:1) ≤ 5B +r 8
πXi6=j

E[ξiξj]

where Z has the standard normal distribution and d1(·,·) is the L1 metric. Our methods
apply in the multidimensional case with the L1 metric replaced by a smooth function
metric.

1

Introduction

We provide non-asymptotic L1 bounds to the normal for three well-known models in statis-
tical physics in Zd; the ferromagnetic nearest-neighbor Ising model, the supercritical bond
percolation model, and the voter model. We recall that the L1, or Wasserstein, distance

0AMS 2010 subject classiﬁcations: Primary 60F05,82B30,60G60.
0Key words and phrases: Random Fields, Block dependence, Correlation inequality, Positive Dependence
∗Research partially supported by NSA-H98230-15-1-0250.

1

between the distributions L(X) and L(Y ) of real valued random variables X and Y is given
by

d1(cid:0)L(X),L(Y )(cid:1) =Z ∞

−∞ |P (X ≤ t) − P (Y ≤ t)|dt.

(1)

Taking the Ising model ﬁrst, questions regarding the distribution of total magnetization
in statistical mechanical models have attracted attention for quite some time. To ﬁx terms,
with Z the set of integers and k ∈ Z let Nk = [k,∞) ∩ Z, and for d a positive integer
let Zd denote the d-dimensional lattice composed of vectors i = (i1, . . . , id) having integer
components, and let Λ be a symmetric hypercube, that is,

Λ = {i ∈ Zd : |i|∞ ≤ k} for some k ∈ N0,

where |i|∞ = sup1≤j≤d |ij|, the supremum norm. We say ω = {ωi : i ∈ Λ} is a conﬁguration
on Λ when ωi takes values in the set {−1, +1} for each i ∈ Λ.
We deﬁne a probability measure on conﬁgurations on Λ, corresponding to the nearest-

neighbor ferromagnetic Ising model. First, ﬁx a conﬁgurationeω = {eωi : i ∈ Zd} on all of Zd,

and the interaction strength J ≥ 0. Now deﬁne the energy function, or Hamiltonian HΛ,h,eω,
by

HΛ,h,eω(ω) = −J Xi,j∈Λ

|i−j|∞=1

ωiωj + Xi∈Λ,j /∈Λ

|i−j|∞=1

ωieωj − hXi∈Λ

ωi,

(2)

where h is the magnetic moment parameter and |i|∞ = sup1≤j≤d |ij| is the supremum norm.
Given an inverse temperature β > 0, the ﬁnite volume Ising probability measure on Λ is
given by

µΛ,β,h,eω(ω) = exp(−βHΛ,h,eω(ω))/ZΛ,β,h,eω,

for a normalizing constant ZΛ,β,h,eω. The cases whereeωj takes the value 0, +1 and −1 for all j ∈

Zd are typically referred to as free, positive, and negative boundary conditions, respectively,
see [ELL06], for example.

Now let {Λn : n ∈ N1} be any increasing sequence of symmetric hypercubes of Zd whose
union is Zd. For ﬁxed β and h, we say that µΛn,β,h,eω converges weakly to µβ,h,eω as n → ∞ if

n→∞Z f dµΛn,β,h,eω =Z f dµβ,h,eω

lim

for all local functions f : Rd → R, where we recall that a function f is said to be local if it
depends only on Λn for some n. Each such weak limit is a probability measure on {−1, 1}Zd.
The set of inﬁnite volume Gibbs measures, denoted Gβ,h, is the closed convex hull of all weak
The structure of Gβ,h depends on parameters β and h. In particular, by [ELL06], there
exists a critical inverse temperature βc such that the limit measures depend on the boundary
conditions, or not, when β < βc or β > βc, respectively. More precisely, for β > 0, h 6= 0
and 0 < β < βc, h = 0, the ﬁnite volume measures µΛn,β,h,eω have a unique weak limit for any

limits of µΛn,β,h,eω for eω any conﬁguration on Zd.

2

choice of boundary conditions eω. Thus, in these cases, Gβ,h consists of a unique measure,

which we denote µβ,h. In the case β > βc, h = 0, the set Gβ,0 contains of two pure phases,
µ+
β,0 and µ−
β,0, which are the inﬁnite volume measures arising as weak limits under positive
and negative boundary conditions respectively. Hence, by deﬁnition, Gβ,0 also contains the
convex combinations µ(α)
β,0, 0 < α < 1. These measures are called
mixed phases.For d = 2, Gβ,0 consists of only pure and mixed phases. For d ≥ 3, the
set Gβ,0 contains nontranslation invariant measures for any suﬃciently large β, which are
not considered in this paper. For additional detail about ﬁnite and inﬁnite volume Gibbs
measures, see [ELL06].

β,0 + (1 − α)µ−

β,0 = αµ+

In this work, we henceforth consider the Ising models on Zd in the cases where the weak
limit is unique, and also the pure or mixed phases when h = 0 and β > βc. More precisely,
we consider measures in the set

µβ,h
β,0, µ−
µ+
µ(α)
β,0

β,0

:
:
:

(β, h) ∈ R+ × R \ {0} ∪ (0, βc) × {0}

β > βc, h = 0

0 < α < 1, β > βc, h = 0

.

(3)

M =



Under the measures in M, we are interested in obtaining L1 bounds to the normal for

the distribution of the total magnetization

Mk = Xi∈Bn

k

ωi

(4)

over the ﬁnite block Bn

k ⊂ Zd with side length n ‘anchored’ at k ∈ Zd, deﬁned in (10).

The second model we consider is bond percolation on Zd for d ≥ 2 (see [Grim99], for
example). In graphical terms, nearest neighbor bonds are the edges between vertices x and
y in Zd satisfying |x− y|∞ = 1; we denote the collection of all such bonds by Ed. For a given
θ ∈ [0, 1], we declare each bond in Ed to be open with probability θ and closed otherwise,
independently of all other bonds. More formally, we take G = {0, 1}Ed, elements of which
are represented as g = (cid:8)g(e) : e ∈ Ed(cid:9), and called conﬁgurations. The value g(e) = 0
corresponds to the bond e being closed and g(e) = 1 corresponds to e being open.

Given a bond conﬁguration g and x ∈ Zd, let C(x) be the set of vertices connected to
x through open bonds, and let |C(x)| denote the number of vertices in C(x), which may be
inﬁnite. Since the probability θ that a bond is open is the same for every e ∈ Ed and each
bond is independent of all others, C(x) has the same distribution for all x ∈ Rd. We deﬁne

ρ(θ) = P (|C(0)| = ∞)

and θc = sup{θ : ρ(θ) = 0},

respectively representing the probability that for a given connectivity θ a vertex belongs to
an inﬁnite cluster, and its threshold, the critical probability. Our interest is in obtaining
L1 bounds to the normal, in the supercritical case θ > θc, for the distribution of the total
number of points in a ﬁnite block that belong to an inﬁnite cluster, speciﬁcally for

Uk = Xx∈Bn

k

1{|C(x)|=∞}

(5)

where Bn

k ⊂ Zd is deﬁned in (10).

3

That is, a site x ∈ Zd changes its state with rate equal to the fraction of its 2d nearest
neighbors that are in the opposite state. We study the occupation time

T t

s =Z s+t

s

ηu(0)du for t > 0, s ≥ 0,

(6)

that is, the amount of time in (s, s + t] that the origin 0 spends in state 1.

The quantities (4), (5) and (6) that we consider in these three models are obtained
by summing or integrating positively associated variables, and we obtain our results by
developing an L1 version of Stein’s method for such instances. We recall that a random
vector ξ = (ξ1, . . . , ξm) ∈ Rm is said to be positively associated whenever

(7)

Cov(cid:0)ψ(ξ), φ(ξ)(cid:1) ≥ 0

The last model we consider is the d-dimensional voter model introduced in [CS73], a
Markov process {ηt : t ≥ 0} taking values in {0, 1}Zd, and one of the simplest interacting
particle systems, see also [CG83]. With a precise formulation deferred to Section 2.3, the
process is speciﬁed by taking the initial distribution {η0(x) : x ∈ Zd} to be a family of
independent, identically distributed Bernoulli random variables with parameter θ ∈ (0, 1),
and having transitions

ηt(x) → 1 − ηt(x) at rate

1

2d(cid:12)(cid:12){y : |y − x|∞ = 1 and ηt(x) 6= ηt(y)}(cid:12)(cid:12).

for all real valued coordinate-wise nondecreasing functions ψ and φ on Rm such that ψ(ξ)
and φ(ξ) posses second moments. In general, a collection {ξα : α ∈ I} of real valued random
variables indexed by a set I is said to be positively associated if all ﬁnite subcollections are
positively associated. Positive association was introduced in [EPW67] and has been found
frequently in probabilistic models in several areas, especially statistical physics.
In some
literature (7) is termed the FKG-inequality, see [New80] for example.

For the Ising model with measure in M in (3), it is well-known that the variables making
: i ∈ Zd} are positively associated whenever J ≥ 0. For the
up the conﬁguration {ωi
percolation model, it is also well-known that {1{|C(x)|=∞} : x ∈ Zd} is positively associated
(see [New80] for both models). For the voter model, taking t > 0, m ∈ N1 and

X t

s,i =Z s+it/m

s+(i−1)t/m

ηu(0)du for i ∈ [m], we have T t

s =

X t

s,i,

mXi=1

(8)

where [m] = {1, 2, . . . , m}. It was demonstrated in [CG84] that the family {X t
s,i : i ∈ [m]}
is positively associated. Hence in each of the models we consider the quantity we study can
be represented as the sum of positively associated random variables.

Over the last few decades, several papers established central limit theorems and rates of
convergence for sums of positively associated random variables under various assumptions.
To state some of these results, recall that a random ﬁeld {Xj : j ∈ Zd} is called second order
stationary when EX 2

j − i, that is, Cov(cid:0)Xi, Xj(cid:1) = R(j − i) for all i, j ∈ Rd, with R(·) necessarily given by

j < ∞ for all j ∈ Zd and the covariance Cov(cid:0)Xi, Xj(cid:1) depends only on

(9)

R(k) = Cov(cid:0)X0, Xk(cid:1).

4

We say the ﬁeld is strictly stationary if for all m ∈ N1 and k, j1, . . . , jm ∈ Zd, the vector
(Xj1, . . . , Xjm) has the same distribution as (Xj1+k, . . . , Xjm+k). From the deﬁnitions, when
second moments exist, strict stationarity implies second order stationarity, and if a second
order stationary ﬁeld is positively associated, then R(k) ≥ 0 for all k ∈ Zd.
We let 1 ∈ Zd denote the vector with all components 1, and write inequalities such as
a < b for vectors a, b ∈ Rd when they hold componentwise. For k ∈ Zd, n ∈ N1 and a
random ﬁeld {Xj : j ∈ Zd}, deﬁne the ‘block sum’ variables, over a block with side length n,
by

Sn

k = Xj∈Bn

k

Xj where Bn

k =(cid:8)j ∈ Zd : k ≤ j < k + n1(cid:9) .

(10)

Note that Bn

k = Bn

0 + k.

For a second order stationary ﬁeld with R(·) given by (9), we have

Var(cid:0)Sn

k(cid:1) = Xi,j∈Bn

k

With

Cov(cid:0)Xi, Xj(cid:1) = ndAn where An =

A = Xk∈Zd

R(k),

1

nd Xi,j∈Bn

1

R(i − j).

(11)

(12)

Lemma 4 of [New80] shows R(0) < ∞, R(k) ≥ 0 and A < ∞ imply limn→∞ An = A. As
An or A equals zero only if the ﬁeld is trivial, we assume without loss of generality in the
following that An > 0 for all n ∈ N1 and A > 0.
Theorem 1.1 of [New80] shows that the collection of properly standardized block sums
Sn
k of a strictly stationary, positively associated random ﬁeld with covariance given by (9)
converges jointly to independent normal variables when A < ∞.
Theorem 1.1 ([New80]) Let {Xj : j ∈ Zd} be a positively associated strictly stationary
random ﬁeld with ﬁnite second moments and covariance R(k) given by (9) that satisﬁes
A < ∞ where A is given in (12). Then the standardized block sums

(13)

(cid:26)Sn

nd/2

nk − ESn

nk

: k ∈ Zd(cid:27)

converge to independent mean zero normal distributions with variance A as n → ∞. That
is, the expectations of bounded continuous functions of (13) that depend on only ﬁnitely
many coordinates converge to the expectation of that same number of independent mean
zero, variance A normal variables.

We note that the blocks Bn

nk over which sums are taken in Theorem 1.1 are disjoint,
and that the limiting distribution has independent coordinates. As an application of our
Theorem 1.4, in Theorem 2.2 we obtain bounds for the sums over overlapping blocks to
an approximating dependent multivariate normal distribution. Rectangular blocks, that is,
blocks with varying side lengths, can also be accommodated by our methods, at the cost of
some additional complexity in our computations.

5

The stationarity assumption was relaxed in [CG84], where it was shown that the block
sums of a positively associated random ﬁeld {Xj : j ∈ Zd} converge to the normal whenever
Xj has ﬁnite third moment for every j ∈ Zd and u(n) converges to zero as n → ∞ where

u(n) = sup

j∈Zd Xi∈Zd:|j−i|∞≥n

Cov(cid:0)Xi, Xj(cid:1).

(14)

The rate of convergence for sums of positively associated variables was ﬁrst obtained in
[Bir88], which achieved the rate log(n)/√n in the Kolmogorov metric in the one dimensional
case, assuming uniformly ﬁnite 3 + ǫ-moments for some ǫ > 0, and that u(n) decays at an
exponential rate. Theorem 1.2 of [Bul95] generalizes the results in [Bir88]. In the following C
will denote a constant whose value may change from line to line. Recall that the Kolmogorov,
or L∞ distance between distributions L(X) and L(Y ) is given by
t∈R |P (X ≤ t) − P (Y ≤ t)|.

dK(cid:0)L(X),L(Y )(cid:1) = sup

Theorem 1.2 ([Bul95]) Let ǫ > 0 and {Xj : j ∈ Zd} be a mean zero, positively associated
random ﬁeld whose elements have uniformly bounded 3 + ǫ moments. Assume that there
exists λ > 0 such that u(n) as deﬁned in (14) satisﬁes

u(n) ≤ κ0e−λn
Then for any ﬁnite subset V ⊂ Zd and
S(V ) =Xj∈V

for some κ0 > 0.

Xj with σ2(V ) = Var(S(V )),

one has

dK(cid:0)L(S(V )/σ(V )),L(Z)(cid:1) ≤ C|V |σ(V )−3(log(|V | + 1))d

where Z is a standard normal random variable, |V | denotes the size of V and C > 0 is a
constant depending only on ǫ, d, κ0 and λ.

In the present work we ﬁrst provide bounds in the L1 distance to the normal for a sum of
elements of a positively associated random ﬁeld in Zd, under the condition that covariances
decay at an exponential rate. We apply these bounds to the total magnetization of the
d-dimensional Ising model as deﬁned in (4) and the total number of points belonging to an
inﬁnite cluster in the bond percolation model as deﬁned in (5).

We also consider the occupation time of the voter model, where the assumption that the
covariance decays exponentially is not satisﬁed. Without using positive association, [CG83]
showed that the occupation time T t
0 of the voter model as deﬁned in (6) satisﬁes the CLT for
d ≥ 2. In later work, [CG84] used the fact that T t
0 is the sum of positively associated random
variables and that u(n) as deﬁned in (14) converges to zero as n → ∞ to prove the CLT for
d ≥ 5. However, error bounds and the rate of convergence appear yet unaddressed in the
literature. Bounds to the limit in the L1 metric for d ≥ 7 are obtained using a technique
provided in Theorem 1.3 below.
We obtain L1 results on the three models considered by developing a version of Stein’s
method for sums of bounded positively associated random variables. Stein’s method was

6

ﬁrst introduced by Charles Stein in his seminal paper [Ste72] and has become one of the
most powerful methods to prove convergence in distribution. Its main advantages are that
it provides non asymptotic bounds on the distance between distributions, and that it can
handle a number of situations involving dependence. For more detail about the method in
general, see the text [CGS11] and the introductory notes [Ros11].

Stein’s method has been used previously in several papers in statistical physics.

In
[ER08], a version of Stein’s method using size bias couplings was developed for a class of
discrete Gibbs measures, that is, probability measures on N0 proportional to eV (k) for some
function V : N0 → R. This work provided bounds in the total variation distance between
the distribution of certain sums of strongly correlated random variables and discrete Gibbs
measures, with applications to interacting particle systems. Stein’s method of exchangeable
pairs was applied to the classical Curie-Weiss model for high temperatures and at the critical
temperature in [EL10], where optimal Kolmogorov distance bounds were produced. The
same result at the critical temperature was also obtained in [CS11]. These results were
extended to the Curie-Weiss-Potts model in [EM15].

Our main result in the one dimensional case is the following.

Theorem 1.3 Let ξ = (ξ1, . . . , ξm) be a positively associated mean zero random vector with
i=1 ξi has variance 1. Let Z

components obeying the bound |ξi| ≤ B, and whose sum W =Pm

be a standard normal random variable. Then

d1(cid:0)L(W ),L(Z)(cid:1) ≤ 5B +r 8
πXi6=j

σij where σij = E[ξiξj].

(15)

We also consider a version of Theorem 1.3 adapted to the multidimensional case, with
the L1 metric replaced by a smooth functions metric, following the development of Chapter
12 of [CGS11]. For

x ∈ Rp

let

|x|1 =

pXi=1

|xi|,

the L1 vector norm,

and for a real valued function ϕ(u) deﬁned on the domain D, let |ϕ|∞ = supx∈D |ϕ(x)|. We
include in this deﬁnition the |·|∞ norm of vectors and matrices, for instance, by considering
them as real valued functions of their indices.
m (Rp) be the collection of all functions h : Rp → R such that for all
0 with |k|1 ≤ m, the partial derivative

k = (k1, . . . , kp) ∈ Np

For m ∈ N0, let L∞

h(k)(x) =

∂|k|1h

∂k1x1 · · · ∂kpxp

exists, and

For f ∈ L∞

m (Rp) let

|h|L∞

m (Rp) := max

0≤|k|1≤m|h(k)|∞ is ﬁnite.

Hm,∞,p = {h ∈ L∞

m (Rp) : |h|L∞

m (Rp) ≤ 1},

7

and for random vectors X and Y in Rp, deﬁne the smooth functions metric

dHm,∞,p(cid:0)L(X),L(Y)(cid:1) = sup

h∈Hm,∞,p |Eh(X) − Eh(Y)|.

(16)

For a positive semideﬁnite matrix H we let H 1/2 denote the unique positive semideﬁnite
square root of H. When H is positive deﬁnite, we write H −1/2 = (H 1/2)−1. Our main
multidimensional result is the following theorem:

deﬁnite. Then

Theorem 1.4 With m, p ∈ N1, let {ξi,j : i ∈ [m], j ∈ [p]} be positively associated mean
zero random variables bounded in absolute value by some positive constant B. Let S =

(S1, S2, . . . , Sp) where Sj =P1≤i≤m ξi,j for j ∈ [p] and assume that Σ = Var(cid:0)S(cid:1) is positive
dH3,∞,p(cid:0)L(Σ−1/2 (S − ES)) ,L(Z)(cid:1) ≤(cid:18)1
+(cid:18) 3
2(cid:19) p2|Σ−1/2|2
√2
+(cid:18)2√2p3B|Σ−1/2|3

+ 2√2(cid:19) p3B|Σ−1/2|3
pXj=1 Xi,k∈[m],i6=k
∞ +(cid:18) 3
√2

2(cid:19) p2|Σ−1/2|2

Cov (ξi,j, ξk,j)

pXj=1

Σj,l,

(17)

1

+

1

+

∞

Σj,j

6

∞

∞(cid:19) Xj,l∈[p],j6=l

where Z ∼ N (0, Ip), a standard normal vector in Rp.

The remainder of this work is organized as follows. In Section 2.1 we state our results for
positively associated random ﬁelds whose covariance decays exponentially, and apply them
to the Ising and percolation models in Section 2.2. In Section 2.3 we state our result for the
voter model separately, as its convariance does not decay exponentially. In Section 3 we use
Stein’s method to prove the two main general results stated above, Theorems 1.3 and 1.4.
One advantage of these latter two theorems is that, unlike many results based on Stein’s
method, they may be applied without the need for coupling constructions.

2 Applications

We begin this section with a general result for a certain class of positively associated random
ﬁelds.

2.1 Second order stationary positively associated ﬁelds with ex-

ponential covariance decay

Let {Xj : j ∈ Zd} be a positively associated random ﬁeld on the d-dimensional integer lattice
Zd. Assume that the ﬁeld is second order stationary, that is, for all j, k ∈ Zd the covariance
Cov(Xj, Xk) exists and equals R(j − k) for some function R. With Sn
k deﬁned in (10),
consider the standardized variables
Sn
k − ESn
√ndAn

, k ∈ Zd, n ∈ N1,

k =

W n

(18)

k

8

that have mean zero and variance 1. The following theorem provides a bound of order
n−d/(2d+2) with an explicit constant on the L1 distance between the distribution of W n
k and
the normal under the condition that the covariance function R(·) decays exponentially in
the L1 norm in Rd. We have chosen to bound the covariance decay in the L1 norm for
convenience in the proof of Lemma 2.4; as all norms in Rd are equivalent, when inequality
(19) holds for any norm with some λ > 0 then it holds for any other norm with λ replaced
by some positive constant multiple.

Theorem 2.1 Let d ∈ N1 and {Xj : j ∈ Zd} be a positively associated second order sta-
tionary random ﬁeld with covariance function R(k) = Cov(Xj, Xj+k) for all j, k ∈ Zd, and
suppose that for some K > 0 it holds that |Xj| ≤ K a.s. for all j ∈ Zd. Assume that there
exist λ > 0 and κ0 > 0 such that

R(k) ≤ κ0e−λ|k|1

for all k ∈ Zd

(19)

and let

µλ =

and

eλ

(eλ − 1)2 (1 − e−λ)

, νλ =

1

(1 − e−λ)2

and γλ,d = (4µλ + 2νλ)d − (2νλ)d

(20)

Cλ,κ0,d =

5Kd√πAn
√2κ0γλ,d

.

Then, for any k ∈ Zd, with W n

k as given in (18) and Z a standard normal random variable,

where, with An is as in (11),

d1(cid:0)L(W n

κ1

nd/(2d+2)

k ),L(Z)(cid:1) ≤
κ1 =  10Kκd

0γd

λ,d2d+1/2

πd/2Ad+1/2

n

λ,κ0,d, C −2/(d+2)

λ,κ0,d o ,

for all n ≥ maxnC 2/d
!1/(d+1)(cid:18) 1

+ 2d

d+1

d

d

1

d+1(cid:19) .

In the following we will make use of the identities

n−1Xk=1
n−1Xa=1

n +

(n − k)wk =

w ((n − 1) − nw + wn)

(w − 1)2

for w 6= 1,

(n − a)(va + v−a) =

v1−n (vn − 1)2

(v − 1)2

for

v 6= 1,

and

n + 2

n−1Xb=1

(n − b)ub =

(1 − u2)n − 2u + 2un+1

(u − 1)2

for u 6= 1.

9

(21)

(22)

(23)

(24)

We have already taken A in (12), without loss of generality, to be positive, and the
exponential decay condition (19) implies that it is also ﬁnite. Lemma 4 of [New80] can now
be invoked to yield that limn→∞ An = A. Hence the values An are bounded away from zero
and inﬁnity as a function of n, and replacing An by its limiting value A in (21) only aﬀects
the bound by a constant and does not alter the rate of convergence.

In certain instances the values of An and A will be close even for moderate the values n,
for instance if equality holds in (19), then using (24) with u = e−λ, which is not equal to one
since λ > 0, as n → ∞ we obtain

j1,...,jd=1

κ0
nd

e−λ|ik−ik| =

dYk=1

nXi1,...,id=1
(n − |ak|)e−λ|ak| =
!d

n + 2e−λ(n+1)

e−λ|ik−ik|

dYk=1
nXik,jk=1
(n − b)e−λb!d
nd n + 2
n−1Xb=1
−→ κ0(cid:18) 1 + e−λ
1 − e−λ(cid:19)d

κ0

= κ0 cothd(λ/2) := A.

An =

κ0

nd Xi,j∈Bn

1

e−λ|i−j|1 =

κ0
nd

=

κ0
nd

dYk=1

n−1Xak=−n+1
= κ0  1 − e−2λ − 2e−λ
(1 − e−λ)2

n

One can apply Theorem 1.2 above, due to [Bul95], to obtain a bound of order logd n/√n,
without an explicit constant, on the Kolmogorov distance between W n
k and the normal by
showing that u(n) as deﬁned in (14) converges to zero at an exponential rate. Here we use
Theorem 1.3 to obtain an L1 result.

We note that the technique in [Bul95], ﬁrst introduced in [Tik80], presents some challenges
when applied to obtain an L1 bound. We consider the argument in the one dimensional case,
as in [Bir88], to illustrate the diﬃculty. Letting fn be the characteristic function of W n
1 and
following the proof in [Bir88], one obtains the bound

(cid:12)(cid:12)(cid:12)fn(t) − e−t2/2(cid:12)(cid:12)(cid:12) ≤ C(cid:16)n−1/2 log(n)t3e−t2/4 + n−1 log3/2(n)t + n−3/2t(cid:17)

over the region 0 ≤ t ≤ γn1/2/ log(n), where γ is a constant deﬁned in [Bir88], and where
here and in the following, C denotes a constant whose value may change from line to line.
Applying Theorem 1.5.2 in [IL71] with T = n1/2/ log(n), the Kolmogorov distance of order
log(n)/n1/2 was obtained in [Bir88]. To get the bound in L1, one may apply Theorem 1.5.4
in [IL71] instead, however the integrand of the term (3) in Theorem 1.5.4

−T  d
Z T

dt

fn(t) − e−t2/2

t

!2

dt

includes (cid:16)fn(t) − e−t2/2(cid:17)2

t4

,

which is not integrable.

We also extend Theorem 2.1 to the multidimensional case. For any p ∈ N1 and indices
k1, . . . , kp in Zd satisfying a separation condition to ensure non-degeneracy of the limiting
distibution, Theorem 2.2 provides a bound in the metric dH3,∞,p to the multivariate normal
for Sn = (Sn
kp) under exponential decay of the covariance function and a condi-
tion limiting the amount of variables common to the coordinates making up the sums Sn.
Regarding multidimensional convergence, under strictly stationary Theorem 1.1 of [New80]

k1, . . . , Sn

10

nk1, . . . , W n

nkp) converges to a standard normal random vector in Rp, but does
shows that (W n
not provide a bound. In the following result and its proof, constants will not be tracked with
precision, but will be indexed by the set of variables on which it depends.

Theorem 2.2 For d ∈ N1, let {Xj : j ∈ Zd} be a positively associated second order sta-
tionary random ﬁeld with covariance function R(k) = Cov(Xj, Xj+k) for all j, k ∈ Zd, and
suppose that there exists constants K > 0, κ0 > 0 and λ > 0 such that |Xj| ≤ K a.s. for all
j ∈ Zd and

R(k) ≤ κ0e−λ|k|1
For p ∈ N1 let k1, . . . , kp ∈ Zd be such that

for all k ∈ Zd.

min

q,s∈[p],q6=s|kq − ks|∞ ≥ (1 − α)n,

(25)

for some 0 < α < 1 with αn an integer. Let Sn = (Sn
(10) and assume that the covariance matrix Σ of Sn is invertible, and let

k1, . . . , Sn

kp), where Sn

k is deﬁned as in

Then, there exists a constant Cλ,κ0,d,p,K such that with Z a standard normal random vector
in Rp,

ψn = nd/2|Σ−1/2|∞.

dH3,∞,p(cid:0)L(Σ−1/2(Sn − ESn)),L(Z)(cid:1)
≤ Cλ,κ0,d,p,K(cid:18)(An + α)
for all n ≥ maxnB2/d

1

d+1 ψ

2d+3
d+1

n (cid:18) 1

d

d

d+1

n,d,α, B−2/(d+2)

n,d,α

+ 2d

2(d+1) + αψ2

1

d+1(cid:19) n− d

n(cid:19)

o where Bn,d,α = dψn(An + α).

(26)

For checking the hypothesis that the covariance matrix of Sn is invertible, and that the
quantity ψn is of order one, and so does not aﬀect the rate in (26) and also so that Bn,d,α is
order one, we present the following condition, proved at the end of this section. We note in
addition that if α = O(n− d

2(d+1) ) then the bound in (26) will be of this same order.

Lemma 2.3 Let {Xj : j ∈ Zd} be a second order stationary random ﬁeld with covariance
function R(k) = Cov(Xj, Xj+k) for all j, k ∈ Zd where R(·) satisﬁes (19). With n ∈ N2,
the covariance matrix Σ of the random vector Sn ∈ Rp, p ≥ 2 as given in Theorem 2.2 is
invertible if for some positive integer b

|kq − ks|∞ ≥ n − b

for all q 6= s, q, s ∈ [p], and b <

nAn

(p − 1)κ0νd

λ

,

(27)

with λ and κ0 as in (19), and νλ as in (20). If b = αn for some

0 < α < min(cid:26)1,

then the matrix Σ is invertible and

An

(p − 1)κ0νd

λ(cid:27)

|Σ−1|∞ ≤

1

nd(An − (p − 1)κ0νd

λα)

11

.

(28)

The proofs of Theorems 2.1 and 2.2 proceed by decomposing the sum Sn

k over the block
Bn
k into sums over smaller, disjoint blocks whose side lengths are at most some integer l.
In particular, given 1 ≤ l ≤ n uniquely write n = (m − 1)l + r for m ≥ 1 and 1 ≤ r ≤ l.
We correspondingly decompose Bn
i,k, i ∈ [m]d, where there are
(m − 1)d ‘main’ blocks having all sides of length l, and md − (m − 1)d remainder blocks
having all sides of length r or l, with at least one side of length r.
i + k − 1 where

In detail, for k ∈ Zd and i ∈ [m]d set Dl
i = {j ∈ Zd : (is − 1)l + 1 ≤ js ≤ isl, is 6= m, (m − 1)l + 1 ≤ js ≤ (m − 1)l + r, is = m}.
Dl
It is straightforward to verify that for i ∈ [m]d with no components equal to m, these vectors
indexing the ‘main blocks’, we have

k into md disjoint blocks Dl

i,k = Dl

and if r = l then Dl
elements of the collection {Dl

Letting

Dl

i = Bl

1 + (i − 1)l

(29)
i is given by (29) for all i ∈ [m]d. Further, it is easy to see that the

i ∈ [m − 1]d,

for

i,k, i ∈ [m]d} are disjoint, and union to Bn
k .

ξl

i,k = Xt∈Dl

i,k

(Xt − EXt)

and W n

k = Xi∈[m]d

ξl
i,k√ndAn

for

i ∈ [m]d,

(30)

i,k.

i,k has mean zero, and W n

we see that ξn
k as in (30) agrees with its representation as given in
(18), and has mean zero and variance one. For simplicity we will drop the index k in ξi,k
when k = 1, as we do also for Di,k, and also suppress n in ξn

By [EPW67], when X = (X1, . . . , Xp) is positively associated and if hk : Rp → R, k ∈ [q]
are coordinate-wise nondecreasing functions, then h1(X), . . . , hq(X) are positively associated.
Hence, as the elements of {ξi,k : i ∈ [m]d} are increasing functions of {Xj : j ∈ Zd} they are
positively associated.
We prove Theorems 2.1 and 2.2 with the help of two lemmas that follow. The ﬁrst,
Lemma 2.4 bounds the sum of the covariances between ξl
j,k, deﬁned in (30), over
i, j ∈ [m]d. Next, Lemma 2.6 bounds the covariance between two block sums of size nd whose
centers are at least n − b apart in the L∞ distance for some integer 1 ≤ b ≤ n.
Lemma 2.4 Let {Xj : j ∈ Zd} be a second order, positively associated stationary random
ﬁeld with covariance function R(k) = Cov(Xj, Xj+k) for all j, k ∈ Zd where R(·) satisﬁes the
exponential decay condition (19). For n ≥ 2 and 1 ≤ l ≤ n, let n = (m − 1)l + r for integers
m ∈ N1 and 1 ≤ r ≤ l. Then for i ∈ [m] and k ∈ Zd, with ξi,k given by (30) we have

i,k and ξl

Xi,j∈[m]d,i6=j

E(cid:2)ξl

i,kξl

j,k(cid:3) ≤

κ0γλ,dnd

,

l

where κ0 is given in (19), and γλ,d in (20).

i ⊂ Bl

Proof: By second order stationarity, it suﬃces to consider the case k = 1. For convenience
write σi,j = E [ξiξj]. Since Dl
t, s ∈ Zd by positive association, with Sl

1 + (i − 1)l for all i ∈ [m]d and Cov(cid:0)Xt, Xs(cid:1) ≥ 0 for all
Xs ≤ Cov(cid:0)Sl

σi,j = CovXt∈Dl

i as given in (10), we have

1+(j−1)l(cid:1)

Xt,Xs∈Dl

j

i 6= j ∈ [m]d.

1+(i−1)l, Sl

for all

(31)

i

12

Note that when i 6= j in [m]d the pair (i, j) must lie in exactly one of the sets Em
given by

s

Hence, using (31),

Em

s =(cid:8)(i, j) ∈ [m]d × [m]d : |{k ∈ [d] : ik 6= jk}| = s(cid:9) for s ∈ [d].
Xi,j∈[m]d,i6=j
1+(j−1)l(cid:1).

dXs=1 X(i,j)∈Em

dXs=1 X(i,j)∈Em

Cov(cid:0)Sl

1+(i−1)l, Sl

σi,j ≤

σi,j =

s

s

for s ∈ [d],

(32)

Recalling the deﬁnition of the block sums in (10) and using second order stationarity, for

(i, j) ∈ Em

s we have

Cov(cid:0)Sl

1+(i−1)l, Sl

1+(j−1)l(cid:1) =

=





(p1 + (j1 − 1)l) − (q1 + (i1 − 1)l)

(pd + (jd − 1)l) − (qd + (id − 1)l)
p1 − q1 + (j1 − i1)l

...

q1,...,qd=1


R
lXp1,...,pd=1



R
lXp1,...,pd=1
(l − |a1|)· · · (l − |ad|) exp−λ(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)


pd − qd + (jd − id)l

q1,...,qd=1

...

a1 + (j1 − i1)l

...

ad + (jd − id)l

 ,

(33)

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)1


≤ κ0

l−1Xa1,...,ad=−l+1

where we have applied (19) in the ﬁnal inequality.

We now apply some invariance properties of the norm |x|1 in order to simplify the sum of
expression (33) when taken over pairs of indices in Em
s . We say that the pairs of indices (i, j)
and (i′, j′) in Em
s are equivalent if (i, j) can be made to agree with (i′, j′) by interchanging ik
and jk for any values of k ∈ [d] and then applying the same permutation to the resulting set
of vectors. Note that as ak and −ak appear symmetrically in the sum (33), and that | · |1 is
invariant under sign changes and permutations of coordinates, equivalent vectors yield the
same value of this sum.

Call an index pair (i, j) ∈ Em

s canonical if ik < jk for all k = 1, . . . , s. Note that as
pairs in Em
s have exactly s inequalities among their coordinates that canonical indices must
agree in their remaining, and last, d − s coordinates. Now associate to every pair (i, j) ∈
Em
s the equivalent, unique canonical vector that is obtained from (i, j) by interchanging all
coordinates k ∈ [d] for which ik > jk, and then applying the permutation that maps the s
unequal coordinates of the pair to positions 1, 2, . . . , s, thus mapping the equal pairs to the
last d − s positions, leaving the relative order of each group unchanged. Partitioning the
sum over Em
into smaller sums over all vectors that are equivalent to the same canonical
s
vector yields a sum over all canonical vectors, with a factor of 2s to account for the number

arrangements of inequalities over the unequal pairs, and a factor of (cid:0)d

positions in which the unequal coordinates may occur. Hence, summing (33) over Em
using identities of the form

s(cid:1) to account for the

s , and

Xa1∈A1,...,ad∈Ad

dYq=1

fq(aq) =

dYq=1 Xaq∈Aq

fq(aq)

13

that hold for any index sets I1, . . . , Id and any functions fq in order to interchange summa-
tions and products notating the index set to be consistent with the formula used above

I s,m
d = {(i, j) ∈ Zd × Zd : 1 ≤ ik < jk ≤ m, k = 1, . . . , s, 1 ≤ ik = jk ≤ m, k = s + 1, . . . , d},
we obtain

1+(i−1)l, Sl

s

d

X(i,j)∈Em
Cov(cid:0)Sl
s(cid:19)2s X(i,j)∈I s,m
≤ κ0(cid:18)d
s(cid:19)2s X(i,j)∈I s,m
= κ0(cid:18)d
s(cid:19)2s X(i,j)∈I s,m
= κ0(cid:18)d
s(cid:19)2s X(i,j)∈I s,m
= κ0(cid:18)d

d

d

d

1+(j−1)l(cid:1)
(l − |a1|)· · · (l − |ad|) exp−λ(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

l−1Xa1,...,ad=−l+1
l−1Xa1,...,ad=−l+1
dYq=1
dYq=1
l−1Xaq=−l+1

sYq=1
l−1Xaq=−l+1

(l − |aq|)e−λ(jq−iq)l−λaq
dYq=s+1

(l − |aq|)e−λ|(jq−iq)l+aq|

(l − |aq|)e−λ|(jq−iq)l+aq|

a1 + (j1 − i1)l

...

ad + (jd − id)l



(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)1


l−1Xaq=−l+1

(l − |aq|)e−λ|aq| ,

where in the ﬁnal equality we have expressed the product in q as two separate products,
and have noted in the ﬁrst of these, as jk − ik ≥ 1 and ak ranges from −l + 1 to l − 1, the
terms (jk − ik)l + ak appearing in the absolute value of the exponent are always positive.
Now expanding the ﬁrst multiple summation as an inner summation on the ﬁrst s indices
and outer sum over the ﬁnal d − s indices, separating out the exponential terms in the ﬁrst
product and noting that the remaining product terms are purely mulitplicative factors, we
obtain

14

s(cid:19)2s X1≤ik=jk≤m
κ0(cid:18)d

e−λ(jq−iq)l

k=1,...,s

s(cid:19)2s  mXi=1

sYq=1
k=s+1,...,d X1≤ik<jk≤m
×
sYq=1
l−1Xaq=−l+1
1!d−s
sYq=1 X1≤iq<jq≤m
×
sYq=1
l−1Xaq=−l+1
(m − k)e−λkl!s
s(cid:19)2smd−s m−1Xk=1
× l +
l−1Xa=1

(l − |aq|)e−λaq
dYq=s+1
e−λ(jq−iq)l
(l − |aq|)e−λaq
dYq=s+1
(l − a)(cid:0)eλa + e−λa(cid:1)!s l + 2

= κ0(cid:18)d

= κ0(cid:18)d

l−1Xaq=−l+1

l−1Xaq=−l+1

(l − |aq|)e−λ|aq|
(l − |aq|)e−λ|aq|
(l − b)e−λb!d−s

.

l−1Xb=1

By applying identity (22) with n = m and w = e−λl and identities (23) and (24) with
n = l, v = eλ and u = e−λ, noting that u, v and w are not zero as λ > 0, the term above
equals

s(cid:19)2smd−s  eλe−2λl(cid:0)eλl − 1(cid:1)2(cid:0)m − 1 − me−λl + e−λlm(cid:1)
κ0(cid:18)d

(eλ − 1)2(1 − e−λl)2

!s
× (cid:0)1 − e−2λ(cid:1) l − 2e−λ + 2e−λ(1+l)

(1 − e−λ)2

eλ

(eλ − 1)2 (1 − e−λ)(cid:19)s(cid:18)

≤ κ0(cid:18)d
= κ0md(cid:18)d

s(cid:19)2smd(cid:18)
s(cid:19)(2µλ)s (lνλ)d−s

l

(1 − e−λ)2(cid:19)d−s

!d−s

(34)

where µλ and νλ are given in (20). By (32) and (34), we have

Xi,j∈[m]d,i6=j

σi,j ≤ κ0md

κ0nd

dXs=1(cid:18)d
dXs=1(cid:18)d

s(cid:19)(2µλ)s (lνλ)d−s
s(cid:19)(4µλ)s (2νλ)d−s
κ0nd(cid:16)(4µλ + 2νλ)d − (2νλ)d(cid:17)

l

l

≤

=

15

where we have used the bounds m ≤ 2n/l and 1/ls ≤ 1/l for all s ∈ [d] in the second
inequality.

(cid:3)

Lemma 2.5 For all n ∈ N2 and λ > 0,

n−1Xa=−n+1

(n − |a|)e−λ|q+a|

is decreasing as a function of |q| ∈ N0.

Proof: We note that the sequence f (a) = (n − |a|)1(|a| ≤ n) is unimodal, and g(a) = e−λ|a|
is log-concave, and hence their convolution

h(q) =

∞Xa=−∞

f (a)g(q − a) =

n−1Xa=−n+1

(n − |a|)e−λ|q−a| =

n−1Xa=−n+1

(n − |a|)e−λ|q+a|

is unimodal, see [Bre89]. Since g(a) is symmetric unimodal, one can also use the fact from
[Sta89] that the convolution of two symmetric unimodal sequences is symmetric unimodal
to prove the result.
(cid:3)

Below we index the coordinates of vectors kj ∈ Zd as(cid:0)kj

1, . . . , kj

d(cid:1).

Lemma 2.6 Let {Xj : j ∈ Zd} be a second order stationary random ﬁeld with covariance
function R(k) = Cov(Xj, Xj+k) for all j, k ∈ Zd where R(·) satisﬁes (19). Let n ∈ N2 and
let b be an integer such that 1 ≤ b ≤ n. Then if k1 and k2 are vectors in Zd such that

then with λ and κ0 as in (19), and νλ as in (20),

|k1 − k2|∞ ≥ n − b,

Proof: Arguing as in the proof of Lemma 2.4 we have

k1, Sn

Cov(cid:0)Sn

k2(cid:1) =

k1, Sn

k2(cid:1) ≤ κ0νd

λbnd−1.

(p1 + k2

1) − (q1 + k1
1)

...

q1,...,qd=0

Cov(cid:0)Sn

R
n−1Xp1,...,pd=0
n−1Xa1,...,ad=−n+1
n−1Xai=−n+1
dYi=1

≤ κ0

= κ0




(pd + k2

d) − (qd + k1
d)

(n − |a1|) . . . (n − |ad|) exp−λ(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)


i )+ai|.

i −k1

a1 + (k2
1 − k1
1)
...
ad + (k2
d − k1
d)



(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)1



(35)

(n − |ai|)e−λ|(k2

Lemma 2.5 yields that

n−1Xai=−n+1

(n − |ai|)e−λ|(k2

i −k1

i )+ai|

is a decreasing function of |k1

i − k2
i |.

(36)

16

i = k2
In particular the ith sum appearing in the product (35) is bounded by its value when k1
i .
As |k1 − k2|∞ ≥ n− b, there must exist at least one i for which |k2
i | ≥ n− b, and whose
corresponding sum is maximized by its value when equality to n− b is achieved, again using
(36). The product of these sums, by (36) again, is maximized when there is just a single
coordinate achieving n − b as its absolute diﬀerence, and where this diﬀerence in all other
terms achieve equality to zero. Hence, by symmetry the term above is bounded by the case
where k1

i − k1

i for i ∈ [d − 1] and k2

d − k1

d = n − b and thus

i = k2

k1, Sn

Cov(cid:0)Sn

k2(cid:1) ≤ κ0

d−1Yi=1

n−1Xai=−n+1
≤ κ0 (nνλ)d−1

n−1Xad=−n+1

(n − |ad|)e−λ|ad+n−b|

(n − |ai|)e−λ|ai|
n−1Xad=−n+1

(n − |ad|)e−λ|ad+n−b|,

(37)

where we have applied (24) in the ﬁnal inequality and νλ is given in (20).

Now considering the sum in (37) for 2 ≤ b ≤ n, we obtain

n−1Xa=−n+1

(n − |a|)e−λ|a+n−b| =

=

−n+b−1Xa=−n+1
n−1Xa=n−b+1

(n − |a|)eλ(a+n−b) +

(n − |a|)e−λ(a+n−b)

(n − a)eλ(−a+n−b) +

(n − a)e−λ(−a+n−b)

n−1Xa=−n+b
n−bXa=1

+

n−1Xa=0

(n − a)e−λ(a+n−b).

For the ﬁrst sum, making a change of variable and applying (22), we obtain

n−1Xa=n−b+1

(n − a)eλ(−a+n−b) = e−λb
= e−λb(cid:18)b

aeλa = e−λb b
b−1Xa=1
eλb − eλ
eλ − 1 −

eλ((b − 1) − beλ + eλb)

(eλ − 1)2

b−1Xa=1

eλa −

(b − a)eλa!
b−1Xa=1
(cid:19)
b(cid:0)eλ − 1(cid:1) + eλ(1−b) − eλ

(eλ − 1)2

=

,

and similarly we may obtain

(n − a)e−λ(−a+n−b) =

beλ(cid:0)eλ − 1(cid:1) + eλ + n(cid:0)1 − eλ(cid:1) eλ(1+b−n) − eλ(1+b−n)

(eλ − 1)2

n−bXa=1

and

n−1Xa=0

(n − a)e−λ(a+n−b) =

eλ(1+b−2n) − eλ(1+b−n) + n(eλ − 1)eλ(1+b−n)

(eλ − 1)2

.

17

Summing these three terms yields

n−1Xa=−n+1

(n−|a|)e−λ|a+n−b| =

b(e2λ − 1) + e(1−b)λ − e−λ(n−b−1)(2 − e−λn)

(eλ − 1)2

≤

be2λ

(eλ − 1)2 = bνλ,

where we lastly note that the equality holds also for b = 1.

(cid:3)

Now we use Theorem 1.3 and Lemma 2.4 to prove Theorem 2.1. In the following, for
positive numbers a and b we will seek to minimize a quantity of the form ald + b/l over
non-negative integers l. Over real values, it is easy to verify that the minimum is achieved
at l0 = (b/ad)1/(d+1). Taking l = ⌊l0⌋ when l0 ≥ 1 and using that l0/2 ≤ l ≤ l0 yields

l∈N1(cid:18)ald +

min

b

l(cid:19) ≤ a(cid:18) b

ad(cid:19) d

d+1

b (cid:19) 1
+ 2b(cid:18)ad

d+1

= a

1

d+1 b

d

d+1(cid:18) 1

d

d

d+1

+ 2d

1

d+1(cid:19) .

(38)

1 the block of size nd as given in (10), and W n

Proof of Theorem 2.1: By second order stationarity, it suﬃces to prove the case k = 1.
Let n ≥ 2, Bn
1 the standardized sum over that
block, as in (18). For any 1 ≤ l ≤ n write n = (m − 1)l + r, 1 ≤ r ≤ l, and decompose W n
as the sum of ξi/√ndAn over i ∈ [m], as in (30).
We apply Theorem 1.3, handling the two terms on the right hand side of (15). For the
ﬁrst term, using |Xj| ≤ K, the deﬁnition (30) of ξi, and the fact that the side lengths of all
blocks Dl

i are at most l, we have

1

Applying Lemma 2.4 for the second term, invoking Theorem 1.3 now yields

(cid:12)(cid:12)(cid:12)(cid:12)

ξi√ndAn(cid:12)(cid:12)(cid:12)(cid:12) ≤ B with B =
d1(cid:0)L(W1),L(Z)(cid:1) ≤

2Kld
√ndAn

for all

i ∈ [m]d.

10Kld
√ndAn

2√2κ0γλ,d
√πlAn

.

+

λ,κ0,d

Recalling that An > 0 for all n ∈ N1, applying the bound (38) yields the result, noting that
l0 = C −1/(d+1)

nd/(2d+2) satisﬁes 1 ≤ l0 ≤ n for n ≥ maxnC 2/d

λ,κ0,d o.

λ,κ0,d, C −2/(d+2)

To prove Theorem 2.2 we apply Theorem 1.4 and use the same techniques as for Theorem
2.1. We remind the reader that for this result we do not explicitly compute the constants,
but index them by the parameters on which they depend.

(cid:3)

Proof of Theorem 2.2: We proceed as in the one dimensional case. For n ≥ 2, and
kq − ESn
1 ≤ l ≤ n we write n = (m − 1)l + r with m ≥ 1 and 1 ≤ r ≤ l, and decompose Sn
for q ∈ [p] as the sum over i ∈ [m]d of the variables ξi,kq given in (30).
Applying Theorem 1.4, we handle the three terms on the right hand side of (17). For the
ﬁrst term, using the deﬁnition (30) of ξi,kq and |Xt| ≤ K, we have

kq

(cid:12)(cid:12)ξi,kq(cid:12)(cid:12) ≤ B where B = 2Kld for all

18

i ∈ [m]d, q ∈ [p]

and thus noting that |Σ−1/2|∞ = n−d/2ψn and that Σjj = ndAn, we may bound the ﬁrst term
as

(cid:18)1

6

+ 2√2(cid:19) p3Bn−3d/2ψ3

n

pXq=1

Σq,q ≤

Cp,KldAnψ3
n

nd/2

.

(39)

For the second term, by Lemma (2.4) we have

(cid:18) 3
√2

+

1

2(cid:19) p2n−dψ2

n

pXq=1 Xi,j∈[m]d,i6=j

E(cid:0)ξi,kqξj,kq(cid:1)

= Cpψ2
n

pXq=1 Xi,j∈[m]d,i6=j

E(cid:18)ξi,kqξj,kq

nd (cid:19) ≤

Cλ,κ0,p,dψ2
n

l

.

(40)

Invoking Lemma 2.6 and assumption (25) we have

and hence we may bound the last term as

(cid:18)2√2p3Bn−3d/2ψ3

λαnd for q 6= s ∈ [p],

Σq,s = Cov(cid:0)Sn
n +(cid:18) 3
√2

+

kq , Sn

ks(cid:1) ≤ κ0νd
2(cid:19) p2n−dψ2
≤(cid:18) Cp,Kldψ3

n3d/2 +

1

n

Σq,s

n(cid:19) Xq,s∈[p],q6=s
nd (cid:19) κ0νd

Cpψ2
n

By Theorem 1.4 and (39), (40) and (41),

≤

λαnd

Cλ,κ0d,p,Kαldψ3
n

nd/2

+ Cλ,κ0,d,pαψ2
n.

(41)

dH3,∞,p(cid:0)L(Σ−1/2W),L(Z)(cid:1) ≤ (Cp,KAn + Cλ,κ0,d,p,Kα)
≤ Cλ,κ0,d,p,K(cid:18)(An + α)

ψ3
nld
nd/2 +
ψ3
nld
ψ2
n
nd/2 +
l

Cλ,κ0,d,pψ2
n

+ αψ2

l

n(cid:19) .

+ Cλ,κ0,d,pαψ2
n

Applying (38) to the ﬁrst two terms in parenthesis, we obtain

l0 =(cid:18)

1

dψn(An + α)(cid:19) 1

d+1

d

2d+2 ,

n

which satisﬁes 1 ≤ l0 ≤ n for the range of n given in (26), and applying (38) yields the
result.

(cid:3)

We now prove the suﬃcient condition given above for the invertibility of the covariance
matrix of Sn, and the bound on the norm of its inverse. Recall that a matrix A ∈ Rp×p is

said to be strictly diagonally dominant if |aii| −Pj6=i |aij| > 0 for all i ∈ [p].

19

Proof of Lemma 2.3: By Lemma 2.6 and the upper bound on b given in (27), for all q ∈ [p]
we have

Σq,q − X1≤s≤p,s6=q

|Σq,s| ≥ nd−1(nAn − (p − 1)κ0νd

λb) > 0.

Hence, Σ is a strictly diagonally dominant matrix, and is therefore invertible by the Ger-
shgorin circle theorem, see for instance Theorem 15.10 of [BR14]. The ﬁnal claim of the
lemma follows from [AN63], where it is shown that the bound (28) holds for the norm
(cid:3)

j=1 |cij|, which dominates |C|∞.

||C||∞ = maxiPp

2.2 The Ising model and the percolation model

In this section we apply Theorems 2.1 and 2.2 over ﬁnite blocks to the net magenetization of
the Ising model and the number of points in the supercritical bond percolation model that
belong to an inﬁnite cluster.

Corollary 2.7 The bounds of Theorems 2.1 and 2.2 apply to the total magnetization Mk,
deﬁned in (4), of the Ising model having inﬁnite volume Gibbs measure in M as given in
(3), and the total number of points Uk, deﬁned in (5), that belong to an inﬁnite cluster in
the supercritical bond percolation model in dimensions d ≥ 2.
Proof: We show that the ﬁelds in two models in question posses the properties required for
Theorems 2.1 and 2.2 to be applied, in particular each must comprise positively associated
and almost surely uniformly bounded variables, must be second order stationary, and must
have an exponentially decreasing covariance function. Clearly the uniformly bounded condi-
tion holds for both, implying the existence of second moments, so second order stationarity
holds under strictly stationary.

The Ising model {ωi : i ∈ Zd}, referring to [New80], is positively associated whenever the
interaction J that appears in the Hamiltonian in (2) is nonnegative. By [ELL06], any Ising
model corresponding to an inﬁnite volume Gibbs measure in M, as given in (3), is strictly
stationary. By [LP68], [ABF87] and [AD15], it is only at the critical point (β, h) = (βc, 0)
that the covariance of the model fails to decay at an exponential rate.

For the supercritical bond percolation model in dimension 2 or higher, again by [New80],
the binary ﬁeld {1{|C(x)|=∞} : x ∈ Zd} is positively associated. Strictly stationarity follows
from the fact that the vertex connection probability θ is the same for each bond e ∈ Ed, and
that the status of each bond is independent of all others. By [CCGKS89], the covariance
between 1{|C(x)|=∞} and 1{|C(y)|=∞} decays exponentially.
(cid:3)

2.3 The Voter Model
In this section, we consider the d-dimensional voter model {ηt : t ≥ 0} with initial state at
time zero given by independent Bernoulli variables with parameter θ ∈ (0, 1) on each site
in Zd, and the occupation time process {T t
s : t ≥ 0}, s ≥ 0, deﬁned in (6), that records the
amount of time in (s, s+t] that the origin spends in state one. The work [CG83] demonstrates
that the family {T t
0 : t ≥ 0} satisﬁes the CLT for d ≥ 2. Here we reﬁne the results for d ≥ 7
in Theorem 2.8 by applying Theorem 1.3 to obtain a rate of convergence in the L1 metric.

20

Though the authors are unaware of any results in the literature that yield distributional
bounds for the voter model, Stein’s method has been successful in obtaining bounds in the
anti-voter model, see [RR97]. The anti-voter model diﬀers from the voter model in that after
a uniformly neighbor of a vertex is chosen the state of that vertex changes to the opposite
state of that neighbor. The work of [RR97] used the exchangeable pair approach to Stein’s
method, and positive association was not an ingredient.

By [CG83], for d ≥ 5 we have
ET t

0 = θt

and limt→∞ At = κ2 for some κ2 > 0, where At =

Letting

At

s =

Var(cid:0)T t
s(cid:1)

t

,

Var(cid:0)T t
0(cid:1)

t

for t > 0.

(42)

(43)

we will show in Lemma 2.13 that for all s ≥ 0, limt→∞ At
ET t

s = θt and At
s > 0.
Standardizing T t

s to have mean zero and variance one we obtain

s = κ2, and for all t > 0 that

Now we deﬁne the last exit time of the origin in [0, u] and [0,∞) by

W t

s =

.

T t
s − θt
st

pAt

and

Lu = sup{s ≤ u : Ys = 0} for u ≥ 0.

L = sup{s < ∞ : Ys = 0},

(44)

(45)

(46)

respectively, where Ys is a rate 1 simple symmetric random walk in Zd starting at the origin
at time zero. By deﬁnition, it is clear that Lu is increasing in u and Lu ≤ L for all u ≥ 0.
The following theorem provides L1 bounds to the normal for the standardized occupation
time W t
s , given in (44). Lemma 2.12 shows that the second moment of Lu, appearing in the
bounds below, is ﬁnite.

Theorem 2.8 For W t

s as deﬁned in (44), for all d ≥ 7 and s ≥ 0,

d1(cid:0)L(W t

s ),L(Z)(cid:1) ≤  180√2θ(1 − θ)EL2

√π(At

s)3/2

2(s+t)

t−1/4

!1/2

with Z ∼ N (0, 1), At

s is as in (43) and Lu as in (45).

for all

t ≥ √2θ(1 − θ)EL2
5pπAt

s

2(s+t)

!2/3

,

We also extend Theorem 2.8 to the multidimensional case, obtaining a bound in Theorem
2.9 in the metric dH3,∞,p to the multivariate normal for St = (T t
sp). The results could
easily be extended to the case where the occupation times are measured over intervals of
varying length, as recorded in the vector (T t1

s1, . . . , T t

s1 , . . . , T tp
sp ).

21

Theorem 2.9 Let d ≥ 7 and t > 0. For p ∈ N1 let s1, . . . , sp ≥ 0 be such that

min

k,l∈[p],k6=l|sk − sl| ≥ (1 − α)t,

(47)

for some 0 < α < 1. Let St = (T t
covariance matrix Σ of St is invertible and let

s1, . . . , T t

sp) where T t

s is deﬁned as in (6), assume that the

Then, there exists a constant Cp,θ such that with Z a standard normal random vector in Rp,

ψt = t1/2|Σ−1/2|∞.

dH3,∞,p(cid:0)L(Σ−1/2(St−θt)),L(Z)(cid:1) ≤ Cp,θ  pXk=1

for all

At

1

sk + α +

t!1/2
t ≥ ψt  pXk=1

ψ5/2

t

t−1/4 + ψ2

At

sk + α +

1

t(cid:19)

(48)

t(cid:18)α +
t!!−2/3

.

1

s ) = tAt

From (43) we have Var(T t

s → κ2 as t → ∞.
For checking the hypothesis that the covariance matrix of St is invertible and the quantity
ψt is of order one, we present the following suﬃcient condition, proved at the end of this
section. In addition, we see from (48) that if α = O(t− 1
4 ) then the bound will be of this same
order.

s and we show in Lemma 2.13 that At

Lemma 2.10 With t > 0, Σ the covariance matrix of the random vector St ∈ Rp, p ≥ 2 as
given in Theorem 2.9 is invertible if for some positive integer b

|sk − sl| ≥ t − b

for all k 6= l, k, l ∈ [p], and b <

t mink∈[p] At

sk − (p − 1)θ(1 − θ)E[L2]

,(49)

2(p − 1)θ(1 − θ)E[L]

where At

s is given in (43) and L in (46). If b = αt for some

0 < α < min(cid:26)1,

mink∈[p] At

sk − (p − 1)θ(1 − θ)E[L2]/t
2(p − 1)θ(1 − θ)E[L]

(cid:27) ,

then the matrix Σ is invertible and

|Σ−1|∞ ≤

t(cid:0)mink∈[p] At

sk − (p − 1)θ(1 − θ) (E[L2]/t + 2αE[L])(cid:1).

1

To prove Theorems 2.8 and 2.9, we apply the following result implied by (0.8) and (0.9)
of [CG83], shown there using a duality that connects the voter model with a system of
coalescing random walks constructed by a time reversal, and tracing the {0, 1} ‘opinion’ of
every site back to its genesis at time zero.

Lemma 2.11 ([CG83]) For t ≥ 0 and 0 ≤ u ≤ v, with Lu as in (45),

Cov(ηu(0), ηv(0)) = θ(1 − θ)P (Lu+v > v − u) .

(50)

22

We now use Lemma 2.11 to prove the following result which will be used in several places

in this section.

Lemma 2.12 For all 0 ≤ r < s < t,

Z s
r Z t

s

Cov(ηu(0), ηv(0))dvdu ≤

θ(1 − θ)

2

E[L2

s+t],

where Lu is as in (45). Moreover, with L as in (46) we have E[L2
u > 0 and d ≥ 7.
Proof: Applying covariance identity (50) from Lemma 2.11 and using the fact that Lu is
increasing in u, we obtain

u] ≤ E[L2] < ∞ for all

Z s
r Z t

s

Cov(ηu(0), ηv(0))dvdu = θ(1 − θ)Z s
r Z t
≤ θ(1 − θ)Z s
r Z t
Z t−r

P(cid:0)Ls+t > v − u(cid:1)dvdu =Z s−r

s−r

0

s

s

Z s
r Z t

s

By a change of variables that preserves the diﬀerence v − u, we have

P(cid:0)Lu+v > v − u(cid:1)dvdu
P(cid:0)Ls+t > v − u(cid:1)dvdu.

P(cid:0)Ls+t > v − u(cid:1)dvdu
Z t

s−r

0

P(cid:0)Ls+t > v − u(cid:1)dvdu.

Hence,

Z s
r Z t

s

0

s−r

≤Z s−r
Cov(ηu(0), ηv(0))dvdu ≤ θ(1 − θ)Z s−r
Z t
= θ(1 − θ)Z s−r
Z t−u
≤ θ(1 − θ)Z s−r
Z t
= θ(1 − θ)Z s−r
Z t
≤ θ(1 − θ)Z t
0 Z t
= θ(1 − θ)Z t
0 Z v
Z t

θ(1 − θ)

=

2

u

u

0

0

0

0

0

s−r−u

s−r−u

θ(1 − θ)

2

≤

E[L2

s+t]

P(cid:0)Ls+t > v − u(cid:1)dvdu.

P (Ls+t > v)dvdu

P (Ls+t > v)dvdu

P (Ls+t > v)dvdu

P (Ls+t > v)dvdu

P (Ls+t > v)dudv

2vP (Ls+t > v)dv

where change of variables are applied in ﬁrst and second equality, Fubini’s theorem in the
third equality, and where in the ﬁnal inequality we apply the standard fact, easily shown

23

using Fubini’s theorem, that if φ(y) is a diﬀerentiable function on [0,∞) satisfying φ(0) = 0
then for Y ≥ 0,

φ′(y)P (Y > y)dy.

(51)

E[φ(Y )] =Z ∞

0

Since Lu ≤ L for all u ≥ 0, to prove the second claim, it suﬃces to show that E[L2] < ∞
for d ≥ 7. Returning to the integral expression for the second moment, and slightly modifying
the calculation for the ﬁrst moment in [CG83] following (0.11), we have

E[L2] =Z ∞

0

2tP (L > t)dt =Z ∞

0

2tZ ∞

t

P (Ys = 0)dsγddt,

(52)

where γd = P (Yt 6= 0 ∀t ≥ 1), known to be positive and increasing for d ≥ 3. Changing the
order of integration in (52) yields

E[L2] = γdZ ∞
0 Z s

0

2tP (Ys = 0)dtds = γdZ ∞

0

s2P (Ys = 0)ds,

implying that E[L2] < ∞ for d ≥ 7 as, see [CG83] for instance, P (Ys = 0) = O(s−d/2).

(cid:3)

The next result shows some important properties of the mean and the variance of T t
s .

Lemma 2.13 For d ≥ 7, t > 0 and s ≥ 0, with T t

s as in (6) and At

s as in (43),

ET t

s = θt, At

s > 0 and

lim
t→∞

At

s = κ2,

where κ2 is given in (42).

Proof: We verify the ﬁrst claim using the deﬁnition of T t

s and (42) to yield

ET t

s = E(cid:2)T t+s

0 − T s

0(cid:3) = (t + s)θ − sθ = tθ.

The second claim follows from (2.1) in [CG83] and the fact that P (Yu = 0) is strictly positive
for all u > 0.

For the ﬁnal claim, note that for s = 0, At

0 = At and the result reduces to (42). For

s > 0, we have

At

s =

Var(T t
s )

t

=

Var(T t+s
0 − T s
0 )
t

=

Var(T t+s

0

0 ) − 2Cov(T s
) + Var(T s
t

0 , T t+s

0

)

=

(t + s)At+s

t

+

sAs
t −

2Cov(T t+s

0
t

, T s
0 )

.

(53)

The ﬁrst term converges to κ2 and the second term tends to zero as t → ∞. Hence it suﬃces
to show that the last term also tends to zero.
Writing the covariance in integral form in two parts and applying Lemmas 2.11 and 2.12

to the ﬁrst and second terms, respectively, we obtain

Cov(T s

0 , T t+s

0

0

) = Z s
0 Z s
Cov(ηu(0), ηv(0))dvdu +Z s
≤ 2θ(1 − θ)Z s
0 Z s
≤ 2s2 + E[L2],

0

P (Lu+v > v − u)dvdu +

0 Z s+t

s

Cov(ηu(0), ηv(0))dvdu

θ(1 − θ)

2

E[L2

2s+t]

24

and thus the last term in (53) tends to zero as t → ∞ since E[L2] is ﬁnite for d ≥ 7 by
Lemma 2.12.

s,i and X t

(cid:3)
Now we use Lemma 2.12 to prove Lemma 2.14, which bounds the sum of the covariances
s,j deﬁned in (8) over i 6= j ∈ [m], followed by Lemma 2.15, which bounds

between X t
the covariance between occupation times starting at r, s satisfying |r − s| ≥ t − b.
Lemma 2.14 For t > 0, s ≥ 0 and m ∈ N1, with X t
s,i as in (8) and Lu as in (45),

Xi,j∈[m],i6=j

Cov(X t

s,i, X t

s,j) ≤ θ(1 − θ)(m − 1)E[L2

2(s+t)].

Proof: Using the deﬁnition of X t

s,i in (8), we have

Xi,j∈[m],i6=j

Cov(X t

s,i, X t

s,j) = 2

= 2

= 2

s,i, X t

s,j)

Cov(X t

mXj=i+1
m−1Xi=1
m−1Xi=1
mXj=i+1
Cov(cid:0)X t
m−1Xi=1Z s+it/m
s+(i−1)t/mZ s+t

s,i,

s+it/m

X t

s,j(cid:1)

Cov(ηu(0), ηv(0))dvdu.

Applying Lemma 2.12 to the integrals above, and using the monotonicity property of Lu in
u > 0, we have

Xi,j∈[m],i6=j

Cov(X t

s,i, X t

s,j) ≤

m−1Xi=1

θ(1 − θ)E[L2

2(s+t)] = θ(1 − θ)(m − 1)E[L2

2(s+t)].

Lemma 2.15 For t > 0, let 0 < b ≤ t and let r, s ≥ 0 satisfy |r − s| ≥ t − b. Then, with T t
as in (6) and L as in (46),

s

(cid:3)

Cov(T t

s , T t

r ) ≤ θ(1 − θ)(cid:0)E[L2] + 2bE[L](cid:1) .

(54)

Proof: It suﬃces to consider the case r ≥ s. Using the deﬁnition of T t
the integral that expresses the covariance we wish to bound into three parts, we have

s in (6) and breaking

Cov(T t

s , T t

r ) =Z s+t
=Z r
s Z r+t

s

r

r

Cov(ηu(0), ηv(0))dvdu

Z r+t
Cov(ηu(0), ηv(0))dvdu +Z s+t
Z r+t
+Z s+t
Z s+t

s+t

r

r

r

Cov(ηu(0), ηv(0))dvdu

Cov(ηu(0), ηv(0))dvdu.

(55)

25

Applying Lemma 2.12 to the ﬁrst two integrals, and using the fact that Lu ≤ L, accounts

for the ﬁrst term in (54). For the last integral, using (50) from Lemma 2.11, we obtain

Z s+t

r

Z s+t

r

r

Cov(ηu(0), ηv(0))dvdu = 2θ(1 − θ)Z s+t
≤ 2θ(1 − θ)Z s+t
= 2θ(1 − θ)Z s+t
≤ 2θ(1 − θ)Z s+t
= 2θ(1 − θ)Z s+t

r

r

r

r

u

u

Z s+t
Z s+t
Z s+t−u
Z ∞

0

0

E[L]du

= 2θ(1 − θ)(t − r + s)E[L]
≤ 2θ(1 − θ)bE[L],

P (Lu+v > v − u)dvdu

P (L > v − u)dvdu

P (L > v)dvdu

P (L > v)dvdu

thus accounting for the second term in (54), where a change of variables is applied in the
second equality, (51) in the third equality, and the assumption that r − s ≥ t− b in the ﬁnal
inequality.

(cid:3)

Now we use Theorem 1.3 and Lemmas 2.12 and 2.14 to prove Theorem 2.8.

Proof of Theorem 2.8: Let m be a positive integer and

X t
s,i − (t/m)θ

ξt
s,i =

st

pAt

for i ∈ [m], s ≥ 0

(56)

s,i is deﬁned as in (8). We apply Theorem 1.3 to W t

where X t
s,i, having mean
s,1, . . . , ξt
zero and variance one. By [EPW67], the components of the vector ξs
s,m) are
positively associated as they are increasing functions of the positively associated variables
{X t
using the deﬁnition of X t

s,i : i ∈ Z}.
We now handle the terms on the right hand side of the bound (15). For the ﬁrst term,

s,i in (8) we have

s = Pm

i=1 ξt
t = (ξt

0 ≤ X t

s,i =Z s+it/m

s+(i−1)t/m

ηu(0)du ≤Z s+it/m

s+(i−1)t/m

1ds =

t
m

,

and thus, by using the deﬁnition of ξt

s,i in (56),
2√t

|ξt
s,i| ≤ B where B =

Applying Lemma 2.14 for the second term, invoking Theorem 1.3 now yields

s

for all i ∈ [m].

mpAt
2√2θ(1 − θ)mE[L2

+

√πAt
st

2(s+t)]

,

d1(cid:0)L(W t

s ),L(Z)(cid:1) ≤

10√t

mpAt

s

26

where E[L2
now yields the result, noting that the lower bound on t in the theorem implies that

2(s+t)] < ∞ by Lemma 2.12. Applying (38) with d = 1 and with m in place of l

m0 = 

5pπAt
√2θ(1 − θ)EL2

st3/2

2(s+t)!1/2

is at least one.

(cid:3)

To prove Theorem 2.9 we apply Theorem 1.4 and use the same techniques as for Theorem
2.8. For this result we index constants by the parameters on which they depend, though we
do not explicitly compute them.

Proof of Theorem 2.9: For m ∈ N1 decompose T t
of the variables Y k

sk − θt for k ∈ [p] as the sum over i ∈ [m]
Applying Theorem 1.4, we handle the three terms on the right hand side of (17). In the
calculation below we use that E[L] and E[L2] are ﬁnite for d ≥ 7 by Lemma 2.12. For the
ﬁrst term, again using the deﬁnition of X t

sk,i − (t/m)θ where X t

sk,i is given in (8).

i = X t

sk,i, we have

2t
|Y k
i | ≤ B where B =
m
Since |Σ−1/2|∞ = t−1/2ψt, and Σk,k = tAt

for all i ∈ [m] and k ∈ [p].

sk we may bound the ﬁrst term as

(cid:18)1

6

+ 2√2(cid:19) p3Bt−3/2ψ3

t

pXk=1

Σk,k =

t √t
Cpψ3
m

At

sk .

pXk=1

(57)

For the second term, by Lemmas (2.14) and 2.12 we have

(cid:18) 3
√2

+

1

2(cid:19) p2t−1ψ2

t

pXk=1 Xi,j∈[m],i6=j

i Y k

E(cid:0)Y k

= Cpψ2
t

j(cid:1)
pXk=1 Xi,j∈[m],i6=j

Cov(cid:0)X t

sk,i, X t
t

sk,j(cid:1)

Cp,θψ2

t m

t

≤

.

(58)

Invoking Lemma 2.15 and assumption (47) we have

and hence we may bound the last term as

(cid:18)2√2p3Bt−3/2ψ3

Σk,l = Cov(T t

sk, T t

sl) ≤ θ(1 − θ)(cid:0)E[L2] + 2αtE[L](cid:1) for k 6= l ∈ [p],
2(cid:19) p2t−1ψ2

t(cid:19) Xk,l∈[p],k6=l
t (cid:19) θ(1 − θ)(cid:0)E[L2] + 2αtE[L](cid:1)

Cpψ2
t

mt3/2 +

Σk,l

Cp,θα√tψ3

Cp,θψ2
t

t

1

+

t +(cid:18) 3
√2
≤(cid:18)Cptψ3

t

Cp,θψ3
t
m√t

≤

+

27

+

t

m

+ Cp,θαψ2
t .

(59)

By Theorem 1.4 and (57), (58) and (59),

+

+

t m

Cp,θψ2

dH3,∞,p(cid:0)L(Σ−1/2(St − θt),L(Z)(cid:1) ≤ Cp√t
pXk=1
m0 = ψt  pXk=1

≤ Cp,θ  √t

t

pXk=1

Cp,θψ2
t

t

At

sk +

1
√t

At

sk + α +

2

1

t!! 1

3
4

t

Applying (38) to the ﬁrst two terms in parenthesis now yields the result, noting that

At

sk +

+ Cp,θα√t! ψ3

t
m

Cp,θ√t

+ Cp,θαψ2
t

+ α√t! ψ3

t
m

+

ψ2
t m
t

+ ψ2

t(cid:18)α +

1

t(cid:19)! .

is at least one for the range of t given in (48).

(cid:3)
Finally, we present the suﬃcient condition given above for the invertibility of the covari-

ance matrix of St.

Proof of Lemma 2.10: By Lemma 2.15 and the upper bound on b given in (49), for all k ∈ [p]
we have

Σk,k − Xl∈[p],l6=k

|Σk,l| ≥ tAt

sk − (p − 1)θ(1 − θ)(E[L2] + 2bE[L]) > 0.

Hence, Σ is a strictly diagonally dominant matrix, and the claims follow as in the proof of
Lemma 2.3.
(cid:3)

3 Proofs of main theorems

In this section we prove our main results, Theorems 1.3 and 1.4, stated in the Introduction.
For this purpose we ﬁrst recall that the pair of random variables (X, Y ) is said to be positive
quadrant dependent, or PQD, if for all x, y ∈ R we have

H(x, y) ≥ 0 where H(x, y) = P (X > x, Y > y) − P (X > x)P (Y > y).

It was shown in [Hoe40] (see also Lemma 2 of [Leh66]), that if (X, Y ) is PDQ and if both
X and Y have ﬁnite second moments then

Cov(cid:0)X, Y(cid:1) =ZRZR

H(x, y)dxdy.

are independent.

The following two lemmas are invoked in the proofs of the main theorems. Lemma

In particular, if (X, Y ) is PQD then Cov(cid:0)X, Y(cid:1) ≥ 0, and if Cov(cid:0)X, Y(cid:1) = 0 then X and Y
3.1 is Lemma 3 of [New80], and allows us to bound Cov(cid:0)φ(X), ψ(Y )(cid:1) by a constant times
Cov(cid:0)X, Y(cid:1) for a PQD pair (X, Y ) and φ and ψ suﬃciently smooth.

28

Lemma 3.1 [New80] Let the random variables X, Y have ﬁnite second moments and be
PQD. Then for any real valued functions φ and ψ that are absolutely continuous on all ﬁnite
subintervals of R,

(cid:12)(cid:12)Cov(cid:0)φ(X), ψ(Y )(cid:1)(cid:12)(cid:12) ≤ |φ′|∞|ψ′|∞Cov(cid:0)X, Y(cid:1).

The following result of [New80], contained in the remark explaining (12) there, provides

a version of (60) for vector valued functions.

(60)

Lemma 3.2 [New80] If ξ = (ξ1, . . . , ξn) are positively associated then for all real valued
diﬀerentiable functions φ and ψ on Rn,

(cid:12)(cid:12)Cov(cid:0)φ(ξ), ψ(ξ)(cid:1)(cid:12)(cid:12) ≤ 3√2

nXi,j=1(cid:12)(cid:12)(cid:12)(cid:12)

∂φ

∂ξi(cid:12)(cid:12)(cid:12)(cid:12)∞(cid:12)(cid:12)(cid:12)(cid:12)

∂ψ

∂ξj(cid:12)(cid:12)(cid:12)(cid:12)∞

Cov(cid:0)ξi, ξj(cid:1).

As for any ﬁxed u the indicator 1X>u is increasing in X, when X and Y are positively
associated then they are PQD. As positive association is preserved by coordinate increasing
functions, the following lemma is immediate.

Lemma 3.3 The pair (X, Y ) = (ψ(ξ), φ(ξ)) is PQD whenever ξ is positively associated and
ψ(ξ) and φ(ξ) are coordinate wise increasing functions of ξ.

the proof that follows we apply the alternative characterization, see [Rac84] for example:

Though one form of the L1, or Wasserstein distance d1(cid:0)L(X),L(Y )(cid:1) is given in (1), in
d1(cid:0)L(X),L(Y )(cid:1) = sup

h∈L |Eh(X) − Eh(Y )| where L = {h : |h(y) − h(x)| ≤ |y − x|}. (61)

Proof of Theorem 1.3 For given h ∈ L let f be the unique bounded solution to the Stein
equation

f ′(w) − wf (w) = h(w) − Nh where Nh = Eh(Z),

with L(Z) the standard normal distribution. Then, (see e.g. [CGS11] Lemma 2.4),

(62)

(63)

ξif (W i + ξi) = E

mXi=1(cid:20)ξif (W i) + ξ2
iZ 1

0

f ′(W i + uξi)du(cid:21) .

29

π

|f ′|∞ ≤r 2
As Var(W ) =Pi,j σij = 1, we obtain
E[f ′(W )] = E  mXi=1
= E  mXi=1
mXi=1

Now letting W i = W − ξi, write

E[W f (W )] = E

ξif (W ) = E

mXi=1

σ2

and |f ′′|∞ ≤ 2.

i f ′(W ) +Xi6=j
i f ′(W ) +Xi6=j

ξ2

σijf ′(W )!

σijf ′(W ) +

i )f ′(W )! .

(σ2
i − ξ2

mXi=1

Recalling the Stein equation (62) and subtracting, we obtain

E[h(W ) − Nh] = E[f ′(W ) − W f (W )]

= E  mXi=1

ξ2

i(cid:18)Z 1
0 (cid:0)f ′(W ) − f ′(W i + uξi)(cid:1) du(cid:19) +
+Xi6=j

mXi=1

i − ξ2
(σ2
mXi=1

σijf ′(W ) −

i )f ′(W )

ξif (W i)! .

(64)

Using the second inequality in (63), we bound the ﬁrst term in (64) by

mXi=1

E

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

ξ2

0 (cid:0)f ′(W ) − f ′(W i + uξi)(cid:1) du(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
i Z 1
=(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
mXi=1

i Z 1
0 Z ξi

f ′′(W i + t)dtdu(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) ≤ 2E

ξ2

uξi

E

mXi=1

= E

ξ2

u|ξi|

i Z 1
0 Z |ξi|
mXi=1
|ξi|3 ≤ BE

dtdu!
mXi=1

ξ2
i ≤ B,

(65)

using the almost sure bound on the variables ξi, and that their sum has mean zero and
variance 1.

To handle the second term in (64), ﬁrst note that W and ξi are coordinate wise increasing

functions of ξ, and hence PQD by Lemma 3.3. Now applying Lemma 3.1 with

mXi=1

mXj=1

σij = 4B,

E

B2

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

f ′(W )(σ2

i − ξ2

≤ 4B

mXi=1

|x| ≤ B
|x| > B
and again using the second inequality in (63), we have

g(x) =(cid:26) x2
Cov(cid:0)f ′(W ), g(ξi)(cid:1)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
= (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
i )(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
mXi=1
mXi=1
Cov(cid:0)W, ξi(cid:1) = 4B
using that Var(cid:0)W(cid:1) =Pi,j σij = 1.
σijf ′(W )(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
Cov(cid:0)ξi, f (W i)(cid:1)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) ≤r 2
=(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
mXi=1

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
EXi6=j
ξif (W i)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

= |Ef ′(W )|Xi6=j

inequality in (63) we obtain

mXi=1

mXi=1

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

π

E

30

σij ≤r 2
πXi6=j

σij.

For the third term in (64), using the nonnegativity of the covariances σij and the ﬁrst

For the ﬁnal term in (64), we note that the variables W i and ξi are coordinate wise
increasing in ξ, hence the pair (W i, ξi) is PDQ by Lemma 3.3. Applying Lemma 3.1 and the
ﬁrst inequality in (63) now yields

Cov(cid:0)ξi, W i(cid:1) =r 2
πXi6=j

σij.

(66)

Summing the bounds (65)-(66) we ﬁnd that |Eh(W )− Nh| is bounded by the right hand
side of (15). Taking supremum over h ∈ L and using the characterization of the d1 metric
given in (61) completes the proof.

(cid:3)

To prove Theorem 1.4 we apply the following result, which is a small variant of Lemma
2.6 of [CGS11], due to [Bar90]. Let Z be a standard normal random vector in Rp. For
h : Rp → R let Nh = Eh(Z) and for u ≥ 0 deﬁne

(Tuh)(s) = Eh(se−u + √1 − e−2uZ).

We write D2h for the Hessian matrix of h when it exists.
Lemma 3.4 For m ≥ 3 and h ∈ L∞

m (Rp) the function

solves

and for any 0 ≤ |k|1 ≤ m

[Tuh(s) − Nh]du

g(s) = −Z ∞
trD2g(s) − s · ∇g(s) = h(s) − Nh,

0

|g(k)|∞ ≤

1

|k|1|h(k)|∞.

Furthermore, for any λ ∈ Rp and positive deﬁnite p × p matrix Σ, f deﬁned by the change
of variable

(67)

(68)

(69)

f (s) = g(Σ−1/2(s − λ))

trΣD2f (s) − (s − λ) · ∇f (s) = h(Σ−1/2(s − λ)) − Nh,

solves

and satisﬁes

|f (k)|∞ ≤

p|k|1

|k|1 |Σ−1/2||k|1

∞ |h(k)|∞.

In particular, if h ∈ Hm,∞,p then
p|k|1

|f (k)|∞ ≤

|k|1 |Σ−1/2||k|1

∞ for all 0 ≤ |k|1 ≤ m.

We apply the same technique as in the univariate case, along with Lemmas 3.2 and 3.4,

to prove our main multivariate theorem.

Proof of Theorem 1.4 Given h ∈ H3,∞,p, let f be the solution of (68) given by (67) with
λ = 0. Writing out the expressions in (68) yields

E(cid:2)h(Σ−1/2S) − Nh(cid:3) = E" pXj=1
pXl=1
pXj=1
f (S) + E Xj,l∈[p],j6=l

∂2
∂s2
j

= E

Σj,j

31

Σj,l

∂2

∂sj∂sl

f (S) −

f (S)#

∂
∂sj

Sj

Σj,l

∂2

∂sj∂sl

f (S) − E

Sj

∂
∂sj

f (S).

(70)

pXj=1
pXj=1

We consider the ﬁrst term of (70) and deal with each term under the sum separately for
j = 1, . . . , p. Letting σ2

i,j = Var(cid:0)ξi,j(cid:1) and σi,j;k,l = Cov(cid:0)ξi,j, ξk,l(cid:1), we have

Σj,j

∂2
∂s2
j

f (S) =

σ2
i,j

∂2
∂s2
j

mXi=1
mXi=1

=

f (S) + Xi,k∈[m],i6=k
f (S) + Xi,k∈[m],i6=k

ξ2
i,j

∂2
∂s2
j

σi,j;k,j

f (S)

∂2
∂s2
j

σi,j;k,j

∂2
∂s2
j

f (S) +

(σ2
i,j − ξ2
i,j)

∂2
∂s2
j

mXi=1

f (S).

(71)

Now, with Sj∗i = Sj − ξi,j we may write the summands of the third term on the right hand
side of (70) as

Sj

∂
∂sj

f (S) =

=

∂
∂sj

∂
∂sj

f (S)

f (S1, . . . , Sj∗i, . . . , Sp)

ξi,j

ξi,j

mXi=1
mXi=1
mXi=1

+

ξ2

i,jZ 1

0

∂2
∂s2
j

f (S1, . . . , Sj∗i + uξi,j, . . . , Sp)du.

(72)

Substituting (71) and (72) into (70), we obtain

E(cid:2)h(Σ−1/2S) − Nh(cid:3) = E

We handle these ﬁve terms separately. For the ﬁrst term in (73), using (69) we have

pXj=1

mXi=1

E

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

ξ2

∂s2
j

0 (cid:18) ∂2
i,jZ 1
pXj=1
mXi=1
pXj=1
mXi=1
i,j − ξ2
(σ2
i,j)
pXj=1 Xi,k∈[m],i6=k

+E

+E

f (S) −

∂2
∂s2
j

f (S1, . . . , Sj∗i + uξi,j, . . . , Sp)(cid:19) du
pXj=1

∂
∂sj

ξi,j

f (S1, . . . , Sj∗i, . . . , Sp)

f (S).

(73)

∂2

Σj,l

σi,j;k,j

∂sj∂sl

∂2
∂s2
j

∂2
∂s2
j

∂2
∂s2
j

f (S) − E

mXi=1
f (S) + E Xj,l∈[p],j6=l
f (S1, . . . , Sj∗i + uξi,j, . . . , Sp)(cid:19) du(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
f (S1, . . . , Sj∗i + t, . . . , Sp)dtdu(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
i,jZ 1
0 Z ξi,j
i,jZ 1
0 Z |ξi,j |
pXj=1
mXi=1
pXj=1
mXi=1
E|ξi,j|3 ≤
pXj=1

p3
6 |Σ−1/2|3

pXj=1

mXi=1

∂3
∂s3
j

Eξ2
i,j

Σj,j,

dtdu

∞B

u|ξi,j|

uξi,j

ξ2

32

f (S) −

ξ2

∂s2
j

0 (cid:18) ∂2
i,j Z 1
= (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
pXj=1
mXi=1

E

ξ2

E

∞

p3
3 |Σ−1/2|3
p3
6 |Σ−1/2|3
p3
6 |Σ−1/2|3

∞

∞B

≤

=

≤

(74)

using the almost sure bound on the variables ξi,j, and that their sum Sj over i from 1 to m
has mean zero.

where with some abuse of notation we let f (s, x) = f (s), and deﬁne

for all s ∈ Rp and x ∈ R. Applying Lemma 3.2 and using the bound (69) and the fact that
(S, ξi,j) are positively associated for all i, j, we obtain

For the second term in (73), we have

E

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

pXj=1

mXi=1

i,j − ξ2
(σ2
i,j)

∂2
∂s2
j

f (S)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

=(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
pXj=1

mXi=1

B2

g(s, x) =(cid:26) x2
i,j(cid:19)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) ≤ 3√2(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
pXj=1

Cov(cid:18) ∂2

∂s2
j

mXi=1

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
pXj=1

f (S), ξ2

f (S), ξ2

i,j(cid:19)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
Cov(cid:18) ∂2

∂s2
j

mXi=1

∂s2
j

Cov(cid:18) ∂2
=(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
pXj=1

|x| ≤ B
|x| > B,

f (S, ξi,j), g(S, ξi,j)(cid:19)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

,

mXi=1
≤ 2√2p3|Σ−1/2|3
= 2√2p3|Σ−1/2|3
= 2√2p3|Σ−1/2|3

∂3

∂g

∞B

∂sl∂s2
j

Cov (Sl, ξi,j)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
f(cid:12)(cid:12)(cid:12)(cid:12)∞(cid:12)(cid:12)(cid:12)(cid:12)
∂x(cid:12)(cid:12)(cid:12)(cid:12)∞
pXl=1(cid:12)(cid:12)(cid:12)(cid:12)
pXl=1
pXj=1
mXi=1
Cov(cid:0)Sl, ξi,j(cid:1)
pXj,l=1
mXi,k=1
pXj,l=1

σi,j;k,l

Σj,l.

∞B

∞B

For the third term in (73), again applying Lemma 3.2 and arguing as for the second term,

we have

E

pXj=1

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

∂2

ξi,j

∂sl∂sj

∂
∂sj

∂
∂sj

3
√2

∂2
∂s2
j

=(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
f (S1, . . . , Sj∗i, . . . , Sp)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
f (S1, . . . , Sj∗i, . . . , Sp)(cid:19)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
Cov(cid:18)ξi,j,
pXj=1
mXi=1
mXi=1
Cov (ξi,j, Sj∗i)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
≤ 3√2(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
 Xl∈[p]\{j}(cid:12)(cid:12)(cid:12)(cid:12)
f(cid:12)(cid:12)(cid:12)(cid:12)∞
Cov (ξi,j, Sl) +(cid:12)(cid:12)(cid:12)(cid:12)
f(cid:12)(cid:12)(cid:12)(cid:12)∞
pXj=1
mXi=1
Cov (ξi,j, Sj∗i)
∞ Xj,l∈[p],j6=l
pXj=1
mXi=1
mXi=1
∞ Xj,l∈[p],j6=l
σi,j;k,j
pXj=1 Xi,k∈[m],i6=k
mXi,k=1
∞ Xj,l∈[p],j6=l
σi,j;k,j .

pXj=1 Xi,k∈[m],i6=k

p2|Σ−1/2|2

p2|Σ−1/2|2

p2|Σ−1/2|2

Cov (ξi,j, Sl) +

σi,j;k,l +

3
√2

3
√2

Σj,l +

≤

=

=

33

For the fourth and the ﬁfth terms in (73), again using (69) we have

p2
2 |Σ−1/2|2

∞

pXj=1 Xi,k∈[m],i6=k

σi,j;k,j

and

σi,j;k,j

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
pXj=1 Xi,k∈[m],i6=k
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
E Xj,l∈[p],j6=l

∂2
∂s2
j

∂2

≤

f (S)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
f (S)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

Σj,l

∂sj∂sl

p2
2 |Σ−1/2|2

≤

∞ Xj,l∈[p],j6=l

Σj,l.

(75)

Summing the bounds (74)-(75) we ﬁnd that(cid:12)(cid:12)E(cid:2)h(Σ−1/2S) − Nh(cid:3)(cid:12)(cid:12) is bounded by the right

hand side of (17). Taking supremum over h ∈ H3,∞,p and using the deﬁnition (16) of dHm,∞,p
completes the proof.

(cid:3)

References

[AN63] Ahlberg, J. H. and Nilson, E. N., Convergence properties of the spline ﬁt, J. SIAM,

11 (1963) 95–104.

[ABF87] Aizenman, M., Barsky, D. J. and Fernandez, R., The phase transition in a general

class of Ising-type models is sharp, Journal of Statistical Physics, 47 (1987) 343–374.

[AD15] Aizenman, M. and Duminil-Copin, H., The truncated correlations of the Ising
model in any dimension decay exponentially fast at all but the critical temperatute,
ArXiv:1506:00625, 2015.

[Bar90] Barbour, A. D., Stein’s method for diﬀusion approximations, Probab. Th. Rel. Fields,

84 (1990) 297–332.

[BR14] Banerjee, S. and Roy, A., Linear Algebra and Matrix Analysis for Statistics, Chap-

man and Hall, 2014.

[Bir88] Birkel, T., On the convergence rate in the central limit theorem for associated pro-

cesses, Annals of Probability, 16 (1988) 1685–1698.

[Bre89] Brenti, F., Unimodal, Log-concave, and P´olya Frequency Sequences in Combina-

torics,, Memoirs Amer. Math. Soc., no. 413 (1989).

[Bul95] Bulinski, A., Rate of convergence in the central limit theorem for ﬁelds of associated

random variables, Theory Probab. Appl., 40 (1995) 136–144.

[CS11] Chatterjee, S. and Shao, Q.-M., Nonnormal approximation by Stein’s method of
exchangeable pairs with application to the Curie-Weiss model, Annals of Applied Prob-
ability, 21 (2011) 464–483.

[CGS11] Chen, L. H. Y., Goldstein, L. and Shao, Q.-M., Normal Approximation by Stein’s

Method, Springer, New York, 2011.

34

[CCGKS89] Chayes, J. T., Chayes, L., Grimmett, G., Kesten, H. and Schonmann, R. H.,
The correlation length for the high-density phase of Bernoulli percolation, Annals of
Probability, 17 (1989) 1277–1302.

[CG83] Cox, T. and Griﬀeath, D., Occupation time limit theorems for the voter model,

Annals of Probability, 11 (1983) 876–893.

[CG84] Cox, T. and Grimmett, G., Central limit theorems for associated random variables

and the percolation model, Annals of Probability, 12 (1984) 514–528.

[CS73] Criﬀord, P. and Subbery, A., A model for spatial conﬂict, Biometrika, 60 (1973)

581–588.

[EL10] Eichelsbacher, P. and L¨owe, G., Steins method for dependent random variables oc-
curring in Statistical Mechanics, Electronic Journal of Probability, 30 (2010) 962–988.

[EM15] Eichelsbacher, P. and Martschink, B., On rates of convergence in the Curie-Weiss-
Potts model with an external ﬁeld, Ann. Inst. H. Poincar´e Probab. Statist., 51 (2015)
252–282.

[ER08] Eichelsbacher, P. and Reinert, M., Steins method for discrete Gibbs measures, Annals

of Probability, 18 (2008) 1588–1618.

[ELL06] Ellis, R. S., Entropy, Large Deviations, and Statistical Mechanics, Springer, New

York, 2006.

[EPW67] Esary, J. D., Proschan F. and Walkup, D. W., Association of random variables,

with applications, Ann. Math. Statist., 38 (1967) 1466–1474.

[Grim99] Grimmett, G., Percolation (2nd edition), Springer, New York, 1999.

[Hoe40] Hoeﬀding, W., Masstabinvariante Korrelations-theorie Schriften, Math. Inst. Univ.

Berlin, 5 (1940) 181–233.

[IL71] Ibragimov, I. A. and Linnik, Yu. V., Independent and Stationary Sequences of Random

Variables, Wolters-Noordhoﬀ, Groningen, 1971.

[LP68] Lebowitz, J. L. and Penrose, O., Analytic and clustering properties of thermody-
namic functions and distribution functions for classical lattice and continuum systems,
Commun. math. Phys., 11 (1968) 99–124.

[Leh66] Lehmann, E. L., Some concepts of dependence, Ann. Math. Statist., 37 (1966) 1137–

153.

[New80] Newman, C., Normal Fluctuations and the FKG inequality, Communications in

Mathematical Physics, 74 (1980) 119–128.

[Rac84] Rachev, S. T., The Monge-Kantorovich transference problem and its stochastic ap-

plications, Theory Probab. Appl., 29 (1984) 647–676.

35

[RR97] Rinott, Y. and Rotar, V., On coupling constructions and rates in the CLT for de-
pendent summands with applications to the antivoter model and weighted U-statistics,
Ann. Appl. Probab., 7(4) (1997) 1080–1105.

[Ros11] Ross, N., Fundamentals of Stein’s method, Prob. Surv., 8 (2011) 210–293.

[Sta89] Stanley, R. P., Log-concave and unimodal sequences in algebra, combinatorics, and

geometry, Graph Theory and Its Applications: East and West, 576 (1989) 500–535.

[Ste72] Stein, C., A bound for the error in the normal approximation to the distribution of
a sum of dependent random variables, Proc. Sixth Berkeley Symp. Math. Statist. Prob.,
Univ. of California Press, 2 (1972) 210–293.

[Tik80] Tikhomirov, A. N., On the convergence rate in the central limit theorem for weakly

dependent random variables, Theory Probab. Appl., 25 (1980) 790–809.

36

