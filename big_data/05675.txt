6
1
0
2

 
r
a

 

M
4
2

 
 
]

.

R
P
h
t
a
m

[
 
 

2
v
5
7
6
5
0

.

3
0
6
1
:
v
i
X
r
a

A Stein characterisation of the generalized hyperbolic

distribution

Robert E. Gaunt∗
University of Oxford

March 2016

Abstract

The generalized hyperbolic (GH) distributions form a ﬁve parameter family of
probability distributions that includes many standard distributions as special or
limiting cases, such as the generalized inverse Gaussian distribution, Student’s t-
distribution and the variance-gamma distribution, and thus the normal, gamma
and Laplace distributions. In this paper, we consider the GH distribution in the
context of Stein’s method.
In particular, we obtain a Stein characterisation of
the GH distribution that leads to a Stein equation for the GH distribution. This
Stein equation reduces to the Stein equations from the current literature for the
aforementioned distributions that arise as limiting cases of the GH superclass.

Keywords: Stein’s method, generalized hyperbolic distribution, characterisations of
probability distributions
AMS 2010 Subject Classiﬁcation: 60F05; 60E05

1

Introduction

In 1972, Stein [44] introduced a powerful technique for deriving distributional bounds for
normal approximation. Stein’s method for normal approximation rests on the following
characterization of the normal distribution: W ∼ N(0, σ2) if and only if

(1.1)
for all real-valued absolutely continuous functions f such that E|f′(Z)| < ∞ for Z ∼
N(0, σ2). This characterisation leads to the so-called Stein equation:

E[σ2f′(W ) − W f (W )] = 0

(1.2)
where Nh denotes Eh(Z) for Z ∼ N(0, σ2), and the test function h is real-valued. Eval-
uating both sides of (1.2) at a random variable W and taking expectations gives

σ2f′(x) − xf (x) = h(x) − Nh,

∗Department of Statistics, University of Oxford, 24–29 St. Giles’, OXFORD OX1 3LB, UK.

E[σ2f′(W ) − W f (W )] = Eh(W ) − Nh.

(1.3)

1

We can thus bound the quantity |Eh(W ) − Nh| by solving the Stein equation (1.2) and
then bounding the left-hand side of (1.3). For a detailed account of the method see the
monograph [10] or the review article [40].

Over the years, the method has been adapted to many other probability distributions,
such as the Poisson [9], gamma [26, 32], exponential [7, 36] and Laplace distribution
[14, 39], and has been applied to a wide range of applications, including random matrix
theory [33], random graph theory [3], urn models [13, 28, 38], goodness-of-ﬁt statistics
[27, 26] and statistical physics [8, 19]. For an overview of the current literature see [31]. In
particular, the method has recently been extended to the variance-gamma distribution;
see [22] and [20]. The variance-gamma distributions form a four parameter family of
distributions that include as special or limiting cases the normal, gamma and Laplace
distributions, as well the product of two (possibly correlated) mean zero normal random
variables and the diﬀerence of two (possibly correlated) gamma random variables; for a
list of the distributions contained in the variance-gamma class see [22]. The variance-
gamma distribution is a limiting case of the ﬁve parameter generalized hyperbolic (GH)
distribution (see [16]), and it is therefore an intriguing prospect to extend Stein’s method
to this distribution. This is the focus of this paper.

The GH distribution was introduced by Barndorﬀ-Nielsen [4], who studied it in con-
nection with the modelling of dune movements. For certain parameter values the GH
distributions have semi-heavy tails which makes them appropriate for ﬁnancial modelling;
see, for example, [6, 17, 18, 34]. The distribution has ﬁve parameters λ ∈ R, δ > 0, µ ∈ R,
α > |β| ≥ 0 and its probability density function is

pGH(x; λ, α, β, δ, µ) =

√2παλ− 1
× Kλ− 1

2

(α2 − β2)λ/2
2 δλKλ(δpα2 − β2)
(αpδ2 + (x − µ)2),

eβ(x−µ)(δ2 + (x − µ)2)(λ− 1
x ∈ R,

2 )/2

(1.4)

where Kν is the modiﬁed Bessel function of the second kind (see the Appendix for a
deﬁnition). If a random variable X has density (1.4), we write X ∼ GH(λ, α, β, δ, µ).
The parameter µ is the location parameter, and in this paper we shall often set it to
0 to simplify the exposition; results for the general case then follow by a simple linear
transformation, because GH(λ, α, β, δ, µ) D= µ + GH(λ, α, β, δ, 0). The support of the
distribution is R, except for certain limiting cases, in which case the support is either
a positive or negative half-line. We collect these special cases in Section 2 (see [16] for
a thorough treatment of all the limiting cases).
Indeed, the combination of the ﬁve
parameters of the model and the ﬂexibility of the modiﬁed Bessel function Kν allow
for a wide variety of distributions to fall into the GH family, including the generalized
inverse Gaussian (GIG) distribution, Student’s t-distribution and also the variance-gamma
distribution. We present a number of important special and limiting cases in Section 2.
In extending Stein’s method to a new distribution, the ﬁrst step is typically to ﬁnd
a suitable characterising equation for the distribution (for the normal distribution this
is (1.1)), from which we obtain a corresponding Stein equation. In Proposition 3.1, we
obtain a characterising equation for the GH(λ, α, β, δ, 0) distribution, which leads to the

2

following Stein equation for the GH(λ, α, β, δ, 0) distribution:

Aλ,α,β,δf (x) :=

x

x2 + δ2

f′′(x) +(cid:20)2λ +
+(cid:20)2λβ − (α2 − β2)x +

2βδ2
x −
β2δ2
x −

δ2

x2(cid:21)f′(x)
x2 (cid:21)f (x) = h(x) − GHλ,α,β

βδ2

δ,0 h,

(1.5)

where GHλ,α,β
δ,µ h denotes Eh(X) for X ∼ GH(λ, α, β, δ, µ). We shall refer to Aλ,α,β,δ as the
GH(λ, α, β, δ, 0) Stein operator, in accordance with standard practice from the literature.
This Stein equation has a number of interesting properties. In particular, in Section 3.2,
we see that, for particular parameter values, (1.5) reduces to the known Stein equations
for the GIG [30], Student’s t [42] and variance-gamma [22] distributions. The only other
instance in the literature in which a comparably large class of distributions can be treated
in one framework are the Stein equations for Pearson and Ord class of distributions (see
[42]).

The Stein equation (1.5) is a second order diﬀerential equation in f , f′ and f′′. Such
Stein equations were uncommon in the literature, although recently [22, 37, 39] have
obtained second order Stein equations. In fact, n-th order Stein equations have recently
been obtained for the product of n independent beta, gamma and central normal random
variables [21, 23] and general linear combinations of gamma random variables [1].

The fact that (1.5) is a second order diﬀerential equation in f , f′ and f′′ means that
the standard generator [2, 29] and density [45] methods (the scope of the density method
has recently been extended by [31]) do not easily lend themselves to deriving this Stein
equation. (Note that a direct application of the density method would lead to a ﬁrst
order Stein equation with complicated coeﬃcients involving the modiﬁed Bessel function
of the second kind, which would most likely be intractable in applications.) To arrive at
our characterisation of the GH distribution that leads to (1.5), we note a second order
homogeneous diﬀerential equation that the density (1.4) satisﬁes and then exploit the
duality between Stein equations and diﬀerential equations of densities to obtain our Stein
equation. This is one the ﬁrst explicit examples in the literature of this technique being
used to derive a Stein equation, but see [31], Section 3.6 for a discussion and example of
this approach.

Despite these interesting properties, the presence of singularities at x = 0 in the Stein
equation (1.5) suggests that it may not be easily tractable for proving approximation
theorems via Stein’s method. We can remove the singularities by making the substi-
tution f (x) = x2g(x), which leads to the following alternative Stein equation for the
GH(λ, α, β, δ, 0) distribution:

x(x2 + δ2)g′′(x) +(cid:0)3δ2 + 2βδ2x + (2λ + 4)x2 + 2βx3(cid:1)g′(x)
+(cid:0)βδ2 + (4λ + β2δ2 + 2) + (2λ + 4)βx2 − (α2 − β2)x3(cid:1)g(x) = h(x) − GHλ,α,β

At ﬁrst glance, (1.6) seems to be more tractable than (1.5). However, there is also a
problem with working with this Stein equation in applications. The solution g to (1.6)
is equal to f (x)/x2, where f is the solution to (1.5), and is given by formula (3.6) in
Proposition 3.5. It is clear from (3.6) that g(x) = f (x)/x2 has a singularity at x = 0

δ,0 h.

(1.6)

3

(except possibly for very particular choices of test function h). As was shown by [24],
it is sometimes possible to prove approximation theorems by Stein’s method when the
derivatives of the solution of a Stein equation are unbounded as |x| → ∞. Although, the
prospect of dealing with a singularity at an interior point seems more challenging and
will not be addressed in this paper. For dealing with the full class, the Stein equations
(1.5) and (1.6) may therefore not be tractable, and alternative methods may be needed to
circumvent the Stein equation, as was done in the recent works [1, 24]. It should, however,
be noted that for particular parameter values, the Stein equation is highly tractable.
For example, the case δ → 0 yields the variance-gamma class for which approximation
theorems have been obtained in [20, 22].
The rest of the article is organised as follows. In Section 2, we present some basic
properties of the GH distributions and note some important special and limiting cases
of this superclass of distributions. In Section 3, we obtain a characterising equation for
the GH distribution that leads to the Stein equation (1.5). In Lemma 3.4, we solve the
Stein equation, and in Lemma 3.5 we prove that the solution and its ﬁrst derivative
are bounded when the test function h is bounded. In Section 3.2, we note that the Stein
equation (1.5) reduces to the known GIG, Student’s t and variance-gamma Stein equations
for appropriate parameter values. The Appendix contains some elementary properties of
modiﬁed Bessel functions that are used throughout this paper.

2 The class of generalized hyperbolic distributions

In this section, we present some basic properties of GH distributions, some of which we
shall need in Section 3. The GH distributions are studied in some detail in [16], and we
refer the reader to this work for further properties. The class of GH distributions can be
obtained by mean-variance mixtures of normal distributions where the mixing distribution
is the GIG distribution [5]. Let GIG(λ, a, b) denote the GIG distribution with parameters
λ ∈ R, a > 0, b > 0 and density
pGIG(x; λ, a, b) =(cid:18)a

xλ−1e−(ax+bx−1)/2,

b(cid:19)λ/2

1

2Kλ(√ab)

x > 0.

(2.1)

If X ∼ N(0, 1) and V ∼ GIG(λ,pα2 − β2, δ) are independent, then

µ + βV + √V X ∼ GH(λ, α, β, δ, µ).

The moment generating function of the GH(λ, α, β, δ, µ) distribution is given by

M(t) =

Kλ(δpα2 − (β + t)2)

Kλ(δγ)

,

(2.2)

eµtγλ

(α2 − (β + t)2)λ/2

for all t ∈ R such that |β + t| < α. The mean and variance of X ∼ GH(λ, α, β, δ, µ) are
given by

EX = µ +

δβKλ+1(δγ)

γKλ(δγ)

,

VarX =

δKλ+1(δγ)
γKλ(δγ)

+

β2δ2

γ2 (cid:18)Kλ+2(δγ)
Kλ(δγ) −

K 2
λ+1(δγ)
K 2

λ(δγ) (cid:19),

(2.3)

(2.4)

4

where γ = pα2 − β2.
In fact, GH distributions possess moments of arbitrary order
(except in a limiting case that corresponds to Student’s t-distribution), and formulas for
these moments are given in [43]. The class is closed under aﬃne transformations [16]: if
X ∼ GH(λ, α, β, δ, µ) then aX + b ∼ GH(λ, α/|a|, β/a, δ|a|, aµ + b). However, the class is
not closed under convolutions, meaning that the sum of two independent GH distributed
random variables is no longer GH distributed. The exceptions being the normal inverse
Gaussian distribution (λ = −1/2) [16] and the variance-gamma distribution (δ → 0) [6].
Except for particular limiting cases (which we note below), the density of the GH
distribution is bounded across its support. As is seen in the following lemma (which the
author could not ﬁnd in the literature), the tails of the GH distribution are semi-heavy,
which makes the class appropriate for ﬁnancial modelling. We shall make use of this
lemma in the proof of Proposition 3.1.

Lemma 2.1. The density p of the GH(λ, α, β, δ, µ) has the following tail behaviour:

p(x) ∼

(α2 − β2)λ/2

2(αδ)λKλ(δpα2 − β2)|x|λ−1e−α|x−µ|+β(x−µ)

ak
xk ,

∞

Xk=0

|x| → ∞,

(2.5)

where the ak are constants independent of x, and a0 = 1. Therefore, p(x) = O(|x|λ−1e−α|x|+βx)
and p′(x) = O(|x|λ−1e−α|x|+βx), as |x| → ∞.
Proof. Applying the asymptotic formula (A.6) to (1.4), we have that

p(x) ∼

√2παλ− 1
×s

(α2 − β2)λ/2
2 δλKλ(δpα2 − β2)

π

2αpδ2 + (x − µ)2

eβ(x−µ)(δ2 + (x − µ)2)(λ− 1
ak(λ − 1/2)

,

2 )/2

e−α√δ2+(x−µ)2 ∞
Xk=0

xk

|x| → ∞,

where the ak(λ − 1/2) are given by (A.4). Using the asymptotic formula
pδ2 + (x − µ)2 = |x − µ|p1 + δ2/(x − µ)2 ∼ |x − µ| + O(x−1),

now yields (2.5). Note that in general the ak diﬀer from the ak(λ − 1/2) except for
a0 = a0(λ − 1/2) = 1, the constant for the leading term in the asymptotic series. The
ﬁnal assertion regarding the order of p(x) and p′(x) as |x| → ∞ is immediate from the
asymptotic series (2.5).

|x| → ∞,

The special and limiting cases of the GH distribution were studied in some detail in
[16]. We now record the relevant (non-degenerate) cases. For derivations of these cases
see [16], although note that they all can be derived directly from the density (1.4) using
the properties (A.2) – (A.6) of the modiﬁed Bessel function of the second kind.

Hyperbolic distribution. This distribution corresponds to the case λ = 1:

pH(x; α, β, δ, µ) =

pα2 − β2

2αδK1(δpα2 − β2)

5

e−α√δ2+(x−µ)2+β(x−µ),

x ∈ R.

Normal-inverse Gaussian distribution. Taking λ = −1/2 gives

pN IG(x; α, β, δ, µ) =

αδ

πpδ2 + (x − µ)2

eδγ+β(x−µ)K1(αpδ2 + (x − µ)2),

x ∈ R.

GIG distribution with parameters λ ∈ R, a > 0, b > 0. Taking β = α − a
2 , α → ∞,
δ → 0, αδ2 → b, µ = 0 in the density (1.4) of the GH(λ, α, β, δ, µ) distribution yields the
GIG(λ, a, b) distribution with density (2.1). Note that the support of this distribution is
the positive real line. Also, as noted by [16], the distribution −GIG(λ, a, b), which has
support on the negative real line is in the GH class. Taking the limit b → 0 yields the
gamma distribution as a limiting case, and the limit a → 0 corresponds to inverse-gamma
distribution. For the gamma case (b → 0) the distribution has singularity at 0 when
0 < λ < 1; otherwise, the GIG distribution is bounded across its support.
Student’s t-distribution. Letting λ = − ν
scaled and shifted Student’s t-distribution with ν degrees of freedom:

2 < 0 and taking the limit α, β → 0 gives a

pt(x; ν, δ, µ) =

Γ( ν+1
2 )
√πδ2Γ( ν

2 )(cid:18)1 +

(x − µ)2

δ2

2 (ν+1)

(cid:19)− 1

,

x ∈ R.

(2.6)

In the case δ = √ν the density (2.6) is that of Student’s t-distribution with ν degrees of
freedom, and specialising further to ν = 1 yields the Cauchy distribution.
Variance-gamma distribution. Letting ν = λ − 1/2 > −1/2 and taking the limit
δ → 0 gives the VG2(ν, α, β, µ) distribution (this notation is consistent with that of [22])
with density

pVG2(x; ν, α, β, µ) =

(α2 − β2)ν+1/2
√πΓ(ν + 1

2α (cid:19)ν
2) (cid:18)|x − µ|

eβ(x−µ)Kν(α|x − µ|),

x ∈ R.

The variance-gamma distribution does itself possess a number of standard probability
distributions as special and limiting cases; see [22]. To identify these cases, it is more
helpful to work with an alternative parametrisation of the distribution. Letting

ν =

r − 1
2

, α =

√θ2 + σ2

σ2

,

β =

θ
σ2

gives the VG1(r, θ, σ, µ) distribution, which has density

pVG1(x; r, θ, σ, µ) =

1

σ√πΓ( r
2)

e

θ

σ2 (x−µ)(cid:18) |x − µ|

2√θ2 + σ2(cid:19)

r−1

2

K r−1

2 (cid:18)√θ2 + σ2

σ2

(2.7)

|x − µ|(cid:19).

The support of the VG1(r, θ, σ, µ) distribution is R when σ > 0, but in the limit σ → 0 the
support is the region (µ,∞) if θ > 0, and is (−∞, µ) if θ < 0. If σ > 0, the distribution
is bounded across its support, except for when r ≤ 1 for which there is a singularity at
the point µ of order − log |x − µ| if r = 1 and of order |x − µ|r−1 if 0 < r < 1 (see [22], p.

6

5). In [22], Proposition 1.3 it is shown that

N(µ, σ2) D= lim
r→∞
Γ(r, λ) D= lim
σ↓0

VG(r, 0, σ/√r, µ),

VG(2r, (2λ)−1, σ, 0),

Laplace(µ, σ) D= VG(2, 0, σ, µ),

and a number of other interesting cases are included, such as the product of two (pos-
sibly correlated) mean zero normal random variables and the diﬀerence of two (possibly
correlated) gamma random variables. Here, Laplace(µ, σ) denotes a Laplace distribution
with density 1

2σ exp(cid:0) − |x−µ|

σ (cid:1), x ∈ R.

3 A Stein equation for the generalized hyperbolic

distribution

3.1 A Stein characterisation of the generalized hyperbolic dis-

tribution

The following proposition gives a characterisation of the GH(λ, α, β, δ, 0) distribution
which leads to the GH Stein equation (1.5). We begin by obtaining a diﬀerential equation
satisﬁed by the density of the GH(λ, α, β, δ, 0) distribution and then exploit the duality of
Stein equations and diﬀerential equations satisﬁed by densities to prove the proposition.
To simplify the exposition, we take µ = 0 throughout this section. We can deduce results
for general case easily, because GH(λ, α, β, δ, µ) D= µ + GH(λ, α, β, δ, 0).

Proposition 3.1. Let W be a real-valued random variable. Then W follows the GH(λ, α, β, δ, 0)
distribution if and only if

E[Aλ,α,β,δf (W )] = 0

(3.1)

for all piecewise twice continuously diﬀerentiable function f : R → R for which E|Aλ,α,β,δf (Z)| <
∞ for Z ∼ GH(λ, α, β, δ, 0), and
lim

(3.2)

|x|→∞|x|λe−α|x|+βxf (k)(x) = 0

for k = 0, 1, 2, where f (0) ≡ f .

Before proving Proposition 3.1, we establish several lemmas.

Lemma 3.2. Suppose g and h are twice diﬀerentiable. Then the general solution to the
diﬀerential equation

w′′(x) −(cid:18)g′′(x)
g′(x) −

g′(x)
g(x)

+

h(x)h′′(x) − 2h′(x)2

+

h(x)2

2h′(x)

h(x) (cid:19)w′(x) −(cid:18)(cid:18) ν2
h(x)g′(x) (cid:19)w(x) = 0
−

h′(x)g′′(x)

g(x)2 + 1(cid:19)g′(x)2 +

h′(x)g′(x)
h(x)g(x)

(3.3)

7

is given by w(x) = Ah(x)Kν(g(x)) + Bh(x)Iν(g(x)), where A and B are arbitrary real-
valued constants. The modiﬁed Bessel functions Kν and Iν are deﬁned in the Appendix.

Proof. We begin by noting that the solution to the homogeneous ordinary diﬀerential
equation

r′′(x) +

1
x

r′(x) −(cid:18)1 +

ν2

x2(cid:19)r(x) = 0

(3.4)

is given by r(x) = AKν(x) + BIν(x) (see (A.1)). We now use (3.4) to obtain a diﬀerential
equation satisﬁed by s(x) = AKν(g(x)) + BIν(g(x)). For y = g(x), we have that d
dy =

1

g′(x)

d

dx and d2

dy2 = 1

g′(x)2

d2

dx2 − g′′(x)

g′(x)3

d
dx . Therefore s satisﬁes

1
g′(x)2 s′′(x) −

g′′(x)
g′(x)3 s′(x) +

1

g(x)g′(x)

s′(x) −(cid:18)1 +

ν2

g(x)2(cid:19)s(x) = 0,

which on multiplying through by g′(x)2 becomes

s′′(x) −(cid:18)g′′(x)
g′(x) −

g′(x)

g(x)(cid:19)s′(x) −(cid:18)1 +

ν2

g(x)2(cid:19)g′(x)2s(x) = 0.

(3.5)

Substituting w(x) = h(x)s(x) into (3.5), using the product rule for diﬀerentiation and
simplifying then shows that w does indeed solve (3.3), which completes the proof.

Corollary 3.3. The density p of the GH(λ, α, β, δ, 0) distribution, as given by (1.4),
satisﬁes

x2 + δ2

x

p′′(x) +(cid:18) − 2(λ − 1) − 2βx −
+(cid:18)2(λ − 1)β − (α2 − β2)x +

2βδ2
x −

β2δ2

x

+

δ2

x2(cid:19)p′(x)
x2 (cid:19)p(x) = 0.

2βδ2

Proof. Apply Lemma 3.2 (taking B = 0 and A 6= 0) with g(x) = α√δ2 + x2 and

h(x) = eβ(x−µ)(δ2 + x2)(λ−1/2)/2, and then multiply through by x2+δ2
calculations.

. We omit the tedious

x

Lemma 3.4. Let h : R → R be measurable. Then the function f : R → R, as given by

f (x) = −

−

= −

+

e−βxKν(α√δ2 + x2)

(δ2 + x2)ν/2

e−βxIν(α√δ2 + x2)

(δ2 + x2)ν/2

e−βxKν(α√δ2 + x2)

(δ2 + x2)ν/2

e−βxIν(α√δ2 + x2)

(δ2 + x2)ν/2

0

x

Z x
Z ∞
Z x
Z x

−∞

0

eβt(δ2 + t2)ν/2Iν(α√t2 + δ2)˜h(t) dt
eβt(δ2 + t2)ν/2Kν(α√t2 + δ2)˜h(t) dt
eβt(δ2 + t2)ν/2Iν(α√t2 + δ2)˜h(t) dt
eβt(δ2 + t2)ν/2Kν(α√t2 + δ2)˜h(t) dt,

(3.6)

(3.7)

solves the GH(λ, α, β, δ, 0) Stein equation (1.5), where ˜h(x) = h(x) − GHν,α,β
λ − 1/2.

δ,0 h and ν =

8

Proof. Since (1.5) is an inhomogeneous linear ordinary diﬀerential equation, we can use
the method of variation of parameters (see [11] for an account of the method) to write
down the general solution of (1.5):

f (x) = −w1(x)Z x

a

tw2(t)˜h(t)

(δ2 + t2)W (t)

dt + w2(x)Z x

b

tw1(t)˜h(t)

(δ2 + t2)W (t)

dt,

(3.8)

where w1 and w2 are solutions to the homogeneous equation

x

δ2

x2 + δ2

2βδ2
x −

w′′(x) +(cid:20)2λ +

x2(cid:21)w′(x) +(cid:20)2λβ − (α2 − β2)x +

x2 (cid:21)w(x) = 0
(3.9)
and a and b are arbitrary constants, and W (t) = W (w1, w2) = w1w′2 − w2w′1 is the
Wronskian.
A simple application of Lemma 3.2 gives that a pair of linearly independent solutions

β2δ2
x −

βδ2

to (3.9) is given by

w1(x) =

e−βxKν(α√δ2 + x2)

(δ2 + x2)ν/2

, w2(x) =

e−βxIν(α√δ2 + x2)

(δ2 + x2)ν/2

.

We now compute the Wronskian W (w1(x), w2(x)). For diﬀerentiable functions u and v,
we have that

W (u(x)Kν(v(x)), u(x)Iν(v(x))) = u(x)2v′(x)[Kν(v(x))I′ν(v(x)) − K′ν(v(x))Iν(v(x))]

u(x)2v′(x)

,

=

v(x)

where we used the formula W (Kν(x), Iν(x)) = x−1 ([35], formula 10.28.2) to obtain the
ﬁnal equality. A simple calculation now gives that

W (w1(x), w2(x)) =

e−2βx

x(δ2 + x2)ν−1 .

Substituting the relevant quantities into (3.8) and taking a = 0 and b = ∞ yields the
solution (3.6). That the solutions (3.6) and (3.7) are equal follows because eβt(δ2 +
t2)ν/2Kν(α√t2 + δ2) is proportional to the GH(λ, α, β, δ, 0) density function.
Lemma 3.5. Suppose that h : R → R is bounded and let f denote the solution (3.6). Then
there exist non-negative constants C0 and C1 such that kfk ≤ C0k˜hk and kf′k ≤ C1k˜hk,
where k˜hk = k˜hk∞ = supx∈R |˜h(x)|.
Proof. The equality between solutions (3.6) and (3.7) means that we can restrict our
attention to the case x ≥ 0 provided that we deal with the cases of positive and negative
β. As h is bounded, we have from (3.6) that, for x ≥ 0,

|f (x)| = k˜hk
+ k˜hk

e−βxKν(α√δ2 + x2)

eβt(δ2 + t2)ν/2Iν(α√t2 + δ2) dt
Z x
(δ2 + x2)ν/2
e−βxIν(α√δ2 + x2)
eβt(δ2 + t2)ν/2Kν(α√t2 + δ2)) dt.
Z ∞

(δ2 + x2)ν/2

x

0

9

The solution f is clearly bounded for all ﬁnite x. Also, from the asymptotic formulas
(A.6) and (A.7) for Kν and Iν, it follows that f is bounded as x → ∞. Let us now show
that f′ is also bounded for all x ∈ R. Diﬀerentiating (3.6) and using that h is bounded
gives that, for x ≥ 0,
d

dx(cid:18) e−βxKν(α√δ2 + x2)
eβt(δ2 + t2)ν/2Iν(α√t2 + δ2) dt
Z x
|f′(x)| = k˜hk(cid:12)(cid:12)(cid:12)(cid:12)
(cid:19)(cid:12)(cid:12)(cid:12)(cid:12)
dx(cid:18)e−βxIν(α√δ2 + x2)
eβt(δ2 + t2)ν/2Kν(α√t2 + δ2) dt.
Z ∞
(cid:19)(cid:12)(cid:12)(cid:12)(cid:12)
+ k˜hk(cid:12)(cid:12)(cid:12)(cid:12)

Diﬀerentiating using the product rule, the formulas d
Iν+1(x)

(δ2 + x2)ν/2

(δ2 + x2)ν/2

and d

([35], formula 10.29.4) and the chain rule gives that

d

x

0

xν

xν (cid:1) = − Kν+1(x)

dx(cid:0) Kν (x)
(cid:19) = −e−βx(cid:18) Kν(α√δ2 + x2)
(δ2 + x2)ν/2 + α
(cid:19) = −e−βx(cid:18) Iν(α√δ2 + x2)

(δ2 + x2)ν/2 − α

dx(cid:0) Iν (x)
Kν+1(α√δ2 + x2)
(δ2 + x2)ν/2+1/2 (cid:19),
Iν+1(α√δ2 + x2)
(δ2 + x2)ν/2+1/2 (cid:19).

xν (cid:1) =

xν

d

(δ2 + x2)ν/2

dx(cid:18)e−βxKν(α√δ2 + x2)
dx(cid:18)e−βxIν(α√δ2 + x2)

(δ2 + x2)ν/2

d

Therefore f′ is bounded for all ﬁnite x and the asymptotic formulas (A.6) and (A.7)
imply that it is the bounded in the limit x → ∞. Since we dealt with the cases of both
positive and negative β, it suﬃced to prove boundedness for x ≥ 0, and the proof is thus
complete.

Remark 3.6. Looking back at the proof of Lemma 3.4, due to the asymptotic behaviour
of Iν(x) as x → ∞ (see (A.7)), to ensure the solution is bounded as x → ∞, we were
forced to take b = ∞. After doing so, we can take a to be any ﬁnite real number and still
obtain a bounded solution. Therefore there are inﬁnitely many bound solutions to (1.5).
Choosing a = 0 does however seem natural, and in fact on setting ν = λ − 1/2 and taking
the limit δ → 0 we recover the solution of the VG1(ν, α, β, 0) Stein equation that was given
in Lemma 3.3 [22]. That solution is in fact the unique bounded solution to VG1(ν, α, β, 0)
Stein equation, provided ν ≥ 0.
Remark 3.7. We shall use Lemma 3.5 in our proof of Proposition 3.1. In proving that
proposition, we only need to make use of the fact that here exist non-negative constants
C0 and C1 such that kfk ≤ C0k˜hk and kf′k ≤ C1k˜hk; we do not need to ﬁnd C0 and C1.
To determine explicit bounds for f , f′ and higher order derivatives of f , we would need to
bound a number of expressions involving integrals of modiﬁed Bessel functions. Bounds of
expressions of a similar form to those we would encounter are given in [25], and were used
to bound the derivatives of the solution of the variance-gamma Stein equation (see [22] and
[15]). However, since we do not use the GH Stein equation to prove any approximation
results in this paper, we omit this analysis.

Proof of Proposition 3.1. Necessity. Suppose that W ∼ GH(λ, α, β, δ, 0). For convenience,
x − βδ2
we let A(x) = x2+δ2
x2 .

x2 and C(x) = 2λβ − (α2 − β2)x + β2δ2

, B(x) = 2λ + 2βδ2

x − δ2

x

10

By two applications of integration by parts, we obtain

E[Aλ,α,β,δf (W )] = E[A(W )f′′(W ) + B(W )f′(W ) + C(W )f (W )]
=Z ∞
−∞(cid:8)A(x)f′′(x) + B(x)f′(x) + C(x)f (x)(cid:9)p(x) dx
=Z ∞
−∞(cid:8)A(x)p′′(x) + (2A′(x) − B(x))p′(x) + (A′′(x) − B′(x) + C(x))p(x)(cid:9)f (x) dx
+hA(x)p(x)f′(x)i∞

+h(cid:8)B(x)p(x) − (A(x)p(x))′(cid:9)f (x)i∞

−∞

−∞

.

(3.10)

Note the conditions imposed on f ensure that the above expectation exists. Straightfor-
ward calculations show that

2A′(x) − B(x) = −2(λ − 1) − 2βx −

2βδ2
x −
A′′(x) − B′(x) + C(x) = 2(λ − 1)β − (α2 − β2)x +

δ2
x2 ,
β2δ2

x

+

2βδ2
x2 .

Therefore, by Corollary 3.3, the integral of equation (3.10) is equal to 0. We also have
that

A(x)p(x)f′(x) = =

x2 + δ2

x

p(x)f′(x),

(cid:8)B(x)p(x) − (A(x)p(x))′(cid:9)f (x) = (cid:8)B(x)p(x) − A′(x)p(x) − A(x)p′(x)(cid:9)f (x)
p′(x)(cid:21)f (x).

= (cid:20)(cid:18)2λ − 1 +

x (cid:19)p(x) −

x2 + δ2

2βδ2

x

The condition (3.2) for f and Lemma 2.1 imply that lim|x|→∞ xp(x)f′(x) = lim|x|→∞ p(x)f (x) =
lim|x|→∞ xp′(x)f (x) = 0, meaning that the ﬁnal two terms of (3.10) are equal to 0. This
completes the proof of necessity.

Suﬃciency. Let z ∈ R and consider the GH(λ, α, β, δ, 0) Stein equation with test

function 1(0,z](x):

Aλ,α,β,δf (x) = 1(0,z](x) − F (z),

(3.11)

where F (·) is the cumulative distribution function of Z ∼ GH(λ, α, β, δ, 0). The solution
to (3.11) is given by (3.6) with ˜h(x) replaced by 1(0,z](x) − F (z). This solution is clearly
piecewise twice continuously diﬀerentiable. By Lemma 3.5, we have that the solution and
its ﬁrst derivative are bounded. Also, rearranging the Stein equation (1.5) gives that

f′′z (x) =

x

2βδ2
x2 + δ2(cid:26)(cid:20)2λ +
x −
+(cid:20)2λβ − (α2 − β2)x +

δ2

x2(cid:21)f′z(x)
β2δ2
x −

βδ2

x2 (cid:21)fz(x) + 1(0,z](x) − F (z)(cid:27).

(3.12)

Since fz, f′z and are bounded for all x ∈ R, we have from (3.12) that lim|x|→∞ f′′z (x) =
(α2−β2) lim|x|→∞ fz(x), meaning that f′′(x) is bounded as |x| → ∞. Therefore fz satisﬁes

11

condition (3.2). As fz satisﬁes (3.11), it follows that E|Aλ,α,β,δfz(Z)| < ∞. Hence, if (3.1)
holds for all piecewise twice continuously diﬀerentiable functions satisfying (3.2) and such
that E|Aλ,α,β,δfz(Z)| < ∞, then by (3.11), we have that, for any z ∈ R,

0 = E[Aλ,α,β,δf (W )] = P(W ≤ z) − F (z),

and so L(W ) = GH(λ, α, β, δ, 0).

(cid:3)

3.2 Limiting cases of the generalized hyperbolic Stein equation

Here, we note a number of interesting limiting cases of the GH Stein equation (1.5). In
doing so, we note that many of the Stein equations from the current literature are limiting
cases of (1.5). For ease of presentation, we mostly present Stein operators, rather than
Stein equations.
Variance-gamma distribution. Taking the limit δ → 0 and setting ν = λ − 1/2 in the
GH(λ, α, β, δ, 0) Stein operator (1.5) gives the following Stein operator for VG2(ν, α, β, 0)
distribution:

Af (x) = xf′′(x) + (2ν + 1 + 2βx)f′(x) + ((2ν + 1)β − (α2 − β2)x)f (x),

(3.13)

which we recognise as the VG2(ν, α, β, 0) Stein operator that was obtained by [22]. A
Stein operator for the VG1(r, θ, σ, 0) distribution how follows on changing variables using
(2.7) and then multiplying through by σ2:

Af (x) = σ2xf′′(x) + (σ2r + 2θx)f′(x) + (rθ − x)f (x).
A Stein equation for the VG1(r, θ, σ, 0) distribution is therefore given by

(3.14)

σ2xf′′(x) + (σ2r + 2θx)f′(x) + (rθ − x)f (x) = h(x) − Eh(X),

where X ∼ VG1(r, θ, σ, 0). The solution of this Stein equation and its ﬁrst derivative
are bounded if h is bounded (see [22], Lemma 3.3), and it was shown by [15] that the
n-th derivative of the solution is bounded if all derivatives of h up to (n − 1)-th order are
bounded.
As was noted by [22], there are number of interesting special and limiting cases of the
Stein operator (3.14). Letting r = 2s, θ = (2λ)−1, µ = 0 and taking the limit σ → 0 in
(3.14) and then multipying through by λ gives the Stein operator

Af (x) = xf′(x) + (s − λx)f (x),

which is the classical Γ(s, λ) Stein operator (see [12] and [32]).

We also note that a Stein operator for the VG1(r, 0, σ/√r, 0) distribution is

xf′′(x) + σ2f′(x) − xf (x),
which in the limit r → ∞ is the classical N(0, σ2) Stein operator.

Af (x) =

σ2
r

12

Since Laplace(0, σ) D= VG1(2, 0, σ, 0), we have the following Stein operator for the

Laplace distribution:

Af (x) = σ2xf′′(x) + 2σ2f′(x) − xf (x),

although note that this Stein operator is diﬀerent from the Laplace Stein operator of [39].
Finally, taking r = 1, θ = 0, σ = σX σY and µ = 0 in (3.14) gives the following Stein
Y ) random

operator for distribution of the product of independent N(0, σ2
variables (see part (iii) of Proposition 1.3 of [22]):

X ) and N(0, σ2

Af (x) = σ2

Y f′(x) − xf (x),

X σ2

Y xf′′(x) + σ2

X σ2

which is in agreement with the Stein equation for the product of two independent, zero
mean normal random variables that was obtained by [21].

Student’s t distribution. Recall that the scaled and shifted Student’s t-distribution
with ν degrees of freedom, with density (2.6) is a limiting case of the GH(λ, α, β, δ, µ)
distribution with λ = − ν
2 < 0 and α, β → 0. A Stein operator for this distribution (with
µ = 0) can be obtained by taking these parameter values in the Stein operator (1.5):

Af (x) =

x2 + δ2

x

f′′(x) +(cid:18) − ν −

δ2

x2(cid:19)f′(x).

Setting f′(x) = xg(x) gives another Stein operator which has no singularity:

Ag(x) = (x2 + δ2)g′(x) − (ν − 1)xg(x).

Finally, applying a shift by µ gives a Stein operator the scaled and shifted Student’s
t-distribution with density (2.6):

Ag(x) = ((x − µ)2 + δ2)g′(x) − (ν − 1)(x − µ)g(x),

(3.15)

which is in agreement with the Stein operator of [15] for the scaled and shifted Student’s t-
distribution. In the special case δ = √ν, µ = 0, we obtain the Stein operator for Student’s
t-distribution that was obtained by [42]. It is interesting to note that the solution of the
Stein equation corresponding to (3.15) is bounded if the test function h is bounded, and
that its n-th derivative is bounded if ν − 2(n − 1) > 0 and the derivatives of h up to
(n − 1)-th order are bounded (see [15]).
GIG distribution. Recall that the GIG(λ, a, b) distribution arises as a limiting case of
the GH(λ, α, β, δ, µ) distribution when we take β = α − a
2 , α → ∞, δ → 0, αδ2 → b
and µ = 0. To obtain a Stein operator for the GIG distribution, we ﬁrst consider the
GH(λ, α, β, δ, 0) Stein operator applied to f (x) = xg(x). Using that f′(x) = xg′(x)+g(x),
f′′(x) = xg′′(x) + 2g′(x) and simplifying gives:

Ag(x) = (x2 + δ2)g′′(x) +(cid:18)2(β + 1)x2 + 2λx + 2(β + 1)δ2 −
βδ2
x −

+(cid:18) − (α2 − β2)x2 + 2(λ + 1)βx + 2λ + β2δ2 +

x(cid:19)g′(x)
x2(cid:19)g(x).

δ2

δ2

13

In anticipation of letting α and β tend to inﬁnity, we divide through by β to get another
Stein operator:

Ag(x) =

x2 + δ2

β

+(cid:18) −

g′′(x) +(cid:18)2(cid:18)1 +
α2 − β2

β

x2 + 2(λ + 1)x +

1

β(cid:19)x2 +

2λ
β
2λ
β

δ2

1

+ βδ2 +

βx(cid:19)g′(x)

β(cid:19)δ2 −
x + 2(cid:18)1 +
δ2
βx2(cid:19)g(x).
x −
2 , α → ∞, δ → 0, αδ2 → b

(3.16)

δ2

If β = α − a
in (3.16) gives the following Stein operator for the GIG(λ, a, b) distribution:

2 , then α2 − β2 = aβ + a2/4. Now, taking β = α − a

Ag(x) = 2x2g′(x) + (−ax2 + 2(λ + 1)x + b)g(x),

(3.17)

which we recognise as the GIG(λ, a, b) Stein operator of [30] (up to a multiple of 2). The
corresponding Stein equation is therefore

2x2g′(x) + (−ax2 + 2(λ + 1)x + b)g(x) = h(x) − Eh(X),

(3.18)

where X ∼ GIG(λ, a, b). To date, no bounds have been obtained for solution of the
general GIG(λ, a, b) Stein equation (3.18). However, the limiting case a → 0, which is
the inverse-gamma distribution, was treated by [15]. They showed that the solution of
the Stein equation (with a = 0) is bounded if λ < −1 and the test function h is bounded,
and that the n-th derivative of the solution is bounded if λ < −(2n + 1) and the n-th
derivative of h exists and is bounded.
It actually turns out that solving the GIG(λ, a, b) Stein equation (3.18) and then
bounding the solution is quite straightforward. This is because the density p, as given by
(2.1), satisﬁes the diﬀerential equation

(s(x)p(x))′ = τ (x)p(x),

where s(x) = 2x2 and τ (x) = −ax2 + 2(λ + 1)x + b, and the Stein equation (3.18) can be
written as s(x)g′(x) + τ (x)g(x) = h(x) − Eh(X). Therefore, by Proposition 1 of [42], we
have that the Stein equation (3.18) has solution

0

1

g(x) =

2x2p(x)Z x
2x2p(x)Z ∞
= −
Kλ+1(√ab)
Kλ(√ab)

1

x

√b√a

[h(t) − Eh(X)]p(t) dt

[h(t) − Eh(X)]p(t) dt.

Now, let l = EX =
[41] to obtain the following bound for the solution:

(see [16]). Then, if h is bounded, we can use Lemma 1 of

kgk ≤

1

2l2p(l)kh − Eh(X)k.

Therefore, the solutions of the variance-gamma, Student’s t and GIG Stein equations that
arise from the GH Stein equation (1.5) are all bounded provided the test function h is
bounded.

14

3.3 Applications of Proposition 3.1

The most common use of Stein characterisations of probability distributions is to identify
an appropriate Stein equation for that distribution, which is then applied through Stein’s
method to prove approximation theorems. However, as Stein characterisations charac-
terise probability distributions, we can use them to infer various distributional properties,
such as moments of distributions (see [22]), moment generating and characteristic func-
tions (see [21] and [22]), and formulas for probability density functions (see [23], in which
a new formula was established for the density of the distribution of the mixed product of
independent beta, gamma and centred normal random variables). We consider one such
example here.

Suppose W ∼ GH(λ, α, β, δ, 0). Then taking f (x) = xk (note that f satisﬁes the
conditions of Proposition 3.1) and setting Mk = EW k in the GH(λ, α, β, δ, 0) charac-
terising equation (3.1) leads to the following recurrence relation for the moments of the
GH(λ, α, β, δ, 0) distribution:

(α2 − β2)Mk+1 = 2λβMk +(cid:0)k(k − 1) + 2λkβδ2(cid:1)Mk−1 + (2k − 1)βδ2Mk−2

+ k(k − 2)δ2Mk−3.

(3.19)

We have that M0 = 1, M1 is given by (2.3), M2 can be read oﬀ from (2.4), and a short
calculation using the moment generating function (2.2) can be used to commute M3. Using
forward substitution in (3.19), one can then obtain formulas for moments of arbitrary order
of the GH(λ, α, β, δ, 0) distribution. The recurrence relation (3.19) appears to be new,
although it should be noted that [43] have already established a formula for the moments
of general order of the GH distribution.

A Elementary properties of modiﬁed Bessel functions

Here we list standard properties of modiﬁed Bessel functions that are used throughout
this paper. All these formulas can be found in [35].

The modiﬁed Bessel function of the ﬁrst kind of order ν ∈ R is deﬁned, for x ∈ R, by

The modiﬁed Bessel function of the second kind of order ν ∈ R is deﬁned, for x > 0, by

The modiﬁed Bessel functions Kν and Iν form a pair of linearly independent solutions to
the following diﬀerential equation:

The modiﬁed Bessel function of the second kind is symmetric in the index parameter ν:

x2f′′(x) + xf′(x) − (x2 + ν2)f (x) = 0.

(A.1)

Kν(x) = K−ν(x),
∀ν ∈ R,
K1/2(x) = K−1/2(x) =r π

2x

e−x.

15

(A.2)

(A.3)

∞

1

Γ(ν + k + 1)k!(cid:16)x

2(cid:17)ν+2k

.

e−x cosh(t) cosh(νt) dt.

Iν(x) =

Xk=0
Kν(x) =Z ∞

0

The modiﬁed Bessel functions have the following asymptotic behaviour. Let a0(ν) = 1
and

,

k = 1, 2, 3, . . . .

(A.4)

ak(ν) =

Then

(4ν2 − 12)(4ν2 − 32) · · · (4ν2 − (2k − 1)2)

k!8k

Kν(x) ∼ (2|ν|−1Γ(|ν|)x−|ν|, x ↓ 0, ν 6= 0,
x ↓ 0, ν = 0,
Kν(x) ∼ r π
x → ∞,
ex
√2πx
Iν(x) ∼

− log x,
Xk=0
e−x
(−1)k ak(ν)
Xk=0

x → ∞.

2x

ak(ν)

,

xk

,

xk

∞

∞

(A.5)

(A.6)

(A.7)

Acknowledgements

The author is supported by EPSRC grant EP/K032402/1.

References

[1] Arras, B., Azmoodeh, E., Poly, G. and Swan, Y. Stein’s method on the second Wiener

chaos : 2-Wasserstein distance. arXiv:1601:03301, 2016.

[2] Barbour, A. D. Stein’s method for diﬀusion approximations. Probab. Theory Rel. 84

(1990), pp. 297–322.

[3] Barbour, A. D., Holst, L. and Janson, S. Poisson Approximation. Oxford University

Press, Oxford, 1992.

[4] Barndorﬀ-Nielsen, O. E. Exponentially decreasing distributions for the logarithm of

particle size. Proc. Roy. Soc. London A 353 (1977), pp. 401–419.

[5] Barndorﬀ-Nielsen, O. E., Kent, J. and Sørensen, M. (1982): Normal Variance-Mean

Mixtures and z-Distributions. Int. Stat. Rev. 50 (1982), pp. 145-159.

[6] Bibby, B. M. and Sørensen, M. Hyperbolic Processes in Finance. In: Rachev, S. (Ed.),
Handbook of Heavy Tailed Distributions in Finance. Elsevier Science, Amsterdam
(2003), pp. 211–248.

[7] Chatterjee, S., Fulman, J. and R¨ollin, A. Exponential approximation by Stein’s
method and spectral graph theory. ALEA Lat. Am. J. Probab. Math. Stat. 8 (2011),
pp. 197–223.

[8] Chatterjee, S. and Shao, Q.–M. Nonnormal approximation by Steins method of ex-
changeable pairs with application to the Curie-Weiss model. Ann. Appl. Probab. 21
(2011), pp. 464–483.

16

[9] Chen, L. H. Y. Poisson approximation for dependent trials. Ann. Probab. 3 (1975),

pp. 534–545.

[10] Chen, L. H. Y., Goldstein, L. and Shao, Q–M. Normal Approximation by Stein’s

Method. Springer, 2011.

[11] Collins, P. J. Diﬀerential and Integral Equations. Oxford University Press, 2006.

[12] Diaconis, P. and Zabell, S. Closed Form Summation for Classical Distributions: Vari-

ations on a Theme of De Moivre. Statist. Sci. 6 (1991), pp. 284–302.

[13] D¨obler, C. Stein’s method of exchangeable pairs for the beta distribution and gener-

alizations. Electron. J. Probab. 20 no. 109 (2015), pp. 1–34.

[14] D¨obler, C. Distributional transformations without orthogonality relations. To appear

in J. Theoret. Probab., 2016+.

[15] D¨obler, C, Gaunt, R. E. and Vollmer, S. J. An iterative technique for bounding

derivatives of solutions of Stein equations. arXiv:1510:02623, 2015.

[16] Eberlein, E. and Hammerstein E. Generalized Hyperbolic and Inverse Gaussian Dis-
tributions: Limiting Cases and Approximation of Processes. in: Dalang, R. C. Dozzi,
M. Russo, F. (Eds.), Seminar on Stochastic Analysis, Random Fields and Applica-
tions IV, in: Progress in Probability 58 Birkh¨auser Verlag, (2004), pp. 105–153.

[17] Eberlein, E. and Keller, U. Hyperbolic distributions in ﬁnance. Bernoulli 1 (1995),

pp. 281–299.

[18] Eberlein, E. and Prause, K. The generalized hyperbolic model: ﬁnancial derivatives
and risk measures. In: Geman, H., Madan, D. B., Pliska, S. and Vorst, T. Eds.,
Mathematical ﬁnance – Bachelier Congress 2000 Springer, Berlin, (2001), pp. 245–
267.

[19] Eichelsbacher, P. and Martschink, B. Rates of Convergence in the Blume-Emery-

Griﬃths Model. J. Stat. Phys. 154 (2014), pp. 1483-1507.

[20] Eichelsbacher, P. and Th¨ale, C. Malliavin-Stein method for Variance-Gamma ap-

proximation on Wiener space. Electron. J. Probab. 20 no. 123 (2015), pp. 1–28.

[21] Gaunt, R. E. On Stein’s method for products of normal random variables and a

generalisation of the zero bias coupling. arXiv:1309.4344, 2013.

[22] Gaunt, R. E. Variance-Gamma approximation via Stein’s method. Electron. J.

Probab. 19 no. 38, pp. 1–33.

[23] Gaunt, R. E. Products of normal, beta and gamma random variables: Stein charac-

terisations and distributional theory. arXiv:1507.07696, 2015.

[24] Gaunt, R. E. Stein’s method for functions of multivariate normal random variables.

arXiv:1507.08688, 2015.

17

[25] Gaunt, R. E. Uniform bounds for expressions involving modiﬁed Bessel functions. To

appear in Math. Inequal. Appl., 2016+.

[26] Gaunt, R. E., Pickett, A. and Reinert, G. Chi-square approximation by Stein’s

method with application to Pearson’s statistic. arXiv:1507.01707, 2015.

[27] Gaunt, R. E. and Reinert, G. The rate of convergence of some asymptotically chi-

square distributed statistics by Stein’s method. arXiv:1603:01889, 2016.

[28] Goldstein, L. and Reinert, G. Stein’s method for the Beta distribution and the P´olya-

Eggenberger Urn. J. Appl. Probab. 50 (2013), pp. 1187–1205.

[29] G¨otze, F. On the rate of convergence in the multivariate CLT. Ann. Probab. 19

(1991), pp. 724–739.

[30] Koudou, A. E. and Ley, C. Characterizations of GIG laws: a survey complemented

with two new results. Probab. Surv. 11 (2014), pp. 161–176.

[31] Ley, C., Reinert, G. and Swan, Y. Approximate computation of expectations : a

canonical Stein operator. arXiv:1408.2998, 2014.

[32] Luk, H. Stein’s Method for the Gamma Distribution and Related Statistical Applica-

tions. PhD thesis, University of Southern California, 1994.

[33] Mackey, L., Jordan, M., I., Chen, R. Y., Farrell, B. and Tropp, J. A. Matrix concen-
tration inequalities via the method of exchangeable pairs. Ann. Probab. 42 (2014),
pp. 906–945.

[34] Madan, D. B. and Seneta, E. The Variance Gamma (V.G.) Model for Share Market

Returns. J. Bus. 63 (1990), pp. 511–524.

[35] Olver, F. W. J., Lozier, D. W., Boisvert, R. F. and Clark, C. W. NIST Handbook of

Mathematical Functions. Cambridge University Press, 2010.

[36] Pek¨oz, E. and R¨ollin, A. New rates for exponential approximation and the theorems

of R´enyi and Yaglom. Ann. Probab. 39 (2011) pp. 587–608.

[37] Pek¨oz, E., R¨ollin, A. and Ross, N. Degree asymptotics with rates for preferential

attachment random graphs. Ann. Appl. Probab. 23 (2013), pp. 1188–1218.

[38] Pek¨oz, E., R¨ollin, A. and Ross, N. Generalized gamma approximation with rates for

urns, walks and trees. To appear in Ann. Probab. 2016+.

[39] Pike, J. and Ren, H. Stein’s method and the Laplace distribution. ALEA Lat. Am.

J. Probab. Math. Stat. 11 (2014), pp. 571–587.

[40] Ross, N. Fundamentals of Stein’s method. Probab. Surv. 8 (2011), pp. 210-293.

[41] Schoutens, W. Orthogonal Polynomials in Steins Method. EURANDOM Report 99-

041, EURANDOM, 1999.

18

[42] Schoutens, W. Orthogonal polynomials in Stein’s method. J. Math. Anal. Appl. 253

(2001), pp. 515–531.

[43] Scott, D. J., W¨urtz, D. Dong, C. and Tran, T. T. Moments of the generalized hyper-

bolic distribution. Computation. Stat. 26 (2011), pp. 459–476.

[44] Stein, C. A bound for the error in the normal approximation to the the distribution
of a sum of dependent random variables. In Proc. Sixth Berkeley Symp. Math. Statis.
Prob. (1972), vol. 2, Univ. California Press, Berkeley, pp. 583–602.

[45] Stein, C. Approximate Computation of Expectations. IMS, Hayward, California, 1986.

19

