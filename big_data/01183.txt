6
1
0
2

 
r
a

M
3

 

 
 
]
S
D
h
t
a
m

.

[
 
 

1
v
3
8
1
1
0

.

3
0
6
1
:
v
i
X
r
a

Solving systems of polynomial inequalities with algebraic

geometry methods

Laura Menini∗, Corrado Possieri†and Antonio Tornambè‡

Dipartimento di Ingegneria Civile e Ingegneria Informatica, Università di Roma Tor

Vergata, Roma, Italy

Abstract

The goal of this paper is to provide computational tools able to ﬁnd a solution of a system
of polynomial inequalities. The set of inequalities is reformulated as a system of polynomial
equations. Three diﬀerent methods, two of which taken from the literature, are proposed to
compute solutions of such a system. An example of how such procedures can be used to solve the
static output feedback stabilization problem for a linear parametrically–varying system is reported.

Introduction

1
In several control problems, it is needed to guarantee the existence of real solutions, and, possibly,
to compute one of them, for a system of polynomial equalities or inequalities [1–3]. For instance, a
solution of a set of polynomial equalities and inequalities has to be found to solve the static output
feedback stabilization problem [4], to compute the equilibrium points of a nonlinear system [5], to
establish if a polynomial can be written as sum of squares [6], to study the stability of linear systems,
with structured uncertainty [7].

In this paper, three algorithms, which use the tools of algebraic geometry, are used to compute
solutions of a system of polynomial equations. Algebraic geometry tools have been already used for
control problems (see, for instance, [8–11]). The ﬁrst algorithm is based on the computation of a
quotient–ring basis [12, 13] and of the eigenvalues of some matrices characterizing such a basis. The
second algorithm is based on the Rational Univariate Representation [14] of a given ideal. The third
algorithm is based on the computation of a Groebner basis [12] of an ‘extended’ ideal. The ﬁrst two
algorithms are taken from the literature, whereas the last one is new, to the best authors’ knowledge.
Even if these techniques are able to solve only systems of equalities, by using the procedure given
in [15], it is possible to reformulate a set of inequalities into a set of equalities; whence, the three
mentioned algorithms can be also used to ﬁnd a solution of a set of inequalities. Moreover, thanks to
the recent advantages in Computer Algebra Systems, able to carry out complex algebraic geometry
computations (as, e.g., Macaulay2 [16]), by using the algorithm based on the computation of a Groebner
basis of an ‘extended’ ideal, which is the new main result, a solution to a set of polynomial inequalities
can be obtained also when some coeﬃcients of the polynomials are unknown parameters. Hence, when
the values of such parameters can be assumed to be known in real time, as for Linear Parametrically–
Varying (brieﬂy, LPV) system, the new method proposed here allows to compute oﬀ–line most of the
solution in parametric form, leaving only small portion of the computations to be executed in real time,
for the actual values of the parameters. In Section 5, this method is applied to compute a parameter
dependent Static Output Feedback (brieﬂy, SOF), which makes a LPV system asymptotically stable.

∗L. Menini: menini@disp.uniroma2.it
†C. Possieri: possieri@ing.uniroma2.it; Corresponding author.
‡A. Tornambè: tornambe@disp.uniroma2.it

1

2 Notation and preliminaries
In this section, some notions of algebraic geometry are recalled, following the exposition in [12, 13].
n , where αi, for
i = 1, . . . , n, are non–negative integers (i.e., α ∈ Zn≥0); a polynomial in x is a ﬁnite R–linear combination
of monomials in x. Let R[x] denote the ring of all the polynomials.
Given a set of polynomials {p1, . . . , ps} ⊂ R[x], the aﬃne variety deﬁned by p1, . . . , ps (see, e.g.,

xn ](cid:62). A monomial in x is a product of the form xα1

1 ··· xαn

Let x = [ x1

···

[17, 18]) is

V (p1, . . . , ps) = {x ∈ Rn : pi(x) = 0, i = 1, . . . , s},

whereas, the semi–algebraic set deﬁned by p1, . . . , ps is

W (p1, . . . , ps) = {x ∈ Rn : pi(x) ≥ 0, i = 1, . . . , s}.

(cid:80)s

The ideal (cid:104)p1, . . . , ps(cid:105) in R[x] is the set of all the polynomials q ∈ R[x], which can be expressed
as a ﬁnite linear combination of p1, . . . , ps, with polynomial coeﬃcients h1, . . . , hs ∈ R[x], i.e., q(x) =
i=1 hi(x)pi(x). Aﬃne varieties and ideals are notions linked by the concept of aﬃne variety of an
ideal. Let I be an ideal in R[x], the aﬃne variety of the ideal I, denoted by V (I), is the set

V (I) = {x ∈ Rn : q(x) = 0, ∀q ∈ I}.

A notation needed to analyze polynomials is the monomial ordering on R[x], denoted as >, which
is a relation on the set of monomials xα, α ∈ Zn≥0, satisfying the following properties: 1) if α > β and
γ ∈ Zn≥0, then α + γ > β + γ; 2) every nonempty subset of monomials has a smallest element under >.
The lex ordering is a monomial ordering, denoted by >l and deﬁned as: let α and β ∈ Zn≥0 be given,
then, α >l β if, in the vector diﬀerence α − β ∈ Zn, the ﬁrst nonzero entry is positive.
The leading term of a polynomial f (x), denoted by LT(f (x)), is, for a ﬁxed a monomial ordering, the
largest monomial appearing in f (x). For a ﬁxed a monomial ordering, a ﬁnite subset G = {g1, . . . , gl}
of an ideal I is said to be a Groebner basis of I if (cid:104)LT(g1), . . . , LT(gl)(cid:105) = (cid:104)LT(I)(cid:105), where the leading
term of the ideal I is LT(I) := {cxα : ∃ f ∈ I, with LT(f (x)) = cxα}. The remainder of the division
of a polynomial function f for the elements of a Groebner basis G of I, denoted by f
, is unique
and is a ﬁnite R–linear combination of monomials xα /∈ (cid:104)LT(I)(cid:105) (for more details see, e.g., [12, 19]).
Moreover, it can be easily checked that, given f, g ∈ R[x], one has that f
and that
G · gG
f
Let I be a given ideal in R[x1, . . . , xn]. The j-th elimination ideal of I is I j := I ∩R[xj+1, . . . , xn].
Let G be a Groebner basis of I, with respect to the lex ordering, with x1 >l x2 >l ··· >l xn. Then, by
the Elimination Theorem, for every 0 ≤ j ≤ n, the set Gj = G ∩ R[xj+1, . . . , xn] is a Groebner basis of
the j-th elimination ideal I j.

+ gG = f + g

= f · g

G

G

G

G

.

G

3 Algebraic geometry algorithms for solving systems of polyno-

mial equations

In this section, three methods to solve a system of polynomial equations, having a ﬁnite number of
solutions, are presented. The ﬁrst algorithm is based on the computation of a quotient–ring basis
and of the eigenvalues of some matrices characterizing this basis [12, 13]. The second one is based on
the computation of a Rational Univariate Representation of the solutions of the system of polynomial
equations [14]. The third one is based on the computation of a Groebner basis of an ‘extended’ ideal.
The ﬁrst two methods are taken from the literature, whereas, the last one is new, to the best authors
knowledge. Such methods are used in Section 4 to ﬁnd a solution to a system of polynomial inequalities.

2

3.1 Solution of a system of polynomial equations by using ﬁnite–dimensional

quotient rings

In this section, the basic notions of quotient rings are recalled and an algorithm, taken form [13]
and [20], to solve systems of polynomial equations is given.
Let I ⊂ R[x] be an ideal, and let f, g ∈ R[x]. The polynomials f and g are congruent modulo I,
denoted by f = g modI, if f − g ∈ I. The equivalence class of f modulo I, denoted by [f ]I, is deﬁned
as [f ]I = {g ∈ R[x] : g = f modI}. The quotient of R[x] modulo I, denoted by R[x]/I is the set of
all the equivalence classes modulo I,

R[x]/I = {[f ]I, f ∈ R[x]}.

G ∈ [f ]I. Hence, the remainder f
G

Let G be a Groebner basis of the ideal I, according to any monomial ordering. By the deﬁnition of
can be used as a standard representative
the class [f ]I, one has that f
of the class [f ]I (in the rest of this paper, the remainder f
is identiﬁed with its class [f ]I). Therefore,
since the operations of sum and product by a constant on R[x]/I have a one–to–one correspondence
with the same operations on the remainders, the elements in R[x]/I can be added and multiplied by
a constant. Thus, the quotient ring R[x]/I has the structure of a vector ﬁeld over R (it is called an
are R–linear combinations of monomials, none of which is in the
algebra). Since all the remainders f
ideal (cid:104)LT(I)(cid:105), it is possible to form a monomial basis B of the quotient ring R[x]/I as

G

G

B = {xα : xα /∈ (cid:104)LT(I)(cid:105)}.

i = LT(g), for some g ∈ G.

The following theorem gives conditions on I, for the algebra A = R[x]/I to be ﬁnite–dimensional.
Theorem 1. [13] Let I be an ideal in R[x] and let G be a Groebner basis of I, according to any
monomial ordering. The following conditions are equivalent:
1. The algebra A = R[x]/I is ﬁnite–dimensional over R.
2. The aﬃne variety V (I) is a ﬁnite set.
3. For each i ∈ {1, . . . , n}, there exists an mi ≥ 0 such that xmi
If an ideal I in R[x] is such that one of the conditions of Theorem 1 hold, then I is called zero
dimensional. An immediate consequence of Theorem 1 is that, if the ideal I is zero dimensional, then
any basis B of R[x]/I has a ﬁnite number of elements, which can be chosen to be all monomials. With
such a choice (assumed in the following), given a polynomial f ∈ R[x], one can use multiplication to
deﬁne a linear map mA

f between A = R[x]/I and itself. More precisely, mA
∀[g]I ∈ A.
Since the algebra A is ﬁnitely generated over R, then the map mA
f can be represented by its
The following two propositions characterize the elements of the aﬃne variety V (I) of a zero di-

associated matrix M A
mensional ideal I.
Proposition 1. [20] Let the ideal I in R[x] be zero dimensional. Let B = {b1, . . . , b(cid:96)} be the basis of
the ﬁnite–dimensional algebra A = R[x]/I. Let M A
be the matrix representing the linear map mA
,
with respect to the basis B, for i = 1, . . . , (cid:96). Deﬁne the real symmetric matrix T as:
bi

f , with respect to the chosen ﬁnite–dimensional basis B of A.

f ([g]I) = [f ]I · [g]I = [f · g]I ∈ A,
mA

f : A → A is deﬁned as:

bi

where [T ]j,k denotes the j × kth entry of T and Tr(·) is the trace operator. The number of elements
(including their multiplicity) of V (I) ⊂ R equals the signature of T , i.e.
the number of positive
eigenvalues of T minus the number of negative eigenvalues of T .

[T ]j,k = Tr(M A
bj

M A
bk

),

3

be the matrix representing
, with respect to the basis B, for i = 1, . . . , n. The real eigenvalues of the matrix

Proposition 2. [13] Let the assumptions of Proposition 1 hold. Let M A
xi
the linear map mA
are the xi–coordinates of the points of V (I) ⊂ Rn, for i = 1, . . . , n.
xi
M A
xi
By Proposition 1 and Proposition 2, Algorithm 1 is able to solve a system of polynomial equations

having a ﬁnite number of solutions.

Algorithm 1 Solution of polynomial equations through computation of eigenvalues.
Input: A zero dimensional ideal I in R[x].
Output: The points in V (I) ⊂ Rn.
1: Deﬁne the algebra A = R/I.
2: Compute a basis B = {b1, . . . , b(cid:96)} of the algebra A.
3: for i = 1 to n do
4:
5:
6: end for
7: Compute the matrix T , such that [T ]j,k = Tr(M A
bj
8: Let d be equal to the signature of the matrix T .
···
9: Let S be the set of the n–tuple sj = [ sj,1
10: return S = V (I).

j = 1, . . . , d, which are such that, for all f ∈ I, f (sj) = 0, for j = 1, . . . , d .

M A
bk

Compute the matrix M A
, representing the map .
Compute the set Ei of the real eigenvalues of M A
xi

.

xi

).
sj,n ](cid:62), sj,i ∈ Ei, for i = 1, . . . , n and for

is m × m, for
Remark 1. Let m be the dimension of the basis B. The dimension of the matrices M A
all i ∈ {1, . . . , n}. Therefore, the sets Ei, deﬁned at Step 5, for i = 1, . . . , n, are composed at most by
m elements. Thus, Step 9 of Algorithm 1 can be carried out by evaluating the polynomials p1, . . . , ps
at most in mn iterations.

xi

3.2 The Rational Univariate Representation
In this section, the Rational Univariate Representation (brieﬂy, RUR), which is able to solve a system
of polynomial equations is reported, following the exposition in [14].
Let C be the ﬁeld of complex number (which is the algebraic closure of R). Let I be a zero
dimensional ideal in R[x]. Let VC(I) ⊂ Cn be deﬁned as

VC(I) = {x ∈ Cn : q(x) = 0, ∀q ∈ I}.

A polynomial q ∈ R[x] is called separating with respect to VC(I) if ∀α, β ∈ VC(I), α (cid:54)= β, then
q(α) (cid:54)= q(β).
Let I be a zero dimensional ideal in R[x], let h be a polynomial in R[t] and let φ : VC(I) → VC((cid:104)h(cid:105))
be an isomorphism represented by a polynomial q ∈ R[t], i.e., φ(α) = q(α), for any α ∈ VC(I). The
pair (φ, h) is a Univariate Representation of VC(I) if, for any α ∈ VC(I), one has that µ(α) = µ(q(α)),
where the symbol µ(·) denotes the multiplicity of the element at argument.
On the other hand, letting I be a zero dimensional ideal in R[x], letting f be any polynomial in
R[x], letting B be a monomial basis of the algebra A = R[x]/I, letting M A
f be the matrix representing
f over the basis B and letting χf be the characteristic polynomial of the matrix M A
the linear map mA
f ,
deﬁne, for any ν ∈ R[x], the following polynomial

gf (ν, t) =

µ(α)ν(α) +

α∈VC(I)

y(cid:54)=f (α), y∈VC((cid:104)χf(cid:105))

the f–representation of I is the polynomial (n + 2)–tuple

{χf (t), gf (1, t), gf (x1, t),··· , gf (xn, t)},

4

(cid:88)

(cid:88)

(t − y),

where χf ∈ R[t], and, if f separates VC(I), the f–representation of I is called the Rational Univariate
Representation of I associated to f. If one is able to compute the RUR of I associated to f, then, the
set VC(I) can be obtained by computing the complex solutions to

(1)
Letting T be the set of all the complex solutions to (1) in t, one has that, by Theorem 3.1 of [14],

χf (t) = 0.

VC(I) = {[ gf (x1,t)

gf (1,t)

···

gf (xn,t)
gf (1,t)

](cid:62), ∀t ∈ T }.

Thus, by construction, the aﬃne variety V (I) ⊂ Rn can be computed as: V (I) = VC(I) ∩ Rn.
However, in [14], an alternative method to compute V (I) is given. Let TR be the set of the real
solutions to (1), i.e. TR = T ∩ R. One has that
V (I) = {[ gf (x1,t)

](cid:62), ∀t ∈ TR}.

···

gf (1,t)

gf (xn,t)
gf (1,t)

A test to compute the number of real roots, with their multiplicity, of an univariate polynomial on

R is given in [21]. Alternatively, the Sturm’s Test [22] can be used.

In [14] an algorithm is given to compute a RUR of a given zero dimensional ideal. Such algorithm
is not reported here for space reasons. An implementation of this algorithms in the CAS Maple is
available through the command RationalUnivariateRepresentation [23, 24].

Thus, the set of real solutions of a system of polynomial system of equations can be computed by

using Algorithm 2.

Algorithm 2 Solution of polynomial equations through RUR.
Input: A zero dimensional ideal I in R[x].
Output: The points in V (I) ⊂ Rn.
1: Compute the RUR {χf , gf (1, t),··· , gf (xn, t)}, of I.
2: Find the number d of real roots of χf .
3: Compute the set TR composed by d real roots of χf .
4: Deﬁne S = {[ gf (x1,t)
](cid:62), ∀t ∈ TR}.
5: return S = V (I).

gf (xn,t)
gf (1,t)

···

gf (1,t)

Remark 2. Note that, before using Algorithm 2, one has to verify that the ideal I is zero dimensional.
In [13] an eﬃcient method to check this property of the ideal I is given.

3.3 The real Polynomial Univariate Representation
In this section, an alternative method, with respect to the ones presented in Section 3.1 and in Sec-
tion 3.2, is presented. Such a method is based on the deﬁnition of an ‘extended’ ideal It = I ∪ (cid:104)h(cid:105) ∈
R[x, t], where h is a polynomial in x and t, and on the computation of the Groebner basis of It,
according to the lex ordering.

For a given ideal J , let J ∈ R[x, t] and let

V t(J ) = {(x, t) ∈ Rn × R : g(x, t) = 0, ∀g ∈ J },

and let the symbol V tC (J ) denote the set

V tC (J ) = {(x, t) ∈ Cn × C : g(x, t) = 0, ∀g ∈ J },

The projection map is deﬁned as the map πt : Cn × C → C, which send each couple (¯x, ¯t) ∈ V tC (J )

in ¯t.

The following theorem characterizes the projection map and can be proved by a little modiﬁcation

of the proof of the Closure Theorem given in [12].

5

Theorem 2. If the ideal It in R[x, t] is zero dimensional, one has that, letting I n

t = It ∩ R[t],

πt(V tC (It)) = {t ∈ C : g(t) = 0, ∀g ∈ I n
t }.

Consider the following assumption.

Assumption 1. Let I ⊂ R[x] be zero dimensional and let s ∈ R[x] be a polynomial separating with
respect to VC(I) ⊂ Cn. Let h be the following polynomial in R[x, t]:

h(x, t) = t − s(x),

where t is an auxiliary variable.

The following two lemmas characterize the ideal It = I∪(cid:104)h(cid:105) and the elimination ideal I n

t := It∩R[t].
Lemma 1. Let Assumption 1 hold. Let C = {c1, . . . , c(cid:96)} be any basis of the ideal I. The ideal
It = (cid:104)c1, . . . , c(cid:96), h(cid:105) ⊂ R[x, t] is zero dimensional.
Proof. Consider the ideal It. By [12], one has that It = I∪(cid:104)h(cid:105). Hence, since V tC (It) = V tC (I)∩V tC ((cid:104)h(cid:105))
[12] and since s is separating with respect to VC(I), one has that V tC (It) is a ﬁnite set. Thus, by
Theorem 1, It is zero dimensional.
Lemma 2. Let Assumption 1 hold. Let Gt be a Groebner basis of the ideal It = I ∪ (cid:104)h(cid:105), with respect
to any lex ordering, with xi >l t, for i = 1, . . . , n. There exists a polynomial η ∈ Gt ∩ R[t] diﬀerent
from the zero polynomial, and the roots in t of the polynomial η are in
T := {t ∈ C : t = f (x), ∀x ∈ VC(I)}.

Proof. By Lemma 1, the ideal It is zero dimensional. Hence, by Theorem 1, one has that there exists
a polynomial η diﬀerent from the zero polynomial, such that η ∈ Gt ∩ R[t], and, by the Elimination
:= It ∩ R[t]. Thus, by considering that
Theorem [12], one has that η is a Groebner basis of I n
πt(V tC (It)) = πt(V tC (I) ∩ V tC ((cid:104)h(cid:105))) = T , by Theorem 2, one has that T = {t ∈ C : g(t) = 0, ∀g ∈
(cid:104)η(cid:105)}.

t

Let the lex ordering, with x1 >l x2 >l ··· >l xn >l t, be ﬁxed. A real Polynomial Univariate

Representation (brieﬂy, PUR) of the ideal I is a (n + 1)–tuple

{η(t), gn(xn, t), gn−1(xn−1, t), . . . , g2(x2, t), g1(x1, t)},

which is such that η ∈ R[t], gi ∈ R[xi, t], LT(gi) = xi, for i = 1, . . . , n, and, letting TR be the set of all
the real solutions to η(t) = 0 in t,

V (I) = {x ∈ Rn : gi(xi, t) = 0, ∀t ∈ TR, i = 1, . . . , n}.

The following theorem gives a constructive method to compute the real PUR of a given ideal I.
Theorem 3. Let Assumption 1 hold. Let the lex ordering, with x1 >l x2 >l ··· >l xn >l t, be ﬁxed.
The Groebner basis Gt of the ideal It = I ∪ (cid:104)h(cid:105) is a real PUR of I.
Proof. By Lemma 2, one has that there exists an η ∈ Gt ∩ R[t] diﬀerent from the zero polynomial,
whose root are in the set T = {t ∈ C : t = f (x), ∀x ∈ VC(I)}. Let TR = T ∩ R be the set of the real
: Rn × R → R, which maps each couple (¯x, ¯t) in ¯xi,
roots of η. Let π
for i = 1, . . . , n. By the Lagrange Interpolation Formula [25], there exists a polynomial i(t) ∈ R[t],
((¯x, ¯t)) = i(¯t), for all the couples (¯x, ¯t) ∈ V t(It), for i = 1, . . . , n. Hence, in the
which is such that π
ideal It there exists polynomials wi = xi − i(t), for i = 1, . . . , n, and, by the deﬁnition of a Groebner
basis, one has that a Groebner basis of It is {η, wn, wn−1, . . . , w1} and, by construction, this is a real
PUR of the ideal I.

denote the projection map, π

R
xi

R
xi

R
xi

6

Algorithm 3 Solution of polynomial equations through PUR.
Input: A zero dimensional ideal I in R[x].
Output: The points in V (I) ⊂ Rn.
1: Deﬁne a random polynomial s(x) ∈ R[x] and the polynomial h(x, t) = t − s(x).
2: Letting {c1, . . . , c(cid:96)} be a set of generators of the ideal I, deﬁne the ideal It = (cid:104)c1, . . . , c(cid:96), h(cid:105).
3: Compute a Groebner basis Gt of the ideal It, according to lex ordering, with x1 >l x2 >l ··· >l
4: Verify that Gt is a real PUR, otherwise return to step 1.
5: Let Gt = {η(t), gn(xn, t), . . . , g1(x1, t)}, where gi = xi − i(t), with i ∈ R[t], for i = 1, . . . , n.
6: Find the number d of real solutions of η(t) = 0.
7: Compute the set TR of the d real solutions of η(t) = 0.
8: Deﬁne S = {[ 1(t)
n(t) ](cid:62), ∀t ∈ TR}.
9: return S = V (I).

xn >l t.

···

By Theorem 3, Algorithm 3 is able to compute the real solutions to a system of equations.

Remark 3. It can be easily proved that, if one deﬁne a random polynomial s(x), there is a probability
of 1 that it is separating (i.e., there exist isolated monomial coeﬃcients which makes the polynomial
s be not separating). Hence, the iterations required by Algorithm 3 are ﬁnite.
Remark 4. By [26], one has that the numerical computation of roots of the polynomial η, obtained by
using Algorithm 3 is, generally, numerically more complex than the computation of the roots of the
polynomial χf , obtained by using Algorithm 2. However, since the representation of V (I) obtained by
using Algorithm 3 is polynomial, it can be preferred to the rational one obtained by using Algorithm 2.
Remark 5. Note that the computations required by Algorithm 1 and Algorithm 3 can be carried
out also when some (or, possibly, all the) coeﬃcients of the polynomials p1, . . . , ps are functions of
some parameters. However, even if the computation of the matrices M A
is generally faster then the
computation of the Groebner basis Gt, since the computations which have to be carried out at Step 9
xi
of Algorithm 1 can be very computationally expensive, in many cases of practical interest, Algorithm 3
may be preferred, because the computations needed to solve Step 7 of Algorithm 3 can be carried out,
generally, in a faster way.

4 Solution of systems of polynomial inequalities
In this section, a procedure to compute, if any, a solution of a system of polynomial inequalities is
given. This method, based on penalizing variables and reported, e.g., in [15], is connected to the
solution of a set of polynomial equations, which can be computed with the algorithms of Section 3.

Consider the following problem.

···

xn ](cid:62). Let the set of polynomials P = {p1, . . . , ps} ⊂ R[x] be given.

Problem 1. Let x = [ x1
(a) Find, if any, a point ¯x ∈ W (p1, . . . , ps).
(b) Let {p1, . . . , p(cid:96)} ⊆ P. Find, if any, a point ¯x ∈ W (p1, . . . , ps), ¯x /∈ V (p1, . . . , p(cid:96)).

Note that a solution ¯x to Problem 1 (a) is a solution of the system of polynomial inequalities
pi(x) ≥ 0, for i = 1, . . . , s, whereas, a solution ¯x to Problem 1 (b) is a solution of the system of
polynomial inequalities pi(x) > 0, for i = 1, . . . , (cid:96), and pi(x) ≥ 0, for i = (cid:96) + 1, . . . , s.
··· ws ](cid:62) ∈ Rs be auxiliary variables. By [15],

vs ](cid:62) ∈ Rs and let w = [ w1

Let v = [ v1

···

Problem 1 (a) can be solved with the following procedure:

1. Let αi, βi, for i = 1, . . . , n, and γk, δk, for k = 1, . . . , s, be ﬁxed random real numbers.

7

2. Deﬁne the polynomial function J ∈ R[x, w]:

n(cid:88)

i=1

J =

αi(xi − βi)2 +

s(cid:88)

k=1

γk(wk − δk)2.

(2)

3. Deﬁne the polynomial function H ∈ R[x, v, w]

s(cid:88)

H = J +

vk(pk − w2
k).

4. Solve the following polynomial system of equations

k=1

∂H(x, v, w)

∂x

∂H(x, v, w)

∂v

∂H(x, v, w)

∂w

= 0,

= 0,

= 0,

(3a)

(3b)

(3c)

in [ x(cid:62) v(cid:62) w(cid:62) ](cid:62) ∈ Rn+2s.

5. Let πx : Rn+2s → Rn be the map which maps each vector [ x(cid:62) v(cid:62) w(cid:62) ](cid:62) ∈ Rn+2s in x ∈ Rn

and let S be the set of the solutions to (3). A solution to Problem 1 (a) is given by

{x ∈ Rn : x = πx(ζ), ∀ζ ∈ S}.

On the other hand, always by [15], a solution to Problem 1 (b) can be obtained by using the same

procedure used to solve Problem 1 (a), by changing only step 3):

3. Deﬁne the polynomial function H ∈ R[x, v, w]

(cid:96)(cid:88)

H = J +

vk(w2

kpk − 1) +

s(cid:88)

vk(pk − w2
k).

k=1

k=(cid:96)+1

Remark 6. By [15], one has that there exists a solution to (3) if and only if there exists a solution to
Problem 1.
Remark 7. Note that the solution to Problem 1 (a) (respectively, Problem 1 (b)) obtained by using
the procedure given in [15] corresponds to computing the stationary points of the function J in (2),
subject to the constraints pi(x) = w2
i pi(x) = 1, for i = 1, . . . , (cid:96),
i > 0, for i = 1, . . . , s. Therefore, since a point
and pj(x) = w2
[ ¯x(cid:62) ¯v(cid:62)
i pi(¯x) = 1, for i = 1, . . . , (cid:96), and
¯w(cid:62) ]) = ¯x is a solution to Problem 1 (a)
pj(x) = w2
(respectively, Problem 1 (b)).

¯w(cid:62) ](cid:62) ∈ S is such that pi(¯x) = ¯w2
j , for j = (cid:96) + 1, . . . , s), one has that πx([ ¯x(cid:62) ¯v(cid:62)

i , for i = 1, . . . , s (respectively, w2

j , for j = (cid:96) + 1, . . . , s), where w2

i ≥ 0 (respectively, ¯w2

∂x

, ∂H(x,v,w)

, ∂H(x,v,w)

By [15] one has that the ideal (cid:104) ∂H(x,v,w)

(cid:105) is, for almost any choice of αi, βi,
γk, δk, zero dimensional, Hence, step 4) of this procedure can be actually carried out by using one of
the three procedures given in Algorithm 1, Algorithm 2 or Algorithm 3 in Section 3.
Remark 8. Note that, as it is pointed out in Remark 5, Algorithm 1 and Algorithm 3 can be used
also when the coeﬃcients of the polynomials depend on some parameters. Hence, Problem 1 can be
solved also with parametric coeﬃcients of the polynomials p1, . . . , ps . Algorithm 3 may be preferred
to Algorithm 1, because the computations needed to carry out Step 7 of the ﬁrst one may be faster
then the ones needed to carry out Step 9 of the latter one.

∂w

∂v

8

Example 1. Let n = 2, x = [ x1 x2 ](cid:62), s = 2, p1(x) = −(16 − x2
p2(x) = 5x2
¯x ∈ W (p1, p2) ⊂ R2,

1 + 8x2)2,
v2 ](cid:62), w = [ w1 w2 ](cid:62). The goal is to compute a point

2 + (−16 + x2

2. Let v = [ v1

By using the procedure given in Section 4 one has to solve the following set of polynomial equations:

1 − x4

1 − 4x2

2 + x4

1)x2

qj(x, v, w) = 0,

for j = 1, . . . , 6,

where q1 = v1(10x1 − 4x3
2 − x2)2 + 2(−8w2
2 + x2
1) + 2v2x1((w2
1 − x2)2 − 2)(x2 − w2
1) − 2v2((x2
2 − 48x2 − x2
4v1((w2
1 + 48)w2
1−x2)4−4(w2
−x4
1−x2)2, q4 = (−8w2
2 +x2
1 +(w2
1) + 2γ1(w1 − δ1), q6 = 4v2w2((x2
(w2
and α1, α2, β1, β2, γ1, γ2, δ1, δ2 are random values.

1 +5x2
1 − x2)2)(x2 − w2

1 +8(x2−2))2 +(x2
2 − 48x2 − x2
1 + 48)w2

(4)
1 + 8(x2 − 2))) + 2α1(x1 − β1), q2 =
1(x2 + 8) + 128) + 2α2(x2 − β2), q3 =
1−16)(w2
2−x2)2, q5 = 8v1w1(2−
1(x2 + 8) + 128) + 2γ2(w2 − δ2)

Figure 1: Solutions to the problem of Example 1, for 100 diﬀerent values of the random constants.

The three algorithms given in Section 3 have been used to solve such a problem, with the same ran-
dom choices of the coeﬃcients α1, α2, β1, β2, γ1, γ2, δ1 and δ2. Figure 1 shows the results obtained by
using these algorithms, for 100 diﬀerent choices of the random parameters α1, α2, β1, β2, γ1, γ2, δ1 and δ2.
As such a ﬁgure shows, these procedures are able to solve a set of inequalities.

5 Application to a LPV SOF stabilization problem
In this section, the techniques given in this paper are used to solve the Static Output Feedback
problem [27] for a Linear Parametrically–Varying system [28].

9

-4-202401234x1x2SolutionsobtainedbyusingAlgorithm1.-4-202401234x1x2SolutionsobtainedbyusingAlgorithm2.-4-202401234x1x2SolutionsobtainedbyusingAlgorithm3.2��� Plotter.nbConsider the following missile model [29, 30]

˙α = καM ((anα2 + bnα + cn)α + dnδ) + q,
˙q = κqM ((amα2 + bmα + cm)α + dmδ),

(5a)
(5b)

where α is the angle of attack, q is the pitch rate, M is the Mach number of the missile, κα, κq, an,
bn, cn, dn, am, bm, cm, dm are known aerodynamic coeﬃcients and δ is the tail ﬁn deﬂection, which is
considered as the control input. It is assumed that the only available measure is the angle α.

System (5) can be rewritten as the following LPV system:

where θ1 = καM (anα2 + bnα + cn) and θ2 = κqM (amα2 + bmα + cm). Hence, letting θ = [ θ1

˙α = θ1α + q + καM dnδ
˙q = θ2α + κqM dmδ,

(cid:21)

(cid:20) καM dn

κqM dm

(cid:20) θ1

θ2

(cid:21)

1
0

A(θ) =

, B =

, C = [ 1

0 ],

(6a)
(6b)
θ2 ](cid:62),

(7a)
(7b)

x = [ α q ](cid:62), system (6) can be written as

˙x = A(θ)x + Bu,

y = Cx.

Problem 2. Let system (7) be given and let δ = K(θ)α, where K(θ), is a scalar gain, dependent on
the vector θ. Find a K(θ) and L ⊂ R2, such that the closed loop system

˙x = (A(θ) + BK(θ)C)x
is exponentially stable, with attraction domain containing L.
Remark 9. Consider that, by construction, the parameters θ1 and θ2 are dependent only on the state
α. Hence, if Problem 2 can be solved, system (7) can be stabilized by measuring α.

(8)

Consider the closed loop dynamic matrix

˜A(θ) = A(θ) + BK(θ)C.

Let p ˜A be the characteristic polynomial of the matrix ˜A(θ),

p ˜A(s, θ) = s2 + p1(θ)s + p2(θ),

where p1(θ) = −KM καdn − θ1 and p2(θ) = −KM dmκq − θ2. Let Θ be a subset of R2. One has that,
for each ﬁxed θ ∈ Θ, the eigenvalues of A(θ) are complex conjugate if

1(θ) − 4p2(θ) < 0,
p2
and the real parts of such eigenvalues are lower than −λ if

p1(θ) > 2λ.

(9a)

(9b)

where λ is a ﬁxed real value greater than zero.

By considering that (9) are polynomial inequalities, parametrized in the unknown vector θ, one has
that they can be actually solved by using the procedure given in Section 4 to transform such a set of
inequalities into a set of equalities, and Algorithm 3 to compute a solution K, depending on θ, of the
set of equalities. By using such a method one obtains the following two polynomials:

η(θ, t),

K(θ, t).

10

For each ﬁxed value ¯θ, one can obtain the correspondent gain K(¯θ), which is such that (9) holds, by
computing a solution ¯t of the equation η(¯θ, t) = 0 and setting K = K(¯θ, ¯t). Note that, by Remark 6,
if one is not able to ﬁnd a solution to η(¯θ, t) = 0, then there exists no solution to (9) for such a value
of ¯θ and for such a λ.

In the rest of this section, Assumption 2 is made.

Assumption 2. Let K(θ) = K(θ, ¯tθ), where ¯tθ is such that

Consider now system (5), with δ = K(θ)α. One has that

η(θ, ¯tθ) = 0.

˙θ1 = καM (2anα + bn) ˙α
˙θ2 = κqM (2amα + bm) ˙α

(10a)
(10b)

where ˙α = καM ((anα2 + bnα + cn)α + dnK(α)α) + q. Hence, by the deﬁnition of the parameters
θ1 and θ2 and of their time derivatives, one has that there exist polynomial functions φ1, φ2, ψ1 and
ψ2 ∈ R[x], which are such that

θ1 = φ1(x),
˙θ1 = ψ1(x),

θ2 = φ2(x),
˙θ2 = ψ2(x).

Assumption 3. Let system (8) be given, let D be a subset of the state space of system (8), with
0 ∈ D, and let

E = {θ ∈ R2 : ∃x ∈ D : θ1 = φ1(x), θ2 = φ2(x)},
F = {ω ∈ R2 : ∃x ∈ D : ω1 = ψ1(x), ω2 = ψ2(x)}.

(11a)
(11b)

1. The matrix ˜A(θ) is Lipschitz in θ in E, i.e. ∃LA:

(cid:107) ˜A(θ) − ˜A(θ(cid:48))(cid:107) < LA(cid:107)θ − θ(cid:48)(cid:107),

for all θ, θ(cid:48) ∈ E.

2. There exist constants m ≥ 1 and λ > 0 such that, for each ﬁxed ¯θ ∈ E, any solution of (8) is

3. Let LA be the Lipschitz constant of item 1) and let m and λ be the constants of item 2). One

such that

has that

(cid:107)x(t)(cid:107) ≤ me−λt(cid:107)x(0)(cid:107),

∀t ≥ 0.

(cid:107) ˙θ(cid:107) <

λ2

4LAm log(m)

for all ˙θ ∈ F.

,

The following three propositions show that for system (8), under Assumption 2, there exists a
domain D, with 0 ∈ D, such that items 1) – 3) of Assumption 3 hold, for some LA > 0, m > 0 and
λ > 0.
Proposition 3. Let Assumption 2 hold. One has that there exists a domain D1 ⊂ Rn, with 0 ∈ D1,
such that the closed loop dynamic matrix ˜A(¯θ) is Lipschitz in ¯θ in E1, with E1 deﬁned as in (11a), with
D replaced by D1.
Proof. The proof of this proposition follows directly by the deﬁnition of the matrix A(θ) and of the
matrix K(θ). As a matter of fact, the matrix A(θ) is trivially Lipschitz, whereas, the matrix K(θ)
is obtained by computing the roots of a polynomial whose coeﬃcients are polynomially dependent on
the parameters vector θ and using the polynomial K. On the other hand K(θ) is diﬀerentiable for all
the values of θ for which the following equalities in t

η(t, θ) = 0,

∂η(t, θ)

∂t

= 0,

11

(12)

have not real solution. As detailed in Remark 10 below, one has that the system of equalities (12) has
no solution for θ = [ φ1(x) φ2(x) ](cid:62), ∀x ∈ R2. Therefore, there exists a bounded domain D1, with
0 ∈ D1, such that (12) does not have any real solution, for all θ ∈ E1. Hence, also the function K(θ) is
Lipschitz in any bounded domain D1, with 0 ∈ D1, for some LA. Note that choosing a larger D1 will
render LA larger, in general cases.
(12) holds, with
the
Remark
[ φ1(x) φ2(x) ](cid:62)}
ideal
θ
, θ1 − φ1(x), θ2 − φ2(x)(cid:105) and by computing any Groebner basis G, with respect
J = (cid:104)η(t, θ), ∂η(t,θ)
to the lex order, with t >l θ1 >l θ2 >l q >l α, of such an ideal. Hence, letting g1, . . . , gl be the
polynomials in R[x] such that {g1, . . . , gl} = G ∩ R[x], all the points in the set N can be obtained as
the solution to the following equalities

{x
∈
computed

set N
can

10. Note

that

deﬁning

the

R2
by

:

=

∂t

=
be

g1(x) = 0,

···

gl(x) = 0,

which can be solved with the algorithms of Section 3. By applying Algorithm 3, it has be proved that
N is empty.

The following proposition can be easily proved by considering that, by using the techniques given
in [21], there exist a domain D2 ∈ R2, with 0 ∈ D2, such that η(θ, t) = 0 has a solution in t for
θ = [ φ1(x) φ2(x) ](cid:62), ∀x ∈ D2 and that, by Assumption 2, one has that (9) holds for all x ∈ D2.
Proposition 4. Let Assumption 2 hold. There exists a domain D2 ⊂ Rn, with 0 ∈ D2, such that,
letting E2 be deﬁned as in (11a), with D replaced by D2, there exists constant m ≥ 1 and λ > 0, such
that, any solution of (8) is such that

(cid:107)x(t)(cid:107) ≤ me−λt(cid:107)x(0)(cid:107),

for each ﬁxed ¯θ ∈ E2.

(13)

Proposition 5. Let Assumption 2 hold. Let LA be the Lipschitz constant chosen in the proof of
Proposition 3 and let m and λ be the constants chosen in the proof of Proposition 4. There exists
D3 ⊂ R2, with 0 ∈ D3, such that

(cid:107) ˙θ(cid:107) <

λ2

4LAm log(m)

for all ˙θ ∈ F,

,

(14)

where F is deﬁned as in (11b), with D replaced by D3.
Proof. By (10), ˙θ is a linear function of ˙α, and ˙θi
with 0 ∈ D3.

˙α is aﬃne in α. Hence, (14) holds in some domain D3,

By Proposition 3, Proposition 4 and Proposition 5, one has that system (8) is such that Assump-
tion 3 holds, with D = D1 ∩ D2 ∩ D3, where D1, D2 and D3 are the domains chosen in the proofs of
Proposition 3, Proposition 4 and Proposition 5, respectively. The following two theorems and lemma
show that the gain K(θ) and a domain L ⊂ D are a solution to Problem 2.
Theorem 4. [28] Let system (8) be given. Let Θ be the set of all the admissible parameters θ. Let
˜A(·) be Lipschitz continuous, with a Lipschitz constant LA, for each θ ∈ Θ. Assume that, for any
ﬁxed ¯θ ∈ Θ, any solution to the LTI system ˙x(t) = ˜A(¯θ)x(t) is such that there exist constants m ≥ 1
4LAm log(m) , ∀t ≥ 0, then 0 is exponentially
and λ > 0 such that a(cid:107)x(t)(cid:107) ≤ me−λt(cid:107)x(0)(cid:107). If (cid:107) ˙θ(t)(cid:107) <
stable, with respect to system (8).
Lemma 3. Let Assumption 2 and Assumption 3 hold. There exists L ⊂ D, such that, if x(0) ∈ L,
then x(t) ∈ D, ∀t ≥ 0.

λ2

12

Proof. By Assumption 2, one has that (9) holds. Hence, by [31], there exists a positive deﬁnite matrix
P (θ), such that

− I = ˜A(θ)P (θ) + ˜A(θ)(cid:62)P (θ),

P (θ) = (cid:82) ∞
(cid:107) ≤(cid:82) ∞

∂θi

∂θi

∂θi

0 eτ ˜A(θ)(cid:62)

eτ ˜A(θ)dτ,

=(cid:82) τ

0 e(τ−u) ˜A(θ) ∂ ˜A(θ)

(15a)
(15b)
where I is the 2–dimensional identity matrix, for all θ ∈ E. By the proof of Proposition 3, one has that
the matrix ˜A(θ) is diﬀerentiable. Hence, by [32], one has that ∂eτ ˜A(θ)
eu ˜A(θ)du,
for i = 1, 2. Therefore, by item 1) and item 2) of Assumption 3, one has that there exists constants
Ci > 0 and λi > 0 such that (cid:107) ∂P (θ)
0 Ciτ e−2λiτ dτ < ∞, i = 1, 2. Hence, there exists a constant
LP , such that (cid:107)P (θ) − P (θ(cid:48))(cid:107) < LP(cid:107)θ − θ(cid:48)(cid:107), for each θ, θ(cid:48) ∈ E. Hence, due to (15a), the function
V = x(cid:62)P (θ)x is such that ˙V ≤ x(cid:62)(LP(cid:107) ˙θ(cid:107) − 1)x, for ˙θ = [ ψ1(x) ψ2(x) ](cid:62), ∀x ∈ D. Hence, by
the continuity of the functions ψ1(x) and ψ2(x) and since ψ1(0) = ψ2(0) = 0, there exists a domain
H = {x ∈ D : (cid:107)[ ψ1(x) ψ2(x) ](cid:62)(cid:107) < L−1
P } such that 0 ∈ H. Thus, let c > 0 be the largest
constant such that W(θ) = {x ∈ R2 : x(cid:62)P (θ)x < c} is a subset of H, for all θ ∈ E. Deﬁne the set
L = ∩θ∈EW(θ). Since V is a Lyapunov function, with respect to system (8), one has that, if x(0) ∈ L,
then x(t) ∈ H ⊂ D, for all times t ≥ 0.
Theorem 5. Let the assumptions of Lemma 3 hold. Then 0 is exponentially stable for system (8),
with L being a conservative estimate of the attraction domain.
Proof. By Lemma 3, if x(0) ∈ L, then x(t) ∈ D, for all times t ≥ 0. Hence, since, if x(t) ∈ D, for all
times t ≥ 0, all the assumptions of Theorem 4 hold, then 0 is exponentially stable, with respect to
system (8).

By Theorem 5, K(θ) and L are a solution to Problem 2.
A gain K, dependent on the parameters θ has been computed by solving (9), with λ = 15, by using
the procedure given in Section 4 and Algorithm 3 to compute the polynomials η(θ, t) and K(θ, t). One
has that the domain D = {x = [ α q ](cid:62) ∈ R2 :
|α| ≤ 100, |q| ≤ 100} is such that all the conditions
of Assumption 3 hold, with LA = 50, λ = 14.5 and m = 1.0026. A simulation has been carried out,
with K(θ) = K(θ, ¯t), where ¯t is a solution to η(θ, t) = 0, from initial conditions starting inside the
domain Q = {x ∈ D : α ≥ 0, q ≥ −5, q ≤ 100} ∪ {x ∈ D : α ≤ 0, q ≥ −100, q ≤ 5}. Figure 2 shows
the trajectories of the system (8) with x(0) ∈ Q.

Figure 2: Trajectories of system (8), with x(0) ∈ Q.

6 Conclusions
Three algorithmic procedures for solving systems of polynomial inequalities are described. The ﬁrst
step, common to the three, is the classical [15] reduction to a system of equalities. To solve this last

13

−505−100−50050100αqsystem two available methods have been adapted and a new one has been derived. The latter one has
been used to solve the Static Output Feedback stabilization problem for a LPV system.

References
[1] C. T. Abdallah, P. Dorato, R. Liska, S. Steinberg, and W. Yang, “Applications of quantiﬁer

elimination theory to control theory,” 1995.

[2] D. Henrion and A. Garulli, Positive polynomials in control. Springer, New York, 2005.

[3] G. Chesi, “LMI techniques for optimization over polynomials in control: a survey,” Automatic

Control, IEEE Transactions on, vol. 55, no. 11, pp. 2500–2510, 2010.

[4] A. Astolﬁ and P. Colaneri, “The static output feedback stabilization problem as a concave-convex

programming problem,” in American Control Conference, 2004. Proceedings of the, 2004.

[5] M. Vidyasagar, Nonlinear systems analysis, vol. 42. Siam, 2002.

[6] P. A. Parillo, Structured semideﬁnite programs and semialgebraic geometry methods in robustness

and optimization. PhD thesis, California Institute of Technology, 2000.

[7] G. Chesi, A. Garulli, A. Tesi, and A. Vicino, “Robust stability of time-varying polytopic systems
via parameter-dependent homogeneous lyapunov functions,” Automatica, vol. 43, no. 2, pp. 309–
316, 2007.

[8] S. Diop, “Elimination in control theory,” Mathematics of control, signals and systems, vol. 4, no. 1,

pp. 17–32, 1991.

[9] L. Menini and A. Tornambe, “On the use of algebraic geometry for the design of high-gain observers

for continuous-time polynomial systems,” in IFAC World Congress, vol. 19, pp. 43–48, 2014.

[10] L. Menini, C. Possieri, and A. Tornambe, “On observer design for a class of continuous-time aﬃne
switched or switching systems,” in 53rd IEEE Conference on Decision and Control (IEEE, ed.),
(Los Angeles, CA), pp. 6234–6239, 2014.

[11] C. Possieri and A. Tornambe, “On polynomial vector ﬁelds having a given aﬃne variety as at-
tractive and invariant set: application to robotics,” International Journal of Control, pp. 1–40,
2014.

[12] D. A. Cox, J. B. Little, and D. O’Shea, Ideals, Varieties, and Algorithms: an introduction to

computational algebraic geometry and commutative algebra. Springer Verlag, 1992.

[13] D. A. Cox, J. B. Little, and D. O’Shea, Using algebraic geometry. Springer New York, 1998.

[14] F. Rouillier, “Solving zero-dimensional systems through the rational univariate representation,”
Applicable Algebra in Engineering, Communication and Computing, vol. 9, no. 5, pp. 433–461,
1999.

[15] B. D. O. Anderson and R. W. Scott, “Output feedback stabilization—solution by algebraic geom-

etry methods,” Proceedings of the IEEE, vol. 65, no. 6, pp. 849–861, 1977.

[16] D. R. Grayson and M. E. Stillman, “Macaulay2, a software system for research in algebraic

geometry.” http://www.math.uiuc.edu/Macaulay2/.

[17] V. I. Danilov and V. V. Šokurov, Algebraic curves, algebraic manifolds, and schemes, vol. 23.

Springer, 1998.

14

[18] Q. Liu and R. Erné, Algebraic geometry and arithmetic curves, vol. 6. Oxford university press

Oxford, 2002.

[19] B. Buchberger, “Bruno Buchberger’s PhD thesis 1965: An algorithm for ﬁnding the basis elements
of the residue class ring of a zero dimensional polynomial ideal,” Journal of symbolic computation,
vol. 41, no. 3, pp. 475–511, 2006.

[20] B. Sturmfels, Solving systems of polynomial equations, vol. 97. American Mathematical Soc.,

2002.

[21] L. Yang, “Recent advances on determining the number of real roots of parametric polynomials,”

Journal of Symbolic Computation, vol. 28, no. 1, pp. 225–242, 1999.

[22] L. González-Vega, T. Recio, H. Lombardi, and M.-F. Roy, Sturm—Habicht Sequences, Determi-

nants and Real Roots of Univariate Polynomials. Springer, 1998.

[23] J.-C. Faugère, “Fgb – a software for computing gröbner bases.” http://fgbrs.lip6.fr.

[24] F. Rouillier., “Rs – a software for real solving of algebraic systems.” ttp://fgbrs.lip6.fr.

[25] T. Sauer and Y. Xu, “On multivariate lagrange interpolation,” Mathematics of Computation,

vol. 64, no. 211, pp. 1147–1170, 1995.

[26] M.-E. Alonso, E. Becker, M.-F. Roy, and T. Wörmann, “Zeros, multiplicities, and idempotents
for zero-dimensional systems,” in Algorithms in algebraic geometry and applications, pp. 1–15,
Springer, 1996.

[27] V. L. Syrmos, C. T. Abdallah, P. Dorato, and K. Grigoriadis, “Static output feedback—a survey,”

Automatica, vol. 33, no. 2, pp. 125–137, 1997.

[28] J. Mohammadpour and C. W. Scherer, Control of linear parameter varying systems with applica-

tions. Springer Science & Business Media, 2012.

[29] R. A. Nichols, R. T. Reichert, and W. J. Rugh, “Gain scheduling for h-inﬁnity controllers: A ﬂight
control example,” Control Systems Technology, IEEE Transactions on, vol. 1, no. 2, pp. 69–79,
1993.

[30] C. Scherer, R. Njio, and S. Bennani, “Parametrically varying ﬂight control system design with full

block scalings,” in IEEE Conference on Decision and Control, vol. 2, pp. 1510–1515, 1997.

[31] C. Desoer, “Slowly varying system x= a (t) x,” Automatic Control, IEEE Transactions on, vol. 14,

no. 6, pp. 780–781, 1969.

[32] R. Wilcox, “Exponential operators and parameter diﬀerentiation in quantum physics,” Journal of

Mathematical Physics, vol. 8, no. 4, pp. 962–982, 1967.

15

