6
1
0
2

 
r
a

PROBABILISTIC AND AVERAGE LINEAR WIDTHS OF

WEIGHTED SOBOLEV SPACES ON THE BALL EQUIPPED

WITH A GAUSSIAN MEASURE

HEPING WANG

 

M
5
1
 
 
]

.

A
C
h
t
a
m

[
 
 

1
v
8
7
5
4
0

.

3
0
6
1
:
v
i
X
r
a

Abstract. Let Lq,µ, 1 ≤ q ≤ ∞, denotes the weighted Lq space of functions
on the unit ball Bd with respect to weight (1 − kxk2
2 , µ ≥ 0, and let
2,µ be the weighted Sobolev space on Bd with a Gaussian measure ν. We
W r
investigate the probabilistic linear (n, δ)-widths λn,δ (W r
2,µ, ν, Lq,µ) and the
2,µ, µ, Lq,µ)p, and obtain their asymptotic
p-average linear n-widths λ
orders for all 1 ≤ q ≤ ∞ and 0 < p < ∞.

2)µ− 1

(a)
n (W r

1. Introduction

Let K be a bounded subset of a normed linear space X with norm k · kX. The

linear and Kolmogorov n-widths of the set K in X are deﬁned by

and

λn(K, X) := inf
Tn

x∈K kx − LnxkX ,
sup

dn(K, X) := inf
Fn

sup
x∈K

y∈Fn kx − ykX,
inf

respectively, where Tn runs over all linear operators from X to X with rank at most
n, and Fn runs through all possible linear subspaces of X with dimension at most n.
They reﬂect the optimal errors of the “worst” elements of K in the approximation
by linear operators with rank n and n-dimensional subspaces.

Now let W be a separable Banach space and assume that W contains a Borel
ﬁeld B consisting of open subsets of W and is equipped with a probability measure
γ deﬁned on B. For 0 < p < ∞, the p-average linear and Kolmogorov n-widths are
deﬁned by

λ(a)
n (W, γ, X)p = inf

d(a)
n (W, γ, X)p = inf

Ln(cid:16)ZW kx − Lnxkp
Fn(cid:16)ZW

y∈Fn kx − ykp
inf

X γ(dx)(cid:17)1/p
X γ(dx)(cid:17)1/p

,

,

and

respectively. They reﬂect the optimal approximation of “most” elements of classes
by linear operators with rank n and n-dimensional subspaces. We stress that for a
centered Gaussian measure, the averaging parameter p is irrelevant up to a constant
(see [12, Theorem 1.2] or [29, Corollary 1]).

2010 Mathematics Subject Classiﬁcation. 41A46; 41A63; 42A61; 46C99.
Key words and phrases. ball, average linear widths, probabilistic linear widths, weighted

Sobolev space, Gaussian measure.

Supported by the National Natural Science Foundation of China (Project No. 11271263), the

Beijing Natural Science Foundation (1132001), and BCMIIS..

1

2

HEPING WANG

Let δ ∈ [0, 1). The probabilistic linear and Kolmogorov (n, δ)-widths of a set W

with a measure γ in the space X are deﬁned by

and

λn,δ(W, γ, X) = inf
Gδ

λn(W\Gδ, X),

dn,δ(W, γ, X) = inf
Gδ

dn(W\Gδ, X),

respectively, where Gδ runs through all possible measurable subsets in W with
measure γ(Gδ) ≤ δ. Hence, the probabilistic linear and Kolmogorov (n, δ)-widths
can be understood as the γ-distribution of the approximation on all measurable
subsets of W by linear operators with rank n and by n-dimensional subspaces.
Therefore, the probabilistic case setting reﬂects the intrinsic structure of the class,
and compared with the worst case setting, allows one to give deeper analysis of the
approximation for the function class.

This paper is devoted to discussing the average and probabilistic linear widths
of weighted Sobolev spaces on the unit ball with a Gaussian measure. Let Bd =
{x ∈ Rd :
kxk2 ≤ 1} denote the unit ball in Rd, where x · y is the usual inner
product, and kxk2 = (x·x)1/2 is the usual Euclidean norm. For the weight Wµ(x) =
2)µ−1/2 (µ ≥ 0), denote by Lp,µ ≡ Lp(Bd, Wµ(x) dx), 1 ≤ p < ∞, the space
(1−kxk2
of measurable functions deﬁned on Bd with the ﬁnite norm

kfkp,µ :=(cid:16)ZBd |f (x)|p Wµ(x)dx(cid:17)1/p

,

1 ≤ p < ∞,

and for p = ∞ we assume that L∞,µ is replaced by the space C(Bd) of continuous
functions on Bd with the uniform norm.
n the space of all polynomials in d variables of degree at most
n the space of all polynomials of degree n which are orthogonal to

We denote by Πd

n, and by V d
polynomials of low degree in L2,µ. Note that

ad
n := dimV d

n =(cid:18)n + d − 1

n

(cid:19) ≍ nd−1.

It is well known (see [9, p. 38 or p. 229]) that the spaces V d
n are just the eigenspaces
corresponding to the eigenvalues −n(n + 2µ + d − 1) =: −λn of the second-order
diﬀerential operator

Dµ := △ − (x · ∇)2 − (2µ + d − 1) x · ∇,

where the △ and ∇ are the Laplace operator and gradient operator respectively.
More precisely,

DµP = −n(n + 2µ + d − 1)P = −λnP for P ∈ V d
n.

n are mutually orthogonal in L2,µ and

Also, the spaces V d
(1.1)

L2,µ =

∞Mn=0
{φnk ≡ φd
be a ﬁxed orthonormal basis for V d

nMk=0
nk | k = 1, . . . , ad
n}
n. Then we know that

V d
n,

Let

Πd

n =

V d
n.

{φnk | k = 1, . . . , ad

n, n = 0, 1, 2, . . .}

is an orthonormal basis for L2,µ with inner product

hf, gi :=ZBd

f (x)g(x)Wµ(x) dx.

Denote by Sn the orthogonal projector of L2,µ onto Πd
n, which is called the Fourier
partial summation operator. Evidently, for any f ∈ L2,µ, (1.1) can be rewritten in
the form

3

f =

P rojnf,

Sn(f ) :=

P rojkf,

nXk=0

∞Xn=0
nXk=1

ad

hφnk, fiφnk(x) =ZBd

where P rojn is the orthogonal projector from L2,µ onto V d

n and can be written as

(1.2)

P rojn(f )(x) =

f (y)Pn(x, y)Wµ(y) dy,

where Pn(x, y) =Pad

n

k=1 φnk(x)φnk(y) is the reproducing kernel for V d

n. It is known

that for µ > 0, the kernel Pn(x, y) has the compact representation (see [32])
(1.3)
Pn(x, y) = bµ
d b

µ− 1
2
1

n + λ

Cλ

n(cid:16)(x, y) + uq1 − kxk2

2q1 − kyk2

2(cid:17)(1 − u2)µ−1du.

Z 1

−1

λ

n is the n-th degree Gegenbauer polynomial, λ = µ + d−1
2 ,

2)γ−1/2dx)−1. See [32] for the proof of the formula of Pn(x, y),

Here, Cλ
bγ
including the limiting case of µ = 0.

d := (RBd(1 − kxk2

Given r ∈ R, we deﬁne the fractional power (−Dd

µ)r/2 of the operator −Dd

µ on

f by

∞Xk=1

∞Xk=1

(−Dd

µ)r/2(f ) =

(k(k + 2µ + d − 1))r/2P rojk(f ) =

λr/2
k P rojk(f ),

in the sense of distribution. We call f (r) := (−Dd
of the distribution f .

For r > 0, the weighted Sobolev space W r

µ)r/2(f ) the r-th-order derivative

2,µ ≡ W r

2,µ(Bd) is deﬁned by

W r

2,µ :=nf =
∞Xn=1
kfk2

W r

2,µ

P rojn(f ) =

∞Xn=1
:= hf (r), f (r)i =

with inner product

ad

hφnk, fiφnk (cid:12)(cid:12)(cid:12) ZBd
nXk=1
∞Xn=1

λr
nkP rojnfk2

2,µ =

f (x)Wµ(x)dx = 0,

λr
n

∞Xn=1

ad

nXk=1

| ˆfnk|2 < ∞o

hf, gir := hf (r), g(r)i.

Obviously, it is a Hilbert space. If 1 ≤ q ≤ ∞, r > (d + 2µ)( 1
space W r

q )+, then the
2,µ can be continuously embedded into the space Lq,µ (see [29, Lemma 1]).
2,µ with a Gaussian measure ν whose mean is zero and whose correla-
l , l = 1, 2, . . . and eigenvalues

tion operator Cν has eigenfunctions φlk, k = 1, . . . , ad

We equip W r

2 − 1

νl = λ−s/2

l

,

s > d,

that is,

Cν φlk = λ−s/2

l

φlk,

k = 1, . . . , ad
l ,

l = 1, 2, . . . .

4

HEPING WANG

Then (see [2, pp. 48-49]),

L2(W r

2,µ, ν) the usual space of ν-measurable functionals φ on W r

the space of all continuous linear functionals on W r

2,µ, and by
2 with ﬁnite norm

2,µ(cid:1)∗
Denote by(cid:0)W r

hCν f, gir =ZW r

2,µ

hf, hirhg, hirν(dh).

kφkL2(ν) :=(cid:16)ZW r

2,µ

|φ(x)|2ν(dx)(cid:17)1/2

.

2,µ :

= W r

2,µ(cid:1)∗
Then(cid:0)W r
H(ν) =ng ∈ W r
Rν(f )(g) :=ZW r

where

2,µ

2,µ can be embedded into L2(W r

2,µ, ν). Put (see [2, p. 44])

|g|H(ν) :=

f ∈(cid:0)W r
2,µ(cid:1)∗

hh, fir hh, gir ν(dh),

sup
=W r

2,µ, Rν (f )(f )≤1

|hf, gi| < ∞o,
2,µ(cid:1)∗
f , g ∈(cid:0)W r

= W r

2,µ.

The space H(ν) is called the Cameron-Martin space (or the reproducing kernel
Hilbert space) of ν. Set ρ = r + s/2. It is easy to see from [2, pp. 48-49] that the
Cameron-Martin space H(ν) of the Gaussian measure ν is W ρ

2,µ, i.e.,

(1.4)

H(ν) = W ρ
2,µ

and (·,·)H(ν) = h·,·iρ.

Then the covariance of ν

Rν (f )(g) =ZW r

2,µ

(1.5)

hf, hirhg, hirν(dh) = hCν f, gir = hCν f, Cνgiρ.

is equal to

For any ﬁxed f1, . . . , fn ∈ W r

measurable space (W r

2,µ, the random vector (hf, f1ir, . . . ,hf, fnir) on the
2,µ, ν) has the centered Gaussian distribution with covariance

matrix(cid:0)hCν fi, fjir(cid:1)i,j=1,...,n =(cid:0)hCν fi, Cνfjiρ(cid:1)i,j=1,...,n. In special, on the cylindri-
cal subsets, the measure ν has the form: let gk, k = 1, 2, . . . , n be any orthonormal
system of functions in L2,µ, gk ∈ H(ν) = W ρ
2,µ, and let D be an arbitrary Borel
subset of Rn, then the measure of the cylindrical subset
1 i,··· ,hf, g(ρ)

G =nf ∈ W r

µ(G) = (2π)− n

2,µ | (hf, g(ρ)
2 ZD

exp(−

1
2

nXl=1

n i) ∈ Do

u2
l )du1 ··· dun.

2 − 1

See [2] and [13] for more information about Gaussian measure on Banach spaces.
Throughout the paper, we always suppose that ν is the above Gaussian measure
on W r

q )+, s > d, and ρ = r + s/2.

2,µ, r > (d + 2µ)( 1

The aim of the paper is to study the average and probabilistic linear widths of
W r
2,µ with the measure ν in Lq,µ. Probabilistic and average widths has been studied
only recently and are closely related with some other diﬀerent problems, such as
ε-complexity and the minimal error of problems of function approximation and
integration by using standard or general linear information, in the probabilistic and
average case setting (see [24], [22]). A few interesting results have been obtained.
These include results on probabilistic and average Kolmogorov and linear widths of
a Sobolev space of single-variate periodic functions with a Gaussian measure and

5

the Cr[0, 1] space equipped with the r-fold Wiener measure in the Lq norm for
1 ≤ q ≤ ∞ (see [10, 11, 14, 15, 16, 17, 18, 19, 23, 25]), of a space of multivariate
periodic Sobolev functions equipped with a Gaussian measure in the Lq norm for
1 < q < ∞ (see [3, 4, 28]), and of a Sobolev space W r
2 (Md−1) with a Gaussian
measure on compact two-point homogeneous spaces Md−1 for 1 ≤ q ≤ ∞ (see [26]).
In the worst and average case setting, the orders of the Kolmogorov and linear
widths of weighted Sobolev classes on Bd in Lq,µ were presented in [27] and [29]
respectively. More information about average and probabilistic case setting results
can be found in [22] and [24].

In this paper, we investigate probabilistic and average linear widths of the
weighted Sobolev space W r
2,µ with the measure ν in Lq,µ, and obtain the sharp
estimation. Our main results (Theorems 1.1 and 1.2 below) can be formulated as
follows:
Theorem 1.1. Let δ ∈ (0, 1/2], 1 ≤ q ≤ ∞, and let ρ > d/2 + 2µd(1/2 − 1/q)+.
Then

(1.6)

λn,δ(W r

2,µ, ν, Lq,µ) ≍(cid:26) n− ρ

n− ρ

d + 1
d + 1

2(cid:0)1 + n− min{ 1
2(cid:0) ln(n/δ)(cid:1)1/2

,

2 , 1

q }(ln( 1

δ ))

1

2(cid:1), 1 ≤ q < ∞,

q = ∞,

where A(n, δ) ≍ B(n, δ) means A(n, δ) ≪ B(n, δ) and B(n, δ) ≪ A(n, δ), A(n, δ) ≪
B(n, δ) means that there exists a positive constant c independent of n and δ such
that A(n, δ) ≤ cB(n, δ) for any n ∈ N and δ ∈ (0, 1/2].
Theorem 1.2. Let 0 < p < ∞, 1 ≤ q ≤ ∞, and let ρ be given as in Theorem 1.1.
Then

(1.7)

λ(a)
n (W r

2,µ, ν, Lq,µ)p ≍(cid:26) n−ρ/d+1/2,

n−ρ/d+1/2pln(en),

1 ≤ q < ∞,
q = ∞.

n (W r

Theorem 1.2 extends (2.17) in [29] which gave the orders of λ(a)

2,µ, ν, Lq,µ)p
for 1 ≤ q < 2 + 1/µ and 0 < p < ∞. The proof of Theorem 1.2 is diﬀerent from the
one in [29]. We use Theorem 1.1 to prove Theorem 1.2. In order to prove Theorem
1.1, we also use the discretization method as in the previous works concerning
probabilistic widths. However, unlike the periodic case and the Wiener measure
case, we cannot ﬁnd an orthogonal transform between a ﬁnite-dimensional function
space and a sequence space of function values with comparable Lq and ℓq norm,
so we cannot use the invariant properties of the standard Gaussian measure under
action of an orthogonal transform to give the discretization theorems. Instead, we
use the comparison theorems for Gaussian measures. Unlike the spherical case, we
cannot ﬁnd a equivalent-weight Marcinkiewicz-Zygmund (MZ) inequalities on the
ball (see Remark 3 in [27]), so we cannot use known results on the probabilistic
linear widths of the identity matrix on Rm. Instead, we need to ﬁnd out and use
the probabilistic linear widths of diagonal matrixes on Rm.

Remark 1.3.
Let BH(ν) be the unit ball of the Cameron-Martin space of the
Gaussian measure ν. Then BH(ν) = BW ρ
2,µ. It follows from [27] that the classical
Kolmogorov and linear widths of BH(ν) in Lq,µ have the same error order for
1 ≤ q ≤ 2, however, for q > 2, the Kolmogorov width dn(BH(ν), Lq,µ) is essentially
less than the linear width dn(BH(ν), Lq,µ), and optimal linear operators lose to
optimal nonlinear operators by a factor cn1/2−1/q in the worst case setting. From
[29, (2.16)] and (1.7), we know that in the average case setting, the Kolmogorov and

6

HEPING WANG

linear widths of W r
2,µ in Lq,µ have the same error order for 1 ≤ q < ∞. This means
that for “most” functions in W r
2,µ, asymptotic optimal linear operators are (modulo
a constant) as good as optimal nonlinear operators in the Lq,µ (1 ≤ q < ∞) metric.
Remark 1.4. Comparing (1.7) with (2.15) in [27], we obtain that in the average
case setting, the Fourier partial summation operators Sn are the asymptotically
optimal linear operators in the Lq,µ metric if and only if 1 ≤ q < 2 + 1/µ. This
is completely diﬀerent from the one-dimensional periodic case and the spherical
case, where the Fourier partial summation operators are the asymptotically optimal
linear operators in the Lq metric for all q, 1 ≤ q ≤ ∞ (see [31], [30], and [26]).

The paper is organized as follows. Section 2 contains some lemmas concerning
probabilistic linear widths of diagonal matrixes in Rm with the standard Gaussian
measure. In Section 3, we give discretization theorems of estimates of probabilistic
linear widths. Finally, based on the results obtained in Sections 3 and 2, we prove
Theorems 1.1 and 1.2 in Section 4.

2. Probabilistic linear widths of diagonal matrixes on Rm

Let ℓm
q

(1 ≤ q ≤ ∞) denote the m-dimensional normed space of vectors x =

(x1, . . . , xm) ∈ Rm, with the ℓm

q norm

kxkℓm

q :=(cid:26) (cid:0)Pm

i=1 |xi|q(cid:1) 1

q ,
max1≤i≤m |xi|,

1 ≤ q < ∞,
q = ∞.

As usual, we identify Rm with the space ℓm
Euclidean inner product of x, y ∈ Rm, and write k · k2 instead of k · kℓm
in Rm the standard Gaussian measure γm, which is given by

2 , use the notation hx, yi to denote the
2 . Consider

γm(G) = (2π)−m/2ZG

exp(−kxk2

2/2) dx,

where G is any Borel subset in Rm.

Let 1 ≤ q ≤ ∞, 1 ≤ n < m, and δ ∈ [0, 1). Then the probabilistic linear

(n, δ)-widths of a linear mapping T : Rm → ℓm
inf
Tn

λn,δ(T : Rm → ℓm

q , γm) = inf
Gδ

q is deﬁned by
x∈Rm\Gδ kT x − Tnxkℓm
q ,

sup

q with rank at most n.

where Gδ runs over all possible Borel subset of Rm with measure γm(Gδ) ≤ δ, and
Tn all linear operators from Rm to ℓm
There are a few results devoted to studying the probabilistic widths of a linear
mapping T : Rm → ℓm
q (see [5, 7, 10, 16, 17, 19]). Throughout the section, we use
the letter D to denote an m × m real diagonal matrix diag(d1, . . . , dm) with d1 ≥
d2 ≥ ··· ≥ dm > 0, the letter Dn the diagonal matrix diag(d1, . . . , dn, 0, . . . , 0) for
1 ≤ n ≤ m, and the letter Im the m by m identity matrix. Moreover, {e1,··· , em}
denotes the standard orthonormal basis in Rm:

e1 = (1, 0,··· , 0),··· , em = (0,··· , 0, 1).

The following lemmas will be used in the proof of Theorem 1.1.
Lemma 2.1. (1) ([10]). If 1 ≤ q ≤ 2, m ≥ 2n, δ ∈ (0, 1/2], then
(2.1)

q , γm) ≍ m1/q + m1/q−1/2pln(1/δ).

λn,δ(Im : Rm → ℓm

7

(2) ([17]). If 2 ≤ q < ∞, m ≥ 2n, δ ∈ (0, 1/2], then

(2.2)

λn,δ(Im : Rm → ℓm

q , γm) ≍ m1/q +pln(1/δ).

(3) ([19]). If q = ∞, m ≥ 2n, δ ∈ (0, 1/2], then

(2.3)

λn,δ(Im : Rm → ℓm
Lemma 2.2. Assume that
mXi=1

q , γm) ≍pln((m − n)/δ) ≍pln m + ln(1/δ).

dβ
i ≤ C(m, β)

for some β > 0.

Then for 2 ≤ q ≤ ∞, m ≥ 2n, δ ∈ (0, 1/2], we have
(2.4)

λn,δ(D : Rm → ℓm

q , γm) ≪(cid:16) C(m, β)
n + 1 (cid:17) 1

Proof. First we show that

(2.5)

ZRm kDx − Dnxkℓm

β

q = ∞.

·( (m1/q +pln(1/δ), 2 ≤ q < ∞,
pln m + ln(1/δ),
·( m1/q,
n + 1 (cid:17) 1
q γm(dx) ≪(cid:16) C(m, β)
√ln m,
γm(dx)(cid:17)1/q
= C(q)(cid:16) mXk=n+1

2 ≤ q < ∞,
q = ∞.

k(cid:17)1/q

dq

ℓm
q

,

β

Indeed, for 2 ≤ q < ∞, it follows from [7, (2.9)] that
(2.6)

(cid:16)ZRm kDx − Dnxkq
2 )(cid:17)1/q

2 Γ( q+1

2 2

q

where C(q) =(cid:16)π− 1

. Since

dβ
i ≤

n+1 ≤

(n + 1)dβ

n+1Xi=1

mXi=1
dn+1 ≤(cid:16) C(m, β)
n + 1 (cid:17) 1
q γm(dx) ≤(cid:16)ZRm kDx − Dnxkq

β

.

we get

(2.7)

Hence, we have

ZRm kDx − Dnxkℓm

dβ
i ≤ C(m, β),

proving (2.5) for 2 ≤ q < ∞. For q = ∞, it follows from (2.6) and (2.7) that for
any 1 < q1 < ∞,

k(cid:17)1/q

β

,

ℓm
q

dq

≪(cid:16) mXk=n+1

γm(dx)(cid:17)1/q
n + 1 (cid:17) 1
≤ dn+1(m − n)1/q ≪ m1/q(cid:16) C(m, β)
∞ γm(dx) ≤(cid:16)ZRm kDx − Dxkq1
γm(dx)(cid:17)1/q1
k (cid:17)1/q1
≤ C(q1)dn+1(m − n)1/q1
n + 1 (cid:17) 1
(cid:1)(cid:17) 1
q1(cid:16) C(m, β)

= C(q1)(cid:16) mXk=n+1
q1(cid:16)Γ(cid:0) q1 + 1

≤ c m

dq1

ℓm
q1

2

.

β

1

ZRm kDx − Dnxkℓm

(2.8)

(Γ(

2 exp(−
Hence, taking q1 = ln(e2m), we obtain from (2.8) that

x (

))

2

2

)

x + 1

1

x ≤ c (√2π )

1

x + 1

1

x + 1

2x

) ≤ c x

1

2 .

ZRm kDx − Dnxkℓm

∞ γm(dx) ≤ c m

which completes the proof of (2.5).

1

q1 q

1
2

n + 1 (cid:17) 1
1(cid:16) C(m, β)

β

≪

n + 1 (cid:17) 1
√ln m(cid:16) C(m, β)

β

,

Now we shall show (2.4). We need the following lemma.

Lemma 2.3. ([2, (1.7.7)], [21, p. 47]) Let F : Rm → R be a function satisfying
the following Lipschitz condition

|F (x) − F (y)| ≤ σkx − yk2, x, y ∈ Rm,

for some σ > 0 independent of x and y. If X ∼ Nm(0, Im)Rm is an Rm-valued
Gaussian random vector with mean 0 and covariance matrix Im, then for all t > 0

(2.9)

P(|F (X) − EF (X)| ≥ t) ≤ 2 exp(−

t2
K 2σ2 ),

with K > 0 being an absolute constant. (2.9) is called the Gaussian concentration
inequality.

We continue to prove Lemma 2.2. Let F (x) = kDx − Dnxkℓm

2 ≤ q ≤ ∞. By (2.7) we obtain for any x, y ∈ Rm

q

for x ∈ Rm and

|F (x) − F (y)| ≤ k(D − Dn)(x − y)kℓm

≤ dn+1(cid:16) mXk=n+1
≤(cid:16) C(m, β)
n + 1 (cid:17) 1
n+1 (cid:17) 1
where σ1 := (cid:16) C(m,β)

(2.9) yields

β

β

q =(cid:16) mXk=n+1

dq

k|xk − yk|q(cid:17) 1

q

|xk − yk|q(cid:17) 1

q

≤ dn+1(cid:16) mXk=n+1

|xk − yk|2(cid:17) 1

2

kx − yk2 =: σ1kx − yk2,

8

HEPING WANG

By Stirling’s formula (see [1, p. 18]):

we obtain

lim

x→+∞

√2πxx− 1

Γ(x)
2 exp(−x)

= 1,

. Thus, applying the Gaussian concentration inequality

P(|F (X) − EF (X)| ≥ t) ≤ 2 exp(−

t2

K 2σ2
1

), ∀t > 0,

where, here and in what follows, X ∼ Nm(0, Im)Rm . In particular, this implies that

for Qδ =(cid:8)x ∈ Rm : F (x) > EF (X) + Kσ1pln(2/δ)(cid:9) with δ ∈ (0, 1),
γm(Qδ) ≤ P(|F (X) − EF (X)(cid:12)(cid:12) > Kσ1pln(2/δ)) ≤ δ.

By the deﬁnition of the linear (n, δ) widths, this last equation further implies that

λn,δ(D : Rm → ℓm

q , γm) ≤ sup

Rm\Qδ kDx − Dnxkq

(2.10)

≤ EF (X) + Kσ1pln(2/δ).

On the other hand, however, using (2.5), we have

9

(2.11)

EF (X) = EkDX − DnXkℓm

q =ZRm kDx − Dnxkℓm

q γm(dx) =: σ2,

where σ2 denotes the right expression of (2.5). Thus, combining (2.10) with (2.11),
we deduce the desired upper estimates.

(cid:3)

3. Discretization of the probabilistic linear widths

This section is devoted to obtaining the discretization theorems which give the
reduction of the calculation of probabilistic widths of a given function class to the
computation of probabilistic widths of a ﬁnite-dimensional set equipped with the
standard Gaussian measure.

Let η be a nonnegative C∞-function on [0, +∞) supported in [0, 2] and equal to

1 on [0, 1]. We also suppose that η(x) > 0 for x ∈ [0, 2). We deﬁne

(3.1)

Ln,η(x, y) :=

η(

j
n

)Pj (x, y),

x, y ∈ Bd,

∞Xj=0

where Pk(x, y) is given in (1.3). It is well known that for any P ∈ Πd
n,
(3.2)

Ln,η(x, y)P (y)Wµ(y)dy = P (x),

x ∈ Bd.

ZBd

We recall that the operator Sn is the orthogonal projection operator from L2,µ to
Πd

n, i.e.,

Snf (x) =

nXk=0

P rojk(f )(x) =

nXk=0ZBd

f (y)Pk(x, y)Wµ(y)dy,

where P rojk is the orthogonal projector from L2,µ onto V d
any f ∈ L2,µ, we deﬁne
(3.3)
Then for x ∈ Bd,

δ1(f ) = S2(f ), δk(f ) = S2k (f ) − S2k−1 (f ) for k = 2, 3 . . . .

k deﬁned by (1.2). For

δk(f )(x) =

2kXj=2k−1+1

P rojj (f )(x) = hf, Mk(·, x)i,

where

(3.4)

Mk(x, y) =

2kXj=2k−1+1

ad

jXi=1

φji(x)φji(y) =

is the reproducing kernel of the Hilbert space L2,µT(cid:0)

2kXj=2k−1+1
2kLj=2k−1+1V d

Pk(x, y)

is an orthonormal basis for V d

j . Obviously, for any x ∈ Bd, Mk(·, x) ∈

j }

j(cid:1), and {φj1, . . . , φjad
2kLj=2k−1+1V d

j

10

HEPING WANG

and for any f ∈
x, y ∈ Bd,

2kLj=2k−1+1V d

j , f (x) = δk(f )(x) = hf, Mk(·, x)i. In special, for any

Now we introduce the metric ˜ρ on Bd:

hMk(·, x), Mk(·, y)i = Mk(x, y).

˜ρ(x, y) := arccos(cid:16)(x, y) +q1 − kxk2

2q1 − kyk2
2(cid:17),

x, y ∈ Bd.

For r > 0, x ∈ Bd, we set B ˜ρ(x, r) := {y ∈ Bd | ˜ρ(x, y) ≤ r}. For δ > 0, n ∈ N, we
say that a ﬁnite subset Λ ⊂ Bd is maximal ( δ

n , ˜ρ)-separated if

Bd ⊂ [y∈Λ

B ˜ρ(y,

δ
n

) and

min

y6=y′∈Λ

˜ρ(y, y′) ≥

δ
n

.

The following cubature formulae and Marcinkiewicz-Zygmund (MZ) inequalities on
Bd are crucial for establishing discretization theorems.

Lemma 3.1. (see [6, 20]) There exists a constant γ > 0 depending only on d and
µ such that for any δ ∈ (0, γ], any positive integer n, and any maximal (δ/n, ˜ρ)-
separated subset Λ ⊂ Bd, there exists a sequence of positive numbers
n +p1 − kξk2
ωξ ≍ n−d( 1
2)2µ, ξ ∈ Λ, for which the following quadrature formula
holds for all f ∈ Πd
4n,
ZBd
f (x)Wµ(x) dx =Xξ∈Λ
kfkq,µ ≍(cid:26) (cid:0)Pξ∈Λ |f (ξ)|q ωξ(cid:1) 1

1 ≤ q < ∞,
q = ∞,
where the constants of equivalence depend only on d and µ.

Moreover, for any 1 ≤ q ≤ ∞, f ∈ Πd

maxξ∈Λ |f (ξ)|,

n, we have

ωξf (ξ).

q ,

Lemma 3.2. (see [27, Lemma 3]) Let µ > 0, β ∈ (0, 1/(2µ)) and let Λ, ωξ be
given as in Lemma 3.1. Then

Xξ∈Λ

ω−β
ξ ≪ nd(1+β).

For k = 1, 2, . . . ,

let γ > 0 be the same as in Lemma 3.1 and let Λk =
{ξ1, . . . , ξuk} be a maximal (γ2−(k+2), ˜ρ)-separated subset of Bd.
It is easy to
know that uk ≍ 2kd. By Lemma 3.1, there exists a sequence of positive numbers
wi ≍ 2−kd(2−k +p1 − kξik2
2)2µ, 1 ≤ i ≤ uk, for which the following quadrature
formula holds for all f ∈ Πd
2k+4 ,
ZBd

f (x)Wµ(x) dx =

wif (ξi).

(3.5)

ukXi=1
|f (ξi)|q ωi(cid:17)1/q

2k+2 , we have

kfkq ≍(cid:16) ukXi=1

= kUk(f )kℓ

,

uk
q,ω

Moreover, for any 1 ≤ q ≤ ∞, f ∈ Πd

11

2k+2 7−→ Ruk is deﬁned by

Uk(f ) = (f (ξ1), . . . , f (ξuk )),

where Uk : Πd
(3.6)
and for x ∈ Ruk ,

uk
q,ω

kxkℓ

q ,
max1≤i≤uk |xi|,
Next, we deﬁne the operator Tk : Ruk 7−→ Πd
(3.7)

:=(cid:26) (cid:0)Puk
i=1 |xi|qωi(cid:1) 1
ukXi=1

Tka(x) :=

2k+1 by

aiwiL2k,η(x, ξi),

1 ≤ q < ∞,
q = ∞.

where a = (a1, . . . , auk ) ∈ Ruk , Ln,η is deﬁned as in (3.1). It is shown in [27, (2.15)]
that for any q, 1 ≤ q ≤ ∞,
(3.8)
For f ∈ Πd

2k , by (3.2) and (3.5) we get

kTkakq,µ ≪ kakℓ

uk
q,ω

.

f (y)L2k,η(x, y)dσ(y) =

wjf (ξj)L2k,η(x, ξj ),

f (x) =ZBd

ukXj=1

which means that f = TkUkf for any f ∈ Πd
to denote uk × uk real diagonal matrixes as follows:
(3.9)

2k . We also use the letters Sk, Rk, Vk

1
2

1
2

Sk = diag(ω
and use the letter R−1

1 , . . . , ω

1
q

1
q

1 , . . . , ω

1 ), Rk = diag(ω

1 ), Vk = diag(ω

),
to represent the inverse matrix of Rk. Clearly, for x ∈ Ruk ,
kRkxkℓ

and Rk = VkSk.

= kxkℓ

, . . . , ω

uk
q,ω

uk
q

k

2 + 1

q

− 1
1

2 + 1

q

− 1
1

Lemma 3.3. For any z = (z1, . . . , zuk ) ∈ Ruk , we have
(3.10)

where Mk(x, y) is given in (3.4), and {ξ1, . . . , ξuk} is deﬁned as above.

Proof. Denote by K the set(cid:8)g ∈

ω1/2
j

ukXj=1
zjMk(·, ξj )(cid:13)(cid:13)(cid:13)2,µ

ω1/2
j

ukXj=1

(cid:13)(cid:13)(cid:13)

ukXj=1

(cid:13)(cid:13)(cid:13)

,

uk
2

ω1/2
j

zjMk(·, ξj)(cid:13)(cid:13)(cid:13)2,µ ≪ kzkℓ
2kLj=2k−1+1V d
zjMk(·, ξj ) ∈ L2,µ\(cid:0)
g∈K(cid:12)(cid:12)(cid:12)(cid:10) ukXj=1
g∈K(cid:16) ukXj=1
ukXj=1

j (cid:12)(cid:12) kgk2,µ ≤ 1(cid:9). Since
j(cid:1),
V d
zjMk(·, ξj), g(cid:11)(cid:12)(cid:12)(cid:12) = sup
g∈K(cid:12)(cid:12)
|g(ξj )|2ωj(cid:17)1/2
|zj|2(cid:17)1/2(cid:16) ukXj=1
|zj|2(cid:17)1/2

2kMj=2k−1+1

kgk2,µ ≤ kzkℓ

ω1/2
j

g∈K

uk
2

(

,

≤ sup

≪ sup

= sup

By the Riesz representation theorem and Cauchy-Schwarz inequality we have

ukXj=1

ω1/2
j

zjg(ξj)(cid:12)(cid:12)

12

HEPING WANG

which proves (3.10).

(cid:3)

Theorem 3.4. Let 1 ≤ q ≤ ∞, σ ∈ (0, 1), and let the sequences of numbers {nk}
k=1 σk ≤ δ.
Then

and {σk} be such that 0 ≤ nk ≤ uk ≍ 2kd, P∞

k=1 nk ≤ n, σk ∈ (0, 1), P∞

(3.11)

λn,σ(W r

2,µ, ν, Lq,µ) ≪

Proof. For convenience, we write

∞Xk=1

2−kρλnk,σk (Vk : Ruk → ℓuk

q , γuk ).

λnk,σk := λnk,σk (Vk : Ruk → ℓuk

q , γuk ),

where γuk is the standard Gaussian measure in Ruk . Denote by Lk a linear operator
from Ruk to Ruk such that the rank of Lk is at most nk and

γuk(cid:16){y ∈ Ruk | kVky − Lkykℓ
k LkSkUkδk(f )kq,µ = kTkUkδk(f ) − TkR−1

> 2λnk,σk}(cid:17) ≤ σk.

2,µ, by (3.8) we have

uk
q

Then for any f ∈ W r
kδk(f ) − TkR−1

k LkSkUkδk(f )kq,µ

≪ kUkδk(f ) − R−1
k LkSkUkδk(f )kℓ
= kVkSkUkδk(f ) − LkSkUkδk(f )kℓ

uk
q,ω

,

uk
q

(3.12)

where δk, Uk, Tk, and Sk, Vk, Rk are deﬁned by (3.3), (3.6), (3.7), and (3.9), re-
spectively. Denote y = SkUkδk(f ) = (ω1/2
uk δk(f )(ξuk )) ∈ Ruk .
Note that for x ∈ Bd,

δk(f )(ξ1), . . . , ω1/2

1

δk(f )(x) = hf, Mk(·, x)i = hf (−r), M (−r,0)

k

(·, x)ir = hf, M (−2r,0)

k

(·, x)ir,

k

where M (r1,0)
(x, y) is the r1-order partial derivative of Mk(x, y) with respect to
the variable x, r1 ∈ R. By the property of Gaussian measures we know that if
a random vector f in W r
2,µ is a centered Gaussian random vector with covariance
operator Cν , then the vector
y = SkUkδk(f ) = (hf, ω1/2

(·, ξ1)ir, . . . ,hf, ω1/2

uk M (−2r,0)

1 M (−2r,0)

(·, ξuk )ir)

in Ruk is a random vector with a centered Gaussian distribution γ in Ruk and its
covariance matrix Cγ is given by

k

k

i M (−2r,0)

k

(·, ξi)), ω1/2

j M (−2r,0)

k

.

i,j=1

Note that

Cγ =(cid:16)hCν (ω1/2
DCν (ω1/2
=Dω1/2
=Dω1/2
ukXj=1

k

k

k

i M (−2r,0)
i M (−2r−s,0)
i M (−ρ,0)

j M (−2r,0)

k

(·, ξi)), ω1/2
(·, ξi), ω1/2

j M (−2r,0)

k

(·, ξi), ω1/2

j M (−ρ,0)

k

ω1/2
j

zjMk(·, ξj ) ∈

2kMj=2k−1+1

V d
j ,

(·, ξj )ir(cid:17)uk
(·, ξj)Er
(·, ξj )Er
(·, ξj )E.

Since for any z = (z1, . . . , zuk ) ∈ Ruk ,

13

by (3.10) we get

ZRuk

(y, z)2γ(dy) = zCγzT =

=D ukXj=1
=(cid:13)(cid:13)(cid:13)
ukXj=1

ukXi,j=1

zizj(cid:10)ω1/2

ω1/2
j

zjM (−ρ,0)

ω1/2
j

zjM (−ρ,0)

i M (−ρ,0)

k

(·, ξi), ω1/2

j M (−ρ,0)

k

(·, ξj)(cid:11)

2

2

2

k

k

k

ω1/2
j

ω1/2
j

(·, ξj ),

ukXj=1

zjM (−ρ,0)

(y, z)2γuk (dy).

(·, ξj)E
zjMk(·, ξj)(cid:13)(cid:13)(cid:13)

ukXj=1
(·, ξj )(cid:13)(cid:13)(cid:13)
2 ≍ 2−2kρ(cid:13)(cid:13)(cid:13)
= 2−2kρZRuk
k LkSkUkδk(f )kq > 2c1c22−kρλnk,σk(cid:9) ,
> 2c22−kρλnk,σko(cid:17)

uk
q

> 2c22−kρλnk,σk(cid:9)(cid:17).

2,µ | kVkSkUkδk(f ) − LkSkUkδk(f )kℓ

(3.13)

≪ 2−2kρkzkℓ
Now consider the subset of W r

uk
2

2,µ

2,µ | kδk(f ) − TkR−1

Gk :=(cid:8)f ∈ W r
ν(Gk) ≤ ν(cid:16)nf ∈ W r

uk
q

= γ(cid:16)(cid:8)y ∈ Ruk | kVky − Lkykℓ
(y, x)2γ1(dx) ≥ZRN

ZRN

where c1, c2 are the positive constants given in (3.12) and (3.13). Then it follows
from (3.12) that

By Theorem 1.8.9 in [2, p. 29], we know that if γ1 and γ2 are two centered Gaussian
measures on RN and satisfy

(y, x)2γ2(dx),

∀ y ∈ RN ,

then for every convex symmetric set E, γ1(E) ≤ γ2(E). Note that for any t > 0,
the set {y ∈ Ruk| kVky − Lkykℓ
q ≤ t} is convex symmetric. It follows from (3.13)
that

uk

uk
q

ν(Gk) ≤ γ(cid:16)(cid:8)y ∈ Ruk | kVky − Lkykℓ
≤ λ(cid:16)(cid:8)y ∈ Ruk | kVky − Lkykℓ
= γuk(cid:16)(cid:8)y ∈ Ruk | kVky − Lkykℓ

> 2c22−kρλnk,σk(cid:9)(cid:17)
> 2c22−kρλnk,σk(cid:9)(cid:17)
> 2λnk,σk(cid:9)(cid:17) ≤ σk,
Iuk is the identity matrix in Ruk . Let us consider the set G = S∞
linear operator fTn on W r

where λ is a centered Gaussian measure in Ruk with covariance matrix c2

2,µ which is given by

uk
q

uk
q

TkR−1

k LkSkUkδk(f ).

22−2kρIuk ,
k=1 Gk and the

From the hypothesis of the theorem, we get that

fTnf =

ν(G) ≤

∞Xk=1
∞Xk=1

ν(Gk) ≤

∞Xk=1

σk ≤ σ,

and

rankfTn ≤

∞Xk=1

rank (TkR−1

k LkSkUkδk) ≤

∞Xk=1

nk ≤ n.

14

HEPING WANG

f ∈W r

λn,δ(cid:16)W r

2,µ, ν, Lq,µ(cid:17) ≤ sup

Consequently, by the deﬁnitions of G, fTn, {Gk}, and {Lk},
2,µ\Gkf −fTnfkq,µ
∞Xk=1(cid:13)(cid:13)(cid:13)δk(f ) − TkR−1
2,µ\Gk(cid:13)(cid:13)(cid:13)δk(f ) − TkR−1

≤ sup

2,µ\G

f ∈W r

f ∈W r

sup

≤

2−kρλnk,δk ,

k LkSkUkδk(f )(cid:13)(cid:13)(cid:13)q,µ
k LkSkUkδk(f )(cid:13)(cid:13)(cid:13)q,µ

∞Xk=1
∞Xk=1

≪

which completes the proof of Theorem 3.4.

(cid:3)

Next we consider the lower estimates. We assume that m ≥ 6 and b1md ≤
j=1 ⊂ {x ∈

n ≤ 2b1md with b1 > 0 being independent of n and m. We let {xj}N

Bd(cid:12)(cid:12) kxk2 ≤ 2/3} such that N ≍ md and
{x ∈ Bd(cid:12)(cid:12) kx − xjk2 ≤ 2/m}\{x ∈ Bd(cid:12)(cid:12) kx − xik2 ≤ 2/m} = ∅,

Obviously, such points xj exist. We may take b1 > 0 suﬃciently large so that
N ≥ 2n. Let ϕ1 be a C∞-function on Rd supported in {x ∈ Rd | kxk2 ≤ 1} and be
equal to 1 on {x ∈ Rd | kxk2 ≤ 2/3}, and let ϕ2 be a nonnegative C∞-function on
Rd supported in {x ∈ Rd | kxk2 ≤ 1/2} and be equal to 1 on {x ∈ Rd | kxk2 ≤ 1/4}.
We deﬁne

if

i 6= j.

ϕi(x) = ϕ1(m(x − xi)) − ciϕ2(m(x − xi)),
for some ci such thatRBd ϕi(x)Wµ(x)dx = 0, i = 1, . . . , N . We set
AN := span{ϕ1, . . . , ϕN} =nFa(x) =
ϕj ∈ W r
2,µ,

ajϕj(x) : a = (a1, . . . , aN ) ∈ RNo.
supp ϕj ⊂ {x ∈ Bd(cid:12)(cid:12) kx − xjk2 ≤ 1/m} ⊂ {x ∈ Bd(cid:12)(cid:12) kxk2 ≤ 5/6},

NXj=1

Clearly,

j = 1, . . . , N,

kϕjkq,µ ≍(cid:16)ZBd |ϕj(x)|q dx(cid:17)1/q

1 ≤ q ≤ ∞,

≍ m−d/q,

and

Hence, if Fa ∈ AN , a = (a1, . . . , aN ) ∈ RN , then

supp ϕj\ supp ϕi = ∅ (i 6= j).

(3.14)

and

For a positive integer v = 0, 1, . . . and Fa ∈ AN , a = (a1, . . . , aN ) ∈ RN , it

follows from the deﬁnition of −Dd

µ that

kFakq,µ ≍(cid:16)N −1

NXj=1

|aj|q(cid:17)1/q

= m−d/qkakℓN

q

.

supp(−Dd

µ)v(ϕj ) ⊂ {x ∈ Bd (cid:12)(cid:12) kx − xjk2 ≤ 1/m},

k(−Dd

µ)v(ϕj )kq,µ ≪ m2v−d/q.

Hence, for 1 ≤ q ≤ ∞ and Fa =PN

j=1 ajϕj ∈ AN ,

k(−Dd

µ)v(Fa)kq,µ ≪ m2v−d/qkakℓN

q

15

.

It then follows by the Kolmogorov type inequality (see [8, Theorem 8.1]) that

For f ∈ L1,µ and x ∈ Bd, we deﬁne

(3.15)

and

1− ρ
q,µ

2+2[ρ]

kF (ρ)

ρ

2+2[ρ]
q,µ

µ)ρ/2(Fa)kq,µ
µ)1+[ρ](Fa)k

a kq,µ = k(−Dd
≪ k(−Dd
kFak
≪ mρ−d/qkakℓN
q ≪ mρkFakq,µ.
2,µZBd
2,µZBd

NXj=1
NXj=1

ϕj (x)
kϕjk2

ϕj(x)
kϕjk2

f (y)ϕ(ρ)

PN (f )(x) =

QN (f )(x) =

f (y)ϕj(y)Wµ(y)dy

j (y)Wµ(y)dy.

Obviously, the operator PN is the orthogonal projector from L2,µ to AN , and if
f ∈ W ρ
2,µ, then QN (f )(x) = PN (f (ρ))(x). Also, it follows from [27] that PN is the
bounded operator from Lq,µ to ANT Lq,µ, i.e., for 1 ≤ q ≤ ∞,
(3.16)
Since QN (f ) ∈ AN for f ∈ W ρ
(3.17)

k(QN (f ))(ρ)k2,µ ≪ mρkQN (f )k2,µ = mρkPN (f (ρ))k2,µ ≪ mρkf (ρ)k2,µ.

kPN (f )kq,µ ≪ kfkq,µ.
2,µ, by (3.15) we have

Theorem 3.5. Let 1 ≤ q ≤ ∞, δ ∈ (0, 1), and let N be given above. Then

λn,δ(W r

2,µ, ν, Lq,µ) ≫ n−ρ/d+1/2−1/qλn,δ(IN : RN → ℓN

q , γN ),

where N ≍ n, N ≥ 2n, IN is the N by N identity matrix, and γN is the standard
Gaussian measure in RN .

Proof. Let Tn be a bounded linear operator on W r

ν(cid:0){f ∈ W r

2,µ (cid:12)(cid:12) kf − Tnfkq,µ > 2λn,δ}(cid:1) ≤ δ,

where λn,δ := λn,δ(W r
W r
also a centered Gaussian measure on W r

2,µ, ν, Lq,µ). Note that if A is a bounded linear operator from
2,µ and from H(ν) to H(ν), then the image measure λ of ν under A is

2,µ to W r

2,µ with covariance

2,µ with rank Tn ≤ n such that

Rλ(f )(f ) = hA∗Cνf, A∗CνfiH(ν),

f ∈ W r
2,µ,
where Cν is the covariance of the measure ν, H(ν) = W ρ
2,µ is the Camera-Martin
space of ν, and A∗ is the adjoint of A in H(ν) (see [2, Theorem 3.5.1, p. 112]).
Furthermore, if the operator A also satisﬁes

then

kAfkH(ν) ≤ kfkH(ν),

Rλ(f )(f ) = kA∗Cν fk2

H(ν) ≤ kA∗k2kCν fk2

H(ν) ≤ hCν f, Cν fiH(ν) = Rν (f )(f ).

16

HEPING WANG

By Theorem 3.3.6 in [2, p. 107], we get that for any absolutely convex Borel set E
of W r

2,µ, there holds inequality

It follows from (3.17) that

ν(E) ≤ λ(E).

kQN (f )kH(ν) = k(QN (f ))(ρ)k2,µ ≪ mρkf (ρ)k2,µ = mρkfkH(ν).

Then there exists a positive constant c3 such that

1
c3mρ QN (f )kH(ν) ≤ kfkH(ν).

k

Note that for any t > 0, the set {f ∈ W r
It then follows that

2,µ | kf − Tnfkq,µ ≤ t} is absolutely convex.

Now we deﬁne the linear operators LN : RN 7−→ AN and JN : AN 7−→ RN by

ν(cid:0){f ∈ W r
≥ ν(cid:0){f ∈ W r

LN (a)(x) =

2,µ | kf − Tnfkq,µ > 2λn,δ}(cid:1)
2,µ | kQN f − TnQN fkq,µ > 2c3mρλn,δ}(cid:1).
NXi=1
a = (a1, . . . , aN ) ∈ RN

ai ϕi(x)
kϕik2,µ

,

and

1

JN (Fa) = (a1kϕ1k2,µ, . . . , aNkϕNk2,µ), Fa ∈ AN ,
respectively. Obviously, LN JN (Fa) = Fa for any Fa ∈ AN . Set y = (y1, . . . , yN ) ∈
kϕj k2,µhf, ϕ(ρ)
RN , where yj =
j i. Then y = JN QN (f ). It follows from (3.14) and
the fact kϕjk2,µ ≍ m−d/2 that
kLN (a)kq,µ ≍(cid:16)N −1

≍ m−d/q+d/2kakℓN

2,µ(cid:17)1/q

|aj|q
kϕjkq

(3.18)

.

q

NXj=1

By (3.16) and (3.18), we know that for any f ∈ W r

2,µ,

kQN (f ) − TnQN (f )kq,µ ≫ kPN (QN (f )) − PN TnQN (f )kq,µ

= kLN JN QN (f ) − LN JN PN TnLN JN QN (f )kq,µ
≫ m−d/q+d/2kJN QN (f ) − JN PN TnLN JN QN (f )kℓN
≫ m−d/q+d/2ky − JN PN TnLN ykℓN
, k = 1, 2, . . . , N is an orthonormal system in L2,µ and
N i) = y in RN on
2,µ, ν) has the standard Gaussian distribution γN in RN .

1 i, . . . ,hf, g(ρ)

.

q

q

2,µ. Then the random vector (hf, g(ρ)

kϕkk2,µ

We remark that gk = ϕk
gk ∈ H(ν) = W ρ
the measurable space (W r
It then follows that
ν(cid:0){f ∈ W r
≥ ν(cid:0){f ∈ W r
= γN(cid:0){y ∈ RN | ky − JN PN TnLN ykℓN

2,µ (cid:12)(cid:12) kQN f − TnQN fkq,µ > 2c3mρλn,δ}(cid:1)

2,µ | ky − JN PN TnLN ykℓN

q

where c4 is a positive constant. Clearly, rank (JN PN TnLN ) ≤ n and

q

> c4mρ+d/q−d/2λn,δ}(cid:1)
> c4mρ+d/q−d/2λn,δ}(cid:1) =: γN (G),
2,µ (cid:12)(cid:12) kf − Tnfkq,µ > 2λn,δ}(cid:1) ≤ δ.

γN (G) ≤ ν(cid:0){f ∈ W r

Therefore,

λn,δ(IN : RN → ℓN

q , γN ) ≤ sup

y∈RN \Gky − JN PN TnLN ykℓN

q ≪ mρ+d/q−d/2λn,δ.

That is,

λn,δ(W r

2,µ, ν, Lq,µ) ≫ n−ρ/d+1/2−1/qλn,δ(IN : RN → ℓN

q , γN ),

which completes the proof of Theorem 3.5.

4. Proofs of Theorems 1.1 and 1.2

17

(cid:3)

For the upper estimates for λn,δ(W r

Proof of Theorem 1.1. The lower estimates for λn,δ(W r
orem 3.5, and (2.1), (2.2), and (2.3) for 1 ≤ q ≤ ∞ immediately.
2,µ, ν, Lq,µ) for 2 ≤ q ≤ ∞, we use Theorem
3.4. For any ﬁxed natural number n, assume C12md ≤ n ≤ C2
1 2md with C1 > 0 to
be speciﬁed later. We may take suﬃciently small positive numbers ε > 0 such that
ρ > d

2,µ, ν, Lq,µ) follow from The-

2 + (1 + ε)(2 + ε)µd( 1

q ) and deﬁne

if j ≤ m,
if j > m,

and δj =(cid:26) 0,

δ2m−j,

if j ≤ m,
if j > m,

nj =( uj,

2 − 1
huj2d(1+ε)(m−j)−1i,
nj ≪ Xj≤m

Xj≥0

and

where uj is given in Theorem 3.4. Then

2jd +Xj>m

2md(1+ε)−dεj ≪ 2md,

∞Xk=1

δk ≤ δ.

j=0 nj ≤ C12md ≤ n. It follows

from Lemma 3.2 that for β ∈ (0,

Hence, we can take C1 suﬃciently large so thatP∞
≪ 2kd2kdβ( 1

ω−β(1/2−1/q)
j

2µ(1/2−1/q) ), 2 ≤ q ≤ ∞,

2 − 1

q ).

1

ukXj=1

β = (2 + ε)µ( 1

If j ≤ m, then nj = uj, and thence λnj ,δj (Vj : Ruj → ℓuj
taking 1
(4.1)
λnj ,δj (Vj : Ruj → ℓuj
and for q = ∞,
(4.2)

2 − 1
q , γuj ) ≪ 2jd( 1

2 − 1

λnj ,δj (Vj : Ruj → ℓuj

q ) and applying Lemma 2.2, we obtain for 2 ≤ q < ∞,

q , γuj ) = 0. If j > m, then

q )−d(1+ε)(m−j)(2+ε)µ( 1

2 − 1

q )(2

jd

q + (ln(

1

2 ),

))

1
δ

q , γuj ) ≪ 2jd/2−d(1+ε)(m−j)(2+ε)µ/2pj + ln(1/δ).

18

HEPING WANG

Now we estimate the upper bounds for λn,δ(W r
∞, by (3.11) and (4.1) we get
2,µ, ν, Lq,µ)

λn,δ(W r

2 , µ, Lq) for 1 ≤ q ≤ ∞. For 2 ≤ q <

q )2−d(1+ε)(m−j)(2+ε)µ( 1

2 − 1

q )(2

jd

q + (ln(

1

2 )

))

1
δ

2 + d

2−j(ρ− d

∞Xj=m+1
≪
q )(cid:16)2md/q + (ln(1/δ))1/2(cid:17)
≪ 2−m(ρ− d
≪ n−ρ/d+1/2(cid:0)1 + n−2/q ln(1/δ)(cid:1)1/2

2 + d

.

For q = ∞, it follows from (3.11) and (4.2) that

λn,δ(W r

2,µ, ν, L∞,µ) ≪

2−jρ2jd/2−d(1+ε)(m−j)(2+ε)µ/2pj + ln(1/δ)

∞Xj=m+1
≪ 2−m(ρ−d/2)pm + ln(1/δ)
≪ n−ρ/d+1/2pln(n/δ).

For 1 ≤ q < 2, we have

λn,δ(W r

2,µ, ν, Lq,µ) ≤ λn,δ(W r

The proof of Theorem 1.1 is complete.

2,µ, ν, L2,µ) ≪ n−ρ/d+1/2(cid:0)1 + n−1 ln(1/δ)(cid:1)1/2

.

(cid:3)

Proof of Theorem 1.2. By the deﬁnition of λn,δ(W r
2,µ, ν, Lq,µ), there exists a linear
operator Ln with rank ≤ n such that for any δ ∈ (0, 1/2] and some subset Gδ ⊂ W r
2,µ
with ν(Gδ) ≤ δ,

sup

2,µ\Gδ kf − Lnfkq,µ ≤ 2λn,δ(W r

f ∈W r

2,µ, ν, Lq,µ).

k=0 of sets, where G1 = W r

2,µ. Then it follows from

Consider the sequence {G2−k}∞
(1.6) that

λ(a)
n (W r

2,µ, ν, Lq,µ)p ≤(cid:16)ZW r

2,µ

kf − Lnfkp

q,µ ν(df )(cid:17)1/p
=(cid:16) ∞Xk=0ZG2−k \G2−k−1 kf − Lnfkp
≤(cid:16) ∞Xk=0
≪(cid:16) ∞Xk=0
≪(cid:26) n−ρ/d+1/2,

q,µ ν(df )(cid:17)1/p
2,µ, ν, Lq,µ))p ν(G2−k )(cid:17)1/p
2,µ, ν, Lq,µ))p(cid:17)1/p

1 ≤ q < ∞,
q = ∞.

2−k(λn,2−k−1 (W r

(2λn,2−k−1 (W r

n−ρ/d+1/2pln(en),

n (W r

For the proof of the lower estimates for λ(a)

2,µ, ν, Lq,µ)p, let Ln be a linear

operator from Lq,µ to Lq,µ with rank at most n. We set

G′ = {f ∈ W r

2,µ (cid:12)(cid:12) kf − Lnfkq,µ ≥

1
2

λn,1/e(W r

2,µ, ν, Lq,µ)}.

Then ν(G′) ≥ 1/e. Otherwise, if ν(G′) < 1/e, then by the deﬁnition of probabilistic
linear (n, δ)-width, we have

19

λn,1/e(W r

2,µ, ν, Lq,µ) ≤

sup

2,µ\G′ kf − Lnfkq,µ ≤

f ∈W r

1
2

λn,1/e(W r

2,µ, ν, Lq,µ),

which leads to a contradiction. Hence ν(G′) ≥ 1/e. It follows from (1.6) that for
0 < p < ∞,

(cid:16)ZW r

2,µ

kf − Lnfkp

q,µ ν(df )(cid:17)1/p

q,µ ν(df )(cid:17)1/p

≥(cid:16)ZG′ kf − Lnfkp
≫(cid:26) n−ρ/d+1/2,

λn,1/e(W r

≥

1
2

n−ρ/d+1/2pln(en),

n (W r

2,µ, ν, Lq,µ) (ν(G′))1/p

1 ≤ q < ∞,
q = ∞,

which gives the required lower estimates for λ(a)
the proof of Theorem 1.2.

2,µ, ν, Lq,µ)p. This completes
(cid:3)

References

[1] G. E. Andrews, R. Askey, R. Roy, Special Functions, Cambridge Univ. Press, Cambridge,

1999.

[2] V. I. Bogachev, Gaussian measures, Mathematical Surveys and Monographs, 62, American

Mathematical Society, Providence, RI, 1998.

[3] G. Chen, G. Fang, Probabilistic and average widths of multivariate Sobolev spaces with mixed

derivative equipped with the Gaussian measure, J. Complexity 20 (6) (2004) 858-875.

[4] G. Chen, G. Fang, Linear widths of a multivariate function space equipped with a Gaussian

measure, J. Approx. Theory 132 (2005) 77-96.

[5] G. Chen, P. Nie, X. Luo, The approximation characteristic of diagonal matrix in probabilistic

setting, J. Complexity 26 (2010), 336-343.

[6] F. Dai, Multivariate polynomial

inequalities with respect to doubling weights and A∞

weights, J. Funct. Anal. 235 (2006) 137-170.

[7] F. Dai, H. Wang, Linear n-widths of diagonal matrices in the average and probabilistic

settings, J. Funct. Anal. 262 (9) (2012) 4103-4119.

[8] Z. Ditzan, Fractional derivatives and best approximation, Acta Math. Hungar., 81(4) (1998)

323-348.

[9] C. F. Dunkl, Yuan Xu, Orthogonal polynormials of several variables, Cambridge Univ. Press,

2001.

[10] G. Fang, P. Ye, Probabilistic and average linear widths of Sobolev space with Gaussian

measure, J. Complexity 19 (2003) 73-84.

[11] G. Fang, P. Ye, Probabilistic and average linear widths of Sobolev space with Gaussian

measure in L∞-norm, Constr. Approx. 20 (2004) 159-172.

[12] X. Fernique, Integrabilite des vecteurs gaussiens, C. R. Acad. Sci. Paris Ser. A 270 (1970)

1698-1699.

[13] H. H. Kuo, Gaussian Measure in Banach Space, Lecture Notes in Mathematics, Vol. 463,

Springer, Berlin, 1975.

[14] V. E. Maiorov, Widths of spaces equipped with a Gaussian measure, Russian Acad. Sci. Dokl.

Math. 45 (2) (1993), 305-309.

[15] V. E. Maiorov, Average n-widths of the Wiener space in L∞-norm, J. Complexity 9 (1993)

222-230.

[16] V. E. Maiorov, Kolmogorov’s (n, δ)-widths of spaces of the smooth functions, Russian Acad.

Sci. Sb. Math. 79 (2) (1994) 265-279.

[17] V. E. Maiorov, Linear widths of function spaces equipped with the Gaussian measure. J.

Approx. Theory 77 (1) (1994) 74–88.

[18] V. E. Maiorov, About n-widths of the Wiener space in Lq-norm, J. Complexity 12 (1) (1996)

47-57.

20

HEPING WANG

[19] V. E. Maiorov, G. W. Wasilkowski, Probabilistic and average linear widths in L∞-norm with

respect to r-fold Wiener measure, J. Approx. Theory 84 (1) (1996) 31-40.

[20] P. Petrushev, Y. Xu, Localized polynomial frames on the ball, Constr. Approx. 27 (2008)

121-148.

[21] G. Pisier, The Volume of Convex Bodies and Banach Space Geometry, Cambridge Univ.

Press, Cambridge, UK, 1989.

[22] K. Ritter, Average-Case Analysis of Numerical Problems, Lecture Notes in Math, Vol.1733,

Springer-Verlag, 2000.

[23] Yongsheng Sun, Chengyong Wang, µ-average, n-widths on the Wiener space, J. Complexity

10 (4) (1994) 428-436.

[24] J. F. Traub, G. W. Wasilkowski, H. Wozniakowski, Information-Based Complexity, Academic

Press, New York, 1988.

[25] C. Wang, Best Approximation Problems and Information-Based Complexity on Abstract

Wiener Spaces, Doctoral Dissertation, 1994, Beijing Normal University, Beijing, China.

[26] H. Wang, Probabilistic and average widths of Sobolev spaces on compact two-point homoge-

neous spaces equipped with a Gaussian measure, Constr. Approx. 39 (2014) 485-516.

[27] H. Wang, H. Huang, Widths of weighted Sobolev classes on the ball, J. Approx. Theory 154

(2) (2008) 126-139.

[28] H. Wang , W. Jiang , X. Zhai, Approximation of multivariate periodic functions on the L2

space with a Gaussian measure, J. Math. Anal. Appl., 388 (2) (2012) 929-941.

[29] H. Wang, X. Zhai, Best approximation of functions on the ball on the weighted Sobolev space

equipped with a Gaussian measure, J. Approx. Theory, 162 (2010) 1160-1177.

[30] H. Wang, X. Zhai, YanweiZhang, Approximation of functions on the sphere in the average

case setting, J. Complexity 25 (2009) 362-376.

[31] H. Wang, Y. Zhang, X. Zhai, Approximation of periodic functions on the Sobolev space with

a Gaussion measure, Science in China Ser A 53 (2) (2010) 373-384.

[32] Y. Xu, Summability of Fourier orthogonal series for Jacobi weight on a ball in Rd, Trans.

Amer. Math. Soc. 351 (1999) 2439-2458.

School of Mathematical Sciences, Capital Normal University, Beijing 100048, China
E-mail address:

wanghp@cnu.edu.cn.

