6
1
0
2

 
r
a

 

M
9
1

 
 
]

.

R
P
h
t
a
m

[
 
 

2
v
8
2
9
3
0

.

3
0
6
1
:
v
i
X
r
a

A VARIANT OF THE SECRETARY PROBLEM: THE BEST OR

THE WORST

L. BAY ´ON, J. GRAU, A. M. OLLER-MARC´EN, M. RUIZ, AND P.M. SU ´AREZ

Abstract. We consider a variant of the secretary problem in which the can-
didates state their expected salary at the interview, which we assume is in
accordance with their qualiﬁcations. The goal is for the employer to hire the
best or the worst (cheapest), indiﬀerent between the two cases. We focus on
the complete information variant as well as on the cases when the number of
applicants is a random variable with a uniform distribution U [1, n] or with a
Poisson distribution of parameter λ. Moreover, we also study two variants of
the original problem in which we consider payoﬀs depending on the number of
conducted interviews.

Keywords: Secretary problem, Combinatorial Optimization
AMS 2010 Mathematics Subject Classiﬁcation 60G40, 62L15

1. Preliminaries

The optimal stopping problem, known as the classical secretary problem, can
be stated as follows: an employer is willing to hire the best secretary out of n
rankable candidates for a position. The candidates are interviewed one by one
in a random order. A decision about each particular candidate is to be made
immediately after the interview. Once rejected, a candidate cannot be recalled.
During the interview, the administrator can rank the applicant among all applicants
interviewed so far, but is unaware of the quality of yet unseen applicants. The
question is about the optimal strategy (stopping rule) to maximize the probability
of selecting the best candidate. The secretary problem is one of many names for
a famous problem of optimal stopping theory.
It is also known as the marriage
problem, the sultan’s dowry problem, the fussy suitor problem and others. This
problem has been extensively studied in the ﬁelds of applied probability, statistics,
and decision theory and has been considered by many authors (see [6], [7] and [12]
for an extensive bibliography). It can also be posed as a decision-taking problem
in a game with the following rules:

(1) You want to choose one object.
(2) The number of objects is known.
(3) The objects appear sequentially in random order.
(4) The objects are rankable.
(5) Each object is accepted or rejected before the next object appears.
(6) The decision depends only on the relative ranks.
(7) Rejected objects cannot be recalled.
(8) Payoﬀ: You only win if the best object is chosen.

This problem has a very elegant solution. Dynkin [5] and Lindley [10] inde-
pendently proved that the best strategy consists in observing roughly n/e of the
candidates and then choosing the ﬁrst one that is better than all those observed

1

2

L. BAY ´ON, J. GRAU, A. M. OLLER-MARC´EN, M. RUIZ, AND P.M. SU ´AREZ

was reﬁned by Gilbert and Mosteller in [8], where they show that(cid:2)(n − 1

so far. This strategy returns the best candidate with a probability of at least 1/e,
this being its approximate value for large values of n. This well-known solution
2 )e−1 + 1
is a better approximation than [n/e], although the diﬀerence is never greater than
1. There are other variants of the secretary problem that also have simple, elegant
solutions. In the “postdoc” problem, for instance, the desire to pick the best is
replaced by the desire to pick the second best (because, according to Vanderbei
[13], the “best” will go to Harvard). For this problem, the probability of success
for an even number of applicants is exactly
4(n−1) . This probability tends to 1/4
as n tends to inﬁnity, illustrating the fact that it is easier to pick the best than the
second best.

2(cid:3)

n

If the number of candidates is unknown, the observer faces an additional risk. If
he rejects any candidate, he may then discover that it was the last one, in which
case he receives nothing at all. In [11] the case in which the number of candidates
is a random variable with a discrete uniform distribution U [1, n] was studied. In
this case, the cutoﬀ value for large N is approximately N e−1/2 and the probability
of success is 2e−2. This same paper also tackles the problem assuming that the
number of candidates is Poisson distributed with parameter λ.

Another interesting variant of the problem was introduced by Bearden [1], con-
sidering a positive payoﬀ that increases with the number interviews. In this case,
the optimal cutoﬀ value is not proportional to the number of candidates and it is
the square root of such number.

In the present paper, we consider a variant of the secretary problem in which
the candidates state their expected salary at the interview, which we assume is
in accordance with their qualiﬁcations. The goal is for the employer to hire the
best or the worst (cheapest), indiﬀerent between the two cases. In other words, it
is the classical problem in which rule 8 above is replaced by: “Payoﬀ: You only
win if the best or the worst is chosen”. The problem is studied in Section 2 in
its version with full information regarding the number of candidates. In Section 3,
we consider the problem if the number of candidates is a random variable with a
uniform distribution U [1, n]. In Section 4, the number of candidates is a random
variable with a Poisson distribution of parameter λ.
In Section 5, we consider
payoﬀs other than the classical binary payoﬀ that are dependent on the number of
interviews carried out. In one case, we consider payoﬀ proportional to the number
of interviews and in another, payoﬀ proportional to the number of interviews not
carried out.

The techniques used throughout the paper are suitable adaptations of those
employed in the study of the solution to the classical secretary problem (limit of
Riemann integrals, expansions at inﬁnity, etc.) to obtain asymptotic formulas of
the type α · n + β + o(1) for the optimal cutoﬀ value. In some proofs related to the
calculation of some limits, details have been omitted and their correctness has been
tested with the powerful symbolic computation tool Mathematica. Several of the
results are formulated in terms of W0 and W
−1 functions, the lower real branches
of the Lambert W function, respectively; see Corless et al. [3] for further details.

2. A variation of the secretary problem: the best or the worst

In this section, we study a variation of the classical secretary problem considering
that the success of the player resides in choosing the worst or the best object,

A VARIANT OF THE SECRETARY PROBLEM: THE BEST OR THE WORST

3

indiﬀerent between the two cases. In this case, as in the secretary problem, the
strategies to consider consist in rejecting a certain number of objects (cutoﬀ value)
and then taking the ﬁrst object that is better or worse than all those previously
rejected. After rejecting r objects, the probability of successfully choosing the k-th
inspected object, P(k), is that of this object being the best or the worst and that
of not having interrupted the inspections by previously choosing another object.
Given that both are independent events, the probability of success will be the
product of the probability of both events. The probability that the k-th object to
be seen is the best or worst of all the objects is 2/n while the probability that the
best and the worst among those seen prior to the k-th is among the ﬁrst r objects
(i.e. the inspections have not ceased before seeing the k-th object) is

Thus, provided 1 < r < k ≤ n, we have that

(cid:0)r
2(cid:1)
2 (cid:1) =
(cid:0)k−1

r(r − 1)

(k − 1)(k − 2)

.

P(k) =

2

n (cid:0)r
2(cid:1)
(cid:0)k−1
2 (cid:1)

and the probability of success, rejecting the ﬁrst r objects, and accepting afterwards
the ﬁrst one which is either better than all the previous ones or worse than all the
previous ones, is

Pn(r) :=

nXk=r+1

P(k) =

2(cid:0)r
2(cid:1)n

nXk=r+1

1

2 (cid:1) .
(cid:0)k−1

Note that for n > r ∈ {0, 1}, it is straightforward to see that the probability of

success is

Theorem 1. Given a positive integer n > 2, consider the function

Pn(0) = Pn(1) =

2
n

.

Pn(r) :=

2(cid:0)r
2(cid:1)n

nXk=r+1

1

(cid:0)k−1
2 (cid:1)

deﬁned for every integer r ∈ [2, n − 1]. Let us denote by M(n) the value for which
the function Pn reaches its maximum. Then,

2r(n − r)
n(n − 1)

i) Pn(r) =
ii) M(n) = ⌊n/2⌋.
iii) The maximum of Pn is:

.

pn := Pn(M(n)) = ⌊ 1+n
2 ⌋
2⌊ 1+n
2 ⌋ − 1

Proof.

=( n

2(n−1) ,
n+1
2n ,

if n is even;

if n is odd.

i) First of all, observe that

Pn(r) =

2(cid:0)r
2(cid:1)n

nXk=r+1

1

2 (cid:1) =
(cid:0)k−1

r(r − 1)

n

nXk=r+1

2

(k − 1)(k − 2)

.

4

L. BAY ´ON, J. GRAU, A. M. OLLER-MARC´EN, M. RUIZ, AND P.M. SU ´AREZ

Now, using telescopic sums, we have that

nXk=r+1

2

(k − 1)(k − 2)

= 2

nXk=r+1(cid:18) 1
k − 2 −

1

k − 1(cid:19) = 2(cid:18) 1

r − 1 −

1

n − 1(cid:19) =

=

2(n − r)

(r − 1)(n − 1)
n(n−1) r2 + 2

and the result follows.
ii) Since Pn(r) = − 2

variable r, it is clear that

(n−1) r is the equation of a parabola in the

M(n) = min{r ∈ [2, n − 1] : Pn(r) ≥ Pn(r + 1)} .

Now,

Pn(r + 1) − Pn(r) =

so it follows that

2

n(n − 1)

(n − 2r − 1)

Pn(r + 1) − Pn(r) ≤ 0 ⇔ (n − 2r − 1) ≤ 0 ⇔ r ≥

n − 1

2

.

Consequently,

M(n) = min(cid:26)r ∈ [2, n − 1] : r ≥

n − 1

2 (cid:27) = ⌊n/2⌋

as claimed.

iii) It is enough to apply the previous result.

If n is even, then n = 2N and

Pn(M(n)) = Pn(N ) =

Moreover, in this case

2N (n − N )
n(n − 1)

=

2N 2

2N (2N − 1)

=

N

2N − 1

(cid:22) 1 + n
2 (cid:23) =(cid:22) 1 + 2N

2

so it follows that

Pn(M(n)) =

N

2N − 1

=

as claimed.

(cid:23) = N
(cid:4) 1+n
2 (cid:5)
2 (cid:5) − 1
2(cid:4) 1+n

(cid:23) = N + 1
(cid:4) 1+n
2 (cid:5)
2 (cid:5) − 1
2(cid:4) 1+n

Otherwise, if n is odd, then n = 2N + 1 and

Pn(M(n)) = Pn(N ) =
In this case

2N (n − N )
n(n − 1)

=

2N (2N + 1 − N )

(2N + 1)2N

=

N + 1
2N + 1

.

(cid:22) 1 + n
2 (cid:23) =(cid:22) 1 + 2N + 1

2

so we also have that

Pn(M(n)) =
and the proof is complete.

N + 1
2N + 1

=

(cid:3)

A VARIANT OF THE SECRETARY PROBLEM: THE BEST OR THE WORST

5

It can be deduced from this result that, for n > 2, the strategy that maximizes
the probability of success consists in rejecting the ﬁrst ⌊ n
2⌋ (optimal cutoﬀ value)
objects and then choosing the ﬁrst to appear that is better or worse than all the
preceding ones. The probability of success following this strategy is

⌊ 1+n
2 ⌋
2⌊ 1+n
2 ⌋ − 1

In the cases n ∈ {1, 2}, it is evident that an optimal cutoﬀ value is r = 0, i.e.
to accept the ﬁrst object that we are shown; the value of the probability of success
being 1 in both cases: p1 = p2 = 1

3. Unknown number of candidates with uniform distribution U [1, n]

In this section, we analyze the case in which the number of objects is unknown,
but it is known that it can be anywhere between 1 and n with equal probability.
As we saw in Theorem 1 i), the probability of success with i > 1 objects while
rejecting the ﬁrst r observed objects is Pi(r) = 2r(i−r)
i(i−1) . Hence, the probability of
success in this case will be the mean probability of the n equally probable possible
scenarios with probability 1/n. That is, the probability of success when rejecting
the r ﬁrst objects before comparing with the previous ones and with an unknown
number of candidates that follows a uniform distribution U [1, n] will be:

P (r, n) :=

nXi=r+1

Pi(r)

n

=

nXi=r+1

2r(i − r)
i(i − 1)n

We denote by m(n) the value for which P (·, n) reaches its maximum value in [1, n]
and by P(n), the maximum value it reaches, i.e. P(n) := P (m(n), n). We shall ﬁrst
prove that the probability of success in the game, P(n), is strictly decreasing for
n > 1, where clearly P(1) = P(2) = 1 and m(1) = m(2) = 0. The technique used
in the proof is an adaptation of the strategy-stealing argument: starting from any
given strategy in the game with a number of objects following a uniform distribution
[1, n + 1], two strategies are developed for the game with a number of objects
following a uniform distribution [1, n], one or other of which necessarily improves
the initial probability of success. More speciﬁcally, we show that if r is the optimal
cutoﬀ value for the problem associated with a uniform distribution [1, n + 1], then
a higher probability of success is achieved in the problem associated with a uniform
distribution [1, n] with either r or r − 1 as the cutoﬀ value.
Lemma 1. Consider the function

P (r, n) :=

nXi=r+1

2(i − r)r
i(i − 1)n

deﬁned for every pair of integers (r, n) with 0 < r < n. Then, one of the following
inequalities holds:

P (r, n + 1) < P (r − 1, n),
P (r, n + 1) < P (r, n).

P (r, n) =

=

nXi=r+1
n "(cid:16) r

2r

In the same way we ﬁnd that

1
i

n−1Xi=r

=

2r
n

2(i − r)r
i(i − 1)n

n − 1(cid:17) +
nXi=r+1
n + 1(cid:20)(cid:18) r

2r

i

nXi=r+1(cid:18) r
i − 1# =

1

P (r, n + 1) =

P (r − 1, n) =

2(r − 1)

n

n + 1 − 1 +

(cid:20)(cid:18) r − 1

n − 1 +

+

1
i − 1
2r

r

+

i − 1(cid:19) =
n − 1(cid:17) + H(n, r)i .

n h(cid:16) r
n(cid:19) + H(n, r)(cid:21) ,
r − 1(cid:19) + H(n, r)(cid:21)

1

1

6

L. BAY ´ON, J. GRAU, A. M. OLLER-MARC´EN, M. RUIZ, AND P.M. SU ´AREZ

Proof. Let us denote H(n, r) :=

. Then we have that

As a consequence, it follows that

P (r, n + 1) − P (r − 1, n) =

P (r, n + 1) − P (r, n) =
Thus, if we assume that both

(cid:20)−

2(1 + n − r)
n(n + 1)

(1 + 2n)(1 + n − r)

n(n + 1)

2r

n(n + 1)(cid:20) 2n(1 + n − r) − r

n(n + 1)

− H(n, r)(cid:21)

+ H(n, r)(cid:21) ,

P (r, n + 1) − P (r − 1, n) ≥ 0 and P (r, n + 1) − P (r, n) ≥ 0,

it follows that

A := H(n, r)n(n + 1) − (1 + 2n)(1 + n − r) ≥ 0,
B := − (H(n, r)n (n + 1)) + 2n (1 + n − r) − r ≥ 0.

But in this case 0 ≤ A + B = −1 − n < 0, a contradiction, and hence the

(cid:3)

result.

Corollary 1. With the previous notation, P(n + 1) < P(n) for every n > 1.

Proof. If n > 1,

P(n + 1) = P (m(n + 1), n + 1) < max{P (m(n + 1), n), P (m(n + 1) − 1, n)} ≤

≤ P (m(n), n) = P(n),

where the ﬁrst inequality follows from Lemma 1 and the second holds by the deﬁ-
nition of m(n).
(cid:3)
Lemma 2. The function g(x) = −2x log x−2x(1−x) reaches its absolute maximum
in the interval [0, 1] at the point
1
2

2
e2 ) = 0.20318786...,

ϑ := −

W (−

where W denotes Lambert W -function. Moreover, the value of this maximum is:

Proof. This is an elementary Calculus exercise. The derivative g′(x) = −4 + 4x −
2 log x = 0 in [0, 1] if and only if x = 1 or x = − 1
2 W(cid:0)− 2
that x = 1 is a minimum and that x = − 1
computations conclude the proof.

g(ϑ) = 2(ϑ − ϑ2) = 0.32380511...
2 W(cid:0)− 2
e2(cid:1). It is easily checked
e2(cid:1) is a maximum and some easy

(cid:3)

A VARIANT OF THE SECRETARY PROBLEM: THE BEST OR THE WORST

7

Theorem 2. With all the previous notation, the following hold:

i) For every positive integer n,
1 = P(1) = P(2) > P(3) > ··· > P(n) > P(n + 1) > ··· > 2(ϑ − ϑ2).
lim
ii)
n→∞
lim
n→∞

P (⌊ϑn⌋, n) = lim
n→∞

= ϑ; i.e., m(n) ∼ ϑn.

P(n) = 2(ϑ − ϑ2).

m(n)

n

iii)

Proof.

i) By Corollary 1, we know that P(2) = 1 and that P(n) is decreasing.

Now, if we recall Lemma 1, we can put

2r

n "(cid:16) r

1

i# =

2r

n
i

1
n

,

2r
n

P (r, n) =

n−1Xi=r

n − 1(cid:17) +

n (cid:16) r
n − 1(cid:17) +

where the latter sum is a Riemann sum. Consequently,

n−1Xi=r
P (r, n) ≃ 2x(x − 1) + 2xZ 1
Finally, since P(n) is decreasing in n and 2(ϑ − ϑ2) is the maximum
value of g(x) due to Lemma 2 it follows that P(n) > 2(ϑ − ϑ2) for every
integer n > 1, as claimed.
ii) By Lemma 2, g(x) reaches its maximum value at ϑ. Since P (·, n) reaches

lim
n→∞
with x = lim
n→∞

dt = 2x(x − 1) − 2x log x = g(x)

r/n.

1
t

x

r/n, it follows immediately that

its maximum at m(n) and x = lim
n→∞
m(n)

lim
n→∞

n

= ϑ.

iii) From the previous work and Lemma 2, it is clear that

P (⌊ϑn⌋, n) = lim
n→∞

lim
n→∞
n→∞⌊ϑn⌋/n = ϑ.
because lim

P(n) = g(ϑ) = 2(ϑ − ϑ2)

(cid:3)

From the above theorem, it can be deduced that, for any value of n, the optimal
strategy achieves success with a probability greater than 2(ϑ − ϑ2) = 0.3238 . . . .
Moreover, this is the approximate value of the probability of success for large val-
ues of n, just by following the simple strategy of rejecting the nearest integer to
− n
e2 ) = n · 0.2031 . . . . Thus, [ϑ · n] constitutes a practical estimation of
the optimal value of initial rejections, just like [n/e] does in the classical secretary
problem. This is, in fact, true:
[nϑ] is within 1 of the correct answer for all n,
although many errors (20%) are made with this estimation:

2 W (− 2

3, 8, 13, 18, 23, 32, 37, 42, 47, 52, 57, 62, 67, 72, 77, 82, 96, 101, 106, 111, 116, 121, . . .

However, it is also true that the error is negligible if compared with the probability
of the optimal strategy for large values of n.

Let us now look at a result that provides a better estimate for m(n) than the one
above. However, let us ﬁrst consider the following auxiliary result where ψ stands
for the digamma function.

8

L. BAY ´ON, J. GRAU, A. M. OLLER-MARC´EN, M. RUIZ, AND P.M. SU ´AREZ

n + 1
Lemma 3. Let us consider the function f (r, n) := − 2r
and let α(n) be the value for which the function f (·, n) reaches it maximum in [1, n].
Then, α(n) ≈ m(n).
Proof. If we recall the deﬁnition of the digamma function ψ, we can write

n ψ(n)− 2r log(r)

n2 + 2r

n + 2r2

n

P (r, n) = −

2r
n

+

2r2
n2 +

2r
n

ψ(n) −

2r
n

ψ(r).

Now, we know that for any integer r

ψ(r) = log r −

1
2r

+ ǫ(r),

with ǫ(r) = O(1/2r) if r → ∞. Thus,

2r
n

2r2
n2 +

2r
n

+

P (r, n) = −
On the other hand, since r ≥ 1, it follows that there exists k such that |2rǫ(r)| ≤

= f (r, n) −

ψ(n) −

+

n

n

n

.

2r log(r)

2rǫ(r)

2rǫ(r)

1
n −

k for every r and hence:

f (r, n) −

k
n ≤ P (r, n) ≤ f (r, n) +

k
n

Obviously both functions g1(r, n) := f (r, n)− k

n reach
their maximum at α(n). Now, let β1(n) and β2(n) points such that g2(β1(n), n) =
g2(β2(n), n) = g1(α(n), n) and α(n) ∈ [β1(n), β2(n)]. The inequality above implies
that

n and g2(r, n) := f (r, n) + k

β1(n) ≤ m(n) ≤ β2(n)

Finally, for every r we have that g2(r, n) − g1(r, n) = 2k/n so it follows that

0 and, consequently also

|β2(n) − β1(n))| −→n→∞

|α(n) − m(n)| −→n→∞

0.

(cid:3)

Theorem 3. With all the previous notation, the following hold:

n
i) m(n) ≈ −
2
ii) m(n) ≈ nϑ +

2e−2+ψ(n)

W(cid:18)−
4 − 2e2−2ϑ .

n

1

(cid:19), where ψ denotes the digamma function.

Proof.

that

i) Since f (·, n) (see Lemma 3) reaches its maximum at α(n), it follows

0 =

∂f
∂r

(α(n), n) = −

4
n

+

4α(n)
n2 +

2
n

ψ(n) −

2 log(α(n))

n

.

From this, and taking into account the deﬁnition of Lambert W function

it follows that

W (−
so it is enough to apply Lemma 3.

α(n) = −

n
2

2e−2+ψ(n)

n

)

A VARIANT OF THE SECRETARY PROBLEM: THE BEST OR THE WORST

9

ii) Using i), we have that

lim
n→∞

(m(n) − nϑ) = lim

n→∞(cid:18)−

n
2

W (−

Thus,

as claimed.

m(n) ≈ nϑ +

) − nϑ(cid:19) =

1

4 − 2e2−2ϑ .

2e−2+ψ(n)

n

1

4 − 2e2−2ϑ

(cid:3)

Using the formulahnϑ +

1

4−2e2−2ϑi as far as our computational capacity let us,

we ﬁnd that the optimal cutoﬀ value produces errors only for very few values of
n. Speciﬁcally, only four are known: 2, 3, 23 and 2971. We now show another
asymptotic result for the solution m(n) ≈ h(n) that improves the result of the
previous theorem in the sense that there is no known value of n > 4 for which
[h(n)] returns a wrong result.

Proposition 1.

m(n) ≈ h(n) :=

1
2

+

3 W ( −2
e2 )

4

+

1

2 W (

e

1

3
2 n n W ( −2
e2 )

.

)

e2 )(cid:1) −

W ( −2
e2 )

4(cid:0)1 + W ( −2
4 − 2e2−2ϑ .

1

nϑ +

Proof. It suﬃces to verify that h(n) has the following straight line as an asymptote:

Although no exceptions to the equality m(n) = [h(n)] have been found for n > 4,
there is no absolute guarantee that this occurs ad inﬁnitum. This is what happens
with the following asymptotic formula for the optimal cutoﬀ value in the classical
secretary problem

(cid:3)

&−

1

2W (− e−(1+1/(2n)

2n

)'

2 W (− 2

which coincides with the solution for all n > 3 with no known exceptions.
Remark. The constant ϑ = − 1
e2 ) = 0.20318786 . . . (A106533 in OEIS)
appears in [7] in the context of the secretary problem considering a payoﬀ of (n −
k+1)/n. In fact, it appears erroneously approximated as 0.20388, but is actually the
constant which appears, as in this study, as the solution of the equation − log(x)−
2 + 2x = 0. Furthermore, as a noteworthy curiosity, it should be pointed out that
this constant has appeared in a completely diﬀerent context from the one addressed
here as the solution to the above equation (the Daley-Kendall model) and is known
as the rumour’s constant [4, 9].

3.1. What is the value of the information regarding the number of ob-
jects? When the number of available objects is unknown, but it is known that
it is a uniform random variable U [0, N ], we have established that the asymptotic
value of the probability of success is 2(ϑ − ϑ2) = 0.3238 . . . . It is natural to ask
how valuable exact knowledge of the number of objects that we shall be able to
observe may be. That is, if we win 1 Euro for making a successful choice, how much

10

L. BAY ´ON, J. GRAU, A. M. OLLER-MARC´EN, M. RUIZ, AND P.M. SU ´AREZ

might we pay to know the value of the random variable U [0, N ] that represents the
number of available objects.

If, prior to the inspections, we are given the information regarding the number
of objects, n ∈ [1, N ], in each case we will adopt the optimal strategy set out in the
ﬁrst section of this paper that gives us a probability of success

pn :=

n

2(n−1) ,
n+1
2n ,
1

if n > 2 is even;

if n > 2 is odd
if n ∈ {1, 2}

and the overall probability of success will be PN := N −1PN

n=1 pn. Thus, it is
straightforward to see that the probability of success with a number of objects
resulting from a uniform random variable [1, N ], whose value is revealed before the
inspections start, when N tends to inﬁnity, is

PN =

lim
N→∞

1
2

Therefore, the value of the information is PN − P(N ), which, when N tends to
inﬁnity, is

lim
N→∞

(PN − P(N )) =

1
2 − 2(ϑ − ϑ2) = 0.1761 . . .

4. Unknown number of candidates with a λ−Poisson distribution
For the classical secretary problem, Presman and Sonin, [11] showed that, if the
number of candidates is Poisson distributed with parameter λ, then the optimal
stopping limit relation is r∗(λ)/λ → e−1 and that this is also the asymptotic value
of the probability of success. In the variant we have introduced in this paper, an
analogous conclusion is reached by replacing 1/e by 1/2, as seen in Section 2.

If the number of objects in the best or worst variant is Poisson distributed with
parameter λ, the probability of success after rejecting the ﬁrst r candidates will be

∞Xi=3
∞Xi=3

2
i

P (0, λ) :=

λ
eλ +

λ2
2 eλ +

2
i

e−λλi

i!

,

P (1, λ) :=

λ2
2 eλ +

e−λλi

,

i!

P (r, λ) :=

∞Xi=r+1

2(i − r)r
i(i − 1)

e−λλi

i!

Following the same notation as in Section 3, we denote by m(λ) the value for
which P (·, λ) reaches its maximum value and by P(λ), the maximum value it
reaches; i.e. P(λ) := P (m(λ), λ). Unlike what occurred in the previous case,
the probability of success in the game, P(λ), is not monotone with respect to λ.
Next, we show the graph of P(λ) (Figure 1), which is seen to comprise concave arcs
in each interval [λi, λi+1], where λ0 = 0, λ1 is such that P (0, λ1) = P (2, λ1) and λi
for i > 1 is such that P (i, λi) = P (i + 1, λi).

solution to the equation

The maximum probability of success is achieved in λ = eλ := 2.01771 . . . , the

0 = −2 + 2 ex − x + 2 γ x + x2 + 2 x Γ(−x) + 2 x log(−x),

A VARIANT OF THE SECRETARY PROBLEM: THE BEST OR THE WORST

11

Figure 1. The probability P (λ).

where m(eλ) = 0 and P(eλ) = 0.726470 . . .

We will proof that, as Figure 1 suggests, P(λ) tends to 1/2 when λ grows to
2 as cutoﬀ

inﬁnity and that this propability can be asymptotically reached using λ
value. But ﬁrst we need some technical results.

Lemma 4. Let us deﬁne the function

f (r, λ) :=

rXi=2

2(i − r)r
i(i − 1)

e−λλi

i!

.

we just need to prove that limn→∞

Now,

an = 0.

an+1 = 22(n + 1)2e−2(n+1)

2i(n + 1)i

i!

and since

2i(n + 1)i

i!

n+1Xi=2

=

+

22
2!

2ini
i!

nXi=2
n! (cid:18)nn +

2n

n
1!

nn−1 +

23
3!
n(n − 1)

2!

+

(2n + 1) +

(3n2 + 3n + 1) + . . . +

nn−2 + . . . +

n(n − 1)··· 2.1

n!

(cid:19) +

2n+1

(n + 1)!

(n + 1)n+1

2 , λ) = 0.
Then, limλ→∞
Proof. First of all, note that

f ( λ

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

λ/2Xi=2

2(i − λ/2)λ/2

i(i − 1)

e−λλi

i!

an := 22n2e−2n

so, if we deﬁne

λi
i!

<

1
λ

λ/2Xi=2

,

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

< λ2e−λ

2ini
i!

nXi=2
n+1Xi=2

12

L. BAY ´ON, J. GRAU, A. M. OLLER-MARC´EN, M. RUIZ, AND P.M. SU ´AREZ

we have that

an+1 = 22(n + 1)2e−2(n+1)

+ 22(n + 1)2e−2(n+1) 22
2!

(2n + 1) + . . . +

+ 22(n + 1)2e−2(n+1) 2n

n
1!

nn−1 +

n(n − 1)

2!

nn−2 + . . . +

n(n − 1)··· 2.1

n!

2ini
i!

nXi=2
n! (cid:18)nn +

+ 22(n + 1)2e−2(n+1) 2n+1
(n + 1)!

(n + 1)n+1

On the other hand,

Hence

2ini
i!

=

an

22n2e−2n .

nXi=2

an+1 =(cid:18) n + 1

n (cid:19)2 an

e2 + 22(n + 1)2e−2(n+1) 22

2!

+ 22(n + 1)2e−2(n+1) 2n

n! (cid:18)nn +

+ 22(n + 1)2e−2(n+1) 2n+1
(n + 1)!

(n + 1)n+1,

(2n + 1) + . . . +

n
1!

nn−1 +

n(n − 1)

2!

nn−2 + . . . +

n(n − 1)··· 2.1

n!

which clearly implies that

n→∞"an+1 −(cid:18) n + 1

n (cid:19)2 an

e2# = 0.

lim

Finally, an being decreasing and non-negative, we have that limn→∞

limn→∞

an = l. Thus,

(cid:19)

(cid:19)

an+1 =

(cid:3)

and

as claimed.

l =

l

e2 ⇒ l(cid:18)1 −

1

e2(cid:19) = 0 ⇒ l = 0

l = lim
n→∞

an = 0

P ⋆(r, λ) :=

∞Xi=2

2(i − r)r
i(i − 1)

e−λλi

i!

.

Theorem 4. Consider the function P ⋆ deﬁned over N × R+ and given by

For a ﬁxed λ, let us denote by M⋆(λ) the value for which P ⋆(·, λ) reaches its
maximum and put P ⋆(λ) := P ⋆(M⋆(λ), λ). Then, the following hold:

i)

=

M⋆(λ)
λ
λ
P ⋆(
, λ) =
ii)
2
iii) M⋆(λ) ≈ λ
2 − 1.

lim
λ→∞
lim
λ→∞

1
2

.

1
2

.

A VARIANT OF THE SECRETARY PROBLEM: THE BEST OR THE WORST

13

Proof. First of all, we are going to compute the value of M⋆(λ). To do so, let us
consider functions

S1(x) =

S2(x) =

S3(x) =

Then, we have that

,

(i − 1)i!

xi

xi

∞Xi=2
∞Xi=2
∞Xi=2
ex − 1

x

i(i − 1)i!
xi
i i!

= −

xi
i i!

∞Xi=2

+ S1(x),

S′′1 (x) =

, S′3(x) =

ex − 1

x − 1.

If we integrate these expressions we obtain that

where

Consequently,

S1(x) = 1 − ex + x − γx + x E(x) − x log x
S3(x) = −γ + E(x) − log x − x

E(λ) = γ + log λ +Z λ

0

ex − 1

x

dx.

S2(x) = 1 − ex + 2x + (γ − E(x) + log x) (1 − x) .

Finally, note that

P ⋆(r, λ) = 2re−λ" ∞Xi=2

Hence,

∂P ⋆(r, λ)

∂r

and, consequently, if we deﬁne

λi

(i − 1)i! − r

i(i − 1)i!# = 2re−λS1(λ) − 2r2e−λS2(λ)

λi

∞Xi=2
= 2e−λS1(λ) − 4re−λS2(λ)

r(λ) :=

1 − eλ + λ − γλ + λ E(λ) − λ log λ

2 [1 − eλ + 2λ + (γ − E(λ) + log λ) (1 − λ)]

it is clear that 0 = ∂P ⋆(r,λ)

|r=r(λ). Thus, we have just obtained that M⋆(λ) = r(λ).
Once we have computed the value of M⋆(λ), we are in the condition to prove

∂r

the three statements of the theorem

i) We have

M⋆(λ)

lim
λ→∞
so, if we recall the deﬁnition of E(λ) we have that

λ [1 − eλ + 2λ + (γ − E(λ) + log λ) (1 − λ)]

lim
λ→∞

1 − eλ + λ − γλ + λ E(λ) − λ log λ

1
2

=

λ

M⋆(λ)

λ

=

1
2

lim
λ→∞

lim
λ→∞

ex

1 − eλ + λ + λR λ
λh1 − eλ + 2λ + (λ − 1)R λ

0

0

−1
x dx

ex−1

x dxi

14

L. BAY ´ON, J. GRAU, A. M. OLLER-MARC´EN, M. RUIZ, AND P.M. SU ´AREZ

and, applying L’Hˆopital’s rule repeatedly we obtain:

M⋆(λ)

λ

=

1
2

1 + λ
λ + 3

=

1
2

,

lim
λ→∞

lim
λ→∞

as claimed.

ii) Now, we have that

P ⋆(

λ
2

lim
λ→∞

, λ) = lim
λ→∞

λ

2eλ"(−λ2 + 3λ)Z λ

0

ex − 1

x

dx + (λ − 2)eλ − 2λ2 + λ + 1)#

so, again by L’Hˆopital’s rule, we obtain:

P ⋆(

λ
2

lim
λ→∞

, λ) =

1
2

lim
λ→∞

6 + 2λ
2λ + 5

=

1
2

.

iii) Since

lim
λ→∞

(M⋆(λ) − λ/2) =
L’Hˆopital’s rule leads to

lim
λ→∞

1
2

1 − eλ + λeλ − 2λ2 + (2λ − λ2)R λ

1 − eλ + 2λ + (λ − 1)R λ

0
ex−1
x dx

ex

0

−1
x dx

lim
λ→∞

(M⋆(λ) − λ/2) =

1
2

lim
λ→∞

−2λ − 4

λ

= −1.

Thus,

as claimed.

M⋆(λ) ≈

λ
2 − 1,

,

(cid:3)

Lemma 5. Assume that the number of objects n is Poisson distributed with pa-
rameter λ. If the (random) value of n is revealed before the inspections start, then
the probability of success tends to 1/2 when λ tends to inﬁnity. In other words:

lim
λ→∞

∞Xn=1

pn

e−λλn

n!

=

1
2

.

Proof. We reason just like in Subsection 3.1. If, prior to the inspections, we are
given the information regarding the number of objects, n ∈ [0,∞), in each case we
will adopt the optimal strategy set out in the ﬁrst section of this paper that gives
us a probability of success pn and the overall probability of success will be

Pλ :=

pn

∞Xn=1

where

so we have that

e−λλn

n!

= 2

∞Xn=1
S(λ) =Z λ

0

sinh(x)

dx.

x

n

e−λλn

−1 + 2 n

n!

=

λ S(λ)

eλ

,

Pλ =

lim
λ→∞

1
2

.

(cid:3)

Theorem 5. In the previous setting we have that

P (

lim
λ→∞

λ
2

, λ) = lim
λ→∞

P (m(λ), λ) = lim
λ→∞

P(λ) =

1
2

.

A VARIANT OF THE SECRETARY PROBLEM: THE BEST OR THE WORST

15

Proof. Since pn (see Lemma 5) is the maximum value of the probability of suceeding
in the problem with complete information with n objects, it follows for all n > 1
that

and hence,

pn ≥ Pn(m(λ)) =

2(n − m(λ))m(λ)

n(n − 1)

pn

∞Xn=1

e−λλn

n! ≥

∞Xn=m(λ)+1

2(n − m(λ))m(λ)

e−λλn

n!

= P(λ)

n(n − 1)
So, if we take upper limits it is clear that limλ→∞

Now, recalling the function f from Lemma 4 we have that

P (m(λ), λ) ≤ 1
2 .

P(λ) = P (m(λ), λ) ≥ P (λ/2, λ) = P ⋆(λ/2, λ) − f (λ/2, λ).

But, due to Lemma 4 and Theorem 4 we obtain that

and taking lower limits:

lim
λ→∞

P ∗(λ/2, λ) − f (λ/2, λ) =

1
2

limλ→∞

P(λ) ≥

1
2

.

In conclusion,

1
2 ≤ limλ→∞

P(λ) ≤ limλ→∞

P(λ) ≤

1
2

and the proof in complete.

(cid:3)

This theorem satisfactorily solves the problem, since it implies that λ/2 is the
best possible estimation for the cutoﬀ value because it guaratees an asymptotical
succeding probability of 1
2 (exactly the same that the exact value of m(λ) would
provide). Thus, this result proves that if the number of objects is unknown with a
λ−Poisson distribution, the strategy that we must follow in order to maximize the
succeding probability is to select the ﬁrst object which is better or worst than the
previous ones just after rejecting the ﬁrst λ/2 objects. With this strategy we will
succeed approximately one half of the times.

Unlike what happened in the previous section (see 3.1.), when facing with an
unknown number of objects resulting from a Poisson distribution with parameter
λ, the value of the information of the number of objects is asymptotically null. For
large values of λ, the diﬀerence between the probability of success with and without
this information is negligible.

In addition, as far as our computing capabilities let us check, ⌊λ/2− 1⌋ coincides
with the exact value m(λ) for every integral value of λ greater than 1. Hence, the
following conjecture.
Conjecture 1. m(λ) ≈ M⋆(λ) ≈ λ

2 − 1.

5. Payoff proportional to the number of performed or

non-performed interviews

We now consider the same underlying game as in the previous sections, but
introducing diﬀerent payoﬀs based on the number of observed objects. We consider
that, in the case of success (choosing the best or the worst object), we shall receive
a payoﬀ based on the number of interviews carried out. The aim is therefore to

16

L. BAY ´ON, J. GRAU, A. M. OLLER-MARC´EN, M. RUIZ, AND P.M. SU ´AREZ

maximize the payoﬀ. Although the goal is still to choose the best or worst object,
there are incentives (or penalties) for carrying out more (or fewer) inspections of
the objects than those that maximize the probability of success found in Section 2,
as higher payoﬀs will be obtained. We ﬁrst consider the case in which the payoﬀ
received is proportional to the number of observed objects and then the case in
which the payoﬀ received is proportional to the number of non-observed objects.

If we consider that the payoﬀ for success in the game with n available objects
after having carried out k inspections is g(k, n), the expected payoﬀ following the
strategy of rejecting r objects and choosing the ﬁrst observed object that is better
or worse than those seen so far will thus be:

G(r, n) :=

2(cid:0)r
2(cid:1)n

nXk=r+1

g(k, n)

(cid:0)k−1
2 (cid:1)

We consider two cases: the ﬁrst, where g(k, n) = k
n , and the second, where g(k, n) =
n−k
n . In both cases, we obtain asymptotic formulas for the optimal cutoﬀ value and
the expected payoﬀ following the optimal strategy.

5.1. Payoﬀ proportional to the number of performed interviews.

Theorem 6. Consider the function

G(r, n) :=

2(cid:0)r
2(cid:1)n2

nXk=r+1

k

(cid:0)k−1
2 (cid:1)

deﬁned for every pair of integers (r, n) such that 1 < r < n. Let us denote by M(n)
the value for which the function G(·, n) reaches its maximun. Then,

i)

ii)

lim
n→∞
lim
n→∞

=

M(n)

n

G(cid:18)(cid:20) n

G(r, n) =

Proof. First of all, observe that

Now, using telescopic sums, we have that

nXk=r+1

Thus,

2k

(k − 1)(k − 2)

G(r, n) =

2r(r − 1)

n2

r

=

4

n − 1

1
√e

; i.e, M(n) ∼ n
√e .

1

k

n2

1
e

.

= 2

r(r − 1)

√e(cid:21) , n(cid:19) =
2(cid:0)r
2(cid:1)n2
nXk=r+1
nXk=r+1
2 (cid:1) =
(cid:0)k−1
k − 1(cid:19) = 2(cid:18) 2
nXk=r+1(cid:18) 2
k − 2 −
i# =
" 2
n−1Xi=r
r − 1 −
n(cid:19) n−1Xi=r
n(cid:18) r
n(cid:17) + 2
n(cid:16)1 −
G(r, n) ≃ 2x2Z 1

4r(n − r)
n2(n − 1)
n
1
n
i

n − 1
r

n −

1
t

+

2

1

1

r

x

lim
n→∞

dt = −2x2 log x = g(x)

2k

(k − 1)(k − 2)

r − 1 −

1

k − 1

1

n − 1(cid:19)+2
n−1Xk=r+1
n−1Xi=r

2r(r − 1)

1
i

n2

=

+

where the latter sum is a Riemann sum. Consequently,

A VARIANT OF THE SECRETARY PROBLEM: THE BEST OR THE WORST

17

with x = lim
n→∞

r/n.

Now, it is an elementary Calculus exercise to see that the function g(x) =

−2x2 log x reaches it absolute maximum at the point

1
√e

= 0.606531 . . .

Moreover, the value of this maximum is:

g(cid:18) 1
√e(cid:19) =

1
e

= 0.367879 . . .

After this previous work we can proof the statements of the theorem.

i) Since G(·, n) reaches its maximum at M(n) and x = lim
n→∞

immediately that

r/n, it follows

M(n)

n

=

1
√e

lim
n→∞

ii) It is clear that

lim
n→∞

G(cid:18)(cid:20) n
√e(cid:21) /n =

1
√e

n→∞(cid:20) n

because lim

√e(cid:21) , n(cid:19) = g(cid:18) 1

√e(cid:19) =

1
e

.

(cid:3)

Recall that in Theorem 2 iv), an asymptotic formula was obtained for the solution
m(n) = nϑ + O(1) taking a series expansion. This was possible because equations
of type 0 = A+ Bx+ C log(x) are solvable in terms of Lambert W Function. In this
case, the equation that appears is of the type A+Bx+C log(x)+Dx log(x) = 0, for
which there is no known solution that can be expressed symbolically. Nonetheless,
the simpliﬁcation of this equation achieved by replacing r/n by its asymptotic value,
1/√e, gives rise to a formula that improves the estimation [n/√e] and, in this case,
for M(n), we conjecture
Conjecture 2.

where µ := 2 − 5

2 √e = 0.483673350 . . .

M(n) ≈

n
√e

+ µ,

In fact, [ n

√e + µ] is the value of M(n) for all n up to 10000, with the only

exceptions of n ∈ {33, 94}.
5.2. Payoﬀ proportional to the number of non-performed interviews.

Theorem 7. Consider the function

G(r, n) :=

2(cid:0)r
2(cid:1)n2

nXk=r+1

n − k

(cid:0)k−1
2 (cid:1)

deﬁned for every pair of integers (r, n) such that 1 < r < n and let

θ := −

1

2W

−1(− 1

2√e )

1
2 +W

−1( −1

2 √e )

= e

18

L. BAY ´ON, J. GRAU, A. M. OLLER-MARC´EN, M. RUIZ, AND P.M. SU ´AREZ

be the solution to the equation 2x log(x) = x − 1. Denote by M(n) the value for
which the function G(·, n) reaches its maximum. Then the following hold:

i)

ii)

lim
n→∞
lim
n→∞

M(n)
G([n · θ], n) = θ(1 − θ) = 0.2036321 . . .

= θ = 0.284668 . . . ; i.e, M(n) ∼ n · θ.

n

Proof. We reason like in the previous theorem. First, observe that

G(r, n) =

2r(r − 1)

(n − k)

nXk=r+1
n(cid:19) − 2

n2

r

2

(k − 1)(k − 2)
n(cid:18)1 −
n(cid:18) r
r
n − 1 −
G(r, n) ≃ 2x − 2x2 − 2x2Z 1

x

= 2

lim
n→∞

2r(r − 1)

=

n2

1

n − 1(cid:19) − 2

n

" n − 2
r − 1 −
n(cid:18) r
n(cid:19) n−1Xi=r
n −

n − 1
n
i

1

r

1

i# =

n−1Xi=r

+

1
n

,

1
t

dt = 2x (1 − x + x log x) = g(x)

where the latter sum is a Riemann sum. Consequently,

with x = lim
n→∞

r/n.

absolute maximum at the point

It is easily seen that g(x) = 2x (1 − x + x log x) reaches it

−1(− 1
Moreover, the value of this maximum is:

2W

2√e )

θ = −

1

= 0.284668 . . .

Now, we prove the statements of the theorem.

g (θ) = θ − θ2 = 0.203632 . . .

i) Since G(·, n) reaches its maximum at M(n) and x = lim
n→∞

immediately that

r/n, it follows

M(n)

n

= θ

lim
n→∞

ii) It is clear that

G ([n · θ] , n) = g (θ) = θ(1 − θ)

lim
n→∞
[n · θ] /n = θ.

because lim
n→∞

(cid:3)

Just like in the previous case, it has not been possible to determine the asymp-
totic formula of the type M(n) ≈ n· θ + β. Nevertheless, it is possible to conjecture
that M(n) ≈ n · θ + O(1). Moreover, we conjecture that M(n) ≈ n · θ + µ, where
µ ∼= 1.4034 is an approximation that has been experimentally found on the basis of
the calculation of the solution for large values of n. In this case, [n · θ + µ] is the
exact value of M(n) for all values of n up to 10000, without any exception.
Remark. The constant θ = −
rumour theory [4, 9] and to Gabriel’s Horn (see A101314 in OEIS).

2√e ) = 0.284668 . . . also appears related to

1
−1(−

2W

1

A VARIANT OF THE SECRETARY PROBLEM: THE BEST OR THE WORST

19

6. Conclusions and future work

In this paper, we have analyzed a very natural variant of the secretary problem
that has probably not received much attention because its asymptotic analysis
for the game with full information is very simple. However, its study has been
found to be of interest in the case of an unknown random number of objects and
with payoﬀs that are proportional to the number of inspected objects. We show a
comparative table of the asymptotic optimal stopping rule m(·) and the E(payoﬀ)
(the asymptotic mean payoﬀ) in the classical problem and in the best/worst variant
studied in this paper.

All the constants that appear in the table can be expressed in terms of the

following three constants:

e = 2.71828 . . . , ϑ :=

W (−2e−2)

2

= 0.20318 . . . ,

θ := −

2W

1

−1(− 1

2√e )
Classic

= 0.28466 . . . .

n objects
λ−Poisson
Uniform [1, n]

Payoﬀ = (n − k)/n

Payoﬀ = k/n

m(·)
ne−1
λ/e

ne−1/2

nϑ
n/2

E(payoﬀ)

e−1
e−1
2e−2
ϑ − ϑ2
1/4

E(payoﬀ)

Best or Worst
m(·)
n/2
λ/2
nϑ
nθ

1/2
1/2

2(ϑ − ϑ2)
θ − θ2
e−1

ne−1/2

Although we have not addressed its study, it is not unreasonable to conjecture
that the counterpart of the 1/e-law of best choice [2] in this game is what we might
call the 1/2-law. Let us suppose that, independently of each other, all applicants
have the same arrival time density f on [0, T ] and let F denote the corresponding
arrival time distribution function, i.e.

F (t) =Z t

0

f (s)ds, 0 ≤ t ≤ T.

The 1/2-law: Let τ be such that F (τ ) = 1/2. Consider the strategy of waiting
and observing all applicants up to time τ and then choosing, if possible, the ﬁrst
candidate after time τ who is better than all the preceding ones.

Thus, this strategy, which we shall call the 1/2-strategy, has the following prop-

erties:

i) It yields for all N a success probability of at least 1/2,
ii) It is the only strategy guaranteeing this lower success probability bound,

1/2, and the bound is optimal,

iii) It chooses, if there is at least one applicant, none at all with a probability

of exactly 1/2.

Finally, we wish to draw attention a question that has not been solved in this
paper, namely that of how to establish the value of the constants that appear
in the asymptotic formula of the optimal cutoﬀ of the problems posed in Section
4. Although from a practical point of view, an approximation of these constants
with 4 digit accuracy seems to provide the correct solution (except, perhaps, for
some isolated values of n), it would be very interesting to obtain them exactly as a

20

L. BAY ´ON, J. GRAU, A. M. OLLER-MARC´EN, M. RUIZ, AND P.M. SU ´AREZ

solution of certain transcendental equations, as was possible in Section 2 with the
constant

4−2e2−2ϑ , where ϑ represents the rumour’s constant.

1

References

[1] J.N. Bearden. A new secretary problem with rank-based selection and cardinal payoﬀs. Jour-

nal of Mathematical Psychology, 50: 58-59. 2006.

[2] F. Th. Bruss. A uniﬁed Approach to a Class of Best Choice problems with an Unknown

Number of Options. Annals of Probability, 12(3): 882-891. 1984.

[3] R. M. Corless, G. H. Gonnet, D. E. G. Hare, D. J. Jeﬀrey, and D. E. Knuth. On the Lambert

W function. Adv. Comput. Math., 5: 329-359. 1996.

[4] D.J. Daley and D.G. Kendall. Stochastic rumours. Journal of the Institute of Mathematics

and Its Applications, 1:42-55. 1965.

[5] E. B. Dynkin. The optimum choice of the instant for stopping a markov process. Soviet

Mathematics - Doklady, 4:627-629, 1963.

[6] T.S. Ferguson. Who solved the secretary problem? Statistical Science, 4(3): 282-296. 1989.
[7] T. S. Ferguson, J. P. Hardwick and M. Tamaki. Maximizing the duration of owning a relatively
best object. Contemporary Mathematics: Strategies for Sequential Search and Selection in
Real Time, American Mathematics Association (T. Ferguson and S. Samuels, eds), 125:
37-58. 1991.

[8] J. Gilbert and F. Mosteller. Recognizing the maximum of a sequence. J. Am. Statist. Assoc.,

61, 35-73, 1966.

[9] E. Lebensztayn, F. P. Machado and P. M. Rodriguez. Limit Theorems for a general sthochastic

rumour model. arxiv.org/pdf/1003.4995.

[10] D. V. Lindley. Dynamic programming and decision theory. Journal of the Royal Statistical

Society. Series C (Applied Statistics), 10(1):39-51, 1961.

[11] E.L. Presman and I.M. Sonin. The best choice problem for a random number of objects.

Theory Prob. Applic., 17, 657-668. 1972.

[12] K.A. Szjowski. A rank-based selection with cardinal payoﬀs and a cost of choice. Sci. Math.

Jpn., 69(2), 285-293. 2009.

[13] R.J. Vanderbei. The Optimal Choice of a Subset of a Population. Mathematics of Operations

Research, 5(4): 481-486. 1980.

E-mail address: bayon@uniovi.es
E-mail address: grau@uniovi.es
E-mail address: oller@unizar.es
E-mail address: mruiz@uniovi.es
E-mail address: pedrosr@uniovi.es

Departamento de Matem´aticas, Universidad de Oviedo, Avda. Calvo Sotelo s/n,

33007 Oviedo, Spain

Departamento de Matem´aticas, Universidad de Oviedo, Avda. Calvo Sotelo s/n,

33007 Oviedo, Spain

Centro Universitario de la Defensa de Zaragoza, Ctra. Huesca s/n, 50090 Zaragoza,

Spain

Departamento de Matem´aticas, Universidad de Oviedo, Avda. Calvo Sotelo s/n,

33007 Oviedo, Spain

Departamento de Matem´aticas, Universidad de Oviedo, Avda. Calvo Sotelo s/n,

33007 Oviedo, Spain

