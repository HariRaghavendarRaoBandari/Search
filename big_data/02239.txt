Distributed constrained optimization and consensus
in uncertain networks via proximal minimization

Kostas Margellos, Alessandro Falsone, Simone Garatti and Maria Prandini

1

6
1
0
2

 
r
a

M
 
7

 
 
]

.

C
O
h
t
a
m

[
 
 

1
v
9
3
2
2
0

.

3
0
6
1
:
v
i
X
r
a

Abstract—We provide a unifying framework for distributed
convex optimization over time-varying networks, in the presence
of constraints and uncertainty, features that are typically treated
separately in the literature. We ﬁrst focus on the deterministic
case, adopt a proximal minimization perspective and show
that this set-up allows us to bypass the difﬁculties of existing
algorithms while simplifying the underlying mathematical anal-
ysis. We develop an iterative algorithm and show convergence
of the resulting scheme to some optimizer of the centralized
problem. Our approach is then extended to the case where
the agents’ constraint sets are affected by a possibly common
uncertainty vector. To tackle this problem we follow a scenario-
based methodology and offer probabilistic guarantees regarding
the feasibility properties of the resulting solution.

Index Terms—Distributed optimization, consensus, proximal

minimization, uncertain systems, scenario approach.

I. INTRODUCTION

O PTIMIZATION in multi-agent networks has attracted

signiﬁcant attention in the control and signal processing
literature, due to its applicability in different domains like
power systems [1], [2], wireless networks [3], [4], robotics [5],
etc. Typically, agents solve a local decision making problem,
communicate their decisions with other agents and repeat the
process on the basis of the new information received. The
main objective of this cooperative set-up is for agents to reach
consensus and agree on a common decision that optimizes
a certain performance criterion for the overall multi-agent
system.

This set-up allows each agent to keep some of its own data
private and enables distributed computation, which may lead
to computational savings compared to centralized paradigms.
Based on the underlying communication structure, two main
optimization architectures can be distinguished: decentralized
and distributed optimization. In the former, computation is
distributed across agents but there is a centralized communi-
cation infrastructure (e.g., a centralized authority) that collects
information from each agent and transmits updates to all of
them. On the other hand, in distributed optimization not only
computation but also communication is distributed, and agents
exchange information only with neighboring agents.

Research was supported by the European Commission, H2020, under the

project UnCoVerCPS, grant number 643921.

K. Margellos was with Politecnico di Milano; he is now with the Depart-
ment of Engineering Science, University of Oxford, Parks Road, OX1 3PJ,
Oxford, UK, e-mail: kostas.margellos@eng.ox.ac.uk

di Elettronica

and M. Prandini

A. Falsone, S. Garatti

are with the Dipar-
timento
Politecnico
Leonardo
di Milano,
20133 Milano,
{alessandro.falsone, simone.garatti,
Italy,
maria.prandini}@polimi.it

Informazione

e Bioingegneria,

da Vinci

32,

Piazza

e-mail:

A. Related work

Most literature builds on the seminal work of [6]–[8] (see
also [9], [10] and references therein for a more recent problem
exposition), where a wide range of optimization problems
is considered, mostly from a decentralized perspective using
techniques based on gradient descent, dual decomposition,
and the method of multipliers. The recent work of [11] deals
with similar problems but from a mean ﬁeld game theoretic
perspective, where agents’ decisions converge to a Nash equi-
librium, not necessarily an optimizer, as the number of agents
tends to inﬁnity. Distributed consensus and/or optimization
problems, but in the absence of constraints in the underlying
optimization programs, have been considered in [12]–[21]. In
most of these references the underlying network is allowed to
be time-varying. In the presence of constraints and following
a distributed paradigm, the authors of [10], [22]–[24] adopt
Newton-based or gradient/subgradient-based approaches and
show asymptotic agreement of the agents’ solutions to an
optimizer of the centralized problem. In [25] a distributed
alternating direction method of multipliers approach is adopted
and its convergence properties are analyzed, whereas in [26],
[27] a constraints consensus approach is adopted. In these
cases, however, the underlying network is time-invariant. In
a time-varying environment, [28], [29] follow a projected
subgradient methodology to solve distributed convex opti-
mization problems in the presence of constraints. In [28],
however, the particular case where the agents’ constraint sets
are all identical is considered. As a result, the computational
complexity of each agents’ local optimization program is the
same with the one of the centralized problem.

In most of the aforementioned references a deterministic set-
up is considered. Of particular interest is, however, the case
where agents cooperate seeking a solution to an optimization
program where constraints depend on an uncertain parame-
ter and should be robustly satisﬁed for all values that this
parameter may take. This poses additional challenges when
devising a distributed solution methodology. Results taking
into account both constraints and uncertainty have recently
appeared in [30]–[32]. In [30] a projected gradient descent
approach is adopted and almost sure convergence results are
provided, where at every iteration of the proposed algorithm a
random subset of each agents’ constraints is considered. In
[31] a penalty-based approach is adopted and convergence
of the proposed scheme is shown under the assumption
that the algorithm is initialized with some feasible solution,
which is, however, not necessarily easy to compute. This
is not required in the approach proposed in this paper. In
[32] an asynchronous algorithm is developed for a particular
communication protocol that involves gossiping, i.e., pairwise

2

communication, under stronger regularity conditions (strong
convexity of the agents’ objective function).

B. Contributions of this work

In this paper we deal with distributed convex optimization
problems over time-varying networks, under a possibly differ-
ent constraint set per agent, and in the presence of uncertainty.
Our approach is most closely related to the work of [28]–
[30], but we adopt a proximal minimization instead of a
subgradient-based perspective, thus avoiding the requirement
for gradient/subgradient computation. We focus ﬁrst on the
deterministic case and provide a rigorous and detailed analysis
of convergence and optimality of the developed iterative
scheme.

We next address the case where uncertainty is also present
by exploiting results on scenario-based optimization [33]–
[38]. In particular, we assume that each agent is provided
with a given set of uncertainty realizations (scenarios) and
enforces the constraints only on these scenarios. We consider
two cases according to whether the scenarios are shared among
all agents or each agent has its own scenario set. In both
cases we show that our distributed algorithm is applicable
and that the converged solution is feasible in a probabilistic
sense for the constraints of the centralized problem, i.e., it
satisﬁes with high probability all agents’ constraints when
an unseen uncertainty instance is realized. To achieve this
we rely on the novel contribution of [39], which leads to a
sharper result compared to the one that would be obtained by
a direct application of the basic scenario theory [34]. Note that
our approach is fundamentally different from the randomized
algorithm of [26], which is based on iteratively exchanging
active constraints over a time-invariant network; in our case the
network is time-varying and we do not require for constraint
exchange, thus reducing the communication requirements.

Our set-up is closely related, albeit different from the ap-
proach of [30]. In [30] different scenarios should be extracted
at every iteration of the proposed algorithm, and these scenar-
ios should be independent from each other, and independent
across iterations. This creates difﬁculties in accounting for
temporal correlation of the uncertain parameter, and poses
challenges if sampling from the underlying distribution is
computationally expensive. On the contrary, our algorithm
allows the use of the same uncertainty scenarios at every
iteration of the process. In the case where each agent
is
provided with a given number of scenarios (as in data driven
optimization), convergence in [30] is not guaranteed, whilst
our scenario-based approach provides probabilistic feasibility
guarantees in such a case as well. If agents are allowed to
extract scenarios of the uncertainty, our results offer proba-
bilistic instead of almost sure feasibility. However, we follow
a different proof line based on proximal minimization that
allows us to bypass the requirement for gradient computations,
thus rendering the developed optimization programs directly
amenable to existing numerical solvers, and do not impose
differentiability assumptions on the agents’ objective functions
and Lipschitz continuity of the objective gradients as in [30].
Overall, we offer a unifying framework for distributed convex

optimization, since we take into account time-varying graphs,
constraints and uncertainty, features that are typically treated
separately in the literature.

In particular, the contributions of our paper can be sum-
marized as follows: 1) We provide a proximal minimization
perspective to the problem of distributed convex optimiza-
tion over time-varying networks and in the presence of a
possibly different constraint set per agent. 2) We provide a
detailed convergence and optimality analysis of the proposed
algorithm, without requiring differentiability of the objective
functions. 3) We extend our approach to the case where the
agents’ constraint sets are affected by a possibly common un-
certainty vector. To tackle this problem we follow a scenario-
based methodology and offer novel probabilistic guarantees
regarding the feasibility properties of the resulting solution.
Our approach is particularly suited for data driven optimization
where agents are provided with a given set of uncertainty
realizations, a setting that is not addressed in [30].

The paper unfolds as follows: In Section II we formulate
the proposed distributed algorithm based on proximal mini-
mization and state the underlying assumptions, and the main
convergence and optimality results. We also discuss how a
speciﬁc problem structure, encountered in many control prob-
lems, allows for a more efﬁcient (in terms of communication
and computation) application of the proposed methodology. In
Section III we provide some preparatory results and establish
useful relations regarding the agents’ local solutions, whereas
in Section IV we show convergence and optimality of the
developed algorithm. Section V extends the proposed scheme
to the case where constraints are affected by uncertainty,
following a scenario-based methodology. Finally, Section VI
concludes the paper and provides some directions for future
work. All proofs omitted from the body of the paper can be
found in the Appendix.

Notation

R, R+ denote the real and positive real numbers, and N,
N+ the natural and positive natural numbers, respectively. For
any x ∈ Rn, ||x|| denotes the Euclidean norm of x, whereas
for a scalar a ∈ R, |a| denotes its absolute value. Moreover,
x(cid:62) denotes the transpose vector of x. For a continuously
differentiable function f (·) : Rn → R, ∇f (x) is the gradient
of f (x). Given a set X, we denote by co(X) its convex hull.
We write dist(y, X) to denote the Euclidean distance of a
vector y from a set X, i.e., dist(y, X) = inf x∈X ||y − x||.
A vector a ∈ Rm is said to be a stochastic vector if all
(cid:80)m
its components aj are non-negative and sum up to one, i.e.,
j=1 aj = 1. Consider a square matrix A ∈ Rm×m and
denote its i-th column by ai ∈ Rm, i = 1, . . . , m. A is
stochastic vectors, i.e.,(cid:80)m
(cid:80)m
said to be doubly stochastic if both its rows and columns are
j = 1 for all j = 1, . . . , m, and

j=1 ai
For the analysis of Section V, write ∆ to denote the set
where uncertainty takes values from. We assume that ∆ is
endowed with a σ-algebra D and that P is a ﬁxed, but
possibly unknown, probability measure deﬁned over D. For
N ∈ N+, PN is the corresponding product measure. We
assume measurability of all involved functions and sets.

j = 1 for all i = 1, . . . , m.

i=1 ai

Algorithm 1 Distributed, optimal consensus
1: Initialization
k = 0.
2:
Consider xi(0) ∈ Xi, for all i = 1, . . . , m.
3:
4: For i = 1, . . . , m repeat until convergence
5:
6:
7:

xi(k +1) = arg minxi∈Xi fi(xi)+ 1
k ← k + 1.

zi(k) =(cid:80)m

j(k)xj(k).

j=1 ai

2c(k)||zi(k)−xi||2.

II. DISTRIBUTED CONSTRAINED CONVEX OPTIMIZATION
A. Problem set-up

We consider a time-varying network of m agents that
communicate to cooperatively solve an optimization problem
of the form

m(cid:88)

P : min
x∈Rn

fi(x)

subject to x ∈ m(cid:92)

i=1

(1)

Xi,

i=1

where x ∈ Rn represents a vector of n decision variables. For
each i = 1, . . . , m, fi(·) : Rn → R is the objective function
of agent i, whereas Xi ⊆ Rn is its constraint set. Since most
of the subsequent results are based on fi(·) and Xi being
convex, we formalize it in the following assumption.
Assumption 1. [Convexity] For each i = 1, . . . , m,
function fi(·) : Rn → R and the set Xi ⊆ Rn are convex.

the

all the constraints in one shot, by encoding (cid:84)m

Problem P can not be solved in a centralized fashion if fi(·)
and Xi represent private information, available only to agent
i, and even if all necessary information (objective functions
and constraint sets) was available to all agents,
imposing
i=1 Xi, may
result in a computationally intensive program. To alleviate this
and account for information privacy, we follow a distributed,
iterative approach, where each agent i solves an appropriate,
local optimization problem and exchanges information with
other agents based on the outcome of this optimization. We
will show that under certain structural and communication
assumptions agents reach consensus to an optimal solution of
P (note that P does not necessarily admit a unique solution).
The basic steps of the proposed approach are summarized in
Algorithm 1.

necessarily to (cid:84)m

Initially, each agent i, i = 1, . . . , m, starts with some
tentative value xi(0), which constitutes its estimate of what a
minimizer of P might be (step 3, Algorithm 1). This estimate
belongs to the local constraint set Xi of agent i, but not
i=1 Xi. One sensible choice for xi(0) is to
set it such that xi(0) ∈ arg minxi∈Xi fi(xi). At iteration k,
each agent i constructs a weighted average zi(k) of those
solutions xj(k), j = 1, . . . , m, communicated by the other
agents and its local one (step 5, Algorithm 1). Coefﬁcient
j(k) ∈ R+ ∪ {0} indicates how agent i weights the solution
ai
received by agent j at iteration k, and ai
j(k) = 0 encodes the
fact that agent i does not require any information from agent
j at iteration k, or the communication link between agents i

3

and j is not active at iteration k. Agent i solves then a local
minimization problem, seeking the optimal solution within Xi
that minimizes a performance criterion, which is deﬁned as a
linear combination of the local objective function fi(xi) and
a quadratic term, penalizing the difference from zi(k) (step 6,
Algorithm 1). The relative importance of these two terms is
dictated by c(k) ∈ R+. Note that, under Assumption 1 and
due to the presence of the quadratic penalty term, the resulting
problem is strictly convex with respect to xi, and hence admits
a unique solution.

B. Further structural assumptions and communication re-
quirements

We impose some additional assumptions on the structure
of problem P in (1) and the communication set-up that
is considered in this paper. These assumptions will play a
crucial role in the convergence analysis of Section IV. In
particular, we shall show that Algorithm 1 provides a fully
distributed implementation, where agent i uses information
only from neighboring agents. This information exchange is
time-varying, since the weighting coefﬁcients depend on the
iteration index k, and may be occasionally the empty set.
Assumption 2. [Compactness] For each i = 1, . . . , m, Xi ⊆
Rn is compact.

Assumption 3. [Interior point] The feasibility region(cid:84)m
of P has a non-empty interior, i.e., there exists ¯x ∈(cid:84)m
||x − ¯x|| < ρ} ⊂(cid:84)m
Note that due to Assumption 2, co(cid:0)(cid:83)m
(cid:1) is also
(cid:1). Moreover, due to Assumptions 1 and 2,
x ∈ co(cid:0)(cid:83)m

compact. Let then D ∈ R+ be such that ||x|| ≤ D for all
fi(·) : Rn → R is Lipschitz continuous on Xi with Lipschitz
constant Li ∈ R+, i.e., for all i = 1, . . . , m,

and ρ ∈ R+ such that {x ∈ Rn :

i=1 Xi
i=1 Xi
i=1 Xi.

i=1 Xi

i=1 Xi

|fi(x) − fi(y)| ≤ Li||x − y||, for all x, y ∈ Xi.

(2)

solution. Therefore, if we denote by X∗ ⊆(cid:84)m

Due to Assumption 3, by the Weierstrass’ theorem (Propo-
sition A.8, p. 625 in [8]), P admits at least one optimal
i=1 Xi the set of
optimizers of P, then X∗ is non-empty. Notice also that fi(·),
i = 1, . . . , m, is continuous due to the convexity condition
of Assumption 1; the addition of Assumption 2 is to imply
Lipschitz continuity. However, fi(·), i = 1, . . . , m, is not
required to be differentiable.
{c(k)}k≥0, that appear in step 6 of Algorithm 1.
Assumption 4. [Coefﬁcient {c(k)}k≥0] Assume that for all
k ≥ 0, c(k) ∈ R+ and {c(k)}k≥0 is a non-increasing
sequence, i.e., c(k) ≤ c(r) for all k ≥ r, with r ≥ 0. Moreover,

We impose the following assumption on the coefﬁcients

1) (cid:80)∞
2) (cid:80)∞

k=0 c(k) = ∞,
k=0 c(k)2 < ∞.

In standard proximal minimization [8] convergence is highly
dependent on the appropriate choice of c(k). Assumption 4
is in fact needed to guarantee convergence of Algorithm 1
in Section IV-C. A direct consequence of the last part of
Assumption 4 is that
limk→∞ c(k) = 0. One choice for
{c(k)}k≥0 that satisﬁes the conditions of Assumption 4 is to

4

select it from the class of generalized harmonic series, e.g.,
c(k) = α/(k+1) for some α ∈ R+. Note that Assumption 4 is
in a sense analogous to the conditions that the authors of [28],
[29] impose on the step-size of their subgradient algorithm.

In line with [6], [7], [19] we impose the following assump-

tions on the information exchange between the agents.
Assumption 5. [Weight coefﬁcients] There exists η ∈ (0, 1)
such that for all i, j ∈ {1, . . . , m} and all k ≥ 0, ai
j(k) ∈
R+ ∪ {0}, ai
j(k) ≥ η.
Moreover, for all k ≥ 0,

j(k) > 0 implies that ai

i(k) ≥ η, and ai

j=1 ai
i=1 ai

j(k) = 1 for all i = 1, . . . , m,
j(k) = 1 for all j = 1, . . . , m.

1) (cid:80)m
2) (cid:80)m

The interpretation of having a uniform lower bound η,
independent of k, for the coefﬁcients ai
j(k) in Assumption
5 is that it ensures that each agent is mixing information
received by other agents at a non-diminishing rate in time [28].
Moreover, Assumptions 5.1 and 5.2, ensure that this mixing is
a convex combination of the other agent estimates, assigning a
i(k) ≥ η.
non-zero weight to its local one due to the fact that ai
For each k ≥ 0 the information exchange between the m
agents can be represented by a directed graph (V, Ek), where
the nodes V = {1, . . . , m} are the agents and the set Ek of
directed edges is given by

Ek =(cid:8)(j, i) : ai

j(k) > 0(cid:9),

(3)

i.e., at time k agent i receives information (estimate xj(k))
from agent j, and this information is weighted by ai
j(k). From
(3), in the absence of communication we set ai
j(k) = 0. If
j(k) > 0 we say that j is a neighboring agent of i at time
ai
k. Under this set-up, Algorithm 1 provides a fully distributed
implementation, where at iteration k each agent i = 1, . . . , m
receives information only from neighboring agents.

(j, i) ∈ Ek for inﬁnitely many k(cid:9)

Let E∞ = (cid:8)(j, i) :

denote the set of edges (j, i) that represent agent pairs that
communicate directly inﬁnitely often. We then impose the
following connectivity and communication assumption.
Assumption 6. [Connectivity and Communication] The graph
(V, E∞) is strongly connected, i.e., for any two nodes there
exists a path of directed edges that connects them. Moreover,
there exists T ≥ 1 such that for every (j, i) ∈ E∞, agent i
receives information from a neighboring agent j at least once
every consecutive T iterations.

Assumption 6 guarantees that any pair of agents commu-
nicates directly inﬁnitely often, and the intercommunication
interval is bounded. For further details on the interpretation of
the imposed network structure the reader is referred to [18],
[28].

Assumptions 5 and 6 are identical to Assumptions 2-5 in
[28] (the same assumptions are also imposed in [29]), but
were reported also here to ease the reader and facilitate the
exposition of our results. Note that these are rather standard
for distributed consensus problems; for possible relaxations
the reader is referred to [19], [40].

The proposed iterative methodology resembles the structure
of proximal minimization for constrained convex optimization

[8] (Chapter 3.4.3). The difference, however, is that our set-
up is distributed and the quadratic term in step 6 does not
penalize the deviation of xi from the previous iterate xi(k),
but from an appropriately weighted average zi(k). Moreover,
our approach is inspired by the work of [28]–[30], where
the authors attempt to solve P under a similar set-up but
following a projected subgradient approach. As mentioned in
[8] (Chapter 3.4, p. 241), proximal minimization serves as an
alternative to gradient methods, where, instead of a gradient
(subgradient) step, a penalty term (proxy) is introduced in
the objective function of each agents’ tentative optimization
problem. The connection between gradient algorithms and
proximal minimization has been further investigated in [41],
in the context of incremental algorithms, where it is stated
that proximal minimization algorithms are more stable in
terms of numerical performance compared to their gradient-
based counterparts. In contrast
to [28]–[30], however, our
approach has an intuitive economic interpretation; at every
iteration k we penalize a consensus residual proxy by the time-
varying coefﬁcient 1/(2c(k)), which, due to Assumption 4,
progressively increases. This can be thought of as a pricing
settling mechanism, where the more we delay to achieve
consensus the higher the price is.
j(k) = 1/m for all i, j = 1, . . . , m,
for all k ≥ 0, that corresponds to a decentralized control
paradigm, the solution of our proximal minimization approach
coincides with the one obtained when the alternating direction
of multipliers [8], [9], is applied to this problem (see eq.
(4.72)-(4.74), p. 254 in [8]). In the latter the quadratic penalty
term is not added to the local objective function as in step 6 of
Algorithm 1, but to the Lagrangian function of an equivalent
problem, and the coefﬁcient c(k) is an arbitrary constant
independent of k; however, a dual-update step is required.
Formal connections between penalty methods and the method
of multipliers have been established in [42].

In the case where ai

C. Statement of main results

Under the structural assumptions and the communication
set-up imposed in the previous subsection, Algorithm 1 con-
verges and agents reach consensus to a common decision
vector. In particular their local estimates xi(k) converge to
some minimizer of problem P.

This is formally stated in the following proposition and
theorem, which constitute two main contributions of our paper.
Proposition 1 (Consensus). Consider Assumptions 1-6. We
have that

k→∞||xi(k) − v(k)|| = 0, for all i = 1, . . . , m,

lim

where

v(k) =

1
m

m(cid:88)

i=1

xi(k), for all k ≥ 0.

(4)

(5)

Theorem 1 (Optimality). Consider Assumptions 1-6. We have
that, for some x∗ ∈ X∗,

k→∞||xi(k) − x∗|| = 0, for all i = 1, . . . , m.

lim

(6)

Proposition 1 shows that consensus is reached and for each
i = 1, . . . , m, as k → ∞, xi(k) converges to the arithmetic
average v(k) of the agents’ estimates, as this is given by (5).
Theorem 1 shows that the consensus vector is some minimizer
of P. The proofs of these statements require to establish ﬁrst
several relations between the agents’ estimates. Therefore,
we defer them until Section IV-B, after some preparatory
results have been provided. Prior to these results, however,
we highlight a particular problem structure that enables a
simpliﬁed application of our distributed methodology.

D. Application to a speciﬁc problem structure

The application of Algorithm 1 can be simpliﬁed when the
underlying optimization problem exhibits a speciﬁc structure.
We consider a speciﬁc instance of P, where agents need to
agree on a common decision vector y ∈ R¯n, but each of them
decides upon a local decision vector ui ∈ Rni, i = 1, . . . , m
as well. Note that the local decision vectors do not necessarily
have the same dimension. Consider then the problem

m(cid:88)

i=1

i=1

min

y∈R ¯n,{ui∈Rni}m
subject to

y ∈ m(cid:92)

Yi,

fi(y, ui)

(7)

(8)

i=1

ui ∈ Ui, for all i = 1, . . . , m,

n = ¯n +(cid:80)m

(9)
where Yi ∈ R¯n and Ui ⊆ Rni, for all i = 1, . . . , m. Setting
i=1 ni, x = (y, u1, . . . , um) ∈ Rn and Xi =
Yi × Rn1 × . . . × Ui × . . . × Rnm, i = 1, . . . , m, it can be
easily observed that the aforementioned optimization program
is in the form of P. Note that the global decision vector y and
the local decision vectors ui, i = 1, . . . , m, are not coupled
via the constraints. We exploit this in the sequel to simplify
the application of Algorithm 1 to problems of such structure.
Suppose that Assumptions 1-3 are satisﬁed for problem (7)-
(9), given the assignments introduced above. In particular,
for all i = 1, . . . , m, assume that fi(·,·) is jointly con-
vex with respect to its arguments, that Yi, Ui are convex
and compact, and that the feasibility region of (7)-(9) has
a non-empty interior. Problem (7)-(9) can be equivalently
i=1 Yi, where
gi(·) : R¯n → R is such that for all i = 1, . . . , m, for any
y ∈ R¯n,

i=1 gi(y) subject to y ∈(cid:84)m

written as miny∈R ¯n(cid:80)m

gi(y) = min
ui∈Ui

fi(y, ui).

(10)

Note that the optimization problem in (10) is feasible for any
y ∈ R¯n, due to the fact that Ui, i = 1, . . . , m, is non-empty.
By [43] (Chapter 3.2.5, p. 87), due to the joint convexity for
fi(·,·), and the fact that Ui is non-empty and convex, the
function gi(·) in (10) is convex for all i = 1, . . . , m.

Therefore, Algorithm 1 is still applicable with y, gi(y) in
place of x, fi(x), respectively. Step 6 of Algorithm 1 would
then be

yi(k + 1) = arg min
yi∈Yi

gi(yi) +

1

2c(k)

||zi(k) − yi||2,

(11)

where zi(k) = (cid:80)m
(cid:0)yi(k + 1), ui(k + 1)(cid:1) = arg min

j=1 ai

we can make it explicit in both y and ui as follows:

j(k)yj(k). By the deﬁnition of gi(·)

5

yi∈Yi,ui∈Ui

fi(yi, ui)

+

1

2c(k)

||zi(k) − yi||2,

(12)

is implicitly assumed that

where it
there exists a unique
solution for ui; if this is not the case one of the corresponding
minimizers can be selected. The advantage of this reasoning
is that the averaging procedure of Algorithm 1 is signiﬁcantly
simpliﬁed, since the local solutions related to ui, i = 1, . . . , m,
need not be exchanged at step 5 of Algorithm 1, and for each
k ≥ 0 agents only need to communicate their local estimates
yi(k), i = 1, . . . , m, of the common decision vector y. The
results of Section II-C guarantee that, following Algorithm
1 with the aforementioned modiﬁcations, agents will reach
consensus on a common vector y that is some minimizer
of (7)-(9), while calculating some, possibly different, optimal
solutions for the local variables ui, i = 1, . . . , m. For each
i = 1, . . . , m, the optimization program in (12) not only
involves fewer constraints compared to the centralized problem
(7)-(9), but also fewer decision variables.

III. PREPARATORY RESULTS

(k)

¯v(k) =

In this section we establish several relations between the
difference of the agent estimates from certain average quanti-
ties. At the end of the section we establish a relation that is
fundamental for the analysis of Section IV.

Under Assumption 3, it is shown in Lemma 2 of [28] that

v(k) ∈ m(cid:92)
where v(k) is given by (5), (k) =(cid:80)m
xi(k) and v(k), which do not necessarily belong to(cid:84)m

for all k ≥ 0,
(13)
i=1 dist(v(k), Xi), and
¯x ∈ Rn, ρ ∈ R+ are as in Assumption 3. Note that unlike
i=1 Xi,
for ¯v(k) this is always the case, thus providing a feasible
solution of P.

(k) + ρ

(k) + ρ

¯x +

Xi,

i=1

ρ

For each i = 1, . . . , m, denote by

ei(k + 1) = xi(k + 1) − zi(k), for all k ≥ 0,

(14)

the error between the values computed at steps 5 and 6 of
Algorithm 1, i.e., the difference of the weighted average zi(k)
computed by agent i at time k from its local update xi(k + 1).

A. Error relations

We provide some intermediate results that form the basis of
the relation of the next subsection. The proofs of both Lemma
1 and Lemma 2 are provided in the Appendix.
Lemma 1. Consider Assumption 2 and Assumption 3. For all
k ≥ 0,

||xi(k) − ¯v(k)|| ≤ µ

||xi(k) − v(k)||,

(15)

m(cid:88)

m(cid:88)

i=1

i=1

where µ = (2/ρ)mD + 1.

6

From step 5 of Algorithm 1 we have that for all k ≥ 0, for

all i = 1, . . . , m,

xi(k + 1) =

=

j(k)xj(k) + xi(k + 1) − zi(k)
ai

ai
j(k)xj(k) + ei(k + 1),

(16)

m(cid:88)
m(cid:88)

j=1

j=1

+

such that ai

(cid:2)Φ(k, s)(cid:3)i

where the last equality follows from (14).
Following [18], for each k ≥ 0 consider a matrix A(k) ∈
Rm×m
j(k) is the j-th element of its i-th column.
For all k, s with k ≥ s, let Φ(k, s) = A(s)A(s + 1) . . . A(k −
1)A(k), with Φ(k, k) = A(k) for all k ≥ 0. Denote by
j element j of column i of Φ(k, s). It is then shown
in [18] that, under Assumption 5, Φ(k, s) is doubly stochastic.
Similarly to [18], by propagating (16) in time, it can be shown
that for all k > s (the inequality is strict for convenience of
the subsequent derivations), for all i = 1, . . . , m,

k=1

(cid:80)N

the next section to establish certain summability results.

(cid:80)m
where ¯L = maxi=1,...,m Li with Li deﬁned according to
(2). We will show that (20) has an interesting relation with
i=1 ||ei(k + 1)||2 and will come back to it often in
Consider Lemma 1 with k + 1 in place of k and Lemma 2,
summing both sides of (19) with respect to i = 1, . . . , m and
setting s = 0. After some algebraic manipulations and index
changes, we have that

2 ¯L

c(k)

||xi(k + 1) − ¯v(k + 1)||

N(cid:88)

m(cid:88)

k=1

i=1

≤ 2mµλ ¯L

N(cid:88)
N(cid:88)

k=1

k=1

c(k)qk

k−1(cid:88)
m(cid:88)

r=0

+ 2mµλ ¯L

N(cid:88)

+ 4µ ¯L

c(k)

k=1

i=1

m(cid:88)

i=1

||xi(0)||

m(cid:88)

c(k)qk−r−1

||ei(r + 1)||

i=1

||ei(k + 1)||,

(21)

jej(r + 1) + ei(k + 1).

(17)

We then have the following lemma, which is the main result

of this section. Its proof is given in the Appendix.
Lemma 3. Consider Assumptions 2-6. Fix any α1 ∈ (0, 1).
We then have that for any N ∈ N+,

For all k > s, the last statement, together with (5) and the fact
that Φ(k, s) is a doubly stochastic matrix, leads to

||xi(k + 1) − ¯v(k + 1)||

N(cid:88)

2 ¯L

m(cid:88)
m(cid:88)

i=1

c(k)

N(cid:88)

k=1

i=1

k=1

< α1

ei(k + 1).

(18)

where

m(cid:88)

j=1

1
m

m(cid:88)
(cid:2)Φ(k, s)(cid:3)i
m(cid:88)
(cid:2)Φ(k, r + 1)(cid:3)i

j=1

jxj(s)

xi(k + 1) =

k−1(cid:88)

+

r=s

j=1

m(cid:88)
m(cid:88)

j=1

1
m

k−1(cid:88)

r=s

j=1

v(k + 1) =

xj(s)

+

1
m

ej(r + 1) +

We then have the following lemma, which relates ||xi(k +
1)− v(k + 1)|| to ||ei(k + 1)||, i = 1, . . . , m. Its proof follows
from the proof of Lemma 4 in [44].
Lemma 2. Consider Assumptions 5 and 6. For all k, s with
s ≥ 0, k > s, and for all i = 1, . . . , m,
||xi(k + 1) − v(k + 1)|| ≤ λqk−s

||xj(s)||

m(cid:88)

k−1(cid:88)

+

λqk−r−1

||ej(r + 1)||

r=s

j=1

m(cid:88)

j=1

m(cid:88)

+ ||ei(k + 1)|| +

where λ = 2(cid:0)1 + η−(m−1)T(cid:1)/(cid:0)1 − η(m−1)T(cid:1) ∈ R+ and q =
(cid:0)1 − η(m−1)T(cid:1)

(m−1)T ∈ (0, 1).

j=1

1

(19)

||ej(k + 1)||,

1
m

B. A summability relation

Let N ∈ N+ and consider the term

N(cid:88)

m(cid:88)

2 ¯L

c(k)

k=1

i=1

||xi(k + 1) − ¯v(k + 1)||,

(20)

||ei(k + 1)||2 + α2

c(k)2 + α3,

(22)

N(cid:88)

k=1

1

(cid:17)

,

mµ2 ¯L2(cid:16)

2
α1

m2λ2

α2 =

(1 − q)2 + 4
α3 = 2m3µ2λ2 ¯L2c(0)2
α1(1 − q)2
q
1 − q

+ 2m2µλ ¯LDc(1)

1

+ 2α1mD2.

(23)

IV. CONVERGENCE, CONSENSUS AND OPTIMALITY

In this section we deal with the convergence properties of
Algorithm 1, and provide the proofs of Proposition 1 and
Theorem 1 of Section II-C.

A. Error convergence

We prove in this subsection convergence properties for the
error in (14), which are instrumental to the proof of both
Proposition 1 and Theorem 1, of Section IV-B. We use the
following result, which is proven in Lemma 4.1 in [8]. If y∗ =
arg miny∈Y J1(y) + J2(y) (assuming uniqueness of the mini-
mizer), where Y ⊆ Rn is a convex set, J1(·), J2(·) : Rn → R
are convex functions and J2(·) is continuously differentiable,
then y∗ = arg miny∈Y J1(y) + ∇J2(y∗)(cid:62)y, where ∇J2(y∗)
is the gradient of J2(y) with respect to y, evaluated at y∗.
Consider step 6 of Algorithm 1. Under Assumption 1 and
since (1/(2c(k)))||zi(k) − xi||2 is continuously differentiable
with respect to xi, applying the previous result to this problem

with xi, Xi in place of y, Y , respectively, fi(xi) in place of
J1(y) and (1/(2c(k)))||zi(k) − xi||2 in place of J2(y), we
have that

xi(k + 1) = arg min
xi∈Xi

fi(xi)
− 1
c(k)

(zi(k) − xi(k + 1))(cid:62)xi, (24)
where in the second term of (24), −(1/c(k))(zi(k)−xi(k+1)),
is the differential of (1/(2c(k)))||zi(k)− xi||2 with respect to
xi, evaluated at xi(k + 1). We then have the following lemma,
which provides a useful relation between the consecutive
algorithm iterates xi(k + 1) and xi(k), and we will be using
it extensively in the subsequent results.
Lemma 4. Consider Assumptions 1-3 and Assumption 5. We
then have that for any k ∈ N+, for any x∗ ∈ X∗,

2c(k)

fi(¯v(k + 1)) +

||ei(k + 1)||2

m(cid:88)

m(cid:88)
m(cid:88)

i=1

+

i=1

≤ 2c(k)

m(cid:88)

i=1

m(cid:88)
m(cid:88)

i=1

||xi(k + 1) − x∗||2

fi(x∗) +

||xi(k) − x∗||2

i=1

+ 2 ¯Lc(k)

||xi(k + 1) − ¯v(k + 1)||.

(25)

i=1

Proof: Under Assumption 1, (24) holds. Due to the fact
that xi(k + 1) ∈ Xi is the minimizer of the optimization
problem that appears in the right-hand side of (24), we have
that

fi(xi(k + 1)) − 1
c(k)
≤ fi(x) − 1
c(k)

(zi(k) − xi(k + 1))(cid:62)xi(k + 1)
(zi(k) − xi(k + 1))(cid:62)x,
for all x ∈ Xi.

(26)
Since the last statement holds for any x ∈ Xi, it will also hold
i=1 Xi of problem P in (1).

for any minimizer x∗ ∈ X∗ ⊆(cid:84)m

||xi(k + 1) − x∗||2

(27)

We have that for any x∗ ∈ X∗,
−(zi(k) − xi(k + 1))(cid:62)(xi(k + 1) − x∗)
1
2

||xi(k + 1) − zi(k)||2 +
||zi(k) − x∗||2.

1
=
2
− 1
2

1

fi(xi(k + 1)) +

By (26), (27), we have that for any x∗ ∈ X∗,
||xi(k + 1) − zi(k)||2
||xi(k + 1) − x∗||2
||zi(k) − x∗||2

+
≤ fi(x∗) +

2c(k)

2c(k)

1

1

≤ fi(x∗) +

1

j(k)||xj(k) − x∗||2,
ai

(28)

2c(k)

m(cid:88)

2c(k)

j=1

7

j=1 ai

j(k)xj(k)−x∗||2 = ||(cid:80)m

5, ||(cid:80)m
stochasticity condition of Assumption 5,(cid:80)m

where the last inequality follows by the deﬁnition of zi(k)
(see step 5 of Algorithm 1), the fact that, under Assumption
and the convexity of || · ||2.
Multiply both sides of (28) by 2c(k), sum with respect to
i = 1, . . . , m, and notice that for any k ≥ 0, under the double
j(k) = 1. We

j(k)(cid:0)xj(k)−x∗(cid:1)||2

j=1 ai

i=1 ai

then have that

m(cid:88)

2c(k)

fi(xi(k + 1)) +

||xi(k + 1) − zi(k)||2

i=1

m(cid:88)

i=1

≤ 2c(k)

+

||xi(k + 1) − x∗||2

fi(x∗) +

||xi(k) − x∗||2.

(29)

i=1

m(cid:88)
m(cid:88)
m(cid:88)

i=1

i=1

Consider Assumption 3, and let ¯v(k) as in (13). Under
Assumptions 1 and 2, by (2) we have that fi(xi(k + 1)) ≥
fi(¯v(k + 1)) − ¯L||xi(k + 1) − ¯v(k + 1)||, where ¯L =
||xi(k + 1) − zi(k)|| =
maxi=1,...,m Li. Recall also that
||ei(k + 1)|| by (14). Therefore, for any x∗ ∈ X∗, the last
statements together with (29), lead to (25) and hence conclude
the proof.

Note that the proof of Lemma 4 deviates from the approach
adopted in [28], [29], it is motivated by the proof of the
alternating direction method of multipliers (Proposition 4.2
in [8], Appendix A of [9]), and relies on our proximal
minimization perspective.

Proposition 2. Consider Assumptions 1-6. We have that

1) (cid:80)∞

(cid:80)m
i=1 ||ei(k)||2 < ∞,

k=1

2) limk→∞ ||ei(k)|| = 0, for all i = 1, . . . , m.

Proof: By Lemma 4, (25) holds. Fix any α1 ∈ (0, 1).
Under Assumption 2-6, let α2, α3 as in (23), and consider
(22). Summing then (25) with respect to k = 1, . . . , N for
an arbitrary N ∈ N+, using (22), rearranging some terms and
due to some cancellations, for all x∗ ∈ X∗ we have that

N(cid:88)

k=1

2

c(k)

m(cid:88)

(cid:16)

i=1

fi(¯v(k + 1)) − fi(x∗)

+ (1 − α1)

m(cid:88)
N(cid:88)
||xi(1) − x∗||2 − m(cid:88)

k=1

i=1

≤ m(cid:88)

||ei(k + 1)||2

||xi(N + 1) − x∗||2

c(k)2 + α3.

i=1

+ α2

N(cid:88)
Since ¯v(k + 1) ∈ (cid:84)m
k=1 c(k)(cid:80)m
minimizer of P, 2(cid:80)N
0. Moreover,(cid:80)m

k=1

i=1 Xi for all k ≥ 0, and x∗ is a
i=1 ||xi(N + 1) − x∗||2 ≥ 0, hence these two
terms can be dropped from (30). Therefore, by (30), we have

fi(¯v(k+1))−fi(x∗)

i=1

(30)

(cid:17) ≥

i=1

(cid:16)

(cid:17)

8

i=1

k=1

that

N(cid:88)

(1 − α1)

||ei(k + 1)||2

||xi(1) − x∗||2 + α2

N(cid:88)
m(cid:88)
≤ m(cid:88)
Let now N → ∞. Since α1 ∈ (0, 1) and (cid:80)m
(cid:80)∞
i=1 ||xi(1) −
(31) implies that (cid:80)∞
(cid:80)m
k=1 c(k)2 + α3 < ∞, by Assumptions 2 and 4,
also (cid:80)∞
(cid:80)m
i=1 ||ei(k + 1)||2 < ∞, and hence
i=1 ||ei(k)||2 < ∞, thus establishing the ﬁrst
part of the proposition. The second part directly follows from
the preceding statement, thus concluding the proof.

x∗||2 + α2

c(k)2 + α3.

(31)

k=1

k=1

k=1

i=1

B. Consensus

In this subsection we prove Proposition 1 of Section II-C
and show that, by applying Algorithm 1, agents reach consen-
sus asymptotically, i.e., limk→∞ ||xi(k) − v(k)|| = 0 for all
i = 1, . . . , m. The proof is similar to the proof of Lemma 4
in [44], however, we include it also here for completeness.
Proof of Proposition 1. Under Assumptions 1-6, by the sec-
ond part of Proposition 2 we have that limk→∞ ||ei(k)|| = 0,
for all i = 1, . . . , m. Then, for any  > 0 we can choose s > 0
such that ||ei(k)|| ≤  for all k > s, for all i = 1, . . . , m.

By (19) of Lemma 2, we then have that for all i = 1, . . . , m,
||xi(k + 1) − v(k + 1)|| ≤ λqk−s

||xj(s)||

m(cid:88)
k−1(cid:88)

j=1

∞(cid:88)

m(cid:88)

(under Assumptions 1-6),(cid:80)∞

(cid:80)m
To achieve this, notice that by the ﬁrst part of Proposition 2
i=1 ||ei(k)||2 < ∞. Letting
then N → ∞ in (22) leads to the following summability result,
which states that

k=1

2 ¯L

c(k)

||xi(k + 1) − ¯v(k + 1)|| < ∞.

(34)

k=1

i=1

The last statement enables us to show the following conver-
gence result.
Theorem 2. Consider Assumptions 1-6. We have that for all
k≥0 is convergent for

x∗ ∈ X∗, the sequence(cid:8)||xi(k) − x∗||(cid:9)

all i = 1, . . . , m.

Proof: By Lemma 4, (25) holds. Summing then (25)
with respect to k = M, . . . , N for arbitrary M, N ∈ N+,
rearranging some terms and due to some cancellations, for all
x∗ ∈ X∗ we have that

2

c(k)

fi(¯v(k + 1)) − fi(x∗)

(cid:17)
m(cid:88)

m(cid:88)
N(cid:88)

i=1

(cid:16)
m(cid:88)

N(cid:88)

k=M

+

≤ m(cid:88)

||ei(k + 1)||2 +

||xi(N + 1) − x∗||2

k=M

i=1

i=1

||xi(M ) − x∗||2

i=1

i=1

k=M

c(k)

(35)

+ 2 ¯L

m(cid:88)

||xi(k + 1) − ¯v(k + 1)||.

N(cid:88)
1) ∈ (cid:84)m
2(cid:80)N
k=M c(k)(cid:80)m
As in the proof of Proposition 2, notice that since ¯v(k +
i=1 Xi for all k ≥ 0, and x∗ is a minimizer of P,
(cid:80)N
(cid:80)m
i=1 ||ei(k + 1)||2 ≥ 0, hence these two terms can
be dropped from the left-hand side of (35). Therefore, by (35)
||xi(N + 1) − x∗||2 ≤ m(cid:88)
m(cid:88)
we have that

(cid:17) ≥ 0. Moreover,

fi(¯v(k + 1)) − fi(x∗)

||xi(M ) − x∗||2

(cid:16)

k=M

i=1

i=1

(32)

+ 2 ¯L

i=1

||xi(k + 1) − ¯v(k + 1)||.

(36)

N(cid:88)

m(cid:88)

c(k)

k=M

i=1

+ mλ

qk−r−1 + 2

m(cid:88)
m(cid:88)

j=1

r=s

||xj(s)|| + mλ

||xj(s)|| + mλ

k−s−1(cid:88)
∞(cid:88)

t=0

qt + 2

qt + 2

= λqk−s

< λqk−s

j=1

≤ mλDqk−s + mλ

t=0

 + 2,

1
1 − q

where the equality is due to a change of the summation limits,
and the last inequality is due to Assumption 2 and the fact that
q ∈ (0, 1).
Taking limit superior in both sides of (32) as k → ∞, we

have that

||xi(k + 1) − v(k + 1)|| ≤ mλ

lim sup
k→∞

(33)

lim sup
N→∞

 + 2.

1
1 − q
statement

Since  > 0 is arbitrary,
implies
limk→∞ ||xi(k + 1) − v(k + 1)|| = 0, and hence
that
limk→∞ ||xi(k) − v(k)|| = 0, for all i = 1, . . . , m, thus
concluding the proof.

the last

C. Algorithm convergence and optimality

that the sequence (cid:8)||xi(k) − x∗||(cid:9)

We show that Algorithm 1 converges, and in particular
k≥0 is convergent for any

minimizer x∗ of P, for all i = 1, . . . , m.

m(cid:88)

i=1

Notice that, under Assumptions 1-6, the summability state-
ment of (34) holds. Taking then in (36) the limit superior as
N → ∞ and the limit inferior as M → ∞, we have that

||xi(N + 1) − x∗||2

≤ lim inf
M→∞

m(cid:88)
i=1 ||xi(k)− x∗||(cid:9)

||xi(M ) − x∗||2.

(37)

i=1

(cid:8)(cid:80)m
i=1 ||xi(k) − x∗||(cid:9)
implies that(cid:8)(cid:80)m
due to Proposition 1, we also have that (cid:8)||xi(k) − x∗||(cid:9)

The last statement, together with the fact that the sequence
k≥0 is bounded due to Assumption 2,
k≥0 converges for all x∗ ∈
X∗. Since xi(k), i = 1, . . . , m, converge to the same vector
k≥0
converges for all x∗ ∈ X∗, for all i = 1, . . . , m,
thus
concluding the proof.

2

i=1

i=1

k=1

k=1

Since (cid:80)N
N(cid:88)

Theorem 2 shows that Algorithm 1 converges. We are now
in a position to prove Theorem 1 of Section II-C, showing
that Algorithm 1 converges to some minimizer x∗ ∈ X∗ of
P, i.e., limk→∞ ||xi(k) − x∗|| = 0 for some x∗ ∈ X∗, for all
i = 1, . . . , m.
Proof of Theorem 1. By Lemma 4, (25) holds. Fix any α1 ∈
(0, 1). Under Assumptions 2-6, let α2, α3 as in (23), and
consider (22). Summing (25) with respect to k = 1, . . . , N
for an arbitrary N ∈ N+, using (22), rearranging some terms
and due to some cancellations, we have that for all x∗ ∈ X∗,
(30) holds (see proof of Proposition 2).
i=1 ||xi(N +
1) − x∗||2 ≥ 0, we can drop the two terms in the left-hand
side of (30). Therefore, by (30), we have that

(cid:80)m
i=1 ||ei(k + 1)||2 ≥ 0 and (cid:80)m
(cid:16)
m(cid:88)
≤ m(cid:88)
(38)
(cid:80)m
(cid:80)∞
(cid:16)
(cid:17)
Let now N → ∞. Notice that, by Assumptions 2 and 4,
2(cid:80)∞
k=1 c(k)(cid:80)m
i=1 ||xi(1) − x∗||2 + α2
k=1 c(k)2 + α3 < ∞. Therefore,
(cid:80)∞
< ∞; however,
fi(¯v(k + 1)) − fi(x∗)
(cid:16)
m(cid:88)
k=0 c(k) = ∞, by Assumption 4. Hence,
fi(¯v(k + 1)) − fi(x∗)

(39)
Due to the continuity of fi(·), i = 1, . . . , m, under the
convexity requirement of Assumption 1, the last statement
implies that there exists some ¯x∗ ∈ X∗ such that

fi(¯v(k + 1)) − fi(x∗)

||xi(1) − x∗||2 + α2

c(k)2 + α3.

lim inf
k→∞

N(cid:88)

(cid:17)

(cid:17)

= 0.

c(k)

k=1

(40)

In other words, (cid:8)||¯v(k) − ¯x∗||(cid:9)

lim inf

k→∞||¯v(k) − ¯x∗|| = 0.

subsequence.

k≥0 converges to 0 across a
By (4) in Proposition 1, limk→∞ ||xi(k) − v(k)|| = 0,
for all i = 1, . . . , m, which together with (15) in Lemma 1,
implies that limk→∞ ||xi(k)−¯v(k)|| = 0, for all i = 1, . . . , m.
Moreover, it was shown in Theorem 2 that for all i = 1, . . . , m,
k≥0 converges for all x∗ ∈ X∗, and hence also
k≥0 converges. Since this
k≥0
k≥0
has a unique limit point, thus limk→∞ ||¯v(k) − ¯x∗|| = 0. The
last statement and the fact that limk→∞ ||xi(k) − ¯v(k)|| = 0,
for all i = 1, . . . , m, leads to (6) and concludes the proof.

(cid:8)||xi(k)−x∗||(cid:9)
for ¯x∗. Therefore, (cid:8)||¯v(k) − ¯x∗||(cid:9)
sequence is convergent, (40) implies that(cid:8)||¯v(k) − ¯x∗||(cid:9)
converges to 0 across all subsequences, i.e.,(cid:8)||¯v(k)− ¯x∗||(cid:9)

i=1

i=1

Note that a direct byproduct of Proposition 1, Theorem 1
and Lemma 1, is that, for some x∗ ∈ X∗, limk→∞ ||xi(k) −
x∗|| = limk→∞ ||v(k)− x∗|| = limk→∞ ||¯v(k)− x∗|| = 0, for
all i = 1, . . . , m.

V. DISTRIBUTED CONSTRAINED CONVEX OPTIMIZATION

IN THE PRESENCE OF UNCERTAINTY

A. Problem set-up

We revisit problem P,

this time considering the more
general case where the constraint set Xi of each agent i =

9

1, . . . , m, depends on an uncertain parameter δ ∈ ∆. To this
end consider the following optimization problem Pδ, where
the subscript δ is introduced to emphasize the dependency
with respect to the uncertainty.

m(cid:88)

Pδ : min
x∈Rn

fi(x)

subject to x ∈ (cid:92)

i=1

m(cid:92)

i=1

Xi(δ).

(41)

δ∈∆

should belong to (cid:84)m

This is a robust program, where any feasible solution x
i=1 Xi(δ) for all realizations δ ∈ ∆ of
the uncertainty. Note that the fact that uncertainty appears
only in the constraints and not in the objective functions is
without loss of generality; in the opposite case, an epigraphic
reformulation would recast the problem in the form of Pδ.
Problem Pδ is generally difﬁcult to solve when ∆ is a
continuous set. To circumvent this, and motivated by data
driven considerations, assume that each agent i, i = 1, . . . , m,
is provided with a ﬁxed number of realizations of δ, referred to
as scenarios, extracted according to the underlying probability
measure P with which δ takes values in ∆. According to
the information about the scenarios that agents possess, two
cases are distinguished in the sequel and the properties of the
corresponding scenario programs are analyzed.

The following modiﬁcations to Assumptions 1-3 are im-
posed: 1) For each i = 1, . . . , m, Xi(δ) is a convex set for
any δ ∈ ∆. 2) For each i = 1, . . . , m, and for any ﬁnite set S
δ∈S Xi(δ) is compact. 3) For any ﬁnite set
δ∈S Xi(δ) has a non-empty

of values for δ,(cid:84)
S of values for δ, the set(cid:84)m

(cid:84)

i=1

interior.

B. Probabilistic feasibility - Scenarios as a common resource
We ﬁrst consider the case where all agents are provided
with the same scenarios of δ, i.e., scenarios can be thought of
as a common resource for the agents. This is the case if all
agents have access to the same set of historical data for δ, or if
agents communicate the scenarios with each other. The latter
case, however, increases the communication requirements.
Let ¯N ∈ N+ denote the number of scenarios, and ¯S =
{δ(1), . . . , δ( ¯N )} ⊂ ∆ be a set of scenarios which is available
to all agents. The scenarios are independently and identically
distributed (i.i.d.) according to P. Consider then the following
optimization program P ¯N , where the subscript ¯N is introduced
to emphasize the dependency with respect to the uncertainty
scenarios.

P ¯N : min
x∈Rn

i=1

fi(x)

m(cid:92)

i=1

Xi(δ).

(42)

subject to x ∈ (cid:92)
Clearly, x ∈ (cid:84)
(cid:84)m
(cid:84)m
apply Algorithm 1 with (cid:84)
¯N ⊆ (cid:84)m

to x ∈
δ∈ ¯S Xi(δ), and P ¯N is amenable to be solved via
the distributed algorithm of Section II-A. In fact, one can
δ∈ ¯S Xi(δ) in place of Xi, for all
i = 1, . . . , m. Let X∗
δ∈ ¯S Xi(δ) be the set of

i=1 Xi(δ) is equivalent

(cid:84)

(cid:84)

δ∈ ¯S

δ∈ ¯S

i=1

i=1

m(cid:88)

10

minimizers of P ¯N . We then have the following corollary of
Theorem 1.
Corollary 1. Consider Assumptions 1-6 with the modiﬁcations
stated in Section V-A. We have that, for some x∗

¯N ∈ X∗
¯N ,

lim

(43)

¯N|| = 0, for all i = 1, . . . , m,

k→∞||xi, ¯N (k) − x∗
step 6 of Algorithm 1, when Xi is replaced by(cid:84)

where xi, ¯N (k) denotes the solution generated at iteration k,
δ∈ ¯S Xi(δ).
We address the problem of quantifying the robustness of the
¯N of P ¯N to which our iterative scheme converges
minimizer x∗
according to Corollary 1. In the current set-up a complete
answer is given by the scenario approach theory [33], [34],
¯N is feasible for Pδ up to a quantiﬁable
which shows that x∗
level ¯ε. This result is based on the notion of support constraints
(see also Deﬁnition 4 in [33]), and in particular on the notion
of support set [39] (also referred to as compression scheme in
[38]). Given an optimization program, we say that a subset of
the constraints constitutes a support set, if it is the minimal
cardinality subset of the constraints such that by solving the
optimization problem considering only this set of constraints,
we obtain the same solution with the original problem that
includes all constraints. As a consequence, all constraints that
do not belong to the support set are in a sense redundant since
their removal leaves the optimal solution unaffected.

By Theorem 3 of [33], for any convex optimization program
the cardinality of the support set is at most equal to the number
of decision variables n, whereas in [45] a reﬁned bound is
provided. The subsequent result is valid for any given bound
on the cardinality of the support set. Therefore, and since
P ¯N is convex, let d ∈ N+ be a known upper-bound for
the cardinality of its support set. A direct application of the
scenario approach theory in [33] leads then to the following
result.
Theorem 3. Fix β ∈ (0, 1) and let

(cid:115)

β(cid:0) ¯N

(cid:1) .

d

¯ε = 1 − ¯N−d

(44)

(45)

We then have that

P ¯N(cid:110) ¯S ∈ ∆ ¯N :
P(cid:110)

δ ∈ ∆ : x∗

¯N /∈ m(cid:92)

(cid:111) ≤ ¯ε

(cid:111) ≥ 1 − β.

Xi(δ)

i=1

In words, Theorem 3 implies that with conﬁdence at least
¯N is feasible for Pδ apart from a set of uncertainty
1 − β, x∗
instances with measure at most ¯ε. Notice that ¯ε is in fact a
function of ¯N, β and d. We suppress this dependency though
to simplify notation. Note that even though P ¯N does not
necessarily have a unique solution, Theorem 3 still holds for
the solution returned by Algorithm 1 (assuming convergence),
since it is a deterministic algorithm and hence serves as a tie-
break rule to select among the possibly multiple minimizers.
Following [34], (44) could be replaced with an improved
= β.
However, we often use (44) since it gives an explicit relation

¯ε, obtained as the solution of (cid:80)d−1

(cid:1)¯εk(cid:0)1 − ¯ε(cid:1) ¯N−k

(cid:0) ¯N

k=0

k

expression for ¯ε, and also renders (45) directly comparable
with the results provided in the next subsection. A numerical
comparison is provided in Section V-C2 (see Fig. 1).

In case ¯ε exceeds one, the result becomes trivial. However,
note that Theorem 3 can be also reversed (as in experiment
design) to compute the number ¯N of scenarios that is required
for (45) to hold for given ¯ε, β ∈ (0, 1). This can be determined
by solving (44) with respect to ¯N with the chosen ¯ε ﬁxed (e.g.,
using numerical inversion). The reader is referred to Theorem
1 of [33] for an explicit expression of ¯N.

, . . . , δ(Ni)

C. Probabilistic feasibility - Scenarios as a private resource
We now consider the case where the information carried
by the scenarios is distributed, that is, each agent has its own
set of scenarios, which constitute agents’ private information.
Assume that each agent i, i = 1, . . . , m, is provided with a
set Si = {δ(1)
} ⊂ ∆ of Ni ∈ N+ i.i.d. scenarios of
δ, extracted according to the underlying probability measure
P. Here, δ(j)
denotes scenario j of agent i, j = 1, . . . , Ni,
i = 1, . . . , m. The scenarios across the different sets Si,
i = 1, . . . , m, are independent from each other. The total
i=1 Ni. Consider then the
following optimization program PN , where each agent has
its own scenario set.

number of scenarios is N = (cid:80)m

i

i

i

m(cid:88)

PN : min
x∈Rn

fi(x)

subject to x ∈ m(cid:92)

i=1

(cid:92)

i=1

δ∈Si

Xi(δ).

(46)

i=1

lim

δ∈Si

(cid:84)

N ⊆(cid:84)m

Program PN can be solved via the distributed algorithm of
Section II-A, so that a solution is obtained without exchanging
any private information regarding the scenarios. In fact, one
Xi(δ) in place of Xi, for

can apply Algorithm 1 with(cid:84)

Similarly to Corollary 1, letting X∗

all i = 1, . . . , m.
Xi(δ)
be the set of minimizers of PN , we have the following
corollary of Theorem 1.
Corollary 2. Consider Assumptions 1-6 with the modiﬁcations
stated in Section V-A. We have that, for some x∗

δ∈Si

N ∈ X∗
N ,

(47)

δ∈Si

N|| = 0, for all i = 1, . . . , m,

As in Section V-B, we show that the minimizer x∗

k→∞||xi,N (k) − x∗
step 6 of Algorithm 1, when Xi is replaced by(cid:84)

N satisﬁes the global constraint (cid:84)m

where xi,N (k) denotes the solution generated at iteration k,
Xi(δ).
N of
PN to which our iterative scheme converges according to
Corollary 2 is feasible in a probabilistic sense for Pδ. Here, a
difﬁculty arises, since we seek to quantify the probability that
x∗
i=1 Xi(δ), where δ is a
common parameter to all Xi(δ), i = 1, . . . , m, while x∗
N has
been computed considering Xi(δ) for uncertainty scenarios
that are independent from those of Xj(δ), j (cid:54)= i, i = 1, . . . , m.
i=1 be a collection of the scenarios of all
agents. Similarly to the previous case, we denote by d ∈ N+
a known upper-bound for the cardinality of the support set
of PN . However,
the way the constraints of this set are

Let S = {Si}m

We then have that (cid:80)m

split among the agents depends on the speciﬁc scenarios S
employed. Therefore, for each set of scenarios S, denote by
di,N (S) ∈ N (possibly equal to zero) the number of constraints
that belong to the support set of PN and correspond to Si,
i = 1, . . . , m, i.e., that belong to the constraints of agent i.
i=1 di,N (S) ≤ d, for any S ∈ ∆N . For
short we will write di,N instead of di,N (S) and make the
dependency on S explicit only when necessary.
1) A naive result: For any collection of agents’ scenarios,
it clearly holds that di,N ≤ d for all i = 1, . . . , m, for any
scenario set. Thus, for each i = 1, . . . , m, Theorem 3 can
be applied conditionally to the scenarios of all other agents to
obtain a local, in the sense that it holds only for the constraints
of agent i, feasibility characterization. Precisely, ﬁx βi ∈ (0, 1)
and let

(cid:115)
(cid:101)εi = 1 − Ni−d

βi(cid:0)Ni

(cid:1) .

d

(48)

(49)

We then have that

PN(cid:110)
P(cid:110)

S ∈ ∆N :
δ ∈ ∆ : x∗

N /∈ Xi(δ)

(cid:111) ≤(cid:101)εi

(cid:111) ≥ 1 − βi.

quantify the probabilistic feasibility of x∗

By the subadditivity of PN and P, (49) can be used to
N with respect to the
i=1 Xi(δ). Following the proof of Corollary
1 in [46], where a similar argument is provided, we have that

δ ∈ ∆ : x∗

S ∈ ∆N :
δ ∈ ∆ : ∃i ∈ {1, . . . , m}, x∗

global constraint(cid:84)m
PN(cid:110)
S ∈ ∆N : P(cid:110)
= PN(cid:110)
P(cid:110)
= PN(cid:110)
P(cid:110) m(cid:91)
N /∈ Xi(δ)
P(cid:110)
≥ PN(cid:110)
m(cid:88)
(cid:110)
S ∈ ∆N : P(cid:110)
≥ PN(cid:110) m(cid:92)
PN(cid:110)
S ∈ ∆N : P(cid:110)
≥ 1 − m(cid:88)
≥ 1 − m(cid:88)

δ ∈ ∆ : x∗

S ∈ ∆N :

S ∈ ∆N :

(cid:110)

i=1

i=1

i=1

i=1

βi,

N /∈ m(cid:92)

(cid:111)
(cid:111)

i=1

i=1

Xi(δ)

(cid:111) ≤ m(cid:88)
(cid:101)εi
(cid:111) ≤ m(cid:88)
(cid:101)εi
N /∈ Xi(δ)
(cid:111)
(cid:101)εi
N /∈ Xi(δ)

(cid:111)(cid:111) ≤ m(cid:88)

i=1

i=1

δ ∈ ∆ : x∗

δ ∈ ∆ : x∗

N /∈ Xi(δ)

δ ∈ ∆ : x∗

N /∈ Xi(δ)

i=1

(cid:111) ≤ m(cid:88)
(cid:111)
(cid:101)εi
(cid:111)(cid:111)
(cid:111) ≤(cid:101)εi
(cid:111)
(cid:111) ≤(cid:101)εi

(50)

i=1

such that (cid:80)m

which leads to the following proposition.
Proposition 3. Fix β ∈ (0, 1) and choose βi, i = 1, . . . , m,

i=1 βi = β. For each i = 1, . . . , m, let (cid:101)εi be as

in (48) and set (cid:101)ε =(cid:80)m
i=1(cid:101)εi. We then have that
(cid:111) ≤(cid:101)ε
N /∈ m(cid:92)

S ∈ ∆N :
δ ∈ ∆ : x∗

PN(cid:110)
P(cid:110)

Xi(δ)

(cid:111) ≥ 1 − β.

11

(51)

i=1

Proposition 3 implies that with conﬁdence at least 1 − β,

N is feasible for Pδ apart from a set with measure at most(cid:101)ε.
a high number of agents. This can be seen by comparing(cid:101)ε with

x∗
This is an a-priori feasibility result, however, it tends to be very
conservative thus prohibiting its applicability to problems with

¯ε, where the latter corresponds to the case where scenarios
are treated as a common resource. To this end, consider the
particular set-up where Ni = ¯N and βi = β/m, for all
i = 1, . . . , m. By inspection of (44) and (48), it follows that

(cid:101)ε = m(cid:101)εi ≈ m¯ε, thus growing approximately (we do not have

exact equality since βi = β/m) linearly with the number of
agents. This can be also observed in the numerical comparison
of Section V-C2 (see Fig. 1). The issue with Proposition 3
is that it accounts for a worst-case setting, where di,N = d
for all i = 1, . . . , m; however, this can not occur, since the
i=1 di,N ≤ d prevents di,N , i = 1, . . . , m, to be
simultaneously equal to d. In fact if di,N = d for some i, then
dj,N = 0, for all j (cid:54)= i, i = 1, . . . , m.

fact that (cid:80)m
sition 3, and exploit the fact that (cid:80)m

2) A tighter result: To alleviate the conservatism of Propo-
i=1 di,N ≤ d, we apply
the following reasoning, which strongly depends on the recent
results of [39].
For each i = 1, . . . , m, ﬁx βi ∈ (0, 1) and consider a
function εi(·) deﬁned as follows:

εi(k) = 1 − Ni−k

(d + 1)(cid:0)Ni

βi

k

(cid:1) , for all k = 0, . . . , d.

(52)

(cid:115)

Notice that εi(·) is also a function of Ni, βi and d, but this
dependency is suppressed to simplify notation. For each i =
1, . . . , m, working conditionally with respect to the scenarios
S \ Si of all other agents, Theorem 1 of [39] entails that

(cid:111) ≤ εi(di,N )

N /∈ Xi(δ)

(cid:12)(cid:12)(cid:12)(cid:8)S \ Si ∈ ∆N−Ni(cid:9)(cid:111) ≥ 1 − βi.

(53)

(54)

Integrating (53) with respect to the probability of realizing the
scenarios S \ Si, if εi(·) is set according to (52), we have that

S ∈ ∆N :
δ ∈ ∆ : x∗

N /∈ Xi(δ)

(cid:111) ≤ εi(di,N )

(cid:111) ≥ 1 − βi.

PN(cid:110)
P(cid:110)

The statement in (54) implies that for each agent i = 1, . . . , m,
with conﬁdence at least 1 − βi, the probability that x∗
N does
not belong to the constraint set Xi(δ) of agent i is at most
equal to εi(di,N ).

Note, however, that (54) is very different from (49), which
is obtained by means of the basic scenario approach theory,
since di,N is not known a-priori but depends on the extracted

PN(cid:110)
P(cid:110)

S ∈ ∆N :
δ ∈ ∆ : x∗

12

Fig. 1.
Probability of constraint violation as a function of the number of
agents, for the case where d = 50, β = 10−6, Ni = ¯N = 4500 and
βi = β/m, for all i = 1, . . . , m. The probability of violation ¯ε (green dashed
line) for the case of Section V-B is independent of m, so it remains constant

as the number of agents m increases. For the case of Section V-C1,(cid:101)ε ≈ m¯ε

(red dotted-dashed line) for the considered set-up, so it grows approximately
linearly with m. For the case of Section V-C2, ε (blue solid line) is moderately
increasing with m, thus offering a less conservative result compared to the
approach of Section V-C1, while, in contrast to the approach of Section V-B,
it allows for distributed information about the uncertainty scenarios.

scenarios. Using (54) in place of (49) in the the derivations of
(50), by the subadditivity of PN and P, we have that

PN(cid:110)
P(cid:110)

S ∈ ∆N :
δ ∈ ∆ : x∗

N /∈ m(cid:92)
≤ m(cid:88)

i=1

Xi(δ)

(cid:111)
(cid:111) ≥ 1 − m(cid:88)

εi(di,N )

βi.

(55)

i=1

i=1

m(cid:88)
m(cid:88)

i=1

Unlike (45) and (51), (55) is an a-posteriori statement due
ering the worst-case value for(cid:80)m
to the dependency of εi(di,N ) on the extracted scenarios.
However, the sought a-priori result can be obtained by consid-
(cid:80)m
i=1 εi(di,N ), with respect to
the different combinations of di,N , i = 1, . . . , m, satisfying
i=1 di,N ≤ d. This can be achieved by means of the

following maximization problem:

εi(di)

(56)

ε = max

{di∈N+}m

i=1

subject to

di ≤ d,

i=1

Problem (56) is an integer optimization program. It can be
solved numerically to obtain ε. The optimal value ε of the
problem above depends on {Ni, βi}m
i=1 and d, but this de-
pendency is suppressed to simplify notation. Notice the slight
abuse of notation, since {di}m
i=1 in (56) are integer decision
variables and should not be related to {di,N}m
i=1. We then
have the following theorem, which can be regarded as the
main result of this section.

(57)

Xi(δ)

i=1

(cid:111) ≤ ε

N /∈ m(cid:92)

(cid:111) ≥ 1 − β.

S ∈ ∆N :
δ ∈ ∆ : x∗

Theorem 4. Fix β ∈ (0, 1) and choose βi, i = 1, . . . , m, such
i=1 βi = β. Set ε according to (56). We then have that

Proof: Fix β ∈ (0, 1) and choose βi, i = 1, . . . , m,
i=1 βi = β. Consider any set S of scenarios and
i=1 di,N (S) ≤ d. This implies that {di,N (S)}m
i=1
constitute a feasible solution of (56). Due to the fact that ε is
i=1 εi(di,N (S)) ≤ ε for any S,
which together with (55), leads to (57) and hence concludes
the proof.

that(cid:80)m
PN(cid:110)
P(cid:110)
such that(cid:80)m
notice that(cid:80)m
the optimal value of (56), (cid:80)m
account for the fact that(cid:80)m
The result of Theorem 4 can be signiﬁcantly less conser-
vative compared to that of Proposition 3, since we explicitly
i=1 di,N ≤ d in the maximization
problem in (56). This can be also observed by means of the
(cid:101)ε and ε change as a function of the number of agents m.
numerical example of Fig. 1, where we investigate how ¯ε,
We consider a particular case where d = 50, β = 10−6,
Ni = ¯N = 4500 and βi = β/m, for all i = 1, . . . , m.
For this set-up, where β is split evenly among agents and
all agents have the same number of scenarios, it turned out
that the maximum value ε in (56) is achieved for di = d/m,
i = 1, . . . , m. As it can be seen from Fig. 1, ¯ε (green dashed
line) for the case of Section V-B is independent of m, so it
remains constant as the number of agents m increases. For the

case of Section V-C1,(cid:101)ε ≈ m¯ε (red dotted-dashed line) for the

considered set-up (see also discussion at the end of Section
V-C1), so it grows approximately linearly with m. For the case
of Section V-C2, ε (blue solid line) is moderately increasing
with m, thus offering a less conservative result compared to the
approach of Section V-C1, while, in contrast to the approach
of Section V-B, it allows for distributed information about the
uncertainty scenarios.

In certain cases (e.g., when the number of agents is high),
however, ε may still exceed one and hence the result of
Theorem 4 becomes trivial (the same for Proposition 3 in such
cases). Similarly to the discussion at the end of Section V-A,
Theorem 4 can be reversed to compute the number of scenarios
Ni that need to be extracted by agent i, i = 1, . . . , m, for
a given value of ε, β ∈ (0, 1). This can be achieved by
numerically seeking for values of Ni, i = 1, . . . , m, that lead
to a solution of (56) that attains the desired ε.

VI. CONCLUSION

In this paper a unifying framework for distributed convex
optimization over time-varying networks, in the presence of
constraints and uncertainty is provided. Focusing ﬁrst on the
deterministic case, a proximal minimization approach was
adopted and an iterative distributed algorithm was developed.
Convergence and optimality of this distributed scheme was
shown. This approach was then extended to the case where
the agents’ constraint sets are affected by a possibly common
uncertainty vector. We followed a scenario-based methodol-
ogy to deal with this problem, accompanying the resulting

Number of agents - m123456789101112131415Probability of violation00.10.20.30.40.50.60.70.80.91"e""13

Proof of Lemma 2. By (17), (18), for all k, s with s ≥ 0,
k > s, and for all i = 1, . . . , m we have that

||xi(k + 1) − v(k + 1)|| =

k−1(cid:88)

m(cid:88)

r=s

j=1

+

+ ei(k + 1) − 1
m

≤ m(cid:88)

j=1

(cid:12)(cid:12)(cid:12)(cid:2)Φ(k, s)(cid:3)i
j − 1
k−1(cid:88)
m(cid:88)

m

+

r=s

j=1

+ ||ei(k + 1)|| +

xj(s)

m

m

j=1

(cid:17)

ej(r + 1)

j − 1

(cid:16)(cid:2)Φ(k, s)(cid:3)i
j − 1
(cid:17)
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
(cid:12)(cid:12)(cid:12)||ej(r + 1)||

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) m(cid:88)
(cid:16)(cid:2)Φ(k, r + 1)(cid:3)i
m(cid:88)
(cid:12)(cid:12)(cid:12)||xj(s)||
(cid:12)(cid:12)(cid:12)(cid:2)Φ(k, r + 1)(cid:3)i
m(cid:88)

j − 1

ej(k + 1)

j=1

m

||ej(k + 1)||.

1
m

j=1

(62)

(cid:12)(cid:12)(cid:12)

(63)

(m−1)T .

Under Assumptions 5 and 6, by Lemma 4 of [18], for all

k, s with s ≥ 0, k ≥ s we have that

(cid:12)(cid:12)(cid:12)(cid:2)Φ(k, s)(cid:3)i
Setting λ = 2(cid:0)1 + η−(m−1)T(cid:1)/(cid:0)1 − η(m−1)T(cid:1) and q =(cid:0)1 −
(cid:12)(cid:12)(cid:12) ≤ λqk−s,
η(m−1)T(cid:1)

(cid:0)1 − η(m−1)T(cid:1) k−s
(cid:12)(cid:12)(cid:12)(cid:2)Φ(k, s)(cid:3)i

j − 1
m
1 + η−(m−1)T
≤ 2
1 − η(m−1)T

for all k ≥ s. Noticing that q ∈ (0, 1), since η ∈ (0, 1), the
last statement together with (62) leads to (19) and concludes
the proof.
Proof of Lemma 3. Fix any N ∈ N+ and, under Assump-
tions 2, 3, 5 and 6, consider (21). To show (22), we treat each
of the three terms that appear in the right-hand side of (21)
separately.

(m−1)T , (63) implies that

j − 1

m

1

k=1 c(k)qk(cid:80)m

i=1 ||xi(0)||.

Due to Assumption 2, ||xi(0)|| ≤ D, for all i = 1, . . . , m.
i=1 ||xi(0)|| ≤ mD. The last statement together
with the fact that, under Assumption 4, c(k) ≤ c(1), leads to
N(cid:88)

m(cid:88)

2mµλ ¯L

c(k)qk

||xi(0)||

Term 1. 2mµλ ¯L(cid:80)N
Therefore,(cid:80)m

k=1

i=1

≤ 2m2µλ ¯LDc(1)

solution with probabilistic guarantees regarding its feasibility
properties.

Current work concentrates on three main directions: 1)
Investigating the convergence rate properties of the developed
algorithm, 2) Developing rolling horizon implementations,
extending the work of [47] to the case where constraints are
also present, and 3) Analyzing the quality of the scenario-
based solutions, providing conﬁdence intervals connecting the
optimal values of P ¯N , PN with the one of Pδ by exploiting the
results of [48], [49]. Moreover, we seek to extend our results
to the case where a “budget” type coupling equality constraint
is added to the problem (common in resource allocation
problems [50]), and investigate the pricing implications of a
distributed scheme for such set-up. From an application point
of view, the main focus is on applying the proposed algorithm
to the problem of energy efﬁcient control of a building network
[51].

APPENDIX

Proof of Lemma 1. We have that for all k ≥ 0
||xi(k) − ¯v(k)||

1

ρ

¯x −

= || (k) + ρ
(k) + ρ
≤
≤ 1
ρ

xi(k) − (k)
(k) + ρ

(cid:0)(k)||xi(k) − ¯x|| + ρ||xi(k) − v(k)||(cid:1)

(cid:0)(k)||xi(k) − ¯x|| + ρ||xi(k) − v(k)||(cid:1),

v(k)||

(k) + ρ

(k) + ρ

(58)

where the last inequality is due to the fact that (k) ≥ 0.
i = 1, . . . , m, we have that for all k ≥ 0

By the deﬁnition of dist(·,·), and since xi(k) ∈ Xi for all

dist(v(k), Xi) ≤ m(cid:88)

m(cid:88)

i=1

(k) =

||xi(k) − v(k)||.

(59)

(cid:16) m(cid:88)

i=1

||xi(k) − v(k)||(cid:17)||xi(k) − ¯x||

i=1

+ ||xi(k) − v(k)||.

(60)

By (58), (59) we have that

||xi(k) − ¯v(k)|| ≤ 1
ρ

Summing both sides of (60) with respect to i = 1, . . . , m,

m(cid:88)

i=1

≤ 1
ρ

||xi(k) − ¯x||(cid:17)

||xi(k) − ¯v(k)||

(cid:16) m(cid:88)
m(cid:88)

i=1

i=1

||xi(k) − v(k)||(cid:17)(cid:16) m(cid:88)
(cid:17) m(cid:88)

||xi(k) − v(k)||

i=1

mD + 1

||xi(k) − v(k)||,

i=1

+

≤(cid:16) 2

ρ

where the last inequality is due to the fact that ||xi(k)− ¯x|| ≤
||xi(k)|| + ||¯x|| ≤ 2D for all i = 1, . . . , m, (see discussion
below (2) for the deﬁnition of D), by Assumption 2. This
concludes the proof.

N(cid:88)

qk

k=1
q
1 − q

(61)

< 2m2µλ ¯LDc(1)

,

(64)

where the last step is due to the fact that, by Lemma 2, q ∈

(0, 1) and hence(cid:80)∞
Term 2. 2mµλ ¯L(cid:80)N

k=1 qk = q(cid:80)∞
(cid:80)k−1
r=0 c(k)qk−r−1(cid:80)m

k=0 qk = q/(1 − q).

i=1 ||ei(r + 1)||.

k=1

independent of i, we have that

2mµλ ¯L

c(k)qk−r−1

N(cid:88)

k−1(cid:88)

m(cid:88)

||ei(r + 1)||

r=0

k=1
< 2m3µ2λ2 ¯L2

i=1
1

α1(1 − q)2 c(0)2 + 2α1mD2

N(cid:88)

k=1

1

α1(1 − q)2

c(k)2

+

i=1

k=1

α1
2

+ 2m3µ2λ2 ¯L2

N(cid:88)
m(cid:88)
k=1 c(k)(cid:80)m
Term 3. 4µ ¯L(cid:80)N
m(cid:88)
(cid:114) 2
(cid:16)

We have that

4µ ¯L

c(k)

k=1

i=1

||ei(k + 1)||

2

2

µ ¯Lc(k)

N(cid:88)
N(cid:88)
≤ N(cid:88)

k=1

=

m(cid:88)
m(cid:88)

i=1

µ2 ¯L2c(k)2 +

α1

k=1

i=1

8
α1

N(cid:88)

k=1

||ei(k + 1)||2,

i=1 ||ei(k + 1)||.

2

(cid:17)(cid:16)(cid:114) α1
||ei(k + 1)||(cid:17)
N(cid:88)
m(cid:88)
N(cid:88)
m(cid:88)

α1
2

k=1

i=1

||ei(k + 1)||2

||ei(k + 1)||2,

k=1

i=1

(68)

(69)

14

Fix any α1 ∈ (0, 1). We then have that

N(cid:88)
N(cid:88)

k=1

2mµλ ¯L

m(cid:88)

=

i=1

k=1

≤ m(cid:88)
m(cid:88)

i=1

N(cid:88)
N(cid:88)

k=1

+

2

r=0

k−1(cid:88)
(cid:16)
k−1(cid:88)
×(cid:16)(cid:114)
k−1(cid:88)
k−1(cid:88)

r=0

r=0

i=1

k=1

r=0

2

m(cid:88)

i=1

(cid:115)

c(k)qk−r−1

2

||ei(r + 1)||

(cid:17)
||ei(r + 1)||(cid:17)

c(k)

mµλ ¯L

α1(1 − q)

α1(1 − q)

2

qk−r−1

m2µ2λ2 ¯L2

α1(1 − q)

2

α1(1 − q)

qk−r−1c(k)2

qk−r−1||ei(r + 1)||2,

(65)

where in the last step we used the fact that 2xy ≤ x2 + y2 for
all x, y ∈ R.

qk−r−1c(r)2

We then have that,

N(cid:88)

k−1(cid:88)

k=1

r=0

k=1

qk−r−1c(k)2 ≤ N(cid:88)
N−1(cid:88)
N−1(cid:88)
N−1(cid:88)

r=0

r=0

=

<

c(r)2

c(r)2

r=0

k−1(cid:88)
N−r−1(cid:88)
∞(cid:88)

t=0

qt

t=0

1
1 − q

c(k)2

=

k=0

<

1
1 − q

c(0)2 +

1
1 − q

c(k)2,

(66)

N(cid:88)

k=1

N(cid:88)

k−1(cid:88)

inequality is due to the fact

where the ﬁrst
that, under
Assumption 4, c(k) ≤ c(r) since k > r. The ﬁrst equality
is due to series convolution, in the last equality we performed
an index change from r to k and the last inequality is included
to introduce the desired summation limits.
Repeating the same derivation as in (66) with ||ei(r + 1)||2

in place of c(r)2 leads to

qk−r−1||ei(r + 1)||2

k=1

r=0

<

1
1 − q

||ei(1)||2 +

N(cid:88)

k=1

1
1 − q

||ei(k + 1)||2

≤ 4
1 − q

D2 +

1
1 − q

||ei(k + 1)||2,

(67)

N(cid:88)

k=1

where the last inequality is due to the fact that ||ei(1)|| ≤ 2D
under Assumption 2.

By (65), (66), (67), and noticing that some terms are

qt

=

8
α1

mµ2 ¯L2

c(k)2 +

α1
2

where for the ﬁrst inequality we follow the same reasoning
with the last step of (65), and the second equality is due to
the fact that the ﬁrst term of the ﬁrst inequality is independent
of i.

We are now in a position to show (22). Substituting (64),
(68) and (69) in (21), and setting α2, α3 according to (23),
leads to (22) (the inequality is strict since the inequalities in
(64), (68) are also strict), thus concluding the proof.

REFERENCES

[1] S. Bolognani, R. Carli, G. Cavraro, and S. Zampieri, “Distributed
reactive power feedback control for voltage regulation and loss mini-
mization,” IEEE Transactions on Automatic Control, vol. 60, no. 4, pp.
966–981, 2015.

[2] Y. Zhang and G. Giannakis, “Distributed stochastic market clearing with
high-penetration wind power and large-scale demand response,” IEEE
Transactions on Power Systems, to appear, pp. 1–12, 2015.

[3] G. Mateos and G. Giannakis, “Distributed recursive least-squares: Stabil-
ity and performance analysis,” IEEE Transactions on Signal Processing,
vol. 60, no. 7, pp. 3740–3754, 2012.

[4] B. Baingana, G. Mateos, and G. Giannakis, “Proximal-gradient algo-
rithms for tracking cascades over social networks,” IEEE Journal of
Selected Topics in Signal Processing, vol. 8, no. 4, pp. 563–575, 2014.
[5] S. Martinez, F. Bullo, J. Cortez, and E. Frazzoli, “On synchronous
robotic networks - Part I: Models, tasks, and complexity,” IEEE Trans-
actions on Automatic C0ntrol, vol. 52, no. 12, pp. 2199–2213, 2007.

[6] J. Tsitsiklis, Problems in decentralized decision making and computa-

tion. Ph.D. Dissertation, MIT, Cambridge, MA, 1984.

[7] J. Tsitsiklis, D. Bertsekas, and M. Athans, “Distributed asynchronous
deterministic and stochastic gradient optimization algorithms,” IEEE
Transactions on Automatic Control, vol. 31, no. 9, pp. 803–812, 1986.
[8] D. Bertsekas and J. Tsitsiklis, Parallel and distributed computation:

Numerical methods. Athena Scientiﬁc (republished in 1997), 1989.

[9] S. Boyd, N. Parikh, E. Chu, B. Peleato, and J. Eckstein, “Distributed
optimization and statistical learning via the alternating direction method
of multipliers,” Foundations and Trends in Machine Learning, vol. 3,
no. 1, pp. 1–122, 2010.

15

[34] M. Campi and S. Garatti, “The exact feasibility of randomized solutions
of uncertain convex programs,” SIAM Journal on Optimization, vol. 19,
no. 3, pp. 1211–1230, 2008.

[35] M. Campi, S. Garatti, and M. Prandini, “The scenario approach for
systems and control design,” Annual Reviews in Control, vol. 33, no. 2,
pp. 149 – 157, 2009.

[36] M. Campi and S. Garatti, “A sampling-and-discarding approach to
chance-constrained optimization: feasibility and optimality,” Journal of
Optimization Theory and Applications, vol. 148, no. 2, pp. 257–280,
2011.

[37] S. Garatti and M. Campi, “Modulating Robustness in Control Design,”

IEEE Control Systems, vol. 33, no. 2, pp. 36 – 51, 2013.

[38] K. Margellos, M. Prandini, and J. Lygeros, “On the connection between
compression learning and scenario based single-stage and cascading op-
timization problems,” IEEE Transactions on Automatic Control, vol. 60,
no. 10, pp. 2716–2721, 2015.

[39] M. Campi, S. Garatti, and F. Ramponi, “Non-convex scenario opti-
mization with application to system identiﬁcation,” IEEE Conference
on Decision and Control, to appear, pp. 1–8, 2015.

[40] A. Nedic, A. Olshevsky, A. Ozdaglar, and J. Tsitsiklis, “On distributed
averaging algorithms and quantization effects,” IEEE Transactions on
Automatic Control, vol. 54, no. 11, pp. 2506–2517, 2009.

[41] D. Bertsekas, “Incremental proximal methods for large scale convex
optimization,” Mathematical Programming, vol. 129, no. 2, pp. 163–
195, 2011.

[42] ——, “Multiplier methods: A survey,” Automatica, vol. 12, no. 2, pp.

133–145, 1976.

University Press, 2004.

[43] S. Boyd and L. Vandenberghe, Convex Optimization.

Cambridge

[44] A. Nedic, A. Ozdaglar, and P. Parrilo, “Constrained consensus and
optimization in multi-agent networks,” Technical Report, pp. 1–35,
2008. [Online]. Available: http://arxiv.org/abs/0802.3922v2

[45] G. Schildbach, L. Fagiano, and M. Morari, “Randomized Solutions to
Convex Programs with Multiple Chance Constraints,” SIAM Journal on
Optimization, vol. 23, no. 4, pp. 2479 – 2501, 2013.

[46] N. Kariotoglou, K. Margellos, and J. Lygeros, “On the computational
complexity and generalization properties of multi-stage and recursive
scenario programs,” under review, pp. 1–6, 2015. [Online]. Available:
http://arxiv.org/pdf/1412.4203v1.pdf

[47] J. Tsitsiklis and M. Athans, “Convergence and asymptotic agreement
in distributed decision problems,” IEEE Transactions on Automatic
Control, vol. 29, no. 1, pp. 42–50, 1984.

[48] T. Kanamori and A. Takeda, “Worst-case violation of sampled convex
programs for optimization under uncertainty,” Journal of Optimization
Theory and Applications, vol. 152, no. 1, pp. 171–197, 2012.

[49] P. Mohajerin, T. Sutter, and J. Lygeros, “Performance bounds for the
scenario approach and an extension to a class of non-convex programs,”
IEEE Transactions on Automatic Control, vol. 60, no. 1, pp. 46–58,
2015.

[50] K. Margellos and S. Oren, “Capacity Controlled Demand Side Man-
agement: A Stochastic Pricing Analysis,” IEEE Transactions on Power
Systems, to appear, pp. 1–12, 2015.

[51] D. Ioli, A. Falsone, and M. Prandini, “Optimal energy management of
a building cooling system with thermal storage: A convex formulation,”
IFAC International Symposium on Advanced Control of Chemical Pro-
cesses, pp. 1151 – 1156, 2015.

[10] I. Necoara, V. Nedelcu, and I. Dumitrache, “Parallel and distributed
optimization methods for estimation and control in networks,” Journal
of Process Control, vol. 21, no. 5, pp. 756–766, 2011.

[11] S. Grammatico, F. Parise, M. Colombino, and J. Lygeros, “Decentralized
convergence to Nash equilibria in constrined mean ﬁeld control,” IEEE
Transactions on Automatic Control (provisionally accepted), pp. 1–37,
2015. [Online]. Available: http://arxiv.org/pdf/1410.4421v2.pdf

[12] T. Vicsek, A. Czirok, E. Ben-Jacob, I. Cohen, and O. Shochet, “Novel
type of phase transitions in a system of self-driven particles,” Physical
Review Letters, vol. 75, no. 6, pp. 1226–1229, 1995.

[13] A. Jadbabaie, J. Lin, and S. Morse, “Coordination of groups of mobile
autonomous agents using nearest neighbor rules,” IEEE Transactions on
Automatic Control, vol. 48, no. 6, pp. 988–1001, 2003.

[14] R. Olfati-Saber and R. Murray, “Consensus problems in networks of
agents with switching topology and time delays,” IEEE Transactions on
Automatic Control, vol. 49, no. 9, pp. 1520–1533, 2004.

[15] M. Cao, D. Spielman, and S. Morse, “A lower bound on convergence of
a distributed network convergence algorithm,” in Proceedings of IEEE
Control and Decision Conference, pp. 2356–2361, 2005.

[16] S. Boyd, A. Ghosh, B. Prabhakar, and D. Shah, “Randomized gossip
algorithms,” IEEE Transactions on Information Theory, vol. 52, no. 6,
pp. 2508–2530, 2006.

[17] B. Johansson, M. Rabi, and M. Johansson, “A simple peer-to-peer algo-
rithm for distributed optimization in sensor networks,” in Proceedings
of IEEE Conference on Decision and Control, pp. 4705–4710, 2007.

[18] A. Nedic and A. Ozdaglar, “Distributed subgradient methods for multi-
agent optimization,” IEEE Transactions on Automatic Control, vol. 54,
no. 1, pp. 48–61, 2009.

[19] A. Olshevsky and J. Tsitsiklis, “Convergence speed in distributed
convergence and averaging,” SIAM Review, vol. 53, no. 4, pp. 747–772,
2011.

[20] A. Nedic and A. Olshevsky, “Distributed optimization over time-varying
directed graphs,” IEEE Transactions on Automatic Control, vol. 60,
no. 3, pp. 601–615, 2015.

[21] D. Varagnolo, F. Zanella, A. Cenedese, G. Pillonetto, and L. Schenato,
“Newton-Raphson consensus for distributed convex optimization,” IEEE
Transactions on Automatic Control, to appear, pp. 1–32, 2015.

[22] B. Johansson, T. Keviczky, M. Johansson, and K. Johansson, “An
interior-point Lagrangian decomposition method for separable convex
optimization,” in Proceedings of IEEE Conference on Decision and
Control, pp. 4185–4190, 2008.

[23] I. Necoara and J. Suykens, “An interior-point Lagrangian decomposition
method for separable convex optimization,” Journal of Optimization
Theory and Applications, vol. 143, no. 3, pp. 567–588, 2009.

[24] Y. Pu, M. Zeilinger, and C.

Jones, “Quantization design for
distributed optimization,” Technical Report, EPFL Lausanne, pp. 1–15,
2015. [Online]. Available: http://infoscience.epﬂ.ch/record/207085/ﬁles/
pu quantization.pdf?version=1

[25] E. Wei and A. Ozdaglar, “On the 1/k convergence if asynchronous
alternating direction method of multipliers over networks,” Technical
Report, MIT, pp. 1–30, 2015. [Online]. Available: https://asu.mit.edu/
sites/default/ﬁles/documents/publications/asynchronousADMM.pdf

[26] L. Carlone, V. Srivastava, F. Bullo, and G. Calaﬁore, “Distributed
random convex programming via constraints consensus,” SIAM Journal
on Control and Optimization, vol. 52, no. 1, pp. 629–662, 2014.

[27] M. B¨urger, G. Notarstefano, and F. Allg¨ower, “A polyhedral approxima-
tion framework for convex and robust distributed optimization,” IEEE
Transactions on Automatic Control, vol. 59, no. 2, pp. 3740–3754, 2014.
[28] A. Nedic, A. Ozdaglar, and P. Parrilo, “Constrained consensus and
optimization in multi-agent networks,” IEEE Transactions on Automatic
Control, vol. 55, no. 4, pp. 922–938, 2010.

[29] M. Zhu and S. Martinez, “On distributed convex optimization under
inequality and equality constraints,” IEEE Transactions on Automatic
Control, vol. 57, no. 1, pp. 151–164, 2012.

[30] S. Lee and A. Nedic, “Distributed random projection algorithm for
convex optimization,” IEEE Journal on Selected Topics in Signal Pro-
cessing, vol. 7, no. 2, pp. 221–229, 2013.

[31] Z. Towﬁc and A. Sayed, “Adaptive penalty-based distributed stochastic
convex optimization,” IEEE Transactions on Signal Processing, vol. 62,
no. 15, pp. 3924–3938, 2014.

[32] S. Lee and A. Nedic, “Asynchronous gossip-based random projection
algorithms over networks,” IEEE Transactions on Automatic Control, to
appear, pp. 1–15, 2015.

[33] G. Calaﬁore and M. Campi, “The scenario approach to robust control
design,” IEEE Transactions on Automatic Control, vol. 51, no. 5, pp.
742–753, 2006.

