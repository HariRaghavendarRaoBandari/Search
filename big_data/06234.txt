6
1
0
2

 
r
a

 

M
0
2

 
 
]

.

C
O
h
t
a
m

[
 
 

1
v
4
3
2
6
0

.

3
0
6
1
:
v
i
X
r
a

STABLE STOCHASTIC PREDICTIVE CONTROL UNDER CONTROL

CHANNEL ERASURES

PRABHAT K. MISHRA, DEBASISH CHATTERJEE, AND DANIEL E. QUEVEDO

Abstract. This article presents tractable and recursively feasible receding horizon
optimization programs for stochastic linear systems with hard bound on control
and unreliable uplink. The stochastic noise in the plant is assumed to be additive
and zero mean. The system matrix A is marginally stable. The proposed policies
ensure mean square boundedness of states in closed-loop for all positive values of
control authority.

1. Introduction

The availability of fast computing machines has spurred the growth of control tech-
niques that involve algorithmic selection of actions that minimize some performance ob-
jective. Receding horizon predictive control, which is based on the idea of algorithmic
selection of control actions, has evolved over the years into one of the most useful control
synthesis techniques currently available to a control engineer. Initial forays into stochastic
versions of receding horizon techniques were made in the operations research community,
with inventory and manufacturing systems as the key application areas. Since then there
has been a steady growth of stochastic receding horizon control in the domain of control
systems, with current application areas ranging in ﬁnancial engineering, industrial elec-
tronics, power systems, process control, etc. See e.g., the recent survey [1] for the current
state-of-the-art and [2, 3] for book-length treatments.

As emphasized in [1], stochastic receding horizon control still lacks a comprehensive and
uniﬁed treatment. In particular, the treatment of potentially unbounded noise appears
to be sketchy, and part of the reason for this lacuna is the complete absence of a ﬁnal
constraint set that can be made positively invariant. Consequently, the conventional tools
developed in the deterministic and robust receding horizon control, e.g., in [4, 5, 6, 7, 8,
9, 10, 11, 12, 13] do not apply; see [1, §3] for a detailed discussion. The literature is even
more sketchy when it comes to stochastic receding horizon control over networks that take
into account the stochastic eﬀects of such communication networks, and this is the precise
area where the contributions of this article lie.

This article is concerned with stochastic predictive control under a noisy control chan-
nel. The plant is assumed to be a noisy linear controlled system, with the plant noise being
a stochastic process entering the dynamics additively. We do not assume that the noise is
bounded. Notice that even without control channel dropouts, since the noise is not nec-
essarily bounded, a conventional terminal constraint argument ´a la [14] to ensure closed
loop stability turns out to be impossible. Since the underlying optimal control problems
are employed in a receding horizon fashion, and each of them are ﬁnite horizon optimal
control problem, stability of the closed loop system under the resulting receding horizon
control is by no means obvious. In the deterministic setting one selects the cost-per-stage
function cs and the ﬁnal cost function cf in a certain way to ensure stability of the closed-
loop system [15]. To deal with stochastic systems, we shall impose a constraint in the
underlying optimal control problem such that it is (globally) feasible and the closed-loop

Key words and phrases. model predictive control, stochastic control, erasure channel, packet

dropouts.

Prabhat K. Mishra and Debasish Chatterjee are with Systems and Control Engineering, Indian

Institute of Technology Bombay, Mumbai, India. prabhat@sc.iitb.ac.in, dchatter@iitb.ac.in .

Daniel E. Quevedo is with Department of Electrical Engineering (EIM-E), University of Paderborn,

Germany. dquevedo@ieee.org.

D. Chatterjee was supported in part by the grant 12IRCCSG005 from IRCC, IIT Bombay.
The authors thank Peter Hokayem for helpful discussions.

1

2

P. K. MISHRA, D. CHATTERJEE, AND D. E. QUEVEDO

system is stable in a precise sense. Such constraint embedding for stability is not new,
and has appeared in the literature concerning deterministic MPC in [14] and stochastic
MPC in [16, 17]. The control channel is modeled as an erasure channel with dropouts
occurring according to a i.i.d. Bernoulli {0, 1} random process. We assume that all com-
munication occurs via a protocol with reliable acknowledgements of receipts. One of our
primary goals is to ensure good stability properties in closed-loop receding horizon policy.
To this end we select the notion of mean-square boundedness of the closed-loop process as
a desirable property, and we demonstrate how to ensure mean-square boundedness under
mild assumptions on the noise. To our knowledge this is the ﬁrst rigorous treatment of
stochastic MPC with bounded controls in the presence of control channel dropouts, and
where stability of closed loop process is ensured.

Control under packet dropouts is extensively studied within the framework of sequence
based control [18, 19, 20] and Packetized Predictive Control (PPC) [21, 22]. In sequence
based control, packet dropouts and communication delays are studied for both uplink and
downlink without any constraint on the control inputs. Hard bounds on the control inputs
are omnipresent in practical applications; therefore it is of paramount importance that
control strategies take into account these bounds at the synthesis stage. PPC handles
the constrained control problems by solving a deterministic optimization program over
It was demonstrated in [23, §2.4] that
open loop input sequences at each time step.
for stochastic systems, the optimization over feedback policies is superior to open-loop
controls in the sense that the cost in the former case is in general lower than in the latter
case. However, the set of decison variables is non-convex for the state feedback policy
[24]. In case of disturbance feedback parametrization, an admissible feedback policy can
be obtained by solving a tractable convex optimization program [24]. The disturbance
feedback parametrization followed by saturation of feedback is used in [25] to satisfy
the constraints on actions in the presence of potentially unbounded disturbance. This
approach was followed in [26] in the presence of i.i.d. packet dropouts, but large enough
control authority was required to ensure mean square boundedness of the states. Our
results extend the main results of [25] and [26] by removing the lower bound on the
control authority in presence of i.i.d. packet dropouts. In addition, we demonstrated in
[27] via numerical simulations that our approach employs less actuator energy than PPC.
The main contributions of this article are as follows: We give a tractable and recursively
feasible solution to stochastic predictive control for linear systems. We impose a hard
bound on the control in the presence of unreliable uplink and possibly unbounded additive
noise.

We present three transmission protocols and systematically show the formulation of
tractable underlying optimization programs.
The article exposes as follows: In §2 we establish the notation and deﬁnitions of the
plant and its properties. In §3 we provide the main results. The proofs of our results are
documented in a consolidated manner in the Appendix.

denote by sn:k the vector (cid:0)s(cid:62)

Our notations are standard. We let R denote the real numbers and N denote the
natural numbers. For any sequence (sn)n∈N taking values in some Euclidean space, we
, k ∈ N. The standard Kronecker
and Schur products of matrices are denoted by ⊗ and (cid:12), respectively. For any z ∈ R we
let z+ and z− denote the positive and the negative parts max{z, 0} and max{−z, 0} of z,
respectively. The notation Ez[·] stands for the conditional expectation with given initial
condition z. For a given vector V its ith component is denoted by V (i). Similarly, M (i)
denotes the ith row of a given matrix M . The vector of all 1’s of length k is denoted by
11:k. For a matrix M the quantity σ1(M ) denotes its largest singular value.

s(cid:62)
n+k−1

(cid:1)(cid:62)

s(cid:62)

n+1

···

n

2.1. Dynamics and objective function. Consider the linear time-invariant control sys-
tem with additive process noise and controlled over an erasure channel given by

2. Problem Setup

(1)

where

xt+1 = Axt + Bua

t + wt,

x0 = x,

STABLE STOCHASTIC PREDICTIVE CONTROL UNDER CONTROL CHANNEL ERASURES

3

νt

wt

xt

Controller

Ct

Dropout
Channel

Smart

Actuator

ua
t

xt+1

Plant

νt−1

Figure 1. An unreliable communication channel is situated between
controller and smart actuator. The parameters of control policy trans-
mitted by the controller depend on the transmission protocols. The
acknowledgement of the successful transmission is causally available to
the controller.

((1)-a) xt ∈ Rd, A ∈ Rd×d, B ∈ Rd×m are given matrices, x ∈ Rd is a given vector. The
system matrix A has simple eigen spectrum and the eigen spectrum is bounded
by unity. The control ua
t is the available control at the actuator end at time t in
presence of the erasure control channel. It takes values in the set

(2)

U := {v ∈ Rm | (cid:107)v(cid:107)∞ (cid:54) Umax},

((1)-b) (wt)t∈N is a sequence of i.i.d. zero mean random vectors taking values in Rd, and
((1)-c) at each time t the state xt is measured perfectly.

A control policy π is a sequence (π0, . . . , πt, . . .) of Borel measurable maps πt : Rd −→
U. Policies of ﬁnite length (πt, πt+1, . . . , πt+N−1) for some N ∈ N will be denoted by
πt:N in the sequel. The control ua
t available at the actuator end at time t depends on
the transmitted parameters of the control policy and the dropouts (νt)t∈N in the control
channel. (νt)t∈N is a sequence of i.i.d. Bernoulli {0, 1} random variables with E[νt] = p ∈
]0, 1] and the sequence (νt)t∈N is independent of (wt)t∈N.
Let symmetric and non-negative deﬁnite matrices Q, Qf ∈ Rd×d and a symmetric
and positive deﬁnite matrix R ∈ Rm×m be given, and deﬁne the cost-per-stage function
cs : Rd × U −→ [0, +∞[ and the ﬁnal cost function cf : Rd −→ [0, +∞[ by

cs(z, v) := (cid:104)z, Qz(cid:105) + (cid:104)v, Rv(cid:105) and cf (z) = (cid:104)z, Qf z(cid:105) ,

respectively. Fix an optimization horizon N ∈ N and consider the objective function at
time t given the state xt:

(cid:20)N−1(cid:88)

(cid:21)

(3)

Vt := Ext

cs(xt+k, ua

t+k) + cf (xt+N )

.

k=0

The cost function Vt therefore, considers the control eﬀort that occurs at the actuator end,
not just the computed control. At each time instant t we are interested in minimizing
the objective function Vt over the class of causal history-dependent feedback strategies Π
deﬁned by

ut+(cid:96) = πt+(cid:96)(xt, xt+1, . . . , xt+(cid:96))

while satisfying ut ∈ U for each t.

The receding horizon control strategy for a given control horizon Nc ∈ {1, . . . , N} and
t:N ∈ Π

time t consists of successive applications of the following steps:
(i) measure the state xt and determine an admissible optimal feedback policy π(cid:63)

that minimizes Vt at time t,

t:Nc−1 of this policy,

(ii) apply the ﬁrst Nc elements π(cid:63)
(iii) increase t to t + Nc and return to step (i).
In common parlance, the case of Nc = 1 is known as model predictive control, and that
of Nc = N is known as rolling horizon control [28, 29, 30, 31]. In this current work we
consider the control horizon Nc equal to the reachability index κ of the system to satisfy
the stability drift conditions (11) and (12) below.

4

P. K. MISHRA, D. CHATTERJEE, AND D. E. QUEVEDO

The states, controls and noise over one horizon N admit the following description
under reliable control channel, in the sense that solely the control action ut is sent over
the communication channel at each time t:



νt11:m
νt+111:m

...

 (cid:12)



ut
ut+1
...

ua
t:N :=

(4)

where

xt:N +1 = Axt + Bua

t:N + Dwt:N ,

 ,

...

νtut

νt+1ut+1

νt+N−1ut+N−1
0d×d
Id
...

 =

, and D :=

(cid:122)
(cid:1) and R := blkdiag(
t:N(cid:105)(cid:3)

t:N ,Rua

...

B
...

...
B

0d×m

A :=

0d×m
0d×m

0d×m
0d×m

νt+N−111:m



Id
A
...
AN

, B :=

ut+N−1
···
···
. . .
AN−1B AN−2B . . .


(cid:122)
(cid:125)(cid:124)
(cid:123)
block diagonal matrices Q := blkdiag(cid:0) N times
(cid:2)(cid:104)xt:N +1,Qxt:N +1(cid:105) + (cid:104)ua
constraint (4),

ut ∈ U for all t,
πt:N ∈ a class of policies.

subject to

minimize

Ext

(5)

πt:N

Id is the d × d identity matrix and 0r×q is the r × q matrix with 0 entries. We deﬁne two
R,··· , R) derived
from the given matrices Q, Qf and R. The compact notation above allows us to state the
following optimal control problem underlying the receding horizon control technique:

Q,··· , Q, Qf

N times

(cid:125)(cid:124)

(cid:123)

AN−1 AN−2

0d×d
0d×d
...

···
···
. . .
. . .

,

0d×d
0d×d
...
Id

In the presence of control channel noise the optimal control problem (5) will undergo
a change due to an appropriate selection of policies.
In particular, we shall employ a
feedback from the process noise in our policies, which will lead to a modiﬁed optimal
control problem. Parameterization of control policies direcly in terms of the noise is
standard [24, 32] and it leads to convex problems under appropriate selection of the cost
and the constraints. We impose the following blanket:

Assumption 1. The communication channel between sensors and the controller is noise-
less.

Two important ingredients of SMPC are the class of control policy and the stability
constraints. We shall discuss them in the following sections. The control policy class
allows us to take the disturbance as feedback and to consider the eﬀects of transmission
protocols, which are discussed in §3. The stability constraints allow us to transcend beyond
the regime of terminal set method. In order to ensure recursive feasibility and mean square
boundedness for any positive bound on control, the stability constraints presented in this
article are diﬀerent from those in [25].

2.2. Control policy class. We recall that the states are completely and exactly measured
and acknowledgment of whether a successful control transmission has occurred or not is
assumed to be causally available to the controller. The architecture is depicted in Fig. 1.
It is therefore possible to reconstruct the noise sequence from the sequence of observed

states and control inputs with the aid of the formula
wt = xt+1 − Axt − Bua
t ,

(6)
This calculation is performed at the controller at each time t ∈ N. We follow the approach
in [28], and employ N -history-dependent policies of the form

t ∈ N.

(7)

ut+(cid:96) = ηt+(cid:96) +

θ(cid:96),t+iei+1(wt+i),

for (cid:96) = 0, 1, . . . , N − 1, where ei : Rd −→ U is a measurable map for each i such that
E[ei(wt+i−1)] = 0. It was shown in [24] that for ei equals to the identity map, there exists
a (nonlinear) bijection between the above class of control policies and the class of aﬃne

i=0

(cid:96)−1(cid:88)

STABLE STOCHASTIC PREDICTIVE CONTROL UNDER CONTROL CHANNEL ERASURES

5


 ,




state feedback policies. The above choice is suboptimal, but it ensures tractability of a
broad class of optimal control problems in a computationally eﬃcient way using convex
optimization techniques [33]. Similarly to [34, 25, 35, 28], the measured noise is saturated
before inserting into the control vector. Hence, we can assume that there exists ϕmax ∈ R
such that (cid:107)ei(wt+i−1)(cid:107)∞ (cid:54) ϕmax for all i = 1,··· , N − 1. The control vector ut:N admits
the following form under the reliable control channel:

 + ϕ(wt:N−1) := ηt + Θt



ηt
ηt+1
...

ηt+N−1

e1(wt)
e2(wt+1)

...

eN−1(wt+N−2)

(8)

ut:N =

=: ηt + Θte(wt:N−1),

where ηt ∈ RmN and Θt is a strictly lower block triangular matrix
0
0
0
...

0
θ1,t
θ2,t
...

0
0
0
...

θ2,t+1

Θt =

(9)

0
0

...

···
···
···
...
···

θN−1,t

θN−1,t+1

θN−1,t+N−3

θN−1,t+N−2

with each θk,(cid:96) ∈ Rm×d and (cid:107)e(wt:N−1)(cid:107)∞ (cid:54) ϕmax. The matter of selection of the functions
ei is left open. As such we can accommodate standard saturation, piecewise linear, and
sigmoidal functions, to name a few. An interesting discussion on ei as a basis element and
θ(cid:96),t+i as a Fourier coeﬃcient can be found in [28, §III].
2.3. Stability Constraints. We recall the following deﬁntion:
Deﬁnition. [36, §III.A] An Rd-valued random process (xt)t∈N0 with given initial condition
x0 = x is said to be mean square bounded if

Ex[(cid:107)xt(cid:107)2] < +∞.

sup
t∈N0

Let us ﬁrst demonstrate the existence of a controller that ensures mean-square bound-
edness of the system (1) if A is marginally stable. Without loss of generality we assume
that the pair (A, B) is in the real Jordan canonical form. It is then a standard observation
[37, §4] that then the pair (A, B) is of the form

(10)
where Ao ∈ Rdo×do is orthogonal and As ∈ Rds×ds is Schur stable, with d = do + ds.
Since the pair (A, B) is stabilizable, there exists a positive integer κ such that the pair

(Ao, Bo) is reachable in κ-steps, i.e., rank(cid:0)Rκ(Ao, Bo)(cid:1) = do, where
o M ··· M(cid:1)

Rk(Ao, M ) :=(cid:0)Ak−1

o M Ak−2

Bs

,

,

for a matrix M of appropriate dimension. It suﬃces to focus on the subsystem (Ao, Bo)
since due to boundedness of the controls we have mean square boundedness of the Schur
stable subsystem by standard arguments [37, §4].

Two types of stability constraints are available in general: Geometric drift condition
and constant negative drift condition. The geometric drift can not be satisﬁed in case
of constrained control. So our main result consist of the following constant negative drift
condition: for any given  > 0, ζ ∈
and for any t = 0, κ, 2κ, ..., the
control ut ∈ U is chosen such that for j = 1, 2,··· , do the following drift conditions hold:

doσ1(Rκ(Ao,Bo)+)

(cid:21)

Umax

0,

√

(cid:18)(cid:18)Ao

0
0 As

(cid:19)

(cid:18)Bo

(cid:19)(cid:19)

(11)

Exo

t

when (xo

t )(j) (cid:62) r +  and

(Aκ
o )

(cid:62)

Rκ(Ao, Bo)ut:κ

(cid:54) −ζ

(12)

Exo

t

(cid:62)

(Aκ
o )

Rκ(Ao, Bo)ut:κ

(cid:62) ζ

(cid:20)(cid:16)
(cid:20)(cid:16)

(cid:20)
(cid:17)(j)(cid:21)
(cid:17)(j)(cid:21)

6

P. K. MISHRA, D. CHATTERJEE, AND D. E. QUEVEDO

ηt+(cid:96) +(cid:80)(cid:96)−1

i=0 θ(cid:96),t+iei+1(wt+i)

ηt, Θt

Controller

νt+(cid:96)

Actuator

Figure 2. Sequential transmission at time t + (cid:96)

when (xo

t )(j) (cid:54) −r − .

Remark 1. The above drift conditions push the jth component of (Aκ
o )
origin whenever the jth component of xo
the ﬁrst κ elements of the control policy.

t+κ towards the
t is outside the set [−r − , r + ] by application of

(cid:62)

xo

(cid:21)

(cid:20)

Remark 2. The amount of constant drift ζ is chosen from the interval

0,

to satisfy the hard bound on control.

√

Umax

doσ1(Rκ(Ao,Bo)+)

Remark 3. The componentwise drift conditions are used to remove the lower bound from
the control authority to extend the main results of [25] and [26].

We shall discuss three transmission protocols in the settings of control channel dropouts.

3. Main results

3.1. Sequential transmission of control. We stipulate that

Transmission Protocol.

(P1) The control values are transmitted to the actuator at every step.

For each t = 0, κ, 2κ,··· , the oﬀset vector and gain matrix are obtained by solving the
optimization problem (14) discussed below. The control (7) is computed and transmitted
at each instant.
For (cid:96) = 0, 1,··· , κ− 1, the control value transmitted at time t + (cid:96) is aﬀected by dropout

at the same time. Hence, ua

t:N in (4) is given by

t:N := Sηt + SΘte(wt:N−1),
ua

(13)

where

S :=



Im ⊗ νt



. . .

Im ⊗ νt+κ−1

Im(N−κ)

and e(wt:N−1) as deﬁned in (8).

Example 1. As an example consider N = 3, κ = 2. According to this protocol, the
following control sequence is valid:

ut = νtηt

ut+1 = νt+1ηt+1 + νt+1θ1,te1(wt)

ut+2 = ηt+2 + θ2,te1(wt) + θ2,t+1e2(wt+1).

STABLE STOCHASTIC PREDICTIVE CONTROL UNDER CONTROL CHANNEL ERASURES

7

Correspondingly, we have the following optimal control problem in lieu of (5):

(14)

minimize

ηt,Θt

subject to

(cid:2)(cid:104)xt:N +1,Qxt:N +1(cid:105) + (cid:104)ua

t:N(cid:105)(cid:3)

t:N ,Rua

Ext



constraint (4),
control (13),
ut ∈ U for all t,
stability constraints.

In the above transmission protocol, if the control packet is lost at some time instant,
null control is applied to the plant. The above protocol does not require any storage or
computational facility at the actuator end.

Remark 4. The bit rate in transmission protocol (P1) can be reduced by storing the
recieved packets ei+1(wt+i) in a buﬀer near the actuator and the corresponding scaling
factors θ(cid:96),t+i’s should be transmitted through the channel at each step.

We have the following theorem:

Theorem 1. Consider the control system (1) and suppose that Assumption 1 holds under
the transmission protocol (P1). Then:

(i) For every t = 0, κ, 2κ, . . ., the optimization problem (14) is convex, feasible, and can

be rewritten as the following tractable program with tightened constraints:

minimize

(ηt,Θt)

2 tr(Θ

(cid:62)
t µ
(cid:62)

S B(cid:62)QDΣ
(cid:62)

(cid:48)
e) + 2x

t A(cid:62)QBµS ηt
(cid:62)

+ tr(η

(cid:62)
t ΣS ΘtΣe) + ct
ΣS ηt) + tr((Θ

where Σe := E[e(wt:N−1)e(wt:N−1)(cid:62)], Σ(cid:48)
µS = E[S], ΣS = E[S(cid:62)(B(cid:62)QB + R)S] and ct := x(cid:62)
subject to :

e := E[wt:N e(wt:N−1)(cid:62)], ΣW := E[wt:N w(cid:62)

t A(cid:62)QAxt + tr(D(cid:62)QDΣW ).

t:N ],

(15)

(16)

(17)

(18)

(19)

ϕmax (cid:54) Umax
for given  > 0 and for every j = 1,··· , do,

for all i = 1,··· , N m,

(cid:12)(cid:12)(cid:12)η(i)

t

(cid:12)(cid:12)(cid:12) +

(cid:13)(cid:13)(cid:13)1

t

(cid:13)(cid:13)(cid:13)Θ(i)
(cid:16)
(cid:16)

Θt having the structure in (9)

(cid:17)(j) (cid:54) −ζ
(cid:17)(j) (cid:62) ζ

(Aκ
o )

(cid:62)

Rκ(Ao, Bo)(ηt)1:κm

whenever (xo

t )(j) (cid:62) r + ,

(cid:62)

(Aκ
o )

Rκ(Ao, Bo)(ηt)1:κm

whenever (xo

t )(j) (cid:54) −r − .

(ii) For any initial condition x ∈ Rd successive application of the control law given by the
optimization problem in (i) for κ steps renders the closed loop system mean square
bounded.

Remark 5. The variance and covariance matrices used in the optimization program are
computed oﬄine to reduce the burden of online computation.

The next transmission protocol is a slight modiﬁcation of that presented in [26].

3.2. Burst transmission of control policy parameters. We stipulate that

Transmission Protocol.

(P2) The oﬀset values of the control policy are transmitted in a single burst every κ steps
to the actuator and the weighted sum of the saturated feedback terms is transmitted
at each step.

8

P. K. MISHRA, D. CHATTERJEE, AND D. E. QUEVEDO

(cid:80)(cid:96)−1

i=0 θ(cid:96),t+iei+1(wt+i)

ηt, Θt

Controller

νt+(cid:96)

νt(ηt)1:mκ

Buﬀer

Figure 3. Control channel and buﬀer at time t + (cid:96) for burst transmis-
sion: Red block is transmitted as a burst at time t and stored in buﬀer.
Green blocks are transmitted at time t+(cid:96) for (cid:96) = 1,··· , κ−1 and added
with correspoding stored oﬀset value before application to the plant.

(cid:96) = 1, 2,··· , κ − 1, (cid:80)(cid:96)−1
and (cid:80)(cid:96)−1

According to this protocol, the burst (ηt)1:mκ is transmitted at time t and stored in a
buﬀer at the actuator end, where (ηt)1:mκ denotes ﬁrst mκ rows of ηt. In addition, for
i=0 θ(cid:96),t+iei+1(wt+i) is transmitted at time t + (cid:96). The plant noise
wt+i is calculated at the controller by (6) correctly with the help of acknowledgements.
Hence, the burst (ηt)1:mκ will be aﬀected by the packet dropout occurring at time t,
i=0 θ(cid:96),t+iei+1(wt+i) is aﬀected by the dropout occurring at time t + (cid:96) for (cid:96) =
1, 2,··· , κ − 1.

The control sequence can therefore be represented in compact form as:

(cid:18) νt ⊗ Imκ

(20)
where K :=
respectively; and e(wt:N−1) is as deﬁned in (8).

0m(N−κ)×mκ

Im(N−κ)

t:N := Kηt + SΘte(wt:N−1),
ua
0mκ×m(N−κ)

(cid:19)

and Θt and S are given in (9) and (13),

Example 2. As an example consider N = 3, κ = 2. According to this protocol, the
following control sequence is valid:

ut = νtηt

ut+1 = νtηt+1 + νt+1θ1,te1(wt)

Correspondingly, we have the following optimal control problem in lieu of (5):

ut+2 = ηt+2 + θ2,te1(wt) + θ2,t+1e2(wt+1).

(cid:2)(cid:104)xt:N +1,Qxt:N +1(cid:105) + (cid:104)ua

t:N(cid:105)(cid:3)

t:N ,Rua

(21)

minimize

ηt,Θt

subject to

Ext



constraint (4),
control (20),
ut ∈ U for all t,
stability constraints.

The above optimization problem has decision variables ηt and Θt rather than a class of
policy as in (5). Also, note that by setting some block elements of Θt to zero, the size
of the above optimization problem can be reduced signiﬁcantly. The above transmission
protocol needs a buﬀer and an adder at the actuator end.

We have the following theorem:

Theorem 2. Consider the system (1) and suppose that Assumption 1 holds under the
transmission protocol (P2). Then:

(i) For every t = 0, κ, 2κ, . . ., the optimization problem (21) is convex, feasible, and can

be rewritten as the following tractable program with tightened constraints:

(22)

minimize

ηt,Θt

ct + 2 tr(Θ

(cid:62)
t µ

(cid:48)
e) + 2x

S B(cid:62)QDΣ
(cid:62)
(cid:62)
t ΣS ΘtΣe)

(cid:62)
t ΣKηt) + tr(Θ

+ tr(η

t A(cid:62)QBµKηt
(cid:62)

STABLE STOCHASTIC PREDICTIVE CONTROL UNDER CONTROL CHANNEL ERASURES

9

where Σe := E[e(wt:N−1)e(wt:N−1)(cid:62)], Σ(cid:48)
E[K], ΣK = E[K(cid:62)(B(cid:62)QB + R)K], µS = E[S],ΣS = E[S(cid:62)(B(cid:62)QB + R)S] and ct :=
t A(cid:62)QAxt + tr(D(cid:62)QDΣW ).
x(cid:62)
subject to :

e := E[wt:N e(wt:N−1)(cid:62)], ΣW := E[wt:N w(cid:62)

t:N ], µK =

Θt having the structure in (9)

ϕmax (cid:54) Umax
for given  > 0 and for every j = 1,··· , do,

for all i = 1,··· , N m,

(cid:12)(cid:12)(cid:12)η(i)

t

(cid:12)(cid:12)(cid:12) +

(cid:13)(cid:13)(cid:13)1

t

(cid:13)(cid:13)(cid:13)Θ(i)
(cid:16)
(cid:16)

(cid:17)(j) (cid:54) −ζ
(cid:17)(j) (cid:62) ζ

(Aκ
o )

(cid:62)

Rκ(Ao, Bo)(ηt)1:κm

whenever (xo

t )(j) (cid:62) r + ,

(cid:62)

(Aκ
o )

Rκ(Ao, Bo)(ηt)1:κm

whenever (xo

t )(j) (cid:54) −r − .

(23)

(24)

(25)

(26)

(ii) For any initial condition x ∈ Rd successive application of the control law given by the
optimization problem in (i) for κ steps renders the closed loop system mean square
bounded.

The transmission protocols (P1) and (P2) do not transmit the data repetitively. We
have next transmission protocol, motivated with the idea of repetitive transmissions [22].

3.3. Sequential transmission of control along with repetitive transmission of
remaining oﬀset values. We stipulate that

Transmission Protocol.
(P3) The remaining blocks of the oﬀset vector are transmitted at each step until the ﬁrst
successful transmission. The control values containing the saturated feedback terms
are transmitted at each instant.

According to this protocol, control values are transmitted at each instant, similar to
the transmission protocol (P1). To mitigate the eﬀects of dropouts, the components of the
burst (ηt)1:mκ which are useful at future instants are also transmitted repetitively until one
burst is successfully received at the actuator end. A successfully recieved burst is stored
in a buﬀer and the corresponding oﬀset block is used in case of packet dropout. For the
simplicity of the optimization program, the buﬀer is emptied after each control horizon.
For (cid:96) = 0, 1,··· , κ − 2, the control value along with the burst of the remaining oﬀset
components transmitted at time t + (cid:96) is aﬀected by dropout at the same time. At time
t + κ− 1, the transmitted control value is aﬀected by the dropout νt+κ−1. The plant noise
wt+i is calculated at the controller by (6) correctly with the help of acknowledgements.

The control sequence can therefore be represented in compact form as:

(27)

where



G :=

νt ⊗ Im
0m×m

...

t:N := Gηt + SΘte(wt:N−1),
ua

0m×m(N−1)

(νt+1 + (1 − νt+1)νt) ⊗ Im 0m×m(N−2)

...



0m(N−κ)×mκ

Im(N−κ)

and Θt and S are given in (9) and (13), respectively; and e(wt:N−1) is as deﬁned in (8).
Example 3. As an example consider N = 3, κ = 2. According to this protocol, the
following control sequence is valid:

ut = νtηt

ut+1 = νt+1ηt+1 + (1 − νt+1)νtηt+1 + νt+1θ1,te1(wt)
ut+2 = ηt+2 + θ2,te1(wt) + θ2,t+1e2(wt+1).

10

P. K. MISHRA, D. CHATTERJEE, AND D. E. QUEVEDO

(ηt)((cid:96)−1)κ+1:mκ

ηt+(cid:96) +(cid:80)(cid:96)−1

i=0 θ(cid:96),t+iei+1(wt+i)

ηt, Θt

Controller

νt+(cid:96)

empty?

Buﬀer

Figure 4. Control channel and buﬀer at time t + (cid:96) for (P3): Red block
is transmitted as a burst only if the buﬀer is empty. Green blocks are
transmitted at time t + (cid:96) for (cid:96) = 0,··· , κ − 1 and are directly applied
to the plant.

Correspondingly, we have the following optimal control problem in lieu of (5):

(28)

minimize

ηt,Θt

subject to

(cid:2)(cid:104)xt:N +1,Qxt:N +1(cid:105) + (cid:104)ua

t:N(cid:105)(cid:3)

t:N ,Rua

Ext



constraint (4),
control (27),
ut ∈ U for all t,
stability constraints.

Remark 6. We can observe that (27) is in the form of (20), hence the underlying opti-
mization program for (P3) can be easily obtained from that of (P2).

Remark 7. The bit rate in transmission protocol (P3) can be reduced by storing the
successfully transmitted values of saturated feedback terms in buﬀer. A more interesting
transmission protocol can be found by repetitively transmitting the future blocks of the
oﬀset parameter and past blocks of e(wt:N−1) until the ﬁrst successful transmission. The
successfully transmitted blocks of the oﬀset parameter and e(wt:N−1) are stored in a buﬀer
near the actuator. The corresponding blocks of the gain matrix are transmitted at each
instant along with only those blocks of e(wt:N−1) which are absent in the buﬀer but are
required to compute the control according to (7).

We have the following theorem:

Theorem 3. Consider the system (1) and suppose that Assumption 1 holds under the
transmission protocol (P3). Then:

(i) For every t = 0, κ, 2κ, . . ., the optimization problem (21) is convex, feasible, and can

be rewritten as the following tractable program with tightened constraints:

minimize

ηt,Θt

ct + 2 tr(Θ

(cid:62)
t µ

(cid:48)
e) + 2x

S B(cid:62)QDΣ
(cid:62)
(cid:62)
t ΣS ΘtΣe)

(cid:62)
t ΣGηt) + tr(Θ

+ tr(η

t A(cid:62)QBµGηt
(cid:62)

where Σe := E[e(wt:N−1)e(wt:N−1)(cid:62)], Σ(cid:48)
E[G], ΣG = E[G(cid:62)(B(cid:62)QB + R)G], µS = E[S],ΣS = E[S(cid:62)(B(cid:62)QB + R)S] and ct :=
t A(cid:62)QAxt + tr(D(cid:62)QDΣW ).
x(cid:62)
subject to :

e := E[wt:N e(wt:N−1)(cid:62)], ΣW := E[wt:N w(cid:62)

t:N ], µG =

(cid:12)(cid:12)(cid:12)η(i)

t

(cid:12)(cid:12)(cid:12) +

(cid:13)(cid:13)(cid:13)Θ(i)

t

(cid:13)(cid:13)(cid:13)1

Θt having the structure in (9)

ϕmax (cid:54) Umax

for all i = 1,··· , N m,

(29)

(30)

(31)

STABLE STOCHASTIC PREDICTIVE CONTROL UNDER CONTROL CHANNEL ERASURES

11

for given  > 0 and for every j = 1,··· , do,

(cid:16)
(cid:16)

(cid:17)(j) (cid:54) −ζ
(cid:17)(j) (cid:62) ζ

(Aκ
o )

(cid:62)

Rκ(Ao, Bo)(ηt)1:κm

whenever (xo

t )(j) (cid:62) r + ,

(cid:62)

(Aκ
o )

Rκ(Ao, Bo)(ηt)1:κm

whenever (xo

t )(j) (cid:54) −r − .

(32)

(33)

(ii) For any initial condition x ∈ Rd successive application of the control law given by the
optimization problem in (i) for κ steps renders the closed loop system mean square
bounded.

Remark 8. Our results for mean zero stochastic noise can be easily extended to non-zero
mean noise by following the approach presented in [35].

Remark 9. The transmitted data under three transmission protocols for the considered
example with N = 3 and κ = 2 is illustrated in Fig. 5. The block transmitted through
sequential transmission (P1) is directly applied to the plant. But, in case of burst trans-
mission (P2), the transmitted oﬀset parameters are stored in a buﬀer. However, at ﬁrst
instant ηt is applied to the plant. For the second instant the saturated value of calculated
disturbance (e1(wt)) multiplied with gain parameter θ1,t of the decision variable is trans-
mitted which is added with ηt+1 before its application to the plant. In the case of (P3), ηt
and ηt+1 are transmitted at time t because buﬀer is empty and ηt is applied to the plant.
If the transmitted data is dropped at time t, we need to transmit future values of oﬀset
parameter at time t + 1 along with the control ut+1. But in this example κ = 2, so only
the control ut+1 is transmitted and is applied to the plant if successfully received at the
actuator.

t+1

t

ηt+1 + θ1,te1(wt)

θ1,te1(wt)

ηt+1 + θ1,te1(wt)

ηt

(P1)

ηt, ηt+1

ηt, ηt+1

(P2)

(P3)

Figure 5. The transmitted blocks for N = 3 and κ = 2, with given
optimization instant t = 0, κ, 2κ,···

4. Simulations

In this section we present simulations to illustrate our results. Consider the three

where noise sequence wt is i.i.d. Gaussian of mean zero with variance 2I3 and the initial
. The eigen values of A are ±i and −1. So, the eigen
spectrum of A is simple. The channel from the controller to the actuator is assumed to
be of erasure type. We consider the i.i.d. channel noise in §4.1 and the correlated channel
noise in §4.2 .

We solved a constrained ﬁnite-horizon optimal control problem corresponding to states

 12

−0.1 −0.4
−0.1
−0.2
19
−0.4 −0.2
2

 , R = 2. We selected an opti-

and control weights Q = I3, Qf =

mization horizon, N = 4, control horizon NC = κ = 3 and simulated the system responses.

dimensional linear stochastic system

 0
10 −10(cid:1)(cid:62)
condition is x =(cid:0)10

0.80 −0.36
0.60

−0.80 −0.60
0.48
0.48 −0.64

xt+1 =

 xt +

0.16
 ut + wt,

0.12
0.14

|ut| (cid:54) 15,

12

P. K. MISHRA, D. CHATTERJEE, AND D. E. QUEVEDO

s
e
t
a
t
s

f
o
m
r
o
n

35

30

25

20

15

10

5

0

0

(P1)
(P2)
(P3)
PPC [22]

20

40

60

80

100

120

140

160

180

200

time steps

Figure 6. Average norm of states: channel noise is i.i.d.

We selected the nonlinear bounded term e(wt:N−1) in our policy to be a vector of scalar
sigmoidal functions ϕ(ξ) = 1−e−ξ
1+e−ξ applied to each coordinate of noise vector. The covari-
ance matrices Σe, ΣW and Σe(cid:48) that are required to solve the optimization problem were
computed empirically via classical Monte Carlo methods [38] using 106 i.i.d. samples.
Computations for determining our policy are carried out in the MATLAB-based software
package YALMIP [39] and are solved using SDPT3-4.0 [40].
In plots for SMPC the decision variables ηt and Θt are computed at time t = 0, κ, 2κ,··· ,
by solving optimization problem according to Theorems 1, 2 and 3, respectively. The sta-
bility constraints (11) and (12) are satisﬁed by putting r = ζ = 0.4729 and  = 0.02. The
control bound Umax = 15 is satisﬁed by all three protocols. All the averages are taken
over 300 sample paths.

4.1. i.i.d. channel noise. The channel noise is considered to be i.i.d. with successful
transmission probability 0.8.

We compare among SMPC (P1), (P2), (P3) and PPC [22]. The plot of average norm
of states is presented in Fig. 6. The transmission protocol (P3) performs better than
rest. All three protocols of SMPC perform better than PPC. The average actuator energy
(u2
t ) and average cost are compared in Fig.7 and Fig.8, respectively. Average cost and
average actuator energy for (P1) and (P2) are comparable and less than those of PPC.
Transmission protocol (P3) employs more actuator energy than (P1), (P2) but less than
PPC. However, the average cost for (P3) is the lowest.

STABLE STOCHASTIC PREDICTIVE CONTROL UNDER CONTROL CHANNEL ERASURES

13

50

45

40

35

30

25

20

15

10

5

0

800

700

600

500

400

300

200

100

0

(P1)

(P2)

(P3)

PPC [22]

(P1)

(P2)

(P3)

PPC [22]

Figure
age actuator
channel noise is i.i.d.

7. Aver-
energy:

Figure
8. Average
cost per stage: channel
noise is i.i.d.

4.2. Correlated channel noise. We model the communication reliability via an under-
lying network state process (Ξt)t∈N taking on values in a ﬁnite set

B = {1, 2, . . . ,|B|},

where |B| is the cardinality of B. Each i ∈ B corresponds to a diﬀerent environmental
condition (such as network congestion or positions of mobile objects). For a given network
state the dropouts are modeled as i.i.d. with probabilities

pi = P{νt = 1| Ξt = i},

i ∈ B.

Correlations can be captured in this model by allowing (Ξt)t∈N to be time-homogeneous
Markovian with transition probabilities:

pij = P(cid:8)Ξt+1 = j(cid:12)(cid:12) Ξt = i(cid:9),

∀i, j ∈ B, t ∈ N.

(34)

(35)

Fig.9 illustrates a simpliﬁed version of the model adopted in [41]. The network state

p11

Ξt = 1

p1

”good”

p12

p21

p22

Ξt = 2

p2

”bad”

Figure 9. Transmission dropout model with a binary network state
(Ξt)t∈N: when Ξt = 1 the channel is reliable with very low dropout
probabilities; Ξt = 2 refers to a situation where the channel is unreliable
and transmissions are more likely to be dropped.

process encompasses Markovian dropouts and i.i.d. dropouts as special cases.

14

P. K. MISHRA, D. CHATTERJEE, AND D. E. QUEVEDO

s
e
t
a
t
s

f
o
m
r
o
n

22

20

18

16

14

12

10

8

6

4

2

0

(P1)
(P2)
(P3)
PPC [22]

0

20

40

60

80

100

120

140

160

180

200

time steps

Figure 10. Average norm of states: correlated channel noise

We considered the packet dropout model in Fig. 9: When the channel is in “good” state
successful transmission probability p1 = 0.8, whereas in the “bad” state that is p2 = 0.4.
The transition probability to switch from a bad channel state to the good state is taken
as p21 = 0.9; the failure rate is taken as p12 = 0.3.

The plot of average norm of states is presented in Fig. 10. The transmission protocol
(P3) performs better than rest. All three protocols of SMPC perform better than PPC.
The average actuator energy (u2
t ) and average cost are compared in Fig.11 and Fig.12,
respectively. Average cost and average actuator energy for (P1) and (P2) are comparable
and less than those of PPC. Transmission protocol (P3) employs more actuator energy
than (P1), (P2) but less than PPC. However, the average cost for (P3) is the lowest.

50

45

40

35

30

25

20

15

10

5

0

600

500

400

300

200

100

0

(P1)

(P2)

(P3)

PPC [22]

(P1)

(P2)

(P3)

PPC [22]

Figure 11. Av-
erage actuator en-
ergy:
correlated
channel noise

Figure 12. Av-
cost
erage
per
stage:
correlated
channel noise

STABLE STOCHASTIC PREDICTIVE CONTROL UNDER CONTROL CHANNEL ERASURES

15

5. Conclusion

This article presents convex and feasible optimal control problems for receding horizon
control of Lyapunov stable plants in the presence of stochastic noise and control channel
erasures. Three transmission protocols are suggested on the basis of the computation and
the storage facility available at the actuator end. The construction of the optimization
programs is systematic and it is useful for other protocols suggested in various remarks
sprinkled through the text as well. For all protocols presented in this article, mean square
boundedness of the closed-loop states and satisfaction of hard bound on control is guar-
anteed and veriﬁed by simulation results.

6. Appendix

This appendix provides the proofs of Theorem 1, Theorem 2 and Theorem 3. For
a real-valued random variable ξ on some probability space, we let ξ+ := max{0, ξ},
ξ− := max{0,−ξ} denote its positive and negative parts, respectively. Let us deﬁne
the component-wise saturation function Rdo (cid:51) z (cid:55)−→ sat∞
if |zi| (cid:54) r,
if zi > r, and
otherwise,

ziζ/r

(cid:0)sat
r,ζ(z)(cid:1)

r,ζ(z) ∈ Rdo to be

ζ
−ζ

∞

=

i

for each i = 1, . . . , do.

We need the following basic result:

Theorem 4 ([42, Theorem 2.1]). Let (Xt)t∈N be a family of real valued random variables
on a probability space (Ω, F, P), adapted to a ﬁltration (Ft)t∈N. Suppose that there exist
scalars J, M, a > 0 such that X0 < J, and

and

EFt [Xt+1 − Xt] (cid:54) −a whenever Xt > J,

E(cid:2)|Xt+1 − Xt|4 (cid:12)(cid:12) X0, . . . , Xt

Then there exists a constant C > 0 such that supt∈N E(cid:2)(Xt)2

(cid:3) (cid:54) M for all t ∈ N.
(cid:3) (cid:54) C.

+

Lemma 1. Consider the orthogonal part of the system (1) given by

xo
t+1 = Aoxo

t + Boua

(36)
as per the decomposition (10) above. Suppose the pair (Ao, Bo) is κ−step reachable. Let
Umax > 0 be given such that (cid:107)ut(cid:107)∞ (cid:54) Umax for all t. Then there exists a κ-history
dependent policy under the transmission protocol (P1) that renders the system (36) mean-
square bounded.

t + wt




 wκt

...

νκtuκt

...

νκ(t+1)−1uκ(t+1)−1



Proof. Consider the κ-subsampled system (36):

xo
κ(t+1) = Aκ

o xo

κt + Rκ(Ao, Bo)

+ Rκ(Ao, Ido )

(37)

wκ(t+1)−1

=: Aκ

o xo
κt + Rκ(Ao, Bo)ua
+ Rκ(Ao, Ido )wκt:κ.

κt:κ

Deﬁne yκt := (A(cid:62)

o )κtxo

(38)

κt for each t ∈ N. It follows that
(cid:62)
o )κ(t+1)Rκ(Ao, Bo)ua
yκ(t+1) = yκt + (A
(cid:62)
o )κ(t+1)Rκ(Ao, Ido )wκt:κ

+ (A

κt:κ

= yκt + ˜uκt + (A

(cid:62)
o )κ(t+1)Rκ(Ao, Ido )wκt:κ,

Let Fκt denote the σ-algebra generated by {xκ(cid:96) | (cid:96) = 0, 1, . . . , t}. From (38), we have

We claim that the sequence

uκt:κ = −Rκ(Ao, Bo)+Aκ(t+1)

o

(cid:62)
o )κtxo
κt

is feasible for the problem (15).

Let us verify the hypotheses of Theorem 4. For the i-th component y(i)

κt of yκt we see

that

and similarly

16

P. K. MISHRA, D. CHATTERJEE, AND D. E. QUEVEDO

where,

˜uκt = (A

(cid:62)
o )κ(t+1)Rκ(Ao, Bo)

EFκt(cid:2)yκ(t+1) − yκt

νκt+κ−1uκt+κ−1

νκt+1uκt+1

νκtuκt

...


(cid:3) = EFκt [˜uκt].
(cid:0)(A

sat

∞
r,ζ

 .

(cid:1).

κt

κt

κt > r,

κ(t+1) − y(i)

κ(t+1) − y(i)

EFκt(cid:2)y(i)
EFκt(cid:2)y(i)
(cid:104)(cid:12)(cid:12)(cid:12)y(i)
κ(t+1) − y(i)
(cid:104)(cid:16)(cid:0)y(i)
(cid:1)

(cid:3) = −pζ whenever y(i)
(cid:3) = pζ whenever y(i)
(cid:12)(cid:12)(cid:12)4 (cid:12)(cid:12)(cid:12) y(i)
(cid:17)2(cid:105) (cid:54) C (i)

(cid:105) (cid:54) M for all t.
(cid:104)(cid:16)(cid:0)y(i)

κt < −r.

κt , . . . , y(i)

(cid:1)

E

κt

0

A straightforward computation relying on uniform boundedness of the control shows that
there exists an M > 0 such that

+ , C (i)− > 0, i = 1, . . . , d, such

Ex

sup
t∈N

Theorem 4 now guarantees the existence of constants C (i)
that

(cid:17)2(cid:105) (cid:54) C (i)− .
Since |y| = y+ + y− = y+ + (−y)+ for any y ∈ R, and that (cid:107)y(cid:107)2 = (cid:80)do
(cid:0)(y(i)
+ )2 + (y(i)− )2(cid:1), we see at once that the preceding bounds imply
2(cid:80)do

(cid:2)(cid:107)yκt(cid:107)2(cid:3) < C for some constant C > 0.

sup
t∈N

and

Ex

i=1

−

κt

κt

+

+

i=1

Ex

sup
t∈N

(cid:12)(cid:12)(cid:12)y(i)(cid:12)(cid:12)(cid:12)2 (cid:54)

Since xo is derived from y by an orthogonal transformation, it immediately follows that

(cid:2)(cid:107)xo
κt(cid:107)2(cid:3) (cid:54) C.

Ex

sup
t∈N

t )t∈N.

A standard argument (e.g., as in [16]) now suﬃces to conclude from mean-square bound-
edness of the κ-subsampled process (xo
κt)t∈N the same property of the original process
(cid:3)
(xo
Lemma 2. Consider the system (1), for every t = 0, κ, 2κ,··· , the problem (5) under
policy (8), transmission protocol (P1) and control set (2) is convex quadratic with respect
to the decision variable (ηt, Θt). The objective function (5) is given by
t A(cid:62)QBµS ηt
(cid:62)

S B(cid:62)QDΣ
(cid:62)

(cid:48)
e) + 2x

minimize

2 tr(Θ

(39)

(ηt,Θt)

(cid:62)
t µ
(cid:62)

+ tr(η

(cid:62)
ΣS ηt) + tr(Θ
t ΣS ΘtΣe) + ct

e := E[wt:N e(wt:N−1)(cid:62)], ΣW := E[wt:N w(cid:62)

where Σe := E[e(wt:N−1)e(wt:N−1)(cid:62)], Σ(cid:48)
µS = E[S], ΣS = E[S(cid:62)(B(cid:62)QB + R)S] and ct := x(cid:62)
Proof. It is clear from the construction that Q is symmetric and non-negative deﬁnite
and R is symmetric and positive deﬁnite. Hence, x(cid:62)
t:N is convex
quadratic. Both xt:N +1 and ua
t:N are aﬃne function of the design parameters (ηt, Θt) for
any realization of noise wt:N . It directly follows that Vt is convex quadratic in (ηt, Θt).

t A(cid:62)QAxt + tr(D(cid:62)QDΣW ).

t:N +1Qxt:N +1 + ua

t:NRua

t:N ],

STABLE STOCHASTIC PREDICTIVE CONTROL UNDER CONTROL CHANNEL ERASURES

17

The control constraint set in (2) is convex aﬃne in (ηt, Θt). Hence the given problem (5)
is a convex quadratic program. The objective function of (5) is given by

Ext

= Ext

= Ext

= Ext

= x

t:N

+ w

(cid:105)

t:N )

+ (ua

+ (ua

t:N ,Rua

t:N + Dwt:N

(B(cid:62)QB + R)ua
t:N
t A(cid:62)QDwt:N
(cid:62)

t:N + x

t:N
(cid:62)
t:N )
t A(cid:62)QBua
(cid:62)

t:N(cid:105)(cid:3)
(cid:17)(cid:62)Q(cid:16)Axt + Bua

+ Dwt:N
(cid:62)Rua
t A(cid:62)QAxt + (ua
(cid:62)
x
(cid:62)

(cid:2)(cid:104)xt:N +1,Qxt:N +1(cid:105) + (cid:104)ua
(cid:104)(cid:16)Axt + Bua
(cid:17)
(cid:104)
t:ND(cid:62)QDwt:N + 2(cid:0)x
(cid:1)(cid:105)
(cid:2)x
(cid:2)(Sηt + SΘte(wt:N−1))
(cid:3)
(cid:2)2x
t A(cid:62)QB(Sηt + SΘte(wt:N−1))(cid:3) + Ext
(cid:2)(SΘte(wt:N−1))

(cid:62)B(cid:62)QDwt:N

(cid:62)B(cid:62)QDwt:N
t:N )
t A(cid:62)QAxt + w
(cid:62)

t:ND(cid:62)QDwt:N + 2x
t A(cid:62)QDwt:N
(cid:62)
(cid:62)
(cid:62)B(cid:62)QDwt:N

(cid:3)
(cid:2)(Sηt
(B(cid:62)QB + R)(Sηt + SΘte(wt:N−1))(cid:3)
(cid:2)S(cid:3)ηt + 0 + Ext
(B(cid:62)QB + R)(SΘte(wt:N−1))(cid:3) + 0

+ 2Ext
+ Ext
+ SΘte(wt:N−1))
t A(cid:62)QAxt + tr(D(cid:62)QDΣW ) + 2(0) + 0
(cid:62)
+ 2Ext
t A(cid:62)QBExt
(cid:62)
+ 2x
+ (SΘte(wt:N−1))
(cid:62)
t µSB(cid:62)QDΣ
(cid:62)E[S(cid:62)
t A(cid:62)QBµS ηt + tr(η
(cid:48)
(cid:62)
(cid:62)
e) + 2x
(B(cid:62)QB + R)S]ΘtΣe) + ct
+ R)S]ηt) + tr((Θ
t E[S(cid:62)
(cid:62)
S B(cid:62)QDΣ
t A(cid:62)QBµS ηt + tr(η
(cid:62)
(cid:48)
(cid:62)
(cid:62)
e) + 2x

(cid:3)
(cid:2)(Sηt)

(cid:62)
t µ

(cid:62)

(cid:62)

(cid:62)

(B(cid:62)QB + R)Sηt

(B(cid:62)QB

ΣS ηt)

= 2 tr(Θ

= ct + 2 tr(Θ

+ tr((Θ

(cid:62)
t ΣS ΘtΣe)

Lemma 3. Consider the orthogonal part of the system (1) as per the decomposition (10)
above given by (36). Let κ denote the reachability index of the pair (Ao, Bo). Let Umax > 0
be given such that (cid:107)ut(cid:107)∞ (cid:54) Umax for all t. Then there exists a κ-history dependent policy
under the transmission protocol (P2) that renders the system (36) mean-square bounded.

(cid:3)

Proof. Consider the κ-subsampled system (36):

xo
κ(t+1) = Aκ

o xo

κt + Rκ(Ao, Bo)

 νκt

 uκt
 wκt


...

...

uκ(t+1)−1

+ Rκ(Ao, Ido )

(40)

wκ(t+1)−1

=: Aκ

κt + Rκ(Ao, Bo)uκt:κνκt

o xo
+ Rκ(Ao, Ido )wκt:κ.

Deﬁne yκt := (A(cid:62)

o )κtxo

κt for each t ∈ N. It follows that

yκ(t+1) = yκt + (A
(cid:62)
o )κ(t+1)Rκ(Ao, Ido )wκt:κ.

+ (A

(cid:62)
o )κ(t+1)Rκ(Ao, Bo)(u)κt:κνκt

We put

uκt:κ = −Rκ(Ao, Bo)+Aκ(t+1)

o

∞
r,ζ

sat

(cid:0)(A

(cid:62)
o )κtxo
κt

(cid:1).

18

Then

P. K. MISHRA, D. CHATTERJEE, AND D. E. QUEVEDO

yκ(t+1) = yκt + (A

(cid:16)−Rκ(Ao, Bo)+Aκ(t+1)

o

o )k(t+1)Rκ(Ao, Bo)×
(cid:62)

(cid:0)(A

∞
r,ζ

sat

(cid:62)
o )κtxo
κt

(cid:1)(cid:17)

νκt+

+ (A

(cid:62)
o )κ(t+1)Rκ(Ao, Ido )wκt:κ.

Let us verify the hypotheses of Theorem 4. Let Fκt denote the σ-algebra generated by

{xκ(cid:96) | (cid:96) = 0, 1, . . . , t}. For the i-th component y(i)

κt of yκt we see that

where p = EFκt [νκt]. In other words, we have

and similarly

(cid:62)
o )κ(t+1)Rκ(Ao, Bo)(u)κt:κνκt

,

κt

κt

sat

(cid:3)

(cid:1)(i)(cid:105)

κ(t+1) − y(i)

κ(t+1) − y(i)

+ (A

EFκt(cid:2)y(i)
= EFκt(cid:104)(cid:0)(A
= pEFκt(cid:104)
EFκt(cid:2)y(i)
EFκt(cid:2)y(i)
(cid:104)(cid:12)(cid:12)(cid:12)y(i)
κ(t+1) − y(i)
(cid:104)(cid:16)(cid:0)y(i)
(cid:1)

∞
r,ζ

(cid:62)
o )κ(t+1)Rκ(Ao, Ido )wκt:κ

(cid:1)(cid:105)
(cid:0)y(i)
(cid:3) = −pζ whenever y(i)
(cid:3) = pζ whenever y(i)
(cid:12)(cid:12)(cid:12)4 (cid:12)(cid:12)(cid:12) y(i)
(cid:17)2(cid:105) (cid:54) C (i)

κ(t+1) − y(i)

E

κt

κt

κt > r,

κt < −r.

0

κt

κt , . . . , y(i)

(cid:105) (cid:54) M for all t.
(cid:17)2(cid:105) (cid:54) C (i)− .
(cid:104)(cid:16)(cid:0)y(i)
(cid:12)(cid:12)(cid:12)y(i)(cid:12)(cid:12)(cid:12)2 (cid:54) 2(cid:80)do
(cid:0)(y(i)
+ )2+(y(i)− )2(cid:1),
(cid:2)(cid:107)yκt(cid:107)2(cid:3) < C for some constant C > 0.

+ , C (i)− > 0, i = 1, . . . , do, such

sup
t∈N

(cid:1)

Ex

i=1

i=1

−

κt

+

+

Ex

sup
t∈N

(cid:2)(cid:107)xo
κt(cid:107)2(cid:3) (cid:54) C.

Ex

sup
t∈N

Theorem 4 now guarantees the existence of constants C (i)
that

Ex

sup
t∈N

Since |y| = y++y− for any y ∈ R, and that (cid:107)y(cid:107)2 =(cid:80)do

and

κt

we see at once that the preceding bounds imply

A straightforward computation relying on uniform boundedness of the control shows that
there exists an M > 0 such that

Since xo is derived from y by an orthogonal transformation, it immediately follows that

t )t∈N.

A standard argument (e.g., as in [16]) now suﬃces to conclude from mean-square bound-
edness of the κ-subsampled process (xo
κt)t∈N the same property of the original process
(cid:3)
(xo
Lemma 4. Consider the system (1), for every t = 0, κ, 2κ,··· , the problem (5) under
policy (8), transmission protocol (P2) and control set (2) is convex quadratic with respect
to the decision variable (ηt, Θt). The objective function (5) is given by
t A(cid:62)QBµKηt
(cid:62)

(cid:48)
e) + 2x

ct + 2 tr(Θ

minimize

(cid:62)
t µ

ηt,Θt

S B(cid:62)QDΣ
(cid:62)
(cid:62)
t ΣS ΘtΣe)

(cid:62)
t ΣKηt) + tr(Θ

+ tr(η

where Σe := E[e(wt:N−1)e(wt:N−1)(cid:62)], Σ(cid:48)
t:N ],
µK = E[K], ΣK = E[K(cid:62)(B(cid:62)QB + R)K], µS = E[S], ΣS = E[S(cid:62)(B(cid:62)QB + R)S] and
ct := x(cid:62)

e := E[wt:N e(wt:N−1)(cid:62)], ΣW := E[wt:N w(cid:62)

t A(cid:62)QAxt + tr(D(cid:62)QDΣW ).

STABLE STOCHASTIC PREDICTIVE CONTROL UNDER CONTROL CHANNEL ERASURES

19

Proof. By the same argument given in proof of Lemma 2 it follows that Vt is convex
quadratic in (ηt, Θt). The objective function of (5) is given by

Ext

= Ext

= Ext

t:N

+ w

(cid:105)

t:N )

+ (ua

+ (ua

t:N ,Rua

t:N + Dwt:N

(B(cid:62)QB + R)ua
t:N
t A(cid:62)QDwt:N
(cid:62)

t:N + x

t:N
(cid:62)
t:N )
t A(cid:62)QBua
(cid:62)

t:N(cid:105)(cid:3)
(cid:17)(cid:62)Q(cid:16)Axt + Bua

+ Dwt:N
(cid:62)Rua
t A(cid:62)QAxt + (ua
(cid:62)
x
(cid:62)

(cid:2)(cid:104)xt:N +1,Qxt:N +1(cid:105) + (cid:104)ua
(cid:104)(cid:16)Axt + Bua
(cid:17)
(cid:104)
t:ND(cid:62)QDwt:N + 2(cid:0)x
(cid:1)(cid:105)
(cid:2)x
(cid:2)(Kηt + (SΘte(wt:N−1))
(cid:3)
(cid:2)2x
t A(cid:62)QB(Kηt + SΘte(wt:N−1))(cid:3) + Ext
(cid:2)(SΘte(wt:N−1))

+ 2Ext
+ Ext
+ SΘte(wt:N−1))
t A(cid:62)QAxt + tr(D(cid:62)QDΣW ) + 2(0) + 0
(cid:62)
+ 2Ext
t A(cid:62)QBExt
(cid:62)
+ 2x
+ (SΘte(wt:N−1))

t:ND(cid:62)QDwt:N + 2x
(cid:62)

t A(cid:62)QDwt:N
(cid:62)
(cid:62)B(cid:62)QDwt:N

(cid:3)
(cid:2)(Kηt
(B(cid:62)QB + R)(Kηt + SΘte(wt:N−1))(cid:3)
(cid:2)K(cid:3)ηt + 0 + Ext
(B(cid:62)QB + R)(SΘte(wt:N−1))(cid:3) + 0

(cid:3)
(cid:62)B(cid:62)QDwt:N
t K(cid:62)
(cid:62)

(cid:62)B(cid:62)QDwt:N
t:N )
t A(cid:62)QAxt + w
(cid:62)

(cid:2)η

(cid:62)

(cid:62)

(cid:62)

(B(cid:62)QB + R)Kηt

= Ext

= x

= ct + 2 tr(Θ

(cid:62)
t µ

S B(cid:62)QDΣ
(cid:48)
(cid:62)
e) + 2x

t A(cid:62)QBµKηt + tr(η
(cid:62)

+ tr(Θ

(cid:62)
t ΣS ΘtΣe)

(cid:62)
t ΣKηt)

(cid:3)

Proof of Theorem 1. Proof of claim (i): The proof of convexity and the formulation of
the objective are given in Lemma 2. The constraints (16) can be found in [28] and the
constraints (18) and (19) are obviously convex. The proposed control input (8) satisﬁes
hard input constraint (2) as long as the following condition is satisﬁed:

(cid:107)ηt + Θte(wt:N−1)(cid:107)∞ (cid:54) Umax

for all e(wt:N−1) such that (cid:107)e(wt:N−1)(cid:107)∞ (cid:54) ϕmax. This is equivalent to the following
condition:

max
(cid:107)e(wt:N−1)(cid:107)∞

(cid:54)ϕmax

t + Θ(i)

t e(wt:N−1)

for all i = 1,··· , N m. By Holder’s inequality, for every i = 1,··· , N m,

(cid:12)(cid:12)(cid:12)η(i)

(cid:12)(cid:12)(cid:12)η(i)

max
(cid:107)e(wt:N−1)(cid:107)∞

(cid:54)ϕmax

t + Θ(i)

t e(wt:N−1)

ϕmax

(cid:12)(cid:12)(cid:12) (cid:54) Umax
(cid:12)(cid:12)(cid:12) +
(cid:12)(cid:12)(cid:12)η(i)
(cid:13)(cid:13)(cid:13)Θ(i)

t

t

(cid:13)(cid:13)(cid:13)1

(cid:12)(cid:12)(cid:12) =

(cid:54) Umax.

(cid:1)

∞
r,ζ

(cid:0)(A
(cid:17)(j)(cid:21)

Hence, the constraint (17) is equivalent to hard control constraint (2). Now, it remains
to show that the constraints (18) and (19) are both feasible and that they imply that the
drift conditions (11) and (12) are satisﬁed. Consider the sequence of control input vectors

˜ut:κ = −Rκ(Ao, Bo)+Aκ(t+1)

o

sat

(cid:62)
o )κtxo
t

. Substituting the input above into the left hand side of

(41)

for ζ ∈ (cid:105)

√

0,

Umax

doσ1(Rκ(Ao,Bo)+)

(11), we get

Exo

(cid:104)
(cid:20)(cid:16)

(Aκ
o )

(cid:62)

Rκ(Ao, Bo)ut:κ

(cid:54) −ζ,

t )(j) (cid:62) r + . Similarly, the control sequence (41) satisﬁes (12) whenever
t )(j) (cid:54) −r − . Moreover, the controls are bounded by Umax by construction because

whenever (xo
(xo
for t ∈ N0 and (cid:96) ∈ {0, 1,··· , κ − 1},

(cid:107)˜ut+(cid:96)(cid:107) (cid:54) (cid:107)˜ut:κ(cid:107) (cid:54) σ1(Rκ(Ao, Bo)+)

√

doζ (cid:54) Umax.

20

P. K. MISHRA, D. CHATTERJEE, AND D. E. QUEVEDO

Therefore, we have shown that there exists a sequence of input vectors ˜ut:κ that is feasible
with respect to the input constraint set (2). Moreover, this policy is encompassed with
the genral policy structure (8), as we can set the design parameter to (˜η)1:κm = ˜ut:κ and
( ˜Θ)1:κm = 0.

Now, the sequence of the control inputs can be written in terms of decision variables

as

(42)

Combining (42) with the stability constraint (11), we obtain

ut:κ := (ηt)1:κm + (Θt)1:κme(wt:N−1).

(cid:16)

(cid:62)

(Aκ
o )

Rκ(Ao, Bo)(ηt)1:κm

(cid:17)(j) (cid:54) −ζ,

t )(j) (cid:62) r + . Accordingly, if the constraint (18) is satisﬁed then (11) is
whenever (xo
satisﬁed as well. Similarly, combining (42) with the stability constraint (12), we conclude
if the constraint (19) is satisﬁed then (12) is also satisﬁed. This completes the claim (i)
of Theorem 1.
Proof of claim (ii): It is shown in [28] that the Schur stable system, under bounded control
(cid:3)
inputs, is mean square bounded. Hence, claim (ii) is directly implied by Lemma 1.

Proof of Theorem 2. Claims (i) and (ii) follow immediately from Lemma 4 and 3, respec-
(cid:3)
tively, along the same lines of arguments as in the proof of Theorem 1.

Proof of Theorem 3. Claims (i) and (ii) follow immediately from Lemma 4 and 3, respec-
tively, with the same lines of arguments as in proof of Theorem 1. The only diﬀerence is
that the matrix K is replaced by G in the present case.
(cid:3)

References

[1] D. Q. Mayne, “Model predictive control: Recent developments and future promise,” Automatica,

vol. 50, no. 12, pp. 2967 – 2986, 2014.

[2] L. Gr¨une and J. Pannek, Nonlinear model predictive control. Springer, 2011.
[3] J. B. Rawlings and D. Q. Mayne, Model predictive control: theory and design. Nob Hill, Madison,

Wisconsin, 2009.

[4] A. Bemporad and M. Morari, “Control of systems integrating logic, dynamics, and constraints,”

Automatica, vol. 35, no. 3, pp. 407–427, 1999.

[5] J. Rossiter, B. Kouvaritakis, and M. Rice, “A numerically robust state-space approach to stable-

predictive control strategies,” Automatica, vol. 34, no. 1, pp. 65–73, 1998.

[6] E. C. Kerrigan and J. M. Maciejowski, “Feedback min-max model predictive control using a single
linear program: robust stability and the explicit solution,” International Journal of Robust and
Nonlinear Control, vol. 14, no. 4, pp. 395–413, 2004.

[7] E. Hartley and J. Maciejowski, “Initial tuning of predictive controllers by reverse engineering,” in

European Control Conference (ECC), 2009, Aug 2009, pp. 725–730.

[8] D. Marruedo, T. Alamo, and E. Camacho, “Input-to-state stable MPC for constrained discrete-
time nonlinear systems with bounded additive uncertainties,” in Proceedings of the 41st IEEE
Conference on Decision and Control, 2002., vol. 4, 2002.

[9] F. Bayer, B. Mathias, and F. Allgower, “Discrete-time Incremental ISS : A Framework for Robust

NMPC,” European Control Conference, pp. 2068–2073, 2013.

[10] S. V. Rakovic, E. C. Kerrigan, K. I. Kouramas, and D. Q. Mayne, “Invariant approximations of
the minimal robust positively invariant set,” IEEE Transactions on Automatic Control, vol. 50,
no. 3, pp. 406–410, 2005.

[11] S. V. Rakovic, B. Kouvaritakis, M. Cannon, C. Panos, and R. Findeisen, “Parameterized tube
model predictive control,” IEEE Transactions on Automatic Control, vol. 57, no. 11, pp. 2746–
2761, 2012.

[12] U. Maeder, F. Borrelli, and M. Morari, “Linear oﬀset-free model predictive control,” Automatica,

vol. 45, no. 10, pp. 2214–2222, 2009.

[13] D. E. Quevedo, G. C. Goodwin, and J. A. De Dona, “Finite constraint set receding horizon quadratic
control,” International journal of robust and nonlinear control, vol. 14, no. 4, pp. 355–377, 2004.
[14] D. Mayne, J. Rawlings, C. Rao, and P. Scokaert, “Constrained model predictive control: Stability

and optimality,” vol. 36, no. 6, pp. 789–814, 2000.

[15] S. S. Keerthi and E. G. Gilbert, “Optimal inﬁnite-horizon feedback laws for a general class of
constrained discrete-time systems: stability and moving-horizon approximations,” Journal of Op-
timization Theory and Applications, vol. 57, no. 2, pp. 265–293, 1988.

[16] D. Chatterjee, F. Ramponi, P. Hokayem, and J. Lygeros, “On mean square boundedness of stochas-
tic linear systems with bounded controls,” Systems & Control Letters, vol. 61, no. 2, pp. 375–380,
2012.

[17] D. Bernardini, M. Donkers, A. Bemporad, and W. Heemels, “A model predictive control approach
for stochastic networked control systems,” in 2nd IFAC Workshop on Estimation and Control of
Networked Systems, Annecy, France, vol. 3, 2010, pp. 7–12.

[18] J. Fischer, M. Dolgov, and U. D. Hanebeck, “On stability of sequence-based LQG control,” in 52nd

Annual Conference on Decision and Control (CDC), 2013.

IEEE, 2013, pp. 6627–6633.

STABLE STOCHASTIC PREDICTIVE CONTROL UNDER CONTROL CHANNEL ERASURES

21

[19] J. Fischer, A. Hekler, M. Dolgov, and U. D. Hanebeck, “Optimal Sequence-Based LQG Control
over TCP-like Networks Subject to Random Transmission Delays and Packet Losses,” Proceedings
of the 2013 American Control Conference (ACC 2013), pp. 1543–1549, 2013.

[20] A. Hekler, J. Fischer, and U. D. Hanebeck, “Control over Unreliable Networks Based on Control In-
put Densities,” Proceedings of the 15th International Conference on Information Fusion (Fusion
2012) (to appear), pp. 1277–1283, 2012.

[21] D. E. Quevedo and D. Neˇsi´c, “Input-to-state stability of packetized predictive control over unreliable
networks aﬀected by packet-dropouts,” IEEE Transactions on Automatic Control, vol. 56, no. 2,
pp. 370–375, 2011.

[22] ——, “Robust stability of packetized predictive control of nonlinear systems with disturbances and

Markovian packet losses,” Automatica, vol. 48, no. 8, pp. 1803–1811, 2012.

[23] P. R. Kumar and P. Varaiya, Stochastic systems: estimation, identiﬁcation and adaptive control.

Prentice-Hall, Inc., 1986.

[24] P. J. Goulart, E. C. Kerrigan, and J. M. MacIejowski, “Optimization over state feedback policies

for robust control with constraints,” Automatica, vol. 42, no. 4, pp. 523–533, 2006.

[25] P. Hokayem, D. Chatterjee, F. Ramponi, G. Chaloulos, and J. Lygeros, “Stable stochastic receding
horizon control of linear systems with bounded control inputs,” in Proceedings of 19th International
Symposium on Mathematical Theory of Networks and Systems, Budapest, Hungary, 2010, pp.
31–36.

[26] D. Chatterjee, S. Amin, P. Hokayem, J. Lygeros, and S. S. Sastry, “Mean-square boundedness of
stochastic networked control systems with bounded control inputs,” in 49th IEEE Conference on
Decision and Control (CDC), 2010.

IEEE, 2010, pp. 4759–4764.

[27] D. E. Quevedo, P. K. Mishra, R. Findeisen, and D. Chatterjee, “A stochastic model predictive
controller for systems with unreliable communications,” in 5th IFAC Conference on Nonlinear
Model Predictive Control, 2015.

IFAC, 2015, in press.

[28] D. Chatterjee, P. Hokayem, and J. Lygeros, “Stochastic receding horizon control with bounded
control inputs—a vector-space approach,” IEEE Transactions on Automatic Control, vol. 56,
no. 11, pp. 2704–2711, 2011.

[29] D. E. Quevedo, G. C. Goodwin, and J. S. Welsh, “Minimizing down-link traﬃc in networked control
systems via optimal control techniques,” in 42nd IEEE Conference on Decision and Control,
2003., vol. 2.

IEEE, 2003, pp. 1200–1205.

[30] K. Aboudolas, M. Papageorgiou, A. Kouvelas, and E. Kosmatopoulos, “A rolling-horizon quadratic-
programming approach to the signal control problem in large-scale congested urban road networks,”
Transportation Research Part C: Emerging Technologies, vol. 18, no. 5, pp. 680–694, 2010.

[31] C. E. Garcia, D. M. Prett, and M. Morari, “Model predictive control: theory and practice – a

survey,” Automatica, vol. 25, no. 3, pp. 335–348, 1989.

[32] J. Lofberg, “Approximations of closed-loop minimax MPC,” in 42nd IEEE International Confer-

ence on Decision and Control (IEEE Cat. No.03CH37475), vol. 2, 2003, pp. 1438–1442.

[33] E. Cinquemani, M. Agarwal, D. Chatterjee, and J. Lygeros, “Convexity and convex approximations
of discrete-time stochastic control problems with constraints,” Automatica, vol. 47, no. 9, pp. 2082–
2087, 2011.

[34] P. Hokayem, E. Cinquemani, D. Chatterjee, F. Ramponi, and J. Lygeros, “Stochastic receding
horizon control with output feedback and bounded controls,” Automatica, vol. 48, no. 1, pp. 77–
88, 2012.

[35] P. Hokayem, D. Chatterjee, and J. Lygeros, “On stochastic receding horizon control with bounded
control inputs,” Proceedings of the IEEE Conference on Decision and Control, pp. 6359–6364,
2009.

[36] D. Chatterjee and J. Lygeros, “On stability and performance of stochastic predictive control tech-

niques,” IEEE Transactions on Automatic Control, vol. 60, no. 2, pp. 509–514, Feb 2015.

[37] F. Ramponi, D. Chatterjee, A. Milias-Argeitis, P. Hokayem, and J. Lygeros, “Attaining mean square
boundedness of a marginally stable stochastic linear system with a bounded control input,” IEEE
Transactions on Automatic Control, vol. 55, no. 10, pp. 2414–2418, 2010.

[38] C. Robert and G. Casella, Monte Carlo statistical methods. Springer Science & Business Media,

2013.

[39] J. Lofberg, “Yalmip: A toolbox for modeling and optimization in matlab,” in International Sym-

posium on Computer Aided Control Systems Design, 2004.

IEEE, 2004, pp. 284–289.

[40] K.-C. Toh, M. J. Todd, and R. H. T¨ut¨unc¨u, “On the implementation and usage of sdpt3–a mat-
lab software package for semideﬁnite-quadratic-linear programming, version 4.0,” in Handbook on
semideﬁnite, conic and polynomial optimization. Springer, 2012, pp. 715–754.

[41] D. E. Quevedo, A. Ahlen, and K. H. Johansson, “State estimation over sensor networks with
correlated wireless fading channels,” IEEE Transactions on Automatic Control, vol. 58, no. 3, pp.
581–593, 2013.

[42] R. Pemantle and J. S. Rosenthal, “Moment conditions for a sequence with negative drift to be
uniformly bounded in Lr,” Stochastic Processes and their Applications, vol. 82, no. 1, pp. 143–
155, 1999.

