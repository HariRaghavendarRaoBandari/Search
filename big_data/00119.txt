From Duels to Battleﬁelds: Computing Equilibria of Blotto and

Other Games∗

Mahdi Ahmadinejad1, Sina Dehghani2, MohammadTaghi Hajiaghayi2, Brendan Lucier3,

Hamid Mahini2, and Saeed Seddighin2

1Department of Management Science and Engineering, Stanford University

2Department of Computer Science, Univeristy of Maryland

amirmahdi.ahmadi@gmail.com

dehghani,hajiagha,hmahini,sseddigh@cs.umd.edu
3Microsoft Research
brlucier@microsoft.com

Abstract

We study the problem of computing Nash equilibria of zero-sum games. Many natural zero-
sum games have exponentially many strategies, but highly structured payoﬀs. For example, in
the well-studied Colonel Blotto game (introduced by Borel in 1921), players must divide a pool
of troops among a set of battleﬁelds with the goal of winning (i.e., having more troops in) a
majority. The Colonel Blotto game is commonly used for analyzing a wide range of applications
from the U.S presidential election, to innovative technology competitions, to advertisement, to
sports. However, because of the size of the strategy space, standard methods for computing
equilibria of zero-sum games fail to be computationally feasible. Indeed, despite its importance,
only a few solutions for special variants of the problem are known.

In this paper we show how to compute equilibria of Colonel Blotto games.
Moreover, our approach takes the form of a general reduction: to ﬁnd a Nash equilibrium
of a zero-sum game, it suﬃces to design a separation oracle for the strategy polytope of any
bilinear game that is payoﬀ-equivalent. We then apply this technique to obtain the ﬁrst polytime
algorithms for a variety of games. In addition to Colonel Blotto, we also show how to compute
equilibria in an inﬁnite-strategy variant called the General Lotto game; this involves showing how
to prune the strategy space to a ﬁnite subset before applying our reduction. We also consider the
class of dueling games, ﬁrst introduced by Immorlica et al. (2011). We show that our approach
provably extends the class of dueling games for which equilibria can be computed: we introduce
a new dueling game, the matching duel, on which prior methods fail to be computationally
feasible but upon which our reduction can be applied.

6
1
0
2

 
r
a

M
3

 

 
 
]
T
G
.
s
c
[
 
 

2
v
9
1
1
0
0

.

3
0
6
1
:
v
i
X
r
a

∗Supported in part by NSF CAREER award 1053605, NSF grant CCF-1161626, ONR YIP award N000141110662,

DARPA GRAPHS/AFOSR grant FA9550-12-1-0423, and a Google faculty research award.

1

Introduction

Computing a Nash equilibrium of a given game is a central problem in algorithmic game theory. It
is known that every ﬁnite game admits a Nash equilibrium (that is, a proﬁle of strategies from which
no player can beneﬁt from a unilateral deviation) [37]. But it is not necessarily obvious how to
ﬁnd an equilibrium. Indeed, the conclusions to date have been largely negative: computing a Nash
equilibrium of a normal-form game is known to be PPAD-complete [15, 20], even for two-player
nO(1) approximation to a Nash equilibrium [12].
games [11]. In fact, it is PPAD-complete to ﬁnd an
These results call into question the predictiveness of Nash equilibrium as a solution concept.

1

This motivates the study of classes of games for which equilibria can be computed eﬃciently.
It has been found that many natural and important classes of games have structure that can be
exploited to admit computational results [14, 19, 28, 34]. Perhaps the most well-known example is
the class of zero-sum two-player games1, where player 2’s payoﬀ is the negation of player 1’s payoﬀ.
The normal-form representation of a zero-sum game is a matrix A, which speciﬁes the game payoﬀs
for player 1. This is a very natural class of games, as it models perfect competition between two
parties. Given the payoﬀ matrix for a zero-sum game as input, a Nash equilibrium can be computed
in polynomial time, and hence time polynomial in the number of pure strategies available to each
player [14]. Yet even for zero-sum games, this algorithimic result is often unsatisfactory. The issue
is that for many games the most natural representation is more succinct than simply listing a payoﬀ
matrix, so that the number of strategies is actually exponential in the most natural input size. In
this case the algorithm described above fails to guarantee eﬃcient computation of equilibria, and
alternative approaches are required.

The Colonel Blotto Game A classical and important example illustrating these issues is the
Colonel Blotto game, ﬁrst introduced by Borel in 1921 [7, 8, 17, 18, 46]. In the Colonel Blotto game,
two colonels each have a pool of troops and must ﬁght against each other over a set of battleﬁelds.
The colonels simultaneously divide their troops between the battleﬁelds. A colonel wins a battleﬁeld
if the number of his troops dominates the number of troops of his opponent. The ﬁnal payoﬀ of
each colonel is the (weighted) number of battleﬁelds won. An equilibrium of the game is a pair of
colonels’ strategies, which is a (potentially randomized) distribution of troops across battleﬁelds,
such that no colonel has incentive to change his strategy. Although the Colonel Blotto game was
initially proposed to study a war situation, it has found applications in the analysis of many diﬀerent
forms of competition: from sports, to advertisement, to politics [36, 32, 35, 13, 29, 30], and has
thus become one of the most well-known games in classic game theory.

Colonel Blotto is a zero-sum game. However, the number of strategies in the Colonel Blotto

game is exponential in its natural representation. After all, there are (cid:0)n+k−1

n troops among k battleﬁelds. The classical methods for computing the equilibra of a zero-sum
game therefore do not yield computationally eﬃcient results. Moreover, signiﬁcant eﬀort has been
made in the economics literature to understand the structure of equilibria of the Colonel Blotto
game, i.e., by solving for equilibrium explicitly [45, 5, 6, 4, 43, 47, 40, 31, 24, 21, 30]. Despite
this eﬀort, progress remains sparse. Much of the existing work considers a continuous relaxation
of the problem where troops are divisible, and for this relaxation a signiﬁcant breakthrough came
only quite recently in the seminal work of Roberson [40], 85 years after the introduction of the
game. Roberson ﬁnds an equilibrium solution for the continuous version of the game, in the special
case that all battleﬁelds have the same weight. The more general weighted version of the problem
remains open, as does the original non-relaxed version with discrete strategies. Given the apparent

k−1 (cid:1) ways to partition

1Or, equivalently, constant-sum games.

1

diﬃculty of solving for equilibrium explicitly, it is natural to revisit the equilibrium computation
problem for Colonel Blotto games.

An Approach: Bilinear Games How should one approach equilibrium computation in such a
game? The exponential size of the strategy set is not an impassable barrier; in certain cases, games
with exponentially many strategies have an underlying structure that can be used to approach the
equilibrium computation problem. For example, Koller, Megiddo and von Stengel [27] show how
to compute equilibria for zero-sum extensive-form games with perfect recall. Immorlica et al. [25]
give an approach for solving algorithmically-motivated “dueling games” with uncertainty. Letchford
and Conitzer [33] compute equilibria for a variety of graphical security games. Each of these cases
involve games with exponentially many strategies. In each case, a similar approach is employed:
reformulating the original game as a payoﬀ-equivalent bilinear game. In a bilinear game, the space
of strategies forms a polytope in Rn, and payoﬀs are speciﬁed by a matrix M : if the players play
strategies x and y respectively, then the payoﬀ to player 1 is xT M y. It has been observed that
such bilinear games can be solved eﬃciently when the strategy polytope has polynomially many
constraints [10, 27]. In each of the examples described above, it is shown how to map strategies
from the original games to appropriate payoﬀ-equivalent bilinear games, in which strategies are
choices of marginal probabilities from the original game.
If one can also map a strategy in the
bilinear game back to the original game, then one has a polytime reduction to the (solved) problem
of ﬁnding equilibria of the bilinear game. In each of these prior works it is this latter step – mapping
back to the original game – that is the most demanding; this generally requires a problem-speciﬁc
way to convert a proﬁle of marginals into a corresponding mixed strategy in the original game.

1.1 Our Contribution

We ﬁrst show how to compute equilibria of the Colonel Blotto game. Like the works described above,
our method is to consider a payoﬀ-equivalent bilinear game deﬁned over a space of appropriately-
selected marginals (in this case, the distribution of soldiers to a given battleﬁeld). However, unlike
those works, we do not explicitly construct a game-speciﬁc mapping to and from a polynomially-
sized bilinear game. We instead use a more general reduction, based on the idea that it suﬃces to
solve linear optimization queries over strategy proﬁles in a (potentially exponentially-sized) bilinear
game. In other words, equilibrium computation reduces to the problem of ﬁnding a strategy that
optimizes a given linear function over its marginal components. We apply our reduction to the
Colonel Blotto game by showing how to solve these requisite optimization queries, which can be
done via dynamic programming.

The reduction described above follows from a repeated application of the classic equivalence of
separation and optimization [22]. In more detail, we formulate the equilibrium conditions as an LP
whose feasibility region is the intersection of two polytopes: the ﬁrst corresponding to the set of
strategies of player 1, and the second encoding payoﬀ constraints for player 2. To ﬁnd a solution of
the LP via Ellipsoid method, it suﬃces to design a separation oracle for each polytope. However,
as we show, separation oracles for the second polytope reduce to (and from) separation oracles for
the set of strategies of player 2. It therefore suﬃces to design separation oracles for the polytope
of strategies for each player, and for this it is enough to perform linear optimization over those
polytopes [22]. Finally, to convert back to an equilibrium of the original game, we make use of a
result from combinatorial optimization: the solution of an LP with polynomially many variables
can always be expressed as a mixed strategy with a polynomial-size support, and such a mixed
strategy can be computed using the separation oracles described previously [22].
The reduction described above is not speciﬁc to the Colonel Blotto game:

it applies to any

2

zero-sum game, and any payoﬀ-equivalent bilinear form thereof. To the best of our knowledge,
this general reduction from equilibrium computation to linear optimization has not previously been
stated explicitly, although it has been alluded to in the security games literature2 and similar ideas
have been used to compute correlated equilibria in compact games [26]. In particular, it is notable
that one requires only a single linear optimization oracle, over the set of pure strategies, to both ﬁnd
an equilibrium of the bilinear game and convert this to a mixed equilibrium in the original game.
We demonstrate the generality of this approach by considering notable examples of games to which
it can be applied. In each case, our approach either results in the ﬁrst known polytime algorithm
for computing equilibria, or else signiﬁcantly simpliﬁes prior analysis. Finally, we note that our
approach also extends to approximations: given the ability to approximately answer separation
oracle queries to within any ﬁxed error ǫ > 0, one can compute a corresponding approximation to
the equilibrium payoﬀs.

In a dueling game, introduced by Immorlica et al. [25], two competitors each
Dueling Games
try to design an algorithm for an optimization problem with an element of uncertainty, and each
player’s payoﬀ is the probability of obtaining a better solution. This framework falls within a
natural class of ranking or social context games [1, 9], in which players separately play a base game
and then receive ultimate payoﬀs determined by both their own outcomes and the outcomes of
others. Immorlica et al. argue that this class of games models a variety of scenarios of competitions
between algorithm designers: for example, competition between search engines (who must choose
how to rank search results), or competition between hiring managers (who must choose from a pool
of candidates in the style of the secretary problem).

Immorlica et al. [25] show how to compute a Nash equilibrium for certain dueling games, by
developing mappings to and from bilinear games with compact representations. We extend their
method, and show how to expand the class of dueling games for which equilibria can be eﬃciently
computed. As one particular example, we introduce and solve the matching duel. In this game,
two players each select a matching in a weighted graph, and each player’s payoﬀ is the probability
that a randomly selected node would have a higher-weight match in that player’s matching than
in the opponent’s. Notably, since the matching polytope does not have a compact representation
[41], the original method of [25] is not suﬃcient to ﬁnd equilibria of this game. We also illustrate
that our approach admits a signiﬁcantly simpliﬁed analysis for some other dueling games previously
analyzed by Immorlica et al.

General Lotto Game Hart [24] considers a variant of the Colonel Blotto game, namely the
General Lotto game. In this game, each player chooses a distribution over non-negative real num-
bers, subject to the constraint that its expectation must equal a certain ﬁxed value. A value is
then drawn from each player’s chosen distribution; the players’ payoﬀs are then functions of these
values. What is interesting about this game is that there are inﬁnitely many pure strategies, which
complicates equilibrium computation. Nevertheless, we show that our techniques can be applied
to this class of games as well, yielding a polynomial-time algorithm for computing Nash equilibria.
It is worth mentioning that the General Lotto game is an important problem by itself, and its
continuous variant has been well studied in the literature (see, for example, [3, 42, 24, 16]).

2Independently and in parallel with an earlier version of this work, Xu et al. [48] implicitly used a similar idea to

solve a class of Stackleberg security games.

3

2 Results and Techniques

We present a general method for computing Nash equilibria of a broad class of zero-sum games.
Our approach is to reduce the problem of computing equilibria of a given game to the problem of
optimizing linear functions over the space of strategies in a payoﬀ-equivalent bilinear game.

Before presenting our general reduction, we will ﬁrst illustrate our techniques by considering
the Colonel Blotto game as a speciﬁc example. In Section 2.1 we describe our approach in detail
for the Colonel Blotto game, explaining the process by which equilibria can be computed. Then
in Section 2.2 we will present the general reduction. Further applications of this technique are
provided in Section 3 (for dueling games) and Appendix B (for the General Lotto game).

2.1 Colonel Blotto

Here, we propose a polynomial-time algorithm for ﬁnding an equilibrium of discrete Colonel Blotto
in its general form. We allow the game to be asymmetric across both the battleﬁelds and the players.
A game is asymmetric across the battleﬁelds when diﬀerent battleﬁelds have diﬀerent contributions
to the outcome of the game, and a game is asymmetric across the players when two players have
diﬀerent number of troops.

i (xi, yi) and uB

i=1 yi = b. Let uA

where Pk
Pk

In the Colonel Blotto game, two players A and B simultaneously distribute a and b troops,
respectively, over k battleﬁelds. A pure strategy of player A is a k-partition x = hx1, x2, . . . , xki
i=1 xi = a, and a pure strategy of player B is a k-partition y = hy1, y2, . . . , yki where
i (xi, yi) be the payoﬀ of player A and player B from the i-th
battleﬁeld, respectively. Note that the payoﬀ functions of the i-th battleﬁeld, uA
i , have
(a + 1) × (b + 1) entries. This means the size of input is Θ(kab). Since Colonel Blotto is a zero-sum
i (xi, yi)3. Note that we do not need to put any constraint on the
game, we have uA
payoﬀ functions, and our result works for all payoﬀ functions. We also represent the total payoﬀ
of player A and player B by hA
i (xi, yi), respectively. A
mixed strategy of each player would be a probability distribution over his pure strategies.

i (xi, yi) = −uB

i and uB

B (x, y) =Pi uA

i (xi, yi) and hB

B (x, y) =Pi uB

Theorem 1 One can compute an equilibrium of any Colonel Blotto game in polynomial time.

Proof: Let X and Y be the set of all pure strategies of players A and B respectively, i.e., each
member of X is a k-partition of a troops and each member of Y is a k-partition of b troops. We

represent a mixed strategy of player A with function p : X → [0, 1] such that Px∈X p(x) = 1.

Similarly, let function q : Y → [0, 1] be a mixed strategy of player B. We may also use x and y,
instead of p and q, for referring to a mixed strategy of player A and B respectively. Since Colonel
Blotto is a zero-sum game, we leverage the MinMax theorem for ﬁnding an NE of the game. This
theorem says that pair (p∗, q∗) is an NE of the Colonel Blotto game if and only if strategies p∗ and
q∗ maximize the guaranteed payoﬀ of players A and B respectively [44]. Now, we are going to ﬁnd
strategy p∗ of player A which maximizes his guaranteed payoﬀ. The same technique can be used for
ﬁnding q∗. It is known that for each mixed strategy p, at least one of the best-response strategies
to p is a pure strategy. Therefore, a solution to the following program characterizes strategy p∗.

max

s.t.

U

(1)

3Note that in the Colonel Blotto game if uA

i (xi, yi) then a special case of this
game with two battleﬁelds can model an arbitrary 2-person normal-form game and thus ﬁnding a Nash Equilibrium
would be PPAD-complete.

i (xi, yi) is not necessarily equal to −uB

Px∈X px = 1,

Px∈X pxhA

B (x, y) ≥ U, ∀y ∈ Y,

4

Unfortunately, LP 1 has |X | variables and |Y| + 1 constraints where |X | and |Y| + 1 are exponential.
We therefore cannot solve LP 1 directly.
Step 1: Transferring to a new space. We address this issue by transforming the solution space to a
new space in which an LP equivalent to LP 1 becomes tractable (See, e.g., [2], for similar technique).
This new space will project mixed strategies onto the marginal probabilities for each (battleﬁeld,
troop count) pair. For each pure strategy x ∈ X of player A, we map it to a point in {0, 1}n(A)
where n(A) = k × (a + 1). For convenience, we may abuse the notation, and index each point
ˆx ∈ {0, 1}n(A) by two indices i and j such that ˆxi,j represents ˆx(i−1)(a+1)+j+1. Now we map a pure
strategy x to GA(x) = ˆx ∈ {0, 1}n(A) such that ˆxi,j = 1 if and only if xi = j. In other words, if player
A puts j troops in the i-th battleﬁeld then ˆxi,j = 1. Let IA = {ˆx ∈ {0, 1}n(A)|∃x ∈ X , GA(x) = ˆx}
be the set of points in {0, 1}n(A) which represent pure strategies of player A. Let M(X ) and M(Y)
be the set of mixed strategies of players A and B respectively. Similarly, we map mixed strategy
x to point GA(x) = ˆx ∈ [0, 1]n(A) such that ˆxi,j represents the probability that mixed strategy
x puts j troops in the i-th battleﬁeld. Note that mapping GA is not necessarily one-to-one nor
onto, i.e., each point in [0, 1]n(A) may be mapped to zero, one, or more than one strategies. Let
SA = {ˆx ∈ [0, 1]n(A)|∃x ∈ M(X ), GA(x) = ˆx} be the set of points in [0, 1]n(A) which represent at
least one mixed strategy of player A. Similarly, we use function GB to map each strategy of player B
to a point in [0, 1]n(B) where n(B) = k×(b+1), and deﬁne IB = {ˆy ∈ {0, 1}n(B)|∃y ∈ Y, GB(y) = ˆy}
and SB = {ˆy ∈ [0, 1]n(B)|∃y ∈ M(Y), GB(y) = ˆy}.

Lemma 1 Set SA forms a convex polyhedron with an exponential number of vertices and facets.

Now, we are ready to rewrite linear program 1 in the new space as follows.

max

s.t.

U

ˆx ∈ SA

(Membership constraint)

hA
B (ˆx, ˆy) ≥ U,

∀ˆy ∈ IB (Payoﬀ constraints)

(2)

where

hA
B (ˆx, ˆy) =

k

a

b

Xi=1

Xta=0

Xtb=0

ˆxi,ta ˆyi,tbuA

i (ta, tb)

is the expected payoﬀ of player A.
Step 2: Solving LP 2. The modiﬁed LP above, LP 2, has exponentially many constraints, but
only polynomially many variables. One can therefore apply the Ellipsoid method to solve the LP,
given a separation oracle that runs in polynomial time [23, 39]. By the equivalence of separation
and optimization [22], one can implement such a separation oracle given the ability to optimize
linear functions over the polytopes SA (for the membership constraints) and SB (for the payoﬀ
constraints).

Stated more explicitly, given a sequence c0, c1, . . . , ck(m+1), where k is the number of battleﬁelds
and m is the number of troops for a player, the required oracle must ﬁnd a pure strategy x =

i=1 xi = m, and ˆx = G(x) minimizes the following equation:

(x1, x2, . . . , xk) ∈ X such that Pk

c0 +

k(m+1)

Xi=1

ci ˆxi,

(3)

and similarly for polytope Y. The following lemma shows that one can indeed ﬁnd a minimizer of
Equation (3) in polynomial time.

5

Lemma 2.1 Given two integers m and k and a sequence c0, c1, . . . , ck(m+1), one can ﬁnd (in poly-
i=1 xi = m, ˆx = G(x) and ˆx

nomial time) an optimal pure strategy x = (x1, x2, . . . , xk) where Pk
minimizes c0 +Pk(m+1)
value of c0 +Pi(t+1)
of c0 +Pk(m+1)

Proof: We employ a dynamic programming approach. Deﬁne d[i, t] to be the minimum possible
i′=1 xi′ = t. Hence, d[k, m] denotes the minimum possible value
ci ˆxi. We have that d[0, j] is equal to c0 for all j. For an arbitrary i > 0 and t, the
optimal strategy x puts 0 ≤ t′ ≤ t units in the i-th battleﬁeld and the applied cost in the equation
3 is equal to c(i−1)(m+1)+t′ +1. Thus, we can express d[i, t] as

i′=1 ci′ ˆxi′ where Pi

i=1

ci ˆxi.

i=1

d[i, t] = min
0≤t′≤t

{d[i − 1, t − t′] + c(i−1)(m+1)+t′ +1}.

Solving this dynamic program, we can ﬁnd the allocation of troops that minimizes P αiˆxi in

polynomial time, as required.
Step 3: Transferring to the original space. At last we should transfer the solution of LP 2 to
the original space. In particular, we are given a point ˆx ∈ SA and our goal is to ﬁnd a strategy
x ∈ M(X ) such that GA(x) = ˆx. To achieve this, we invoke a classic result of [22] which states that
an interior point of an n-dimensional polytope P can be decomposed as a convex combination of at
most n + 1 extreme points of P , in polynomial time, given an oracle that optimizes linear functions
over P . Note that this is precisely the oracle required for Step 2, above. Applying this result to
the solution of LP 2 in polytope SA, we obtain a convex decomposition of ˆx into extreme points of

SA, say ˆx = Pi αiˆxi. Since each ˆxi corresponds to a pure strategy in X , it is trivial to ﬁnd point
xi with GA(xi) = ˆxi, since the marginals of each ˆxi lie in {0, 1}. We then have that x =Pi αixi is

Combining these three steps, we ﬁnd a Nash Equilibrium of the Colonel Blotto game in poly-

the required mixed strategy proﬁle.

nomial time, completing the proof of Theorem 1. See Appendix A for more details.

2.2 A general framework for bilinear games

In our method for ﬁnding a Nash Equilibrium of the Colonel Blotto game, the main steps were
to express the game as a bilinear game of polynomial dimension, solve for an equilibrium of the
bilinear game, then express that point as an equilibrium of the original game. To implement the
ﬁnal two steps, it suﬃced to show how to optimize linear functions over the polytope of strategies in
the bilinear game. This suggests a general reduction, where the equilibrium computation problem
is reduced to ﬁnding the appropriate bilinear game and implementing the required optimization
algorithm. In other words, the method for computing Nash equilibria applies to a zero-sum game
when:

1. One can transfer each strategy x of player A to GA(x) = ˆx ∈ Rn(A), and each strategy y of
player B to GB(y) = ˆy ∈ Rn(B) such that the payoﬀ of the game for strategies ˆx and ˆy can
be represented in a bilinear form based on ˆx and ˆy, i.e., the payoﬀ is ˆxtM ˆy where M is a
n(A) × n(B) matrix.

2. For any given vector α and real number α0 we can ﬁnd, in polynomial time, whether there is

a pure strategy ˆx in the transferred space such that α0 +Pi αi ˆxi ≥ 0.

We refer to such a game as polynomially separable. A direct extension of the proof of Theorem 1
implies that Nash equilibria can be found for polynomially separable games.

6

Theorem 2 There is a polytime algorithm which ﬁnds a Nash Equilibrium of a given polynomially
separable game.

This general methodology can be used for ﬁnding a NE in many zero-sum games. In subsequent
sections, we show how our framework can be used to ﬁnd Nash equilibria for a generalization of
Blotto games, known as games, and for a class of dueling games introduced by Immorlica et al.
[25].

We also show one can use similar techniques to compute the approximate equilibrium payoﬀs
of a dueling game when we are not able to answer the separation problem in polynomial time but
instead we can polynomially solve the ǫ-separation problem for any ǫ > 0. The proof of Theorem
2 is deferred to Appendix E.

Theorem 3 Given an oracle function for the ǫ-separation problem, one can ﬁnd an ǫ-approximation
to the equilibrium payoﬀs of a polynomially separable game in polynomial time.

2.3 General Lotto

The General Lotto game is a relaxation of the Colonel Lotto game (See [24] for details). In this
game each player’s strategy is a distribution of a nonnegative integer-valued random variable with
a given expectation. In particular, players A and B simultaneously determine (two distributions
of) two nonnegative integer-valued random variables X and Y , respectively, such that E[X] = a
and E[Y ] = b. The payoﬀ of player A is

hA
Γ (X, Y ) =

∞

∞

Xi=0

Xj=0

Pr(X = i) Pr(Y = j)u(i, j),

(4)

and again the payoﬀ of player B is the negative of the payoﬀ of player A, i.e., hB
Γ (X, Y ) =
−hA
Γ (X, Y ). Hart [24] presents a solution for the General Lotto game when u(i, j) = sign(i − j).
Here, we generalize this result and present a polynomial-time algorithm for ﬁnding an equilibrium
when u is a bounded distance function. Function u is a bounded distance function, if one can write
it as u(i, j) = fu(i − j) such that fu is a monotone function and reaches its maximum value at
uM = fu(uT ) where uT ∈ O(poly(a, b)). Note that u(i, j) = sign(i − j) is a bounded distance
function where it reaches its maximum value at i − j = 1. Now, we are ready to present our main
result regarding the General Lotto game.

Theorem 4 There is a polynomial-time algorithm which ﬁnds an equilibrium of a General Lotto
game where the payoﬀ function is a bounded distance function.

Main challenge Note that in the General Lotto game, each player has inﬁnite number of pure
strategies, and thus one cannot use neither our proposed algorithm for the Colonel Blotto game nor
the technique of [25] for solving the problem. We should prune strategies such that the problem
becomes tractable. Therefore, we characterize the extreme point of the polytope of all strategies,
and use this characterization for pruning possible strategies.

To the best of our knowledge, our algorithm is the ﬁrst algorithm of this kind which computes

an NE of a game with inﬁnite number of pure strategies.

3 Application to Dueling Games

Immorlica et al.
In these games, an optimization
problem with an element of uncertainty is considered as a competition between two players. They

[25] introduced the class of dueling games.

7

also provide a technique for ﬁnding Nash equilibria for a set of games in this class. In this section,
we formally deﬁne the dueling games and bilinear duels. Then, in Section 3.3, we describe our
method and show that our technique solves a more general class of dueling games. Furthermore,
we provide examples to show how our method can be a simpler tool for solving bilinear duel games
compared to [25] method. Finally, in Section 3.4, we examine the matching duel game to provide
an example where the method of Immorlica et al. [25] does not work, but our presented method
can yet be applied.

3.1 Dueling games

Formally, dueling games are two player zero-sum games with a set of strategies X, a set of possible
situations Ω, a probability distribution p over Ω, and a cost function c : X × Ω → R that deﬁnes
the cost measure for each player based on her strategy and the element of uncertainty. The payoﬀ
of each player is deﬁned as the probability that she beats her opponent minus the probability that
she is beaten. More precisely, the utility function is deﬁned as

hA(x, y) = −hB(x, y) = Pr
ω∼p

[c(x, ω) < c(y, ω)] − Pr
ω∼p

[c(x, ω) > c(y, ω)]

where x and y are strategies for player A and B respectively. In the following there are two dueling
games mentioned in [25].

Binary search tree duel. In the Binary search tree duel, there is a set of elements Ω and a
probability distribution p over Ω. Each player is going to construct a binary search tree containing
the elements of Ω. Strategy x beats strategy y for element ω ∈ Ω if and only if the path from ω to
the root in x is shorter than the path from ω to the root in y. Thus, the set of strategies X is the
set of all binary search trees with elements of Ω, and c(x, ω) is deﬁned to be the depth of element
ω in strategy x.

Ranking duel. In the Ranking duel, there is a set of m pages Ω, and a probability distribution
p over Ω, notifying the probability that each page is going to be searched. In the Ranking duel,
two search engines compete against each other. Each search engine has to provide a permutation
of these pages, and a player beats the other if page ω comes earlier in her permutation. Hence, set
of strategies X is all m! permutations of the pages and for permutation x = (x1, x2, . . . , xm) and
page ω, c(x, ω) = i iﬀ ω = xi.

3.2 Dueling games are Polynomially Separable

Consider a dueling game in which each strategy ˆx of player A is an n(A) dimensional point in
Euclidean space. Let SA be the convex hull of these strategy points. Thus each point in SA is a
mixed strategy of player A. Similarly deﬁne strategy ˆy, n(B), and SB for player B. A dueling game
is bilinear if utility function hA(ˆx, ˆy) has the form ˆxtM ˆy where M is an n(A) × n(B) matrix. Again
for player B, we have hB(ˆx, ˆy) = −hA(ˆx, ˆy). Immorlica et al. [25] provide a method for ﬁnding an
equilibrium of a class of bilinear games which is deﬁned as follows:

Deﬁnition 1 Polynomially-representable bilinear dueling games: A bilinear dueling game is poly-
nomially representable if one can present the convex hull of strategies SA and SB with m polynomial
linear constraints, i.e. there are m vectors {v1, v2, . . . , vm} and m real numbers {b1, b2, . . . , bm} such
that SA = {ˆx ∈ Rn(A)|∀i ∈ {1, 2, . . . , m}, vi.ˆx ≥ bi}. Similarly SB = {ˆy ∈ Rn(B)|∀i ∈ {1, 2, . . . , m′}, v′
b′
i}.

i.ˆy ≥

In the following theorem, we show that every polynomially representable bilinear duel is also
polynomially separable, as deﬁned in Section 2.2. This implies that the general reduction described
in Section 2.2 can be used to solve polynomially representable bilinear duels as well.

8

Theorem 5 Every polynomially-representable bilinear duel is polynomially separable.

Let SA and SB be the set of strategy points for player A and player B, respectively.
Proof:
We show that if SA can be speciﬁed with polynomial number of linear constraints, then one could

Let {(v1, b1), (v2, b2), . . . , (vm, bm)} be the set of constraints which specify SA where vi is a vector
of size n(A) and bi is a real number. We need to check if there exists a point satisfying both

design an algorithm that ﬁnds out whether there exists a point ˆx ∈ SA such that α0 +P αi ˆxi ≥ 0.
constraints in {(v1, b1), (v2, b2), . . . , (vm, bm)} and α0 +P αi ˆxi ≥ 0. Recall that m is polynomial.

Since all these constraints are linear, we can solve this feasibility problem by a LP in polynomial
time. The same argument holds for SB, therefore every polynomially representable bilinear duel is
polynomially separable as well.

3.3 A Simpliﬁed Argument for Ranking and Binary Search Duels

In this section, we revisit some examples of dueling games, and show how to use Theorem 2 to
establish that they can be solved in polynomial time. The application of Theorem 2 as two main
steps. First, it is necessary to express the duel as a bilinear game: that is, one must transfer every
strategy of the players to a point in n(A) and n(B) dimensional space, such the outcome of the
game can be determined for two given strategy points with an n(A) × n(B) matrix M . Second, one
must implement an oracle that determines whether there exists a strategy point satisfying a given
linear constraint.

To illustrate our method more precisely, we propose a polynomial-time algorithm for ﬁnding an

NE for ranking and binary search tree dueling games in what follows.

Theorem 6 There exists an algorithm that ﬁnds an NE of the Ranking duel in polynomial time.

Proof: We transfer each strategy x of player A to point ˆx in Rm2
where ˆxi,j denotes the probability
that ωi stands at position j in x. The outcome of the game is determined by the following equation

m

m

m

Xi=1

Xj=1

Xk=j+1

ˆxi,j ˆyi,kp(ωi) −

m

m

Xi=1

Xj=1

j−1

Xk=1

ˆxi,j ˆyi,kp(ωi)

Where p(ωi) denotes the probability that ωi is searched.

Here, we need to provide an oracle that determines whether there exists a strategy point for

a player that satisﬁes a given linear constraint α0 +P αi,j ˆxi,j ≥ 0. Since each pure strategy is a
matching between pages and indices, we can ﬁnd the pure strategy that maximizes P αi,j ˆxi,j with

the maximum weighted matching algorithm. Therefore, this query can be answered in polynomial
time. Since we have reduced this game to a polynomially-separable bilinear duel, we can ﬁnd a
Nash equilibrium in polynomial time.

Theorem 7 There exists an algorithm that ﬁnds an NE of the Binary search tree duel in polynomial
time.

Proof: Here we map each strategy x to the point ˆx = hˆx1,1, ˆx1,2, . . . , ˆx1,m, ˆx2,1, ˆx2,2, . . . , ˆxm,mi ∈
Rm2
where ˆxi,j denotes the probability that depth of the i-th element is equal to j. Therefore, the
payoﬀ of the game for strategies ˆx and ˆy is equal to

m

m

m

Xi=1

Xj=1

Xk=j+1

ˆxi,j ˆyi,kp(ωi) −

m

m

Xi=1

Xj=1

j−1

Xk=1

ˆxi,j ˆyi,kp(ωi)

9

Where p(ωi) denotes the probability that i-th element is searched.

Next, we need to provide an oracle that determines whether there exists a strategy point for a

player that satisﬁes a given linear constraint α0 +P αi,j ˆxi,j ≥ 0. To do this, we ﬁnd the binary
search tree that maximizes P αi,j ˆxi,j. This can be done with a dynamic program. Let D(a, b, k)
denote the maximum value of Pb

i=a αi,j ˆxi,j for a subtree that its root is at depth k. D(a, b, k) can

be formulated as

D(a, b, k) =(a < b, mina≤c≤b{D(a, c − 1, k + 1) + D(c + 1, b, k + 1) + αc,k}

a = b, αa,k

Therefore, we can ﬁnd the Binary search tree which maximizes P αi,j ˆxi,j in polynomial time and

see if it meets the constraint. Since we have reduced this game to a polynomially-separable bilinear
duel, we can ﬁnd an NE in polynomial time.

3.4 Matching duel

In matching duel we are given a weighted graph G = (V, E, W ) which is not necessarily bipartite.
In a matching duel each pure strategy of players is a perfect matching, set of possible situations Ω is
the same as the set of nodes in G, and probability distribution p over Ω determines the probability
of selection of each node.
In this game, strategy x beats strategy y for element ω ∈ Ω if ω is
matched to a higher weighted edge in strategy x than strategy y.

The matching duel may ﬁnd its application in a competition between websites that try to match
people according to their desire. In this competition the website that suggest a better match for
each user will get that user, and the goal of each website is to maximize the number of its users.
We mention that the ranking duel is a special case of the matching duel, when G is a complete
bipartite graph with n nodes on each side, in which the ﬁrst part denotes the web pages and the
second part denotes the positions in the ranking. Thus, the weight of the edge between page i and
rank j is equal to j.

First, we describe how our method can solve this game and then we show the method of

Immorlica et al. [25] cannot be applied to ﬁnd an NE of the matching duel.

Theorem 8 There exists an algorithm that ﬁnds an NE of the matching duel in polynomial time.

Proof: We transfer every strategy x to a point in |E|-dimensional Euclidean space ˆx, where
ˆxe denotes the probability that x chooses e in the matching. Thus, the payoﬀ function is bilinear
and is as follows:

Xω∈Ω Xe1∈N (ω) Xe2∈N (ω)

[p(ω)ˆxe1 ˆye2 × sign(w(e1) − w(e2))]

where N (ω) is the set of edges adjacent to ω4. Next, we need to prove that the game is polynomially
separable. That is, given a vector α and a real number α0, we are to ﬁnd out whether there is a
strategy ˆx such that α0 + α.ˆx ≥ 0. This problem can be solved by a maximum weighted prefect
matching, where the graph is G = (V, E, W ) and w(e) = αe. Thus our framework can be used to
ﬁnd an NE of the matching duel in polynomial time.

Note that Rothvoss [41] showed that the feasible strategy polytope (the perfect matching poly-
tope) has exponentially many facets. Therefore, the prior approach represented in the work of
Immorlica et al. [25] is not applicable to the matching duel. This example shows that our frame-
work nontrivially generalizes the method of Immorlica et al.
[25] and completes the presentation
of our simpler and more powerful tool for solving bilinear duels.

4Note that sign(w) is 1, −1, and 0 if w is positive, negative, and zero respectively.

10

References

[1] Ashlagi, I., Krysta, P., and Tennenholtz, M. 2008. Social context games. In Internet

and Network Economics. Springer, 675–683.

[2] Azar, Y., Cohen, E., Fiat, A., Kaplan, H., and Racke, H. 2003. Optimal oblivious

routing in polynomial time. In STOC. 383–388.

[3] Bell, R. M. and Cover, T. M. 1980. Competitive optimality of logarithmic investment.

Math. Oper. Res. 5, 2, 161–166.

[4] Bellman, R. 1969. On colonel blotto and analogous games. Siam Review 11, 1, 66–68.

[5] Blackett, D. W. 1954. Some blotto games. Nav. Res. Logist. Q. 1, 55–60.

[6] Blackett, D. W. 1958. Pure strategy solutions to blotto games. Nav. Res. Logist. Q. 5,

107–109.

[7] Borel, ´E. 1921. La th´eorie du jeu et les ´equations int´egrales `a noyau sym´etrique. Comptes

Rendus de l’Acad´emie 173, 13041308, 97–100.

[8] Borel, ´E. 1953. The theory of play and integral equations with skew symmetric kernels.

Econometrica 21, 97–100.

[9] Brandt, F., Fischer, F., Harrenstein, P., and Shoham, Y. 2009. Ranking games.

Artiﬁcial Intelligence 173, 2, 221–239.

[10] Charnes, A. 1953. Constrained games and linear programming. Proceedings of the National

Academy of Sciences of the United States of America 39, 7, 639.

[11] Chen, X. and Deng, X. 2006. Settling the complexity of two-player nash equilibrium. In

FOCS. Vol. 6. 47th.

[12] Chen, X., Deng, X., and Teng, S.-H. 2006. Computing nash equilibria: Approximation
and smoothed complexity. In Foundations of Computer Science, 2006. FOCS’06. 47th Annual
IEEE Symposium on. IEEE, 603–612.

[13] Chowdhury, S. M., Kovenock, D., and Sheremeta, R. M. 2009. An experimental

investigation of colonel blotto games. Econ. Theor., 1–29.

[14] Dantzig, G. B. 1963. Linear programming and extensions. Princeton university press.

[15] Daskalakis, C., Goldberg, P. W., and Papadimitriou, C. H. 2009. The complexity of

computing a nash equilibrium. SIAM Journal on Computing 39, 1, 195–259.

[16] Dziubi´nski, M. 2011. Non-symmetric discrete general lotto games. Int. J. Game Theory,

1–33.

[17] Fr´echet, M. 1953a. Commentary on the three notes of emile borel. Econometrica 21,

118–124.

[18] Fr´echet, M. 1953b. Emile borel, initiator of the theory of psychological games and its

application. Econometrica 21, 95–96.

11

[19] Garg, J., Jiang, A. X., and Mehta, R. 2011. Bilinear games: Polynomial time algorithms

for rank based subclasses. In Internet and Network Economics. Springer, 399–407.

[20] Goldberg, P. W. and Papadimitriou, C. H. 2006. Reducibility among equilibrium prob-
lems. In Proceedings of the thirty-eighth annual ACM symposium on Theory of computing. ACM,
61–70.

[21] Golman, R. and Page, S. E. 2009. General blotto: games of allocative strategic mismatch.

Public Choice 138, 3-4, 279–299.

[22] Gr¨otschel, M., Lov´asz, L., and Schrijver, A. 1981. The ellipsoid method and its

consequences in combinatorial optimization. Combinatorica 1, 2, 169–197.

[23] Gr¨otschel, M., Lov´asz, L., and Schrijver, A. 1988. Geometric algorithms and combi-

natorial optimization. Springer4060 XII, 362 S.

[24] Hart, S. 2007. Discrete colonel blotto and general lotto games.

[25] Immorlica, N., Kalai, A. T., Lucier, B., Moitra, A., Postlewaite, A., and Tennen-

holtz, M. 2011. Dueling algorithms. In STOC. 215–224.

[26] Jiang, A. X. and Leyton-Brown, K. 2015. Polynomial-time computation of exact corre-

lated equilibrium in compact games. Games and Economic Behavior 91, 0, 347 – 359.

[27] Koller, D., Megiddo, N., and Von Stengel, B. 1994. Fast algorithms for ﬁnding ran-
domized strategies in game trees. In Proceedings of the twenty-sixth annual ACM symposium on
Theory of computing. ACM, 750–759.

[28] Kontogiannis, S. and Spirakis, P. 2010. Exploiting concavity in bimatrix games: New
polynomially tractable subclasses. In Approximation, Randomization, and Combinatorial Opti-
mization. Algorithms and Techniques. Springer, 312–325.

[29] Kovenock, D. and Roberson, B. 2010. Conﬂicts with multiple battleﬁelds. CESifo Working

Paper Series 3165, CESifo Group Munich. September.

[30] Kovenock, D. and Roberson, B. 2012. Coalitional colonel blotto games with application

to the economics of alliances. J. Pub. Econ. Theory 14, 4, 653–676.

[31] Kvasov, D. 2007. Contests with limited resources. J. Econ. Theory 136, 1, 738–748.

[32] Laslier, J.-F. and Picard, N. 2002. Distributive politics and electoral competition. J.

Econ. Theory 103, 1, 106–130.

[33] Letchford, J. and Conitzer, V. 2013. Solving security games on graphs via marginal

probabilities. In AAAI.

[34] Lipton, R. J., Markakis, E., and Mehta, A. 2003. Playing large games using simple

strategies. In Proceedings of the 4th ACM conference on Electronic commerce. ACM, 36–41.

[35] Merolla, J., Munger, M., and Tofias, M. 2005. In play: A commentary on strategies in

the 2004 us presidential election. Public Choice 123, 1-2, 19–37.

[36] Myerson, R. B. 1993. Incentives to cultivate favored minorities under alternative electoral

systems. Am. Polit. Sci. Rev., 856–869.

12

[37] Nash, J. 1951. Non-cooperative games. Annals of mathematics, 286–295.

[38] Osborne, M. J. and Rubinstein, A. 1994. A Course in Game Theory. MIT Press Books.

The MIT Press.

[39] Papadimitriou, C. H. and Steiglitz, K. 1998. Combinatorial optimization: algorithms

and complexity. Courier Dover Publications.

[40] Roberson, B. 2006. The colonel blotto game. Econ. Theor. 29, 1, 1–24.

[41] Rothvoss, T. 2014. The matching polytope has exponential extension complexity. In STOC.

263–272.

[42] Sahuguet, N. and Persico, N. 2006. Campaign spending regulation in a model of redis-

tributive politics. J. Econ. Theory 28, 1, 95–124.

[43] Shubik, M. and Weber, R. J. 1981. Systems defense games: Colonel blotto, command and

control. Nav. Res. Logist. Q. 28, 2, 281–287.

[44] Sion, M. 1957. General Minimax Theorems. United States Air Force, Oﬃce of Scientiﬁc

Research.

[45] Tukey, J. W. 1949. A problem of strategy. Econometrica 17, 73.

[46] von Neumann, J. 1953. Communication on the borel notes. Econometrica 21, 124–127.

[47] Weinstein, J. 2005. Two notes on the blotto game. Manuscript, Northwestern University.

[48] Xu, H., Fang, F., Jiang, A. X., Conitzer, V., Dughmi, S., and Tambe, M. 2014. Solving
zero-sum security games in discretized spatio-temporal domains. In Proceedings of the Twenty-
Eighth AAAI Conference on Artiﬁcial Intelligence, July 27 -31, 2014, Qu´ebec City, Qu´ebec,
Canada. 1500–1506.

A Colonel Blotto

In this appendix we provide a more detailed desciption of our polynomial time algorithm for ﬁnding
a Nash equilibrium (NE) of the Colonel Blotto game. Hart showed that the Colonel Lotto game
is equivalent to a special case of the Colonel Blotto game [24]. Therefore, our algorithm could be
used to ﬁnd a NE of the Colonel Lotto game as well.

In section A.1, we present a procedure for mapping strategies of both players to a new space.
The new space maintains the important information of each strategy and helps us to ﬁnd a Nash
equilibrium of the game. Next in section A.2, we show how we check the feasibility of the member-
ship constraint in the new space. Moreover, we present a polynomial-time algorithm for determining
an equilibrium of the Colonel Blotto game in the new space. At last in section A.3, we present an
algorithm which transfers a Nash equilibrium from the new space to the original space.

13

A.1 Transferring to a new space

In this subsection we deﬁne a new notation for describing the strategies of players and discuss about
the properties of the transferred strategies. Let n(A) = k(a + 1), and x be a strategy of player
A. We deﬁne the function GA in the following way: GA(x) = ˆx where ˆx is a point in Rn(A) such
that ˆx(i−1)(a+1)+j+1 is equal to the probability that strategy x puts j units in the i-th battleﬁeld,
for 1 ≤ i ≤ k and 0 ≤ j ≤ a. For simplicity we may represent ˆx(i−1)(a+1)+j+1 by ˆxi,j. We deﬁne
n(B) and GB similarly for player B. Let n = max{n(A), n(B)}. Note that, GA maps each strategy
of the ﬁrst player to exactly one point in Rn(A). However, each point in Rn(A) may be mapped to
zero, one, or more than one strategies. Let us recall the deﬁnition of M(X ) which is the set of all
strategies of player A, and the deﬁnition of SA which is

SA = {ˆx ∈ [0, 1]n(A)|∃x ∈ M(X ), GA(x) = ˆx}.

In order to design an algorithm for checking the membership constraint, we ﬁrst demonstrate in
Lemma A.1 that set SA is a polyhedron with an exponential number of vertices and facets. This
lemma is a more formal statement of Lemma 1. Then we prove in Lemma A.2 that set SA can be
formulated with O(2poly(n)) number of constraints. These results allow us to leverage the Ellipsoid
method for checking the membership constraint [23].

Lemma A.1 Set SA forms a convex polyhedron with no more than n(A)n(A) vertices and no more
than n(A)(n(A)2) facets.

See Appendix D for the proof of Lemma A.1.

Lemma A.2 Set SA can be formulated with O(2poly(n)) number of constraints

See Appendix D for the proof of Lemma A.2.

A.2 Checking the membership constraint and the payoﬀ constraints

As we brieﬂy described in Subsection 2, the ﬁnal goal of this section is to determine a NE of the
Colonel Blotto game. To do this, we provide linear program 2 and show that this LP can be solved
in polynomial time. Since we use the Ellipsoid method to solve the LP, we have to implement an
oracle function that reports a violating constraint for any infeasible solution. In this subsection we
focus on the membership constraint of LP 2 and show that for any infeasible point ˆx which violates
membership constraint, a polynomial-time algorithm ﬁnds a hyperplane that separates ˆx from SA.

Lemma A.3 There exists a polynomial time algorithm that gets a point ˆx as input, and either
ﬁnds a hyperplane that separates ˆx from SA, or reports that no such hyperplane exists.

Proof: Let ˆx = (ˆx1, ˆx2, . . . , ˆxn(A)). Consider the following LP, which we will refer to as LP 5:

α0 +

α0 +

n(A)

n(A)

Xj=1
Xj=1

αj ˆxj < 0

αj ˆvj ≥ 0

∀ˆv ∈ IA

14

(5)

(6)

The variables of the linear program are α0, α1, . . . , αn(A), which describe the following hyperplane:

α0 +

n(A)

Xj=1

αj ˆx′

j = 0.

Constraints 5 and 6 force LP 5 to ﬁnd a hyperplane that separates ˆx from SA. Hence, LP 5 ﬁnds
a separating hyperplane if and only if ˆx is not in SA.

Hyperplane separating oracle is an oracle that gets variables α0, α1, . . . , αn(A) as input and ﬁnds
if constraints 6 are satisﬁed. Moreover, if some constraints are violated it returns at least one of
the violated constraints. In Section C we describe a polynomial-time algorithm for the hyperplane
separating oracle. Constraint 5 also can be checked in polynomial time. Our LP has n(A) + 1
variables and |IA| + 1 constraints which is O(2poly(n)) by Lemma A.1. Thus we can solve this LP
in polynomial time with the Ellipsoid method [23].

In the next step, we present an algorithm to determine the outcome of the game when both
players play optimally. We say x is an optimal strategy of player A, if it maximizes the guaranteed
payoﬀ of player A. By the MinMax Theorem, in a NE of a zero-sum game players play optimally
[44]. Therefore, it is enough to ﬁnd an optimal strategy of both players. Before we discuss the
algorithm, we show the payoﬀ hA
B (x, y) can be determined by GA(x) and GB(y). Recall the deﬁnition
of hA

B (ˆx, ˆy) which is

hA
B (ˆx, ˆy) =

k

a

b

Xi=1

Xα=0

Xβ=0

ˆxi,α ˆyi,βuA

i (α, β).

Lemma A.4 Let x ∈ M(X ) and y ∈ M(Y) be two mixed strategies for player A and B respec-
tively. Let ˆx = GA(x) and ˆy = GB(y). The outcome of the game is determined by hA

B (ˆx, ˆy).

Proof: Let x and y be two mixed strategies of players A and B respectively, and let E[uA
be the expected value of the outcome in battleﬁeld i. We can write E[uA

i (x, y)] as follows

i (x, y)]

E[uA

i (x, y)] =

a

b

Xα=0

Xβ=0

ˆxi,α ˆyi,βuA

i (α, β).

We know that the total outcome of the game is the sum of the outcome in all battleﬁelds, which is

E" k
Xi=1

uA

i (x, y)# =

k

Xi=1

E[uA

i (x, y)] =

k

a

b

Xi=1

Xα=0

Xβ=0

ˆxi,α ˆyi,βuA

i (α, β) = hA

B (ˆx, ˆy).

Theorem A.1 There exists a polynomial time algorithm that ﬁnds a NE of the Colonel Blotto
game in the new space.

Proof: The Colonel Blotto is a zero-sum game, and the MinMax theorem states that a pair of
strategies (ˆx, ˆy) is a Nash equilibrium if ˆx and ˆy maximize the guaranteed payoﬀ of players A and
B respectively [44].

Recall that LP 2 ﬁnds a point ˆx ∈ SA which describes an optimal strategy of player A5. This
LP has n(A) + 1 variables ˆx1, ˆx2, . . . , ˆxn(A) and U where ˆx1, ˆx2, . . . , ˆxn(A) describe point ˆx. The

5The same procedure ﬁnds an optimal strategy of player B.

15

membership constraint guarantees ˆx is in SA. It is known that in any normal-form game there
always exists a best-response strategy which is a pure strategy [38]. Hence, variable U represents
the maximum payoﬀ of player A with strategy ˆx when player B plays his best-response strategy
against ˆx. Note that, Lemma A.4 shows hA
B (ˆx, ˆy) is a linear function of ˆx, when ˆy is a ﬁxed strategy
of player B. This means the payoﬀ constraints are linear constraints. Putting all these together
show, LP 2 ﬁnds a point ˆx such that:

1. There exists strategy x such that GA(x) = ˆx.

2. The minimum value of hA

B (x, y) is maximized for every y ∈ M(Y).

Next we show that this LP can be solved in polynomial time with the Ellipsoid method. First,
Lemma A.3 proposes a polynomial-time algorithm for checking the membership constraint. Second,
best-response separating oracle is an oracle that gets point ˆx and variable U as input and either
reports point ˆx passes all payoﬀ constrains or reports a violated payoﬀ constraint. In Section C,
we will show that the running time of this oracle is O(poly(n)).

At last we prove LP 2 has O(2poly(n)) number of constraints, and we can leverage the Ellipsoid
method for ﬁnding a solution of this LP. Note that Lemma A.2 indicates that set SA can be
represented by O(2poly(n)) number of hyperplanes. On the other hand, Lemma A.1 shows LP 2 has
at most |IB| = O(2poly(n)) constraints.

A.3 Finding a Nash equilibrium in the original space

In the previous subsection, we presented an algorithm which ﬁnds a Nash equilibrium (GA(x), GB(y))
of the game in the new space. The remaining problem is to retrieve x from GA(x).

Theorem A.2 Given a point ˆx ∈ SA, there exists a polynomial time algorithm which ﬁnds a
strategy x ∈ M(X ) such that GA(x) = ˆx.

Proof: Since every strategy of player A is a convex combination of elements of X , our goal is to
ﬁnd a feasible solution of the following LP.

min .

0

s.t. Xx∈X
Xx∈X

αx = 1

αxGA(x)j = ˆxj

∀1 ≤ j ≤ n(A)

αx ≥ 0

∀x ∈ X

(7)

(8)

(9)

(10)

where αx is the probability of pure strategy x ∈ X . Note that, this LP ﬁnds a mixed strategy of
player A by ﬁnding the probability of each pure strategy. Since every feasible solution is acceptable,
objective function does not matter. To ﬁnd a solution of this LP, we write its dual LP as follows.

max .

β0 +

s.t.

β0 +

n(A)

n(A)

Xj=1
Xj=1

ˆxjβj

GA(x)jβj ≤ 0

∀x ∈ X

16

(11)

(12)

Where variable β0 stands for constraint 8, and variables β1, β2, . . . , βn(A) stand for constraints 9.
An oracle similar to the hyperplane separating oracle can ﬁnd a violating constraint for any infea-
sible solution of the dual LP. Since the number of constraints in the dual LP is |IA| = O(2poly(n))
based on Lemma A.1, we can use the Ellipsoid method and ﬁnd an optimal solution of the dual LP
in polynomial time.

The next challenge is to ﬁnd an optimal solution of the primal LP from an optimal solution of
the dual LP. We resolve this problem by the following lemma. We know ˆx is in SA. This means
there is strategy x ∈ M(X ) such that GA(x) = ˆx. Hence, linear program 7 and its dual are feasible,
and we can apply Lemma A.5.

Lemma A.5 Assume we have a separation oracle for primal LP max{cT x : Ax ≤ b} with expo-
nentially many constraints and polynomially many variables. If primal LP is feasible, then there is
a polynomial-time algorithm which returns an optimum solution of dual LP min{bT y : AT y ≥ c}.

Since the primal LP is feasible, we can assume OP T = max{cT x : Ax ≤ b}. The
Proof:
Ellipsoid method returns an optimum solution of primal LP by doing binary search and ﬁnding
the largest K which guarantees feasibility of {cT x ≤ K : Ax ≤ b}. Let ( ˆA, ˆb) be the set of
polynomially many constraints returned by the separation oracle during all iterations. We ﬁrst
prove max{cT x : ˆAx ≤ ˆb} = OP T . Note that ( ˆA, ˆb) is a set of constraints returned by the
Ellipsoid method. Note that ( ˆA, ˆb) is a subset of all constraints (A, b). This means every vector
x which satisﬁes Ax ≤ b will satisfy ˆAx ≤ ˆb as well. Therefore, max{cT x : ˆAx ≤ ˆb} ≥ max{cT x :
Ax ≤ b} = OP T . On the other hand, we know ( ˆA, ˆb) contains constraints which guarantees
infeasibility of max{cT x ≥ OP T + ǫ : Ax ≤ b}. So, LP max{cT x ≥ OP I + ǫ : ˆAx ≤ ˆb} is
infeasible which means max{cT x : ˆAx ≤ ˆb} ≤ OP T . Putting all these together we can conclude
that max{cT x : ˆAx ≤ ˆb} = OP T .

Linear program max{cT x : ˆAx ≤ ˆb} has polynomially many constraints and polynomially many
variables, and we can ﬁnd an optimum solution to its dual min{ˆbT ˆy : ˆAT ˆy ≥ c} in polynomial time.
Let ˆy∗ be an optimum solution of dual LP min{ˆbT ˆy : ˆAT ˆy ≥ c}, and let S = {i|(Ai, bi) is in ( ˆA, ˆb)}
where Ai is the i-th row of matrix A, i.e., be set of indices corresponding to constraints in ( ˆA, ˆb).
For every vector y and every set of indices R we deﬁne yR to be the projection of vector y on set R.
Now consider vector y∗ as a solution of dual LP min{bT y : AT y ≥ c} such that y∗
S = ˆy∗ and y∗
i = 0
for all i 6∈ S. We prove y∗ is an optimum solution of dual LP min{bT y : AT y ≥ c} as follows:

• We ﬁrst show y∗ is feasible. Note that y∗

i = 0 for all i 6∈ S which means AT y∗ = ˆAT ˆy∗ ≥ c

where the last inequality comes from the feasibility of ˆy∗ in dual LP min{ˆbT y : ˆAT y ≥ c}.

i y∗

• Note that bT y∗ =Pi bT

i = ˆbT ˆy∗. The last equality comes from the
i = ˆbT ˆy∗. Since ˆy∗ is an optimum solution of dual
facts that y∗
the LP min{ˆbT y : ˆAT y ≥ c}, by the weak duality, it is equal to max{cT x : ˆAx ≤ ˆb} = OP T .
Therefore, bT y∗ = OP T .

i = 0 for all i 6∈ S, andPi∈S bT

i =Pi∈S bT

i y∗

i y∗

i +Pi6∈S bT

i y∗

We have proved y∗ is a feasible solution to dual LP min{bT y : AT y ≥ c} and bT y∗ = OP T . We
also know OP T = max{cT x : Ax ≤ b} by deﬁnition. Therefore, the weak duality insures y∗ is an
optimum solution of dual LP min{bT y : AT y ≥ c}.

17

B General Lotto

Γ (X, Y ) = −hA

Γ (X, Y ) where hA

Γ (X, Y ) and player B’s aim is to maximize hB

In this section we study the General Lotto game. An instance of the General Lotto game is deﬁned
by Γ(a, b, u), where players A and B simultaneously deﬁne probability distributions of non-negative
integers X and Y , respectively, such that E[X] = a and E[Y ] = b. In this game, player A’s aim is to
maximize hA
Γ (X, Y ) is
deﬁned as Ei∼X,j∼Y u(i, j). The previous studies of the General Lotto game considered a special case
of the problem where u(i, j) = sign(i − j)6. Here, we generalize the payoﬀ function to a bounded
distance function and present an algorithm for ﬁnding a Nash equilibrium of the General Lotto game
in this case. Function u is a bounded distance function, if one can write it as u(i, j) = fu(i − j) such
that fu is a monotone function and reaches its maximum value at fu(tu) where tu ∈ O(poly(a, b)).
We ﬁrst deﬁne a new version of the General Lotto game, which is called the ﬁnite General Lotto
game. We prove a Nash equilibrium of the ﬁnite General Lotto game can be found in polynomial
time. Then we reduce the problem of ﬁnding a Nash equilibrium of the General Lotto game with a
bounded distance function to the problem of ﬁnding a Nash equilibrium of the ﬁnite General Lotto
game. This helps us to propose a polynomial-time algorithm which ﬁnds a Nash equilibrium of the
General Lotto game where the payoﬀ function is a bounded distance function.

B.1 Finite General Lotto

We deﬁne the ﬁnite General Lotto game Γ(a, b, u, S) to be an instance of the General Lotto game
where every strategy of players is a distribution over a ﬁnite set of numbers S. Here, we leverage
our general technique to show the ﬁnite General Lotto game is a polynomially-separable bilinear
game and, as a consequence, it leads to a polynomial time algorithm to ﬁnd a Nash equilibrium for
this game.

Theorem B.1 There exists an algorithm which ﬁnds a Nash equilibrium of the ﬁnite General Lotto
game Γ(a, b, u, S) in time O(poly(|S|)).

Proof: First we map each strategy X to a point ˆx = hˆx1, ˆx2, . . . , ˆx|S|i, where ˆxi denotes Pr(X =
Si). Without loss of generality we assume the elements of S are sorted in strictly ascending order,
i.e.
for each 1 ≤ i < j ≤ |S|, Si < Sj. Now the utility of player A when A plays a strategy
corresponding to ˆx and B plays a strategy corresponding to ˆy is obtained by the following linear
function.

|S|

|S|

hA
Γ (ˆx, ˆy) =

Xi=1

ˆxˆyu(i, j) −

ˆxˆyu(i, j).

Xi=1

Xj=i+1

|S|

i−1

Xj=1

Therefore the game is bilinear. Now we prove the game is polynomially separable.

Given a real number r and a vector v, we provide a polynomial-time algorithm which determines
whether there exists a strategy point ˆx such that r + v.ˆx ≥ 0. We design the following feasibility

6 sign(x) =

−1 x < 0
0
x = 0
x > 0
1




18

program for this problem with |S| variables ˆx1 to ˆx|S| and three constraints.

|S|

ˆxi = 1

ˆxiSi = a

|S|

Xi=1
Xi=1

r + v.ˆx ≥ 0

(13)

(14)

(15)

Constraints 13 and 14 force the variables to represent a valid strategy point (i.e., the probabilities
sum to 1 and the expectation equals a). Thus every point ˆx is a valid strategy point iﬀ it satisﬁes
Constraints 13 and 14. On the other hand, Constraint 15 enforces the program to satisfy the
given linear constraint of the separation problem. Thus there exists a strategy point ˆx such that
b + v.ˆx ≥ 0 iﬀ there is a solution for the feasibility LP. The feasibility of the program can be
determined in polynomial time, hence, the separation problem is polynomially tractable.

Therefore the ﬁnite General Lotto game is a polynomially-separable bilinear game and by Theo-
rem 2, there exists a polynomial-time algorithm which ﬁnds a Nash equilibrium of the ﬁnite General
Lotto game.

B.2 General Lotto with bounded distance functions

In this section, we consider General Lotto game Γ(a, b, u) where u is a bounded distance function
and design a polynomial-time algorithm for ﬁnding a Nash equilibrium of the game. In the following
part of this section we assume a ≤ b. Recall the deﬁnition of bounded distance functions.

Deﬁnition B.1 Function u is a bounded distance function, if one can write it as u(i, j) = fu(i − j)
such that fu is a monotone function and reaches its maximum value at uM = fu(uT ) where uT ∈
O(poly(a, b)). We call uT the threshold of function u, and uM the maximum of function u 7 .

First we deﬁne a notion of paired strategies and claim that for every strategy of a player there
is a best-response strategy which is a paired strategy. Then, using this observation, we can prove
nice bounds on the set of optimal strategies.

Consider a probability distribution which only allows two possible outcomes, i.e., there are
only two elements in S with non-zero probabilities. We call such a distribution a paired strategy.
We deﬁne Ti,j to be a paired strategy which only has non-zero probabilities at elements i and j.
Furthermore, we deﬁne T a
i,j, the
probabilities of elements i and j are determined by αa
i,j =
j) = a−i
i,j. In the following structural lemma, we show that every distribution T over a
ﬁnite set S can be constructed by a set of paired strategies.

i,j to be a paired strategy with E[T a

i,j] = a. In paired strategy T a

j−i = 1 − αa

i,j = i) = a−j

i−j and αa

i,j = P r(T a

j,i = P r(T a

Lemma B.1 For every distribution T over S with E[T ] = a and t elements with non-zero prob-
8, and for all

ability, there are m ≤ t paired strategies σ1, σ2, . . . , σm such that T = Pm

1 ≤ i ≤ m we have βi ∈ [0, 1] and E[σi] = a.

r=1 βrσr

7Note that sign function is a special case of distance functions.
8This lemma claims that the strategy of a player in the ﬁnite General Lotto game can be written as a probability
distribution over paired strategies. Thus T = β1σ1 + β2σ2 + . . . + βmσm describes a strategy in which the paired
strategy σi is played with probability βi.

19

0,a is a paired strategy and the claim holds by setting σ1 = T a

Proof: We prove this claim by induction on the number of elements with non-zero probabilities
If there is only one element with non-zero probability in T , i.e., t = 1, then we have
in T .
P r(T = a) = 1. Thus T = T a
0,a and
β1 = 1. Now assuming the claim holds for all 1 ≤ t′ < t, we prove the claim also holds for t.
Suppose T be a probability distribution with t non-zero probability elements. Since t ≥ 2, there
should be some i < a with P r(T = i) > 0 and some j > a with P r(T = j) > 0. We choose the
largest possible number 0 < β ≤ 1 such that βαa
j,i ≤ P r(T = j). If β = 1,
then P r(T = i) + P r(T = j) ≥ αa
i,j is a paired strategy and the
claim holds by setting σ1 = T a
i,j where
T ′ =

i,j and β1 = 1. Otherwise, we can write T = (1 − β)T ′ + βT a

j,i = 1. This means T = T a

i,j ≤ P r(T = i) and βαa

. Furthermore we have

i,j + αa

T −βT a
i,j

1−β

E[T ′] =

E[T − βT a

i,j]

1 − β

=

E[T ] − βE[T a

i,j]

1 − β

= a.

We select β such that at least one of the probabilities P r[T ′ = i] or P r[T ′ = j] becomes zero. Thus
compared to T , the number of elements with non-zero probability in T ′ is at least decreased by one,
m′ where m′ ≤ t − 1.
and by the induction hypothesis we can write T ′ = β′
Let βi = (1 − β)β′
i,j. Now we can write
T = β1σ1 + β2σ2 + . . . + βm′+1σm′+1 where each σi is a paired strategy and E(σi) = a. Furthermore,
m = m′ + 1 ≤ t and the proof is complete. Since t ≤ |S|, m is polynomial in the size of input.
Therefore paired strategies σ1, σ2, . . . , σm and their corresponding coeﬃcients β1, β2, . . . , βm can be
computed in polynomial time.

m′ σ′
i for 1 ≤ i ≤ m′ and βm′+1 = β and σm′+1 = T a

i and σi = σ′

2 + . . . + β′

1 + β′

1σ′

2σ′

Lemma B.2 For every strategy of player A in a ﬁnite General Lotto game there is a best-response
strategy of player B which is a paired strategy.

Proof: Consider ﬁnite General Lotto game Γ(a, b, u, S), strategy X of player A, and a best-
response strategy Z of player B. Since Z is a distribution on S, by using Lemma B.1 we can write
r=1 βrσr) and because of the linearity of
Γ (X, σr). Since Z is a best-response strategy, we

r=1 βrσr. Thus, we have hB

Γ (X, Z) = hB
r=1 βrhB

Γ (X,Pm

Z = Pm

expectation we can write hB
have:

Γ (X, Z) = Pm

∀1 ≤ r ≤ m, hB

Γ (X, σr) = hB

Γ (X, Z).

(16)

This means paired strategy σr, for each 1 ≤ r ≤ m, is a best-response strategy of player B.

In the following lemmas, using the structural property of the best-response strategies, we show

some bounds for each player’s optimal strategies.

j+1.

1 − c

Lemma B.3 For any strategy X with E[X] = c and any integer j we have Pj
Proof: Since P+∞

i=0 iPr(X = i) = c, we have (j + 1)P+∞

j

+∞

i=j+1 Pr(X = i) ≤ c. This implies

i=0 Pr(X = i) ≥

Pr(X = i) = 1 −

Xi=0

Pr(X = i) ≥ 1 −

Xi=j+1

c

.

j + 1

Lemma B.4 Consider Nash equilibrium (X, Y ) of General Lotto game Γ(a, b, u) where u is a

bounded distance function with threshold uT . We have Pa−1

i=0 Pr(Y = i) ≤ uT

uT +1 .

20

Proof: Let X ′ be a pair distribution of player A that chooses a − 1 with probability p and chooses
a + uT − 1 with probability 1 − p. Thus p = uT −1
uT . The payoﬀ of playing strategy X ′ against Y is

Γ (X ′, Y ) =
hA

+∞

Xi=0

Pr(Y = i)[pu(a − 1, i) + (1 − p)u(a + uT − 1, i)].

(17)

Note that by the deﬁnition of u, u(i, j) ≥ 0 if and only if i − j ≥ 0 and u(i, j) ≤ 0 if and only
if i − j ≤ 0. Furthermore, if i − j ≥ uT then u(i, j) = uM and if i − j ≤ −uT then u(i, j) = −uM .
Therefore,

a−1

a−1

Xi=0
Xi=0
Xi=a

+∞

Pr(Y = i)pu(a − 1, i)

≥ 0

Pr(Y = i)(1 − p)u(a + uT − 1, i)

≥ (1 − p)uM

Pr(Y = i)[pu(a − 1, i) + (1 − p)u(a + uT − 1, i)] ≥

− uM

+∞

Xi=a

Pr(Y = i)

(18)

a−1

Xi=0

Pr(Y = i)

Note that a ≤ b and (X, Y ) is a Nash equilibrium which means hA
Γ (X ′, Y ) ≤ 0. Thus, by applying Equality 17 and Inequality 18 we have
hA

Γ (X, Y ) ≤ 0. This implies

a−1

+∞

which implies P+∞

substituting uT −1
uT

0 ≥ hA

Pr(Y = i) − uM

Γ (X ′, Y ) ≥ (1 − p)uM

Xi=0
i=0 Pr(Y = i) ≥ (2 − p)Pa−1
i=0 Pr(Y = i). Thus, Pa−1
instead of p we can conclude Pa−1

i=0 Pr(Y = i) ≤ uT

Xi=a

uT +1 .

Pr(Y = i),

i=0 Pr(Y = i) ≤ 1

2−p . By

In the following lemma we provide an upper-bound for the maximum variable with non-zero

probability of a player’s strategy in the equilibrium.

Lemma B.5 Consider a Nash equilibrium (X, Y ) of General Lotto game Γ(a, b, u) where u is a
bounded distance function with threshold uT .
If ˆu = (4buT + 4b + uT )(2uT + 2), then we have
P r(Y > ˆu + uT ) = 0 and P r(X > ˆu) = 0.

Proof: First, we prove for any integer z > ˆu, Pr(X = z) = 0. The proof is by contradiction. Let
z > ˆu be an integer with non-zero probability in X. Thus there is an integer x < a with non-zero
x,z. We deﬁne another pair distribution T a
probability in X. Consider the pair distribution T a
x,y
where y = 4buT + 4b + uT .

Consider strategy X ǫ = X − ǫT a

x,y. Note that (X, Y ) is a Nash equilibrium of the game.
This means strategy X is a best response of player A to strategy Y of player B which implies
hA
Γ (X, Y ) ≥ hA

Γ (X ǫ, Y ). On the other hand, because of the linearity of expectation we can write

x,z + ǫT a

hA
Γ (X ǫ, Y ) = hA

Γ (X, Y ) − ǫhA

Γ (T a

x,z, Y ) + ǫhA

Γ (T a

x,y, Y ).

Therefore, we conclude w = hA

Γ (T a

x,z, Y ) − hA

Γ (T a

x,y, Y ) ≥ 0. Let p = αa

z,x and q = αa

y,x. We have

w =

+∞

Xi=0

Pr(Y = i)[(1 − p)u(x, i) + pu(z, i)] −

+∞

Xi=0

21

Pr(Y = i)[(1 − q)u(x, i) + qu(y, i)] ≥ 0.

We write w as w = w1 + w2 − w3 − w4 + w5, where

x

Pr(Y = i)[[(1 − p)u(x, i) + pu(z, i)] − [(1 − q)u(x, i) + qu(y, i)]],

Pr(Y = i)[(1 − p)u(x, i) − (1 − q)u(x, i)],

w1 =

w2 =

w3 =

w4 =

w5 =

y−uT −1

+∞

Xi=0
Xi=x+1
Xi=x+1
Xi=y−uT
Xi=x+1

+∞

+∞

Pr(Y = i)qu(y, i),

Pr(Y = i)qu(y, i),

Pr(Y = i)pu(z, i).

Since 1 − p ≥ 1 − q and u(z, i) = u(y, i) = uM for all i ≤ x, we can conclude w1 ≤ 0. For all
i > x, we have u(x, i) ≤ 0, and we also know 1 − p ≥ 1 − q. These mean w2 ≤ 0. Since for all
i ≤ y − uT we have u(y, i) = uM , we conclude

w3 = quM

y−uT −1

Xi=x+1

Pr(Y = i)

Moreover, for any arbitrary integers i and j, we have −uM ≤ u(i, j) ≤ uM . Thus

+∞

−w4 ≤ quM

w5 ≤ puM

Xi=y−uT
Xi=x+1

+∞

Pr(Y = i)

Pr(Y = i)

Therefore by knowing w ≥ 0, w1 ≤ 0, w2 ≤ 0, and considering Inequalities 19, 20, and 21, we
conclude

uM (−q

y−uT −1

Xi=x+1

Pr(Y = i) + q

+∞

Xi=y−uT

Pr(Y = i) + p

+∞

Xi=x+1

Pr(Y = i)) ≥ w ≥ 0.

(22)

i=0 Pr(Y = i) ≤ uT

y − uT − 1 = 4buT + 4b − 1 and by Lemma B.3, Py−uT −1
that x < a which means Px
Pa−1

i=0 Pr(Y = i) ≤Pa−1
uT +1 . Hence we can conclude Px
Xi=x+1

Pr(Y = i) =

Pr(Y = i) −

Xi=0

y−uT −1

y−uT −1

x

Xi=0

4uT +4 . Note
i=0 Pr(Y = i). On the other hand, Lemma B.4 says

Pr(Y = i) ≥ 1 −

4buT +4b = 4uT +3

i=0

b

i=0 Pr(Y = i) ≤ uT

uT +1 . Therefore

Pr(Y = i) ≥

3

4uT + 4

and

+∞

Xi=y−uT

Pr(Y = i) = 1 −

y−uT −1

Xi=0

22

Pr(Y = i) ≤

1

4uT + 4

.

(19)

(20)

(21)

(23)

(24)

By Inequalities 22, 23, 24, and P+∞

3

i=x+1 Pr(Y = i) ≤ 1, we have

−q

4uT + 4

+ q

1

4uT + 4

+ p ≥ 0.

(25)

p ≤ 2uT + 2. Recalling p = αa
y ≤ z−x

which implies q
y−x , and z > y, we can bound
z
y as follows z
p ≤ 2uT + 2. Therefore z ≤ y(2uT + 2) = ˆu which is a contradiction.
Knowing that player A put zero probability on every number z > ˆu and considering the deﬁnition
of bounded distance function u, player B will put zero probability of every number greater than
ˆu + uT in any Nash equilibrium.

z−x , q = αa

y,x = a−x

z,x = a−x

y−x = q

The following theorem follows immediately after Theorem B.1 and Lemma B.5.

Theorem B.2 There is a polynomial time algorithm which ﬁnds a Nash Equilibrium of the General
Lotto game Γ(a, b, u) where u is a bounded distance function.

Let ¯u = (4buT + 4b + uT )(2uT + 2) + uT . Lemma B.5 shows there is a bound on the
Proof:
optimal strategies in a Nash equilibrium. More precisely P r(Y > ¯u) = 0, where Y is a strategy
of player A or B. Thus General Lotto game Γ(a, b, u) is equivalent to ﬁnite General Lotto game
Γ(a, b, f, S), where S = {1, 2, . . . , ¯u}. By Theorem B.1, a polynomial-time algorithm ﬁnds a Nash
equilibrium of the game.

C Oracles

In this section we describe, in precise detail, the separating oracles used by the ellipsoid method
to solve our represented linear programs. Consider we are given a sequence c0, c1, . . . , ck(m+1),
where k is the number of battleﬁelds and m is the number of troops for a player. We ﬁrst present
i=1 xi = m, and

an algorithm which ﬁnds a pure strategy x = (x1, x2, . . . , xk) ∈ X such that Pk

ˆx = G(x) minimizes the following equation.

c0 +

k(m+1)

Xi=1

ci ˆxi

(26)

Then we leverage this algorithm and design polynomial-time algorithms for the hyperplane sepa-
rating oracle and best-response separating oracle. The following lemma shows that Algorithm 1
(FindBestPure ) ﬁnds the minimizer of Equation 26.

Lemma C.1 Given two integers m and k and a sequence c0, c1, . . . , ck(m+1), algorithm FindBestPure

i=1

ci ˆxi.

Proof:

correctly ﬁnds an optimal pure strategy x = (x1, x2, . . . , xk) where Pk
minimizes c0 +Pk(m+1)
to be the minimum possible value of c0 +Pi(t+1)
the minimum possible value of c0 +Pk(m+1)

In Algorithm FindBestPure , using a dynamic programming approach, we deﬁne d[i, t]
i′=1 xi′ = t. Hence, d[k, m] denotes
ci ˆxi. Now, we show that Algorithm FindBestPure
correctly computes d[i, t] for all 0 ≤ i ≤ k and 0 ≤ t ≤ m. Obviously d[0, j] is equal to c0. For an
arbitrary i > 0 and t, the optimal strategy x puts 0 ≤ t′ ≤ t units in the i-th battleﬁeld and the
applied cost in the equation 26 is equal to c(i−1)(m+1)+t′ +1. Thus,

i′=1 ci′ ˆxi′ where Pi

i=1 xi = m, ˆx = G(x) and ˆx

i=1

d[i, t] = min
0≤t′≤t

{d[i − 1, t − t′] + c(i−1)(m+1)+t′ +1}

23

Algorithm 1 FindBestPure
input: m, k, c0, c1, c2, . . . , ck(m+1)
1: for j ← 1 to m do
2:
3: end for
4: for i ← 1 to k do
5:

for t ← 0 to m do

d[0, j] ← c0

6:

7:

8:

9:

10:

11:

for j ← 0 to t do

if d[i − 1, t − j] + c(i−1)(m+1)+j+1 < d[i, t] then

d[i, t] ← d[i − 1, t − j] + c(i−1)(m+1)+j+1
r[i, t] ← j

end if

end for

end for

12:
13: end for
14: rem ← m
15: for i ← k downto 1 do
16:

xi ← r[i, rem]
rem ← rem − r[i, rem]

17:
18: end for
19: return x = (x1, x2, . . . , xk)

To compute the optimal pure strategy x = (x1, x2, . . . , xk) we also keep a value

r[i, t] = argmin
0≤t′≤t

{d[i − 1, t − t′] + c(i−1)(m+1)+t′ +1}

which determines the number of units the optimal strategy should put in the i-th battleﬁeld to
i′=1 ci′ ˆxi′. Assuming we have correctly computed xi+1, . . . , xk, in line 16, al-
j=i+1 xj]. Since
xk = r[k, m] we can conclude algorithm FindBestPure correctly computes the optimal strategy
x = (x1, x2, . . . , xk).

minimize c0 +Pi(t+1)
gorithm FindBestPure correctly computes xi which is equal to r[i, m − Pk

C.1 Hyperplane separating oracle

Algorithm 2 (HyperplaneOracle ) gets a hyperplane as input and either ﬁnds a point in IA
which violates constraints in LP 5 or reports that all points in IA are satisfying all constraints in
LP 5. We suppose that the input hyperplane is described by the following equation,

α0 + α1 ˆx1 + . . . + αk(a+1) ˆxk(a+1) = 0

and we want to ﬁnd a point ˆx ∈ IA that violates the following constraint:

α0 +

n

Xi=1

αi ˆxi ≥ 0

(27)

(28)

This problem is equivalent to ﬁnding a point ˆxmin ∈ IA which minimizes equation α0 +
i=1 αi ˆxi.
≥ 0 it means all points in IA are satisfying the constraints of
LP, and otherwise ˆxmin is a point which violates constraint 6. Since points in IA are equivalent

i=1 αi ˆxmin

i

Pn

If α0 +Pn

24

to pure strategies of player A, we can use algorithm FindBestPure to ﬁnd ˆxmin. Thus we can
conclude algorithm HyperplaneOracle correctly ﬁnds a violated constraint or reports that the
hyperplane satisﬁes constraints 6 of LP 5.

Algorithm 2 HyperplaneOracle
input: a, k, α0, α1, . . . , αk(a+1)
1: xmin ← FindBestPure(a, k, α0, α1, . . . , αk(a+1))
2: ˆxmin ← GA(xmin)

αi ˆxmin

i ≥ 0 then

3: if α0 +Pk(a+1)

return pass

i=1

4:
5: else
6:
7: end if

return α0 +Pk(a+1)

i=1

αi ˆxmin

i < 0

C.2 Best-response separating oracle

Algorithm 3 (BestRespOracle ) gets a pair (ˆx, U ) as input and decides whether there is a pure
strategy y = (y1, y2, . . . , yk) ∈ Y such that for ˆy = GB(y), we have

k

a

b

Xi=1

Xta=0

Xtb=0

We can rewrite inequality 29 as follows:

ˆxi,ta ˆyi,tbuA

i (ta, tb) < U.

(29)

k

b

ˆyi,tb

a

Xta=0

ˆxi,tauA

i (ta, tb) < U

Xtb=0
Xi=1
Therefore, by letting ci,tb = Pa
ˆymin ∈ IB which minimizes Pk(b+1)
constraint of LP 2 and if Pk(b+1)

i (ta, tb), this problem is equivalent to ﬁnd a point
i′ < U we have found a violating payoﬀ
i′ ≥ U , pair (ˆx, U ) satisﬁes all the payoﬀ constraints of LP
2. Thus, by Lemma C.1 we conclude that algorithm BestRespOracle correctly ﬁnds a violating
payoﬀ constraint of LP 2 or reports that (ˆx, U ) satisﬁes all the payoﬀ constrains.

ci′ ˆyi′. If Pk(b+1)

ta=0 ˆxi,tauA

ci′ ˆymin

ci′ ˆymin

i′=1

i′=1

i′=1

D Proofs Ommitted from Appendix A

Proof of Lemma A.1: We need Lemmas D.1 and D.2 for proving Lemma A.1.

r=1 αrGA(xr).

r=1 αr = 1, and
r=1 αrxr be a mixed strategy that plays strategy xr with probability αr, then GA(x) =

Lemma D.1 Let x1, x2, . . . , xt be t arbitrary mixed strategies of player A, Pt
x = Pt
Pt
Proof: Since x = Pt
have [GA(x)]j =Pt

r=1 αr[GA(xr)]j, for all 1 ≤ j ≤ n(A). Therefore, GA(x) =Pt

r=1 αrxr and GA(xr)j represent the probability that strategy xr plays j, we

r=1 αrGA(xr).

Lemma D.2 SA is a convex set.

25

Algorithm 3 BestRespOracle
input: a, b, k, U , ˆx1, . . . , ˆxk(a+1)
1: for i ← 1 to k do
2:

for tb ← 0 to b do

3:

ta=0 ˆxi,ta uA

i (ta, tb)

end for

c(i−1)(b+1)+tb +1 = ci,tb =Pa

4:
5: end for
6: ymin ← FindBestPure(b, k, c0, c1, c2, . . . , ck(b+1))
7: ˆymin ← GB(ymin)
ci ˆymin
return pass

i ≥ U then

8: if Pk(b+1)

i=1

9:
10: else
11:
12: end if

return Pk(b+1)

i=1

ci ˆymin

i < U

Proof: A set of points is convex if and only if every segment joining two of its points is completely
n(A)) be two points in Rn(A). We show
in the set. Let ˆx = (ˆx1, ˆx2, . . . , ˆxn(A)) and ˆx′ = (ˆx′
that if ˆx, ˆx′ ∈ SA then for every 0 ≤ α ≤ 1, ˆx′′ = (αˆx + (1 − α)ˆx′) ∈ SA.
Since ˆx and ˆx′ are in SA, there exist mixed strategies x and x′ in M(X ), such that ˆx = GA(x) and
ˆx′ = GA(x′). Let x′′ = αx + (1 − α)x′ be a mixed strategy of player A that plays x with probability
α and x′ with probability 1 − α. By Lemma D.1 we have GA(x′′) = αˆx + (1 − α)ˆx′ = ˆx′′ hence,
ˆx′′ ∈ SA.

2, . . . , ˆx′

1, ˆx′

Now we are ready to proof Lemma A.1. By Lemma D.2, we know SA is convex. We show that
we can ﬁnd a ﬁnite set of points in SA, such that every point in SA can be written as a convex
combination of these points. Note that, X = {X 1, X 2, . . . , X |X |} is the set of all pure strategies
of player A and IA = { ˆX 1, ˆX 2, . . . , ˆX |X |} is the set of points where ˆX i = GA(X i). Note that, IA
and X are ﬁnite sets. Every strategy of player A is either a pure strategy or a mixed strategy and
can be written as a convex combination of the pure strategies. Therefore, according to Lemma D.1
every point in SA is either in IA or can be written as a convex combination of points in IA. Hence,
SA forms a convex polyhedron in Rn(A).

Next we show that the number of vertices and facets of SA is O(2poly(n)). Let ˆx be a vertex of
polyhedron SA and x be a strategy of player A such that GA(x) = ˆx. Since ˆx is a vertex of SA, it
cannot be written as a convex combination of other vertices of SA. If x is a mixed strategy, it can
be written as a convex combination of other strategies and according to Lemma D.1, GA(x) can be
written as convex combination of other points of SA. This implies that either x is a pure strategy
or there exists a pure strategy x′ such that GA(x′) = ˆx. Therefore, the number of vertices of SA
is no more than the number of pure strategies of player A. Since each pure strategy of player A
is a partition of a units into k battleﬁelds the number of pure strategies is no more than (a + 1)k.
Thus, the number of vertices of SA is at most n(A)n(A).

Let d ≤ n(A) be the dimension of SA. Since every facet of SA can be uniquely determined by

d vertices of SA, the number of facets is no more than

(cid:18)|IA|
d (cid:19) ≤ (|IA|)d ≤ (n(A)n(A))d ≤ n(A)(n(A)2).

Proof of Lemma A.2: Note that the dimension of SA is not necessarily n(A). Let d be the
dimension of SA and H(SA) be the aﬃne hull of SA. Since H(SA) is a d-dimensional subspace of

26

Rn(A), it can be represented as the intersection of n(A) − d orthogonal hyperplanes. Let L be a set
of such hyperplanes. Let C be the set of all hyperplanes perpendicular to hyperplanes in L which
contain a facet of SA. We need Lemma D.3, Lemma D.4, Lemma D.5, and Lemma D.6 for proving
Lemma A.2.

Lemma D.3 There exists exactly one hyperplane perpendicular to all hyperplanes in L which con-
tains all points of a (d − 1)-dimensional subspace of H(SA).

Let O be the orthogonal basis of the (d − 1)-dimensional subspace and N be the set
Proof:
of normal vectors of hyperplanes in L. Since every vector in O is in H(SA), all vectors in O are
orthogonal to all vectors in N . Therefore, the desired hyperplane should be orthogonal to all vectors
N ∪ O. Since |N ∪ O| = n(A) − 1 and all vectors in N ∪ O are pairwise orthogonal, there exists
exactly one hyperplane containing the subspace and perpendicular to all hyperplanes in L.

Lemma D.4 There exists exactly one hyperplane perpendicular to all hyperplanes of L which con-
tain all points of some facet f of SA.

Since f is a facet of SA, its dimension is d − 1. Therefore, its aﬃne hull is a (d − 1)-
Proof:
dimensional subspace of H(SA). Note that, a hyperplane contains f if and only if it contains
aﬃne hull of f . Lemma D.3 states that there exists exactly one hyperplane perpendicular to
all hyperplanes of L that contains the aﬃne hull of f . Hence, there exists a unique hyperplane
containing f which is perpendicular to all hyperplanes of L.

Lemma D.5 For every point ˆx ∈ H(SA) which is not in SA, there exists a hyperplane perpendicular
to all hyperplanes in L, which contains a facet of SA and separates ˆx from SA.

Proof: Consider a segment between ˆx and one point of SA. Since one endpoint of the segment
is in SA and the other one is not, it has intersection with at least one facet of SA, namely f . By
Lemma D.4, there exists one hyperplane which contains f and is perpendicular to hyperplanes in
L. This hyperplane has intersection with the segment and separates ˆx from SA.

Lemma D.6 Point ˆx ∈ Rn(A) is in SA if and only if all hyperplanes in L contain ˆx and no
hyperplane in C separates ˆx from SA.

Proof: Since SA is in the intersection of all hyperplanes in L, if ˆx ∈ SA it is also in all hyperplanes
in L and obviously no hyperplane in C separates ˆx from SA. Now suppose ˆx /∈ SA, if ˆx /∈ H(SA),
then ˆx is not in all hyperplanes of L, otherwise by Lemma D.5 there exists a hyperplane in C that
separates ˆx from SA.

Now we are ready to prove Lemma A.2. By Lemma D.6 we conclude that set of hyperplanes in
L and C are suﬃcient to formulate SA. We know |L| is at most n(A), and by Lemma D.4 we can
ﬁnd out that |C| is equal to the number of facets of SA. Moreover Lemma A.1 states that |C| is
O(2poly(n)) which means |C| + |L| ∈ O(2poly(n)).

E Approximating the payoﬀ of the game

We can observe that in some dueling games the separation problem cannot be solved in polynomial
time. However, having a ﬁxed error threshold, it is possible to approximately solve the separation
problem in polynomial time. In this section we present a technique for approximating the payoﬀ
of the dueling games via providing an approximate solution for the separation problem.

27

We say a (not necessarily feasible) point ˆx is an ǫ-solution of the LP in a bilinear dueling game
where there exists a feasible strategy point ˆx′ such that |ˆx − ˆx′| ≤ ǫ and the minimum payoﬀ of
strategy ˆx diﬀers by at most ǫ from that of the MinMax strategies. Remark that, in the separation
problem we are given a linear constraint α0, α1, . . . and are to ﬁnd out whether there exists a

strategy point for a player which has the property α0 +Pi αi ˆxi ≥ 0. We say a separation oracle

solves this problem with approximation factor ǫ if it always ﬁnds such a point when there exists
a violating point having a distance of at least ǫ from the hyperplane. Note that, the approximate
oracle may not report a correct answer when the distance of all desired points to the hyperplane is
less than ǫ. We say a dueling game is polynomially ǫ-separable if we can approximately solve the
separation problem in polynomial time for every ǫ > 0. The following theorem provides a strong
tool for approximating the payoﬀ of the game in an NE for a broad set of dueling games.

Theorem E.1 Let B be a bilinear dueling game ranging over [0, 1]n(A) × [0, 1]n(B) (i.e. SA ⊂
[0, 1]n(A) and SB ⊂ [0, 1]n(B)) with payoﬀ matrix M and n = max{n(A), n(B)}. If we can solve the
ǫ-separation problem in time f (ǫ, n) then we can ﬁnd an ǫ-solution of the LP in time O(poly(n) ·

f (ǫ/β, n)), where β = max{1,Pi,j |Mi,j|}.

Suppose we solve LP 2 with Ellipsoid method using an ǫ/β-separating oracle instead of
Proof:
the exact oracle and let ˆx be the solution we ﬁnd. First we show that there exists at least one
feasible strategy ˆx′ such that |ˆx′ − ˆx| ≤ ǫ. Next, we will compare the minimum payoﬀ of ˆx′ with
that of the MinMax strategies. Remark that, in order to determine whether or not ˆx is within the
set of feasible strategy points we solve the following linear program (which is the same as LP 5
from the proof of Lemma A.3) and see if there is any violating constraint.

αj ˆxj < 0

αj ˆvj ≥ 0 ∀ˆv ∈ IA

α0 +Xj
α0 +Xj

(30)

Since the ǫ/β-separating oracle does not report any violating constrains for ˆx, either there is no
violating constrain or the distance of ˆx from all violating hyperplanes is less than ǫ/β. Therefore
there exists a point ˆx′ in the set of feasible solution such that |ˆx′ − ˆx| ≤ ǫ/β ≤ ǫ.
Next, we compare the minimum payoﬀ of strategy ˆx′ with the minimum payoﬀ of the MinMax

strategies. From the previous argument we have |ˆx′ − ˆx| < ǫ/β. Since β = Pi,j |Mi,j|, we have

|(ˆxM ˆy) − (ˆx′M ˆy)| < |ˆx′ − ˆx|.β < ǫ for each strategy ˆy of the second player. Moreover, since every
MinMax strategy is a potential solution of the linear program and ˆx is the solution which maximizes
the objective function, the minimum possible payoﬀ oﬀ ˆx is not less than the minimum possible
payoﬀ of the MinMax strategies. Thus, the diﬀerence between the minimum possible payoﬀ of ˆx′
and that of the MinMax strategies is at most ǫ.
Since we’re using Ellipsoid method, the number of times we call the ǫ-separation oracle is poly(n),
hence the running time of the algorithm is O(poly(n) · f (ǫ/β, n)).

Note that, Theorem E.1 states if we can ﬁnd an approximate solution of the separation problem
in polynomial time, then we can ﬁnd an approximate solution of the LP in polynomial time as well.
Since an approximate solution may not necessarily be a feasible strategy point, it cannot be used
in order to characterize the properties of the MinMax strategies. However, we can approximate the
payoﬀ of the players in an NE by computing the payoﬀs for the ǫ-solution of the LP.

28

