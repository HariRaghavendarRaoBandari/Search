Scale-Invariant Reconstruction of Separated

1

Sources

Zbynˇek Koldovsk´y and Francesco Nesta

1Faculty of Mechatronics, Informatics, and Interdisciplinary Studies, Technical University of

Liberec,

Studentsk´a 2, 461 17 Liberec, Czech Republic. E-mail: zbynek.koldovsky@tul.cz,

fax:+420-485-353112, tel:+420-485-353534

2Conexant System, 1901 Main Street, Irvine, CA (USA)

Abstract

Consider an array processing system that separates or identiﬁes a signal or a signal subspace up to an
unknown scaling factor. Sometimes it is necessary to cope with the scaling ambiguity, which can be done through
reconstructing the signal as it is received by sensors, because scales of the sensor responses have known physical
interpretations. In this paper, we propose computing the sensor responses using a scale-invariant formula that is
derived based on the assumption that the signal (subspace) of interest is uncorrelated with other components in
the original mixture. This approach is compared with a widely used one that assumes a regular mixing matrix
and computes its inverse. We show, through a theoretical perturbation analysis and simulations, that the former
approach is less sensitive to identiﬁcation errors and is more practical, because the whole mixing matrix need not
be identiﬁed. Moreover, in an underdetermined case, the approach is optimal in the mean-squared error sense.
Applications from the area of noise reduction in speech and de-noising of signals from electrocardiogram are
demonstrated.

Index Terms

Beamforming, Blind Source Separation, Independent Component Analysis, Principal Component Analysis, Independent

Vector Analysis

A. Mixture Model

I. INTRODUCTION

The linear instantaneous complex-valued mixture model

x = Hs

(1)

describes many situations where multichannel signals are observed, especially those considered in the ﬁeld of
array processing [1] and Blind Source Separation (BSS) [2], [3]. The vector x = [x1, . . . , xd]T represents d
observed signals on sensors, s = [s1, . . . , sr]T represents original signals, and H is a d × r complex-valued
matrix representing the linear mixing system. We will focus on the regular case when the number of the observed

6
1
0
2

 
r
a

 

M
4
1

 
 
]

D
S
.
s
c
[
 
 

1
v
9
7
1
4
0

.

3
0
6
1
:
v
i
X
r
a

2

signals r is the same as that of the original signals, but later in the article we will also address an undetermined
case where r > d. From this point forward, let H be a d × d full rank matrix.

Consider a situation where only a subset of the original signals is of primary interest (e.g., only one particular
source or the subspace spanned by some sources). Without a loss of generality, let s be divided into two
components [s1; s2] where the sub-vectors s1 and s2 have, respectively, length m and d − m, 1 ≤ m < d.
The former component will be referred to as target component, and the latter as interference. Correspondingly,
let H be divided as [H1 H2] where the sub-matrices H1 and H2 have dimensions d × m and d × (d − m),
respectively. Then (1) can be written as

x = H1s1 + H2s2.

(2)

The terms H1s1 and H2s2 correspond to the contributions of s1 and s2, respectively, for the mixture x, and
will be denoted as si (cid:52)
= Hi si, i ∈ {1, 2}. If, for example, s2 is not active, then x = s1, which is equal to the
observations of s1 on the sensors, that is, the sensor responses of s1.

In audio applications, s1 is often a scalar signal (m = 1) originating from a point source located in the
room. Its responses on microphones s1 are referred to as the source’s images; see [4], [5], [6]. In biomedical
applications, s1 (or s2) can consist of components related to a target activity such as muscular artifacts in
electroencephalogram (EEG) [7], maternal or fetal electrocardiogram (ECG) [8], and so forth.

In this paper, we address the problem of retrieving si from x, especially, with the aid of methods for Blind

Source Separation.

B. Blind Source Separation

The objective of BSS is to separate the original signals based purely on their general properties (independence,
sparsity or nonnegativity). In a general sense, BSS involves Principal Component Analysis (PCA), Indepen-
dent Component Analysis (ICA) [2], [9], Independent Vector Analysis (IVA) [10], [11], Nonnegative Matrix
Factorization [12], etc. Some methods separate all of the one-dimensional components of s [13], [14], extract
selected components only [15], or separate multidimensional components; see, e.g., [16], [17], [18], [19], [20].
The separation can also proceed in two steps where a steering vector/matrix (a part of the mixing matrix) is
identiﬁed ﬁrst, while the signals are separated in the second step using an array processor such as the minimum
variance distortion-less (MVDR) beamformer [21].

The separation or identiﬁcation are often not unique. For example, the order and scaling factors of the
separated components are random and cannot be determined without additional assumptions. Throughout this
paper, it is assumed that the problem of the random order has already been resolved [22], [23], [24].

To cope with the scaling ambiguity, it is possible to aim at reconstruction of the sensor responses of the
separated components [6]. The advantage is that si can be retrieved without prior knowledge of the scale of
si. The scale of si has clear physical interpretation (e.g., voltage), so the retrieval is highly practical.
Consider a demixing transform obtained by a BSS method as a regular d × d matrix W such that

WH = bdiag(Λ1, Λ2),

(3)

where Λ1 and Λ2 are arbitrary regular matrices representing the random scaling factors of dimensions m × m
and (d − m) × (d − m), respectively; bdiag(·) denotes a block-diagonal matrix with the arguments on its
block-diagonal. By applying W to x, the outputs are

Λ1s1

 =

Λ2s2

y1

 .

y2

3

(4)

y = Wx = WHs =

The components y1 = Λ1s1 and y2 = Λ2s2 are separated in the sense that each is a mixture only of s1 and
s2, respectively.

Let W1 and W2 be sub-matrices of W such that W = [W1; W2], and W1 contains the ﬁrst m rows of W,

i.e., y1 = W1x. From (3) it follows that WH = bdiag(W1H1, W2H2), so W1H2 = 0 and W2H1 = 0.

C. Reconstruction Using Inverse Matrix

Once demixing W is given, a popular approach to retrieve si, especially in the frequency-domain audio BSS,

proceeds using the inverse of W

(cid:52)
= W−1,

A

(5)

see, e.g., [5], [28]. Let A = [A1 A2] be divided in the same way as the system matrix H. The following
proposition gives a formula to compute (estimate) si from x using W [6].

Proposition 1: Assume that W is a demixing transform and A = [A1 A2] its inverse matrix. It holds that

for i ∈ {1, 2}.

Proof: By (3) it holds that Ai = HiΛ−1

i

. Then,

AiWix = si,

AiWix = AiWi(H1s1 + H2s2)

= AiWiHisi
= HiΛ−1

i Λisi = Hisi = si.

(6)

(7)

(8)

(9)

Readily it follows that (6) is independent of the scaling matrices Λ1 and Λ2.
One advantage is that the transform AiWi is purely a function of W and does not explicitly depend on
the signals or on their statistics. This makes the approach suitable for real-time processing [25]. Nevertheless,
there are two drawbacks. First, AiWi is a function of the whole W through the matrix inverse; it does not
depend solely on Wi, as one would expect when only si should be estimated. Formula (6) can thus be used
only if the whole demixing W is available. BSS methods extracting only selected components (e.g., one-unit
FastICA [13]) cannot be applied together with (6). Second, it simultaneously follows that potential errors in
the estimate of W2 can have an adverse effect on the estimation of s1.

The following section introduces an alternative approach to estimate si given only Wi. Section III contains
a perturbation analysis that studies cases where the demixing transform contains “small” errors. Section IV
studies properties of the proposed solution in underdetermined situations, that is, when there are more original

4

signals than the observed ones. Section V presents results of simulations, and, ﬁnally, Section VI demonstrates
two applications.

Let s1, . . . , sd be zero-mean complex random variables such that Cs

(cid:52)
= E[ssH ] exists and has the full rank.

II. PROPOSED SOLUTION

We will assume that s1 and s2 are not correlated, that is,

E[s1sH

2 ] = 0.

(10)

The idea behind the computation of si given only Wi is based on the fact that the missing complement of
Wi to the hypothetical regular demixing matrix W is already determined since (10) is fulﬁlled. The following
proposition introduces the formula, which is derived in Appendix A, and proves its validity.

Proposition 2: Consider the mixture model (2) where s1 and s2 satisfy (10). Let Wi be given such that
Wix = yi = Λisi where Λi is regular. It means that Wi satisﬁes WiHj = 0, j (cid:54)= i, and WiHi = Λi. Then,
it holds that

si = CWH

i (WiCWH

i )−1Wix,

(11)

where C

(cid:52)
= E[xxH ] is the covariance matrix of the observed data x.

Proof: According to (1) it holds that C = E[xxH ] = H CsHH. From (10) it follows that Cs has the
(cid:52)
= E[s1sH
1 ]
2 ] are regular (because Cs is assumed to be regular). Without a loss of generality, let i = 1.

same block-diagonal structure as the right-hand side of (3), so Cs = bdiag(Cs1 , Cs2 ) where Cs1
and Cs2
Since W1H = (Λ1 0),

(cid:52)
= E[s2sH

CWH

1 (W1CWH

= HCsHHWH

1 )−1W1x
1 (W1HCsHHWH
1 )−1Λ1s1

1 )−1W1Hs

= H1Cs1ΛH

1 (Λ1Cs1 ΛH

= H1s1 = s1.

(12)

(13)

(14)

(15)

The transform in (11) is independent of the scaling matrices Λ1 and Λ2. Indeed, when Wi is re-scaled as

Wi ← ΛWi by an arbitrary regular Λ, (11) remains the same as well as (6).

It is worth pointing out that (11) involves a matrix inverse, namely, of WiCWH

i . Nevertheless, this matrix
(actually, the covariance of yi) has a lower dimension than W and is more likely well conditioned so that the
computation of its inverse is numerically stable.

A. A Special Case m = 1

For the special case when the target component has dimension one, that is m = 1, W1 is a row vector that

separates s1 from x; let us denote Wi by w. To obtain s1, (11) takes the form

s1 =

CwH w
wCwH x.

(16)

This formula is, in particular, useful for the frequency-domain audio BSS [23], [26], [27], [28].

TABLE I

COMPARISON OF EXPRESSIONS (19) AND (21)

5

Expression (19)
Expression (21)

m = 1

1 + (d − 1)λ2
λ2
2(d − 1)λ2

2

1

m = d/2
d2
1 + λ2
4 (λ2
2)
d2
2 λ2
1

m = d − 1

(d − 1)2λ2

1 + (d − 1)λ2

2

2(d − 1)λ2

1

III. PERTURBATION ANALYSIS

Now, consider the transform matrices T1

Throughout this section it is assumed that W = H−1. Now, we perform an analysis of the sensor response
estimators (6) and (11) when W is known up to a small deviation. Let V = W +Ξ be the available observation
of W where Ξ is a “small” matrix; V1 will denote the sub-matrix of V containing the ﬁrst m rows; similarly
Ξ = [Ξ1; Ξ2]; A = V−1 and A1 contains the ﬁrst m columns of A.
(cid:52)
= CVH

1 )−1V1 estimating s1 from x,
respectively, deﬁned through (6) and (11). From here, the estimators (6) and (11) will be referred to as INV (an
estimator using system matrix INVerse) and SRR (Sensor Response Reconstruction), respectively. The analysis
resides in the computation of their squared distances (the Frobenius norm) from the ideal transform, that is,
from H1W1. Using ﬁrst-order expansions and neglecting higher-order terms, it is derived in Appendix B that
the following approximations hold.

(cid:52)
= A1V1 and T2

1 (V1CVH

(cid:107)H1W1 − T1(cid:107)2
(cid:107)H1W1 − T2(cid:107)2

F ≈ (cid:107)H Ξ H1W1 − H1Ξ1(cid:107)2
F ,

F ≈(cid:13)(cid:13)(cid:13)H1(Ξ1CWH

− H1Ξ1 − C ΞH

1 )C−1

s1

1 + W1C ΞH
1 C−1

W1

.

s1

(cid:13)(cid:13)(cid:13)2

F

W1

(17)

(18)

2I. Let the elements of Ξ all be independent
i . Then, the

As a particular case, let H = W = I, Cs1 = σ2

1I, and Cs2 = σ2

random variables with zero mean such that the variance of each element of Ξi is equal to λ2
expectation values of (17) and (18), respectively, are equal to

(cid:104)(cid:107)H1W1 − T1(cid:107)2
(cid:104)(cid:107)H1W1 − T2(cid:107)2

F

F

(cid:105) ≈ m2λ2
(cid:18)
(cid:105) ≈

1 +

E

E

(cid:19)
1 + m(d − m)λ2
2,
σ2
m(d − m)λ2
2
1.
σ2
1

Comparing (19) and (20) shows the pros and cons of the estimators. The latter depends on σ2

1, which
reﬂects the ratio between the power of s1 and that of s2. The expression (19) does not depend on this ratio
explicitly.

2/σ2

Assume for now that σ2

2/σ2

1 = 1, so (20) changes to

(cid:104)(cid:107)H1W1 − T2(cid:107)2

F

(cid:105) ≈ 2m(d − m)λ2

1.

E

Table I compares the expressions (19) and (21) in three different cases. For m = 1, which means that the target
2 (cid:29) λ2
component s1 is a scalar signal, INV is twice as accurate as SRR when λ2
1,
which means that the target component is estimated with higher accuracy than the interference, the accuracy
of INV is becoming deteriorated while that of SRR is independent of λ2
2.

2. However, when λ2

1 ≈ λ2

(19)

(20)

(21)

6

Fig. 1. Ratio between the expressions (19) and (21), that is, the relative mean-squared error of the estimation error by INV and SRR as
the function of λ2

2. The function is shown for the dimension d = 10.

1/λ2

For m = d/2 (assuming d is even), the estimators behave similarly when λ2

1 ≥ λ2

1 ≈ λ2
2. They thus perform
2 compared to INV when

approximately the same until λ2

2. SRR proﬁts from its independency of λ2

1.
2 > λ2
λ2
The last case, when m = d − 1, corresponds to a situation where the observed data are contaminated by a
1 and its accuracy is becoming worse with

scalar (low-dimensional) signal. Here, INV is more sensitive to λ2
the growing dimension d.

Fig. 1 shows the ratio of the expressions (19) and (21), i.e., the relative mean-squared error, as the function
2 while the accuracy of SRR is independent

2. It reveals the fact that INV suffers from large values of λ2

of λ2
1/λ2
of λ2
2.

IV. NOISE EXTRACTION FROM UNDERDETERMINED MIXTURES

A. Mixture Model

Now we focus on a more realistic scenario where a linear mixture of m signals of interest is observed through

d sensors and each observed signal is disturbed by noise. The mixture is described as

x = H1s1 + s2,

(22)
where H1 is a d × m matrix having full column rank, s1 is an m × 1 vector of target components, and s2 is
a d × 1 vector of noise signals. These models are often considered in frequency-domain audio noise reduction
systems [29]. The noise signals are assumed to be uncorrelated with s1, that is, the assumption (10) holds.
Note that, in this model, s2 is simultaneously equal to s2.

The mixture model corresponds with (1), but H is equal to [H1 Id×d] and has dimensions d × (m + d),

which makes the problem underdetermined. Since s1 and s2 are uncorrelated, the covariance of x reads

C = H1Cs1HH

1 + Cs2 .

(23)

−40−30−20−10010203040−20−1001020304010⋅log10(λ12/λ22) [dB]relative mean squared error [dB]  m=1m=d/2m=d−17

In general, a transform that separates s1 from x does not exist, unless (22) is implicitly regular (e.g., Cs2
has rank d − m)1. From now on, we focus on the difﬁcult case where, generally speaking, neither s1 nor s2
can be separated.

B. Target Signal Cancelation and Noise Scale Reconstruction

Since the separation of s1 is not possible, multichannel noise reduction systems follow an inverse approach:
the target components s1 are ﬁrst linearly canceled from the mixture in order to estimate a scaled version of
the noise components s2. Second, adaptive ﬁltering is used to subtract the noise from the mixture; see, e.g.,
[32], [33], [34], [35], [36], [37]. However, the scaling uncertainty makes the ﬁnal adaptive ﬁltering difﬁcult,
since the scaling needs to be estimated from the data.

Speciﬁcally, the cancelation of the target component is possible since m ≤ d and can be done using any W

such that

Since H1 has rank m, the maximum possible rank of W is d − m.

Assume for now that any such W having rank d − m has been identiﬁed (e.g., using BSS). We propose to

WH1 = 0.

(24)

apply (11) to estimate s2 as

(cid:98)s2 = CWH (WCWH )−1Wx.

(25)

An important property of the estimator is formulated by the following proposition.

Proposition 3: Let W be a transform matrix having rank d − m and satisfying (24). Among all estimators

of s2 of the form QWx where Q is a d × (d − m) matrix, (25) is a minimizer of

E(cid:2)(cid:107)(cid:98)s − s2(cid:107)2

F

(cid:3) .

(cid:98)s=QWx

min

Proof: Since W is orthogonal to H1, it holds that

(26)

(27)

(28)

The minimization problem (26) can be written as

Wx = Ws2,

and WC = WCs2.

min

Q∈Cd×(d−m)

=

min

Q∈Cd×(d−m)

(cid:3) =
E(cid:2)(cid:107)QWx − s2(cid:107)2
E(cid:2)(cid:107)QWs2 − s2(cid:107)2
(cid:3)
tr(cid:0)(QW − I)Cs2 (WH QH − I)(cid:1),

F

F

(29)
where tr(·) denotes the trace of the argument. Putting the derivative by the conjugate of Q equal to zero, the
condition for Q being a minimizer says that

Q∈Cd×(d−m)

min

=

QWCs2WH − Cs2WH = 0.

(30)

1For example, model (22) is often studied under the assumption that at most d signals out of s1 and s2 are active at a given time instant,

cf. [30], [31].

By putting Q = CWH (WCWH )−1, the transform matrix in (25), into (30) and using (27),

CWH (WCWH )−1WCs2WH − Cs2WH =

Cs2WH (WCs2WH )−1WCs2WH − Cs2WH = 0,

which concludes the proof.

V. SIMULATIONS

8

(31)

(32)

This section is devoted to extensive Monte Carlo simulations where the signals and system parameters are
randomly generated. Real and complex parts of random numbers are always generated independently according
to the Gaussian law with zero mean and unit variance. Each trial of a simulation consists of the following steps.

1) The dimension parameters d and m are chosen.
2) N = 104 samples of the original components s1 and s2 are randomly generated according to the Gaussian

law.

3) The mixing matrix H is generated, W = H−1, x = Hs, and C = xxH /N.

4) The estimation of W is simulated by adding random perturbations to its blocks, that is, (cid:99)W1 = W1 + Ξ1
and (cid:99)W2 = W2 + Ξ2, where the elements of Ξ1 and Ξ2 have, respectively, variances λ2
2; (cid:99)W =
[(cid:99)W1(cid:99)W2].
estimate (cid:99)W, is evaluated using the normalized mean-squared error deﬁned as

5) The accuracy of the reconstruction of s1 through (6) or (11) where W is replaced by the simulated

1 and λ2

NMSE =

F

,

(33)

(cid:107)H1W1 − T(cid:107)2

(cid:107)H1W1(cid:107)2

F

where T symbolizes the transform matrix in (6) or in (11) yielding the estimate of s1 as Tx.

The following subsection reports results of simulations assuming the determined model. The next subsection

considers the underdetermined model (22).

A. Determined model

1) Inﬂuence of the Estimation Errors in (cid:99)W: The experiment is done with d = 5 and m = 2; λ2

to one of four constants (10−1, 10−2, 10−3, and 10−4) while λ2
trials. The average NMSE achieved by INV and SRR are shown in Fig. 2.

2 is equal
1 is varied. Each simulation is repeated in 105

2 that controls the perturbation of (cid:99)W2. For example, for

The results of INV are highly inﬂuenced by λ2
2 = 10−1 and λ2
λ2
even if λ2
NMSE of INV decreases with decreasing λ2

1, which controls the perturbation of (cid:99)W1, is relatively “small”. For λ2

2 = 10−2, the method fails in the sense that the achieved NMSE is above 0 dB. This happens
2 = 10−4, the
1. However, the NMSE is lower bounded (does not improve as

1 → 0). All these results point to the dependency of INV on (cid:99)W2.

2 = 10−3 and λ2

λ2

The NMSE of SRR depends purely on λ2

1 (it is only
limited by the length of data which inﬂuences the accuracy of the covariance matrix C). In this experiment,
INV thus appears to be beneﬁcial compared to SRR only in situations where the whole (cid:99)W is a sufﬁciently
2 is higher than −14 dB.
SRR is outperformed by INV only in a few cases, namely, when λ2

1. It is always improved with the decreasing value of λ2

2 = 10−4 and λ2

1/λ2

accurate estimate of W.

9

Fig. 2. NMSE averaged over 105 trials where d = 5 and m = 2, λ2

2 is ﬁxed, and λ2

1 is varied.

Fig. 3. NMSE averaged over 105 trials as a function of d = 2, . . . , 20; here m = 1 and λ2

2 = 10−3.

-40-30-20-1001020304010·log10(λ12/λ22) [dB]-35-30-25-20-15-10-505101520mean NMSE [dB]INV, λ22=10-1SRR, λ22=10-1INV, λ22=10-2SRR, λ22=10-2INV, λ22=10-3SRR, λ22=10-3INV, λ22=10-4SRR, λ22=10-42468101214161820d-25-20-15-10-50510152025mean NMSE [dB]INV, λ12/λ22 = -10 dBSRR, λ12/λ22 = -10 dBINV, λ12/λ22 = 0 dBSRR, λ12/λ22 = 0 dBINV, λ12/λ22 = 10 dBSRR, λ12/λ22 = 10 dB10

Fig. 4. NMSE averaged over 105 trials where d = 20 and m = 1, . . . , 19.

2) Varying Dimension: In the situation here, the target component s1 has dimension one, i.e., m = 1, while
2 are ﬁxed, namely,
2 corresponds, respectively, to −10, 0, and 10 dB. The NMSE

the dimension of the mixture d is changed from 2 through 20. The variances λ2
2 = 10−3 and λ2
1 is chosen such that λ2
λ2
averaged over 105 trials is shown in Fig. 3.

1 and λ2

1/λ2

The NMSE values of both methods are increasing with growing d. In the INV case, the NMSE grows
smoothly until it reaches a certain threshold value of d. The experiments show that this threshold depends on
2. Above this threshold, the NMSE of INV abruptly grows. It points to a higher sensitivity of INV to
1 and λ2
λ2

the estimation errors in (cid:99)W when the dimension of data is “high”.

2 as well as the data dimension d are sufﬁciently small.

SRR yields smooth and monotonic behavior of NMSE for every d. It is outperformed by INV only if both
1 and λ2
λ2
3) Target Component Dimension: The dimension of the mixture d is now put equal to 20, while the dimension
of the target component m is varied from 1 through d − 1. Results for three different choices of λ2
1 and λ2
2
2 = 10−3 appears to be difﬁcult for both methods as they
are shown in Fig. 4. The scenario with λ2
2 corresponds to −10 dB (i.e.,
do not achieve NMSE below 0 dB. INV also fails when λ2
1 = 10−4) until m ≤ 17. This is in accordance with the results of the previous example that show that INV
λ2
2 and d are “too large”. The example here reveals one more detail: INV can beneﬁt from smaller
fails when λ2
perturbations of the target component (λ2
1 is larger, but the dimension of that component
must be large enough with respect to d.

1 = 10−4) even if λ2

1 = λ2

2 = 10−3 and λ2

1/λ2

1, λ2

24681012141618m-10-505101520mean NMSE [dB]INV, λ22=10-3, λ12/λ22 = -10 dBSRR, λ22=10-3, λ12/λ22 = -10 dBINV, λ22=10-4, λ12/λ22 = 0 dBSRR, λ22=10-4, λ12/λ22 = 0 dBINV, λ22=10-3, λ12/λ22 = 0 dBSRR, λ22=10-3, λ12/λ22 = 0 dB11

Fig. 5. Average NMSEs2 as a function of d achieved by the proposed estimator (25) in an experiment with the underdetermined model
(22); m = 1. MMSE denotes the minimum mean square error solution (35). The signals are generated as random complex Gaussian i.i.d.

SRR performs independently of λ2

in Fig. 4: these lines coincide as both correspond to the same λ2
by INV only when λ2
small.

1 = λ2

2, which is conﬁrmed by the cases that are plotted with solid and dashed lines
2). SRR is outperformed

2 = 10−4, which, again, occurs when the estimation error of the whole (cid:99)W is very

1 (although different λ2

B. Underdetermined model

In the example of this subsection, we consider the underdetermined mixture model (22) where m = 1 and
d = 2, . . . , 20. The goal is to examine the reconstruction of the noise components s2 through (25). H1 is
randomly generated. Then, W is such that its rows form a basis of the subspace that is orthogonal to H1
1 = 10k,
plus a random Gaussian perturbation matrix whose elements have the variance values equal to λ2
k = −2,−3, . . . ,−6, respectively. After applying (25), the evaluation is done using the normalized mean
square distance

(cid:107)s2 −(cid:98)s2(cid:107)2

F

where(cid:98)s2 is the estimate of s2.
Owing to the statement of Proposition 3, it is worth comparing the NMSEs2 of(cid:98)s2 with that of the minimum

NMSEs2 =

(cid:107)s2(cid:107)2

F

,

(34)

mean square error (MMSE) solution [1] deﬁned as the minimizer of

(cid:107)s2 − Qx(cid:107)2
F ,

min
Q∈Cd×d

(35)

2468101214161820d-14-12-10-8-6-4-2024mean NMSEs2 [dB]MMSEλ12 = 10-2λ12 = 10-3λ12 = 10-4λ12 = 10-5λ12 = 10-612

The oracle approach: SNR improvement, SDR and TDR averaged over used channels as functions of SNRin. The RTFs are

Fig. 6.
estimated from two seconds of noise-free learning segment using the conventional time-domain RTF estimator.

SNR improvement, SDR and TDR averaged over used channels as functions of SNRin. The RTFs are estimated using the

Fig. 7.
frequency-domain BSS method from the 2-second learning interval mixed with Gaussian noise at the given SNRin.

which gives the minimum achievable value of NMSEs2; cf. (26).

The results averaged over 103 independent trials are shown in Fig. 5. One observation is that NMSEs2
achieved through (25) approaches that of the MMSE solution (35) as λ2
1 approaches zero. Next, NMSEs2
improves with growing dimension d, but it appears that it stops improving at a certain d and grows beyond this
1 = 10−4, the NMSEs2 is decaying until d = 8
threshold value, which depends on λ2
and grows beyond d > 10.

1. For example, when λ2

-20-1001020SNRin [dB]246810121416SNR improvement [dB]2 mics3 mics4 mics5 mics6 mics7 mics8 mics-20-1001020SNRin [dB]-10-505SDR [dB]-20-1001020SNRin [dB]3.544.555.566.5TDR [dB]-20-1001020SNRin [dB]051015SNR improvement [dB]2 mics3 mics4 mics5 mics6 mics7 mics8 mics-20-1001020SNRin [dB]-6-4-2024SDR [dB]-20-1001020SNRin [dB]01234TDR [dB]13

A. Noise Reduction in Speech

VI. APPLICATIONS

1) Mixing model: A multi-microphone recording of a speaker’s voice that is disturbed by ambient noise can,

in the time-domain, be described through

xj(n) = hj(n) ∗ s(n) + yj(n),

j = 1, . . . , d,

(36)

where n is the sample index, xj(n) is the signal observed on the jth microphone, d is the number of microphones,
s(n) denotes the speaker’s voice signal, ∗ denotes the convolution operator, hj(n) denotes the acoustic impulse
response (AIR) between the speaker and the jth microphone, and yj(n) is the noise signal on the jth microphone.
After applying the Discrete Fourier Transform to a segment of signals, the convolution is approximated by
multiplication, and the (36) turns to a set of underdetermined models (22), one for each frequency bin. Adopting
the notation from (22), the frequency-domain model of the recording is

x(k) = H1(k)s(k) + s2(k),

(37)

where s(k) is the kth frequency component of s(n) (standing for the variable s1 in (22)); H1(k) is a column
vector stacking frequency components of the transfer functions of h1(n), . . . , hd(n); and s2(k) consists of the
frequency components of y1(n), . . . , yd(n).

We consider an experiment where 6 seconds of female utterance from SiSEC 2013 [38] are taken as the target
signal s(n); the sampling frequency is 16 kHz. Two seconds of the signal are for learning and four seconds
for evaluations. Next, eight AIRs were taken from the database [39] corresponding to the speaker position that
is 2 meters distant from a linear array of eight microphones with 8-cm spacings; the reverberation time is
T60 = 360 ms. Eight-channel babble noise recording was obtained during a social evening in a meeting room.
Then, the speech signal was convolved with the AIRs and mixed with the noise at a chosen signal-to-noise
ratio (SNRin).

2) Noise Reduction Method: The mixture was processed in the short-term Fourier transform (STFT) domain
as follows. Let d be the number of used microphones, d = 2, . . . , 8, and L be the length of the STFT analysis
window; k = 0, . . . , L − 1.
1) For i = 1, . . . , d − 1, the relative transfer function (RTF) between the ith and the (i + 1)th microphone
is estimated. The RTF is deﬁned as the ratio between the transfer functions of hi+1(n) and hi(n), see,
e.g., [40], [41], [42]. The RTF estimators used here will be discussed below. Let H i
RTF(k) denote the ith
estimated RTF.

2) The RTFs are used to form (d − 1) × d blocking matrices W(k) deﬁned by



Wij(k) =

H i
RTF(k)
− exp{−2π

√−1Dk

L

}

0

j = i

j = i + 1

otherwise

(38)

D is an integer delay introduced within the RTF estimates due to causality issues. W(k) is thus designed
to block the speech signal, i.e., to be orthogonal to H1(k). The rank of W(k) is equal to d − 1.

14

3) The covariance matrix C(k) of x(k) is estimated. Possible singularity of C(k) can be treated by adding

a “small” multiple of the identity matrix to it [1].

4) The noise term s2(k) is estimated using (25), that is,

(cid:98)s2(k) = C(k)WH (k)·

5) An approximate single-channel Wiener ﬁlter [43] is used to attenuate the noise on each channel as follows:

(W(k)C(k)WH (k))−1W(k)x(k).

(39)

The gain for the kth frequency and the jth microphone is computed as

max{|[x(k)]j|2 − |[(cid:98)s2(k)]j|2, }

E[|hj(n) ∗ s(n)|2]

E[|(cid:98)sj(n) − hj(n) ∗ s(n)|2]
E[|(cid:101)sj(n) − hj(n) ∗ s(n)|2]

E[|hj(n) ∗ s(n)|2]

,

Gj(k) =

(40)
where [·]j denotes the jth element of the argument;  is a small positive constant to avoid division by zero.
Then, the kth frequency component of the noise-free speech signal on the jth microphone, is estimated

as (cid:98)sj(k) = Gj(k)[x(k)]j. Inverse STFT is applied to the outputs to obtain the time-domain signals on

|[x(k)]j|2 + 

,

which the evaluation proceeds.

Two methods for the RTF estimation (Step 2) were considered: an oracle and a BSS one. The oracle method
estimates the RTFs from the 2-s learning segment that is free of noise, using the time-domain least-squares
estimator [44], [45]. The BSS method is based on the frequency-domain BSS algorithm that estimates the RTF
using the constrained natural gradient algorithm [28]. It is applied to the learning segment that is mixed with
eight-channel Gaussian white noise2. The BSS permutation problem is resolved using the knowledge of the
direction from which the speech signal arrives (0◦).

3) Evaluation: The SNR is measured at the output of the noise-reduction method, and the average over
d channels is taken. Since this criterion does not reﬂect possible distortions of the output signals, we also
show two additional criteria: the signal-to-distortion ratio (SDR) and the signal-to-target-distortion ratio (TDR),
respectively, deﬁned as

SDRj =

,

(41)

where(cid:98)sj(n) denotes the time-domain counterpart of(cid:98)sj(k), which is the estimate of hj(n)∗ s(n), and(cid:101)sj(n) is
the speech-only component of(cid:98)sj(n).

TDRj =

(42)

Often, an SNR improvement after applying the single-channel Wiener ﬁlter (40) is achieved with certain loss

in SDR and/or TDR. It is therefore necessary to take into account all of these three criteria simultaneously.

4) Results: Figures 6 and 7 show results as functions of SNRin, respectively, when the RTFs are estimated

by the oracle and BSS methods.

The SNR improvement grows with the number of used microphones for any level of SNRin. The highest
SNR improvements are mostly achieved in low SNRin situations, i.e., when SNRin < 0 dB. This could be

2We do not consider the situation when the RTFs are blindly estimated from signals mixed with (multi-source) babble noise, because

such a problem is highly challenging (especially for SNRin ≤ 0 dB) and goes beyond the scope of this paper.

15

explained by the fact that the signal is dominated by noise, so the action of the single-channel Wiener ﬁlter
mostly attenuates the noise, which improves the SNR. Therefore, it is important to also evaluate SDR and TDR.
The SDR mostly grows with SNRin up to a certain decrease in the case of the oracle RTF estimation when
SNRin ≥ 0. The TDR behaves similarly with the oracle method but it always grows with SNRin in the BSS
case. While SNR improvement grows with d, the TDR is decreasing, and similar behavior yields the SDR
when SNRin ≥ 0. This loss on SDR and TDR is the typical price for the high SNR improvement, here,
particularly achieved when d > 3. A trade-off between SDR/TDR and SNR improvements is possible using
other parameterized single-channel ﬁlters; see, e.g., [43].

Comparing the oracle and the BSS variants of the experiment, the latter is naturally not as accurate as the
former. The performance is lower due to less accurate RTF estimates computed through BSS from noisy signals.
Less accurate RTFs cause target signal leakage into (39), which results in a noticeable drop in SDR/TDR after
applying the single-channel Wiener ﬁlter [36].

B. De-noising of Electrocardiogram

Fig. 8 shows two seconds of a recording from a three channel electrocardiogram (ECG) of a Holter monitor,
which was sampled at 500 Hz. The recording is strongly interfered with a noise signal originating from the
Holter display. The fundamental frequency of the noise is 37 Hz, and the noise contains several harmonics.

Since the noise is signiﬁcantly stronger than the ECG components, Principal Component Analysis (PCA)
can be used to ﬁnd a demixing transform that separates the noise from the mixture. Therefore, we take the
eigenvector corresponding to the highest eigenvalue of the covariance matrix of the recorded data (the principal
vector) as the separating transform. Then, the noise responses on the electrodes are computed using (11) and
subtracted from the original noisy recording.

To compare, we repeated the same experiment using the vector obtained through Independent Component
Analysis (ICA). One-unit FastICA [13] with tanh(·) nonlinearity was used to compute the vector separating
the noise component. To avoid the permutation ambiguity, the algorithm was initialized from [1 1 1], because
the noise appears to be uniformly distributed over the electrodes.

Figures 9 and 10 show the resulting signals where the estimated sensor responses of the noise component were
removed, respectively, through PCA and ICA. Both results show very efﬁcient subtraction of the noise. A visual
inspection of the detail in Fig. 9 shows certain residual noise that does not appear in Fig. 10. In conclusion,
ICA estimates the separating vector with higher accuracy than PCA, which results in a more efﬁcient noise
suppression.

VII. CONCLUSIONS

We have proposed a new estimator of sensor responses for sources that were separated from a multichannel
signal up to an unknown scaling factor. The estimator is scale invariant and depends purely on the transform
separating the source and on the covariance matrix of the multichannel signal. Simulations and perturbation
analysis have shown that the estimator is less sensitive to identiﬁcation errors of the separating transform,
which makes it more practical than the conventionally used method exploiting the whole demixing matrix.

16

Fig. 8. A two-second sample of a three channel electrocardiogram interfered by a noise signal originating from a Holter display.

Fig. 9. Cleaned data from Fig. 8 after the subtraction of noise responses that were estimated through the main principal component and
(11).

00.20.40.60.811.21.41.61.82time [s]0123# electrode00.20.40.60.811.21.41.61.82time [s]00.511.522.533.5# electrode17

Fig. 10.

Cleaned data from Fig. 8 after the subtraction of noise responses that were estimated using the one-unit FastICA and (11).

The estimator possesses the mean-squared error optimality formulated by Proposition 3, which was shown to
be very practical when estimating noise within underdetermined mixtures. The noise-reduction applications in
speech signal and electrocardiogram processing have demonstrated the wide applicability of the estimator in
array signal processing.

APPENDIX A: THE WAY TO DERIVE (11)

Without a loss of generality, assume that W1 be given such that W1H = (Λ1 0), so W1x = Λ1s1. W1

could be seen as the upper part of a regular d × d transform W whose structure is

W1

 ,

B

where B has full row rank equal do d − m. Then,

W =

W1x

 =



Bx

Wx =

 =

 .

y1

y2

(43)

(44)

Λ1s1

BH1s1 + BH2s2

Now, it can be seen that, under the assumption (10), it holds that W satisﬁes (3), i.e., it is a separating transform,
if and only if E[y1yH

2 ] = 0. The latter condition requires that

BCWH

1 = 0,

(45)

which means that the rows of B are orthogonal to the columns of CWH
form

1 . It can be veriﬁed that any B of the

B = Q(I − CWH

1 (W1CCWH

1 )−1W1C),

(46)

00.20.40.60.811.21.41.61.82time [s]0123# electrodewhere Q can be an arbitrary (d − m) × m full-row-rank matrix such that B has full row-rank, meets the
condition (45).

Now, (6) can be applied, for which A1 must be computed. A1 consists of ﬁrst m columns of A = W−1,

so it satisﬁes

18

W1A1 = I,
BA1 = Q(I − CWH

(47)

1 (W1CCWH

1 )−1W1C)A1 = 0.

(48)
1 R where R is a m × m matrix. To satisfy also (47), we

1 )−1. By putting A1 into (6), (11) is obtained.

The latter equation is satisﬁed whenever A1 = CWH
select R = (W1CWH

1 )−1, hence A1 = CWH

1 (W1CWH

APPENDIX B: ASYMPTOTIC EXPANSIONS

Computation of (17)

Let E contain ﬁrst m columns of the d × d identity matrix. It follows that

HE = H1,

EHW = W1,

AE = A1,

EH V = V1.

To derive an approximate expression for A, we will use the ﬁrst-order expansion

A = V−1 = (W + Ξ)−1 = (I + HΞ)−1H

≈ (I − HΞ)H = H − HΞH.

(49)

(50)

Now we apply this approximation and neglect terms of higher than the ﬁrst order.

(cid:107)H1W1 − A1V1(cid:107)2

F =(cid:13)(cid:13)H1W1 − AEEH V(cid:13)(cid:13)2

(cid:13)(cid:13)H1W1 − (H − HΞH)EEH (W + Ξ)(cid:13)(cid:13)2

F ≈

(cid:107)H1W1 − (H1 − HΞH1)(W1 + Ξ1)(cid:107)2

F =
F ≈

We start with the ﬁrst approximation

Computation of (18)

(cid:13)(cid:13)H1W1 − CVH

1 (V1CVH

1 )−1V1

(cid:13)(cid:13)2
F =(cid:13)(cid:13)(cid:13)H1W1 − C(WH
(cid:13)(cid:13)(cid:13)H1W1 − C(WH

1 + ΞH

· ((W1 + Ξ1)C(WH

1 + ΞH
1 )
1 ))−1(W1 + Ξ1)

(cid:13)(cid:13)(cid:13)2

F

1 + ΞH
1 )

· (W1CWH

1 + Ξ1CWH

1 + W1CΞH

1 )−1(W1 + Ξ1)

.

(52)

(cid:107)HΞH1W1 − H1Ξ1(cid:107)2
F .

(51)

≈

(cid:13)(cid:13)(cid:13)2

F

Since W is now the exact inverse of H, it holds that W1CWH
of the matrix inverse inside the expression,

1 = Cs1. By applying the ﬁrst-order expansion

(cid:13)(cid:13)(cid:13)H1W1 − C(WH

19

.

(53)

(54)

1 + ΞH

Ξ1CWH

1 )(I + C−1
+ C−1

s1

s1

W1CΞH

(cid:13)(cid:13)(cid:13)H1W1 − C(WH

1 +
1 )−1C−1

s1

(W1 + Ξ1)

1 + ΞH

1 )(I − C−1

s1

(cid:13)(cid:13)(cid:13)2

F

≈
1 −
Ξ1CWH
− C−1

s1

(cid:13)(cid:13)(cid:13)2

F

(W1 + Ξ1)

W1CΞH

1 )C−1

s1

Since,

CWH

1 C−1

s1

W1 = H bdiag(Cs1 , Cs2 )HHWH

1 C−1

s1

W1

the zero order term in (53) vanishes. By neglecting higher than the ﬁrst-order terms, (18) follows.

= H1W1,

ACKNOWLEDGMENTS

This work was supported by The Czech Science Foundation through Project No. 14-11898S and partly by

California Community Foundation through Project No. DA-15-114599.

We thank BTL Medical Technologies CZ for providing us the three-channel ECG recording.

REFERENCES

[1] H. L. Van Trees, Optimum Array Processing: Part IV of Detection, Estimation, and Modulation Theory, John Wiley & Sons, Inc.,

2002.

[2] P. Comon and C. Jutten, Handbook of Blind Source Separation: Independent Component Analysis and Applications, Academic Press,

2010.

[3] J.-F. Cardoso, “Blind signal separation: statistical principles”, Proceedings of the IEEE, vol. 90, n. 8, pp. 2009-2026, October 1998.
[4] Vincent, E., Gribonval, R., and C. F´evotte, “Performance Measurement in Blind Audio Source Separation,” IEEE Trans. on Speech

and Audio Processing, Vol 14, No. 4, pp. 1462–1469, July 2006.

[5] S. Ukai, T. Takatani, H. Saruwatari, K. Shikano, R. Mukai, H. Sawada, “Multistage SIMO-based Blind Source Separation Combining

Frequency-Domain ICA and Time-Domain ICA, IEICE Trans. Fundam., E88-A, no. 3, pp. 642–650, 2005.

[6] K. Matsuoka and S. Nakashima, “Minimal distortion principle for blind source separation,” Proceedings of 3rd International
Conference on Independent Component Analysis and Blind Source Separation (ICA ’01), pp. 722-727, San Diego, Calif, USA,
Dec. 2001.

[7] S. Sanei and J. A. Chambers, EEG Signal Processing, Wiley, July 2007.
[8] L. De Lathauwer, B. De Moor, J. Vandewalle, “Fetal Electrocardiogram Extraction by Blind Source Subspace Separation”, IEEE
Transactions on Biomedical Engineering, Special Topic Section on Advances in Statistical Signal Processing for Biomedicine, vol.
47, no. 5, pp. 567–572, May 2000.

[9] A. Hyv¨arinen, J. Karhunen, and E. Oja, Independent Component Analysis, Wiley-Interscience, New York, 2001.
[10] T. Kim, I. Lee; T.-W. Lee, “Independent Vector Analysis: Deﬁnition and Algorithms,” The Fortieth Asilomar Conference on Signals,

Systems and Computers, pp. 1393–1396, 2006. doi: 10.1109/ACSSC.2006.354986

[11] M. Anderson, G. Fu, R. Phlypo, T. Adali, “Independent Vector Analysis: Identiﬁcation Conditions and Performance Bounds,” IEEE

Transactions on Signal Processing, vol. 62, no. 17, pp. 4399–4410, 2014.

[12] D. D. Lee and H. S. Seung, “Learning the parts of objects by non-negative matrix factorization,” Nature, vol. 401, pp. 788–791, Oct.

1999.

20

[13] A. Hyv¨arinen, “Fast and Robust Fixed-Point Algorithms for Independent Component Analysis”, IEEE Transactions on Neural

Networks, vol. 10, no. 3, pp. 626–634, 1999.

[14] J.-F. Cardoso and A. Souloumiac, “Blind Beamforming from non-Gaussian Signals,” IEE Proc.-F, vol. 140, no. 6, pp. 362-370, Dec.

1993.

[15] S. A. Cruces-Alvarez, A. Cichocki, and S. Amari, “From Blind Signal Extraction to Blind Instantaneous Signal Separation: Criteria,

Algorithms, and Stability,” IEEE Transactions on Neural Networks, vol. 15, no. 4, July 2004.

[16] D. Lahat, J.-F. Cardoso, and H. Messer, “Blind Separation of Multidimensional Components via Subspace Decomposition: Performance

Analysis,” IEEE Transactions on Signal Processing, vol. 62, no. 11, pp. 2894–2905, June 2014.

[17] A. Hyv¨arinen and U. K¨oster, “FastISA: A fast ﬁxed-point algorithm for independent subspace analysis,” In Proc. European Symposium

on Artiﬁcial Neural Networks, Bruges, Belgium, 2006.

[18] J. Cardoso, “Multidimensional independent component analysis,” in Proceedings of the 1998 IEEE International Conference on

Acoustics, Speech and Signal Processing, vol. 4, pp. 1941–1944, 12-15 May 1998.

[19] D. Lahat, J.-F. Cardoso, and H. Messer, “Second-order multidimensional ICA: performance analysis,” IEEE Transactions on Signal

Processing, vol. 60, no. 9, pp. 4598–4610, Sept. 2012.

[20] Z. Koldovsk´y and P. Tichavsk´y, “Time-domain blind separation of audio sources on the basis of a complete ICA decomposition of

an observation space”, IEEE Trans. on Speech, Audio and Language Processing, vol. 19, no. 2, pp. 406–416, Feb. 2011.

[21] J. Capon, “High-resolution frequency-wavenumber spectrum analysis,” Proc. of IEEE, vol. 57, no. 8, pp. 1408–1418, Aug. 1969.
[22] P. Tichavsk´y and Z. Koldovsk´y, “Optimal Pairing of Signal Components Separated by Blind Techniques”, IEEE Signal Processing

Letters, vol. 11, no. 2, pp. 119–122, 2004.

[23] H. Sawada, R. Mukai, S. Araki, and S. Makino, “A robust and precise method for solving the permutation problem of frequency-domain

blind source separation,” IEEE Trans. Speech Audio Processing, vol. 12, no. 5, pp. 530-538, 2004.

[24] T. Kim, H. T. Attias, S.-Y. Lee, T-W. Lee, “Blind Source Separation Exploiting Higher-Order Frequency Dependencies,” IEEE

Transactions on Audio, Speech, and Language Processing, vol. 15, no. 1, Jan. 2007.

[25] K. Matsuoka, “Elimination of ﬁltering indeterminacy in blind source separation,” Neurocomputing, vol. 71, pp. 2113-2126, 2008.
[26] S. Makino, Te-Won Lee, and H. Sawada, Blind Speech Separation, Springer, Sept. 2007.
[27] Parra, L., and Spence, C.: “Convolutive Blind Separation of Non-Stationary Sources”, IEEE Trans. on Speech and Audio Processing,

Vol. 8, No. 3, pp. 320-327, May 2000.

[28] F. Nesta and M. Matassoni, “Blind source extraction for robust speech recognition in multisource noisy environments,” Journal

Computer Speech and Language, vol. 27, no. 3, pp. 730–725, May 2013.

[29] J. Benesty, J. Chen, and E. Habets, Speech Enhancement in the STFT Domain, Springer Briefs in Electrical and Computer Engineering,

2011.

[30] F. Abrard, Y. Deville, “A time-frequency blind signal separation method applicable to underdetermined mixtures of dependent sources,”

Signal Processing, vol. 85, issue 7, pp. 1389–1403, July 2005.

[31] T-W. Lee, M. S. Lewicki, M. Girolami, T. J. Sejnowski, “Blind Source Separation of More Sources Than Mixtures Using Overcomplete

Representations,” IEEE Signal Processing Letters, vol. 6, no. 4, 1999.

[32] L. Grifﬁths and C. Jim, “An alternative approach to linearly constrained adaptive beamforming,” IEEE Trans. Antennas Propag., vol.

30, no. 1, pp. 27–34, Jan. 1982.

[33] J. Even, C. Ishi, H. Saruwatari, and N. Hagita, “Close speaker cancellation for suppression of non-stationary background noise
for hands-free speech interface,” Proc. of the 11th Annual Conference of the International Speech Communication Association
(Interspeech 2010), pp. 977-980, Makuhari, Chiba, Japan, September 26-30, 2010.

[34] O. Hoshuyama, A. Sugiyama, A. Hirano, “A robust adaptive beamformer for microphone arrays with a blocking matrix using

constrained adaptive ﬁlters,” IEEE Transactions on Signal Processing, vol. 47, no. 10, pp. 2677–2684, Oct. 1999.

[35] Y. Takahashi, T. Takatani, K. Osako, H. Saruwatari, K. Shikano, “Blind Spatial Subtraction Array for Speech Enhancement in Noisy

Environment,” IEEE Transactions on Audio, Speech, and Language Processing, vol. 17, no. 4, pp. 650–664, May 2009.

[36] S. Gannot, D. Burshtein, and E. Weinstein, “Signal enhancement using beamforming and nonstationarity with applications to speech,”

IEEE Trans. on Signal Processing, vol. 49, no. 8, pp. 1614–1626, Aug. 2001.

[37] S. Gannot and I. Cohen, “Speech Enhancement Based on the General Transfer Function GSC and Postﬁltering,” IEEE Trans. on

Speech and Audio Processing, vol. 12, No. 6, pp. 561–571, Nov. 2004.

[38] N. Ono, Z. Koldovsk´y, S. Miyabe, N. Ito, “The 2013 Signal Separation Evaluation Campaign,” Proc. of IEEE International Workshop

on Machine Learning for Signal Processing, Southampton, UK, Sept. 2013.

21

[39] E. Hadad, F. Heese, P. Vary, and S. Gannot, “Multichannel audio database in various acoustic environments,” International Workshop

on Acoustic Signal Enhancement 2014 (IWAENC 2014), Antibes, France, Sept. 2014.

[40] O. Shalvi and E. Weinstein, “System identiﬁcation using nonstationary signals,” IEEE Trans. Signal Processing, vol. 44, no. 8, pp.

2055-2063, Aug. 1996.

[41] K. Reindl, S. Markovich-Golan, H. Barfuss, S. Gannot, W. Kellermann, “Geometrically Constrained TRINICON-based relative transfer
function estimation in underdetermined scenarios,” IEEE Workshop on Applications of Signal Processing to Audio and Acoustics
(WASPAA), pp. 1–4, 2013.

[42] A. Krueger, E. Warsitz, and R. Haeb-Umbach, “Speech enhancement with a GSC-like structure employing eigenvector-based transfer

function ratios estimation,” IEEE Audio, Speech, Language Process., vol. 19, no. 1, Jan. 2011.

[43] I. Tashev, Sound Capture and Processing: Practical Approaches, John Wiley & Sons Ltd., 2009.
[44] Z. Koldovsk´y, J. M´alek, and S. Gannot, “Spatial Source Subtraction Based on Incomplete Measurements of Relative Transfer Function,”

IEEE/ACM Trans. on Speech, Audio and Language Processing, vol. 23, no. 8, pp. 1335–1347, Aug. 2015.

[45] Z. Koldovsk´y, P. Tichavsk´y, D. Botka, “Noise Reduction in Dual-Microphone Mobile Phones Using A Bank of Pre-Measured Target-

Cancellation Filters,” Proc. of ICASSP 2013, pp. 679–683, Vancouver, Canada, May 2013.

