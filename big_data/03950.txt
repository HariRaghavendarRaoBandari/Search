6
1
0
2

 
r
a

 

M
2
1

 
 
]
P
A

.
t
a
t
s
[
 
 

1
v
0
5
9
3
0

.

3
0
6
1
:
v
i
X
r
a

A Copula-Based Linear Model of

Coregionalization for Non-Gaussian

Multivariate Spatial Data

Pavel Krupskii and Marc G. Genton1

March 15, 2016

Abstract

We propose a new copula model for replicated multivariate spatial data. Unlike clas-
sical models that assume multivariate normality of the data, the proposed copula is based
on the assumption that some factors exist that aﬀect the joint spatial dependence of all
measurements of each variable as well as the joint dependence among these variables. The
model is parameterized in terms of a cross-covariance function that may be chosen from the
many models proposed in the literature. In addition, there are additive factors in the model
that allow tail dependence and reﬂection asymmetry of each variable measured at diﬀerent
locations and of diﬀerent variables to be modeled. Permutation asymmetry of diﬀerent vari-
ables can also be obtained, thus providing greater ﬂexibility. The likelihood of the model
can be obtained in a simple form and therefore the likelihood estimation is quite fast. We
use simulation studies to demonstrate the wide range of dependence structures that can be
generated by the proposed model with diﬀerent parameters. We apply the proposed model
to temperature and pressure data and compare its performance with the performance of a
popular model from multivariate geostatistics.

Some key words: Copula; Heavy tails; Spatial statistics; Tail asymmetry; Permutation
asymmetry.

Short title: A Copula-Based Linear Model of Coregionalization

1CEMSE Division, King Abdullah University of Science and Technology, Thuwal 23955-6900, Saudi

Arabia. E-mail: pavel.krupskiy@kaust.edu.sa, marc.genton@kaust.edu.sa
This research was supported by the King Abdullah University of Science and Technology (KAUST).

1

Introduction

Modeling spatial data is a challenging task as it often requires ﬂexible, but simple and

tractable models that can handle multivariate data. In many applications, models for mul-

tivariate spatial data are of interest for co-criging; see Furrer and Genton (2011) and ref-

erences therein. To set up the problem, we assume that we have a p-dimensional random

ﬁeld, Z(s) = {Z1(s), . . . , Zp(s)}T, deﬁned at locations s ⊂ Rd. In this case, several variables

are observed at diﬀerent locations and the main task is to model dependence both within

each variable, Zi(s), i = 1, . . . , p (at diﬀerent locations), and between diﬀerent variables.

If Z(s) is a mean-zero Gaussian multivariate random ﬁeld, only a covariance structure of

Z(s) is needed to completely characterize the dependence structure of the ﬁeld; i.e., the

cross-covariance functions Ci1,i2(s1, s2) = cov{Zi1(s1), Zi2(s2)} need to be modeled. A pop-

ular approach is to model a matrix of correlations for each variable and cross-correlations

of diﬀerent variables using a multivariate covariogram and a cross-variogram (Chil´es and

Delﬁner, 1999; Wackernagel, 2003) or using pseudo cross-variograms (Myers, 1991). The

linear model of coregionalization (LMC) has been widely used to model cross-covariances;

see Goulard and Voltz (1992), Wackernagel (2003), Gelfand et al. (2004), Apanasovich and

Genton (2010), and the review by Genton and Kleiber (2015) and references therein.

The LMC for a stationary Gaussian process with zero mean assumes a linear structure:

Zi(s) =

rXk=1

Aik ˜Zk(s),

where ˜Z1, . . . , ˜Zr are independent stationary Gaussian processes, so that

Ci1,i2(s1, s2) = Ci1,i2(s1 − s2) =

rXk=1

ρk(si1 − si2)Ai1kAi2k,

1 ≤ r ≤ p,

where A is a p × r full rank matrix and ρk(·) are valid stationary correlation functions.

1

Diﬀerent structures for the correlation functions have been proposed in the literature, such

as the Mat´ern covariance function; see for example Gneiting (2002) and Gneiting et al. (2007)

for a review of covariance functions. Parameters in the LMC can be estimated using the least

squares method (Goulard and Voltz, 1992) or using maximum likelihood (Zhang, 2007).

Despite its simplicity and tractability, the LMC focuses on modeling the cross-covariance

structure and may not be appropriate if the joint normality assumption is not valid for the

multivariate spatial data under consideration. This can happen, for example, with data

with strong joint dependence in the tails (i.e., when large/small values are simultaneously

observed more often than predicted by the model), or with data with reﬂection asymmetry

(i.e., when large values are simultaneously observed more often than small values, or vice

versa).

To overcome this problem, more ﬂexible copula-based models can be considered. Cop-

ulas have been used in a wide range of actuarial, ﬁnancial and environmental studies; see

Krupskii and Joe (2015a), Genest and Favre (2007), Patton (2006) and others. A copula is a

multivariate cumulative distribution function with univariate uniform U(0, 1) marginals; this

function can be used to link univariate marginals to construct the joint distribution function.

Sklar (1959) showed that for continuous univariate distribution functions, F1, . . . , Fn, and a

continuous n-dimensional distribution function, F , there exists a unique copula function, C,

such that F (z1, . . . , zn) = C{F1(z1), . . . , Fn(zn)} for any z1, . . . , zn.

Some copula-based models have been proposed in the literature to model univariate

spatial processes. One popular approach is to use vine copula models in which the joint

distribution is constructed using bivariate linking copulas and from which diﬀerent types

of dependence structures can be obtained; see Kurowicka and Cooke (2006) and Aas et al.

(2009) for details. The models using vine copulas have been applied to study climate,

2

geology, radiation and other spatial data; see Gr¨aler and Pebesma (2011), Gr¨aler (2014),

Erhardt et al. (2014) and others.

In these models, the dependence structure is selected

based on the likelihood, making interpretability diﬃcult. Moreover, likelihood estimation

can be quite slow in high dimensions.

Other copula models for univariate spatial data include copulas parameterized in terms

of pairwise dependencies, for instance a v-transformed copula of B´ardossy and Li (2008)

and a chi-squared copula of B´ardossy (2006). These copulas are constructed by using a non-

monotonic transformation of multivariate normal variables. As such, they cannot handle tail

dependence. Moreover, the likelihood function has no simple form and obtaining parameter

estimates in these models is a diﬃcult task. Recently, Krupskii et al. (2015) proposed a

factor copula model for spatial data that allows tail dependence and reﬂection asymmetry

to be modeled. Likelihood estimates in that model can be obtained quite easily with some

choice of the common factor, even if the number of locations is fairly large. However, to

the best of our knowledge, ﬂexible copula models have not yet been studied for multivariate

spatial data with replicates, i.e., when there are several variables repeatedly measured at

diﬀerent locations.

In this paper, we extend the approach of Krupskii et al. (2015) and propose a model

for stationary spatial data that combines the ﬂexibility of a copula modeling approach, the

interpretability of LMC, and the tractability of the Gaussian copula in high dimensions. The

model and the corresponding copula are based on the following multivariate random process:

Wi(s) = Zi(s) + αU

i0E U

0 + αU

i E U

i − αL

i0E L

0 − αL

i E L
i

(s ∈ Rd, i = 1, . . . , p),

(1)

where Zi(s) are cross-correlated Gaussian processes, αU

i ≥ 0 for identiﬁability and

i0, αU

i , αL

i0, αL

E U
i , E L

i , E U

0 , E L

0 ∼ Exp(1) are independent common factors with unit exponential distribution

3

that do not depend on the spatial location, s. This choice of the common factors allows

diﬀerent types of dependence structures to be generated and makes parameter estimation

in this model fairly easy. The joint dependence of the Gaussian processes, Zi(s), can be

modeled using LMC, and therefore the proposed model can be seen as an extension of LMC

that allows tail dependence and asymmetric dependence to be modeled. Of course, more

complex joint dependence of Zi(s) can be considered as well; see the review by Genton and

Kleiber (2015).

In our model, as well as in many other copula-based models, replicates are needed to

estimate dependence parameters. With diﬀerent sets of parameters in (1) models with the

same covariance and cross-covariance structures but with diﬀerent tail properties can be

obtained. Repeated measurements of the multivariate spatial process are thus needed to

estimate dependence both in the middle of the joint distribution and in its tails.

The remainder of paper is organized as follows. In Section 2, we describe the model (1)

in detail and study its dependence properties. We ﬁrst deﬁne the model in a general case

with p ≥ 2, and then, in the following sections, we provide more details about the bivariate

case, p = 2. In Section 3, we conduct a small simulation study to show the ﬂexibility of the

model when data are modeled both in the middle of the distribution and in the tails. More

details on the likelihood estimation and assessing the goodness of ﬁt of the estimated models

are given in Section 4. We discuss other choices of the common factors in (1) in Section 5

and also provide more details on the Pareto factors. We apply the proposed copula model

to bivariate spatial data of temperature and atmospheric pressure in Oklahoma, USA, in

Section 6, and we conclude with a discussion in Section 7.

4

2 Copula-Based Linear Model of Coregionalization

We use the following notation: Φ(·) is the cumulative distribution function of the univariate

standard normal random variable, whereas ΦΣ(·) is that of the multivariate standard normal

random vector with correlation matrix Σ. For simplicity, in the bivariate case with Σ12 = ρ,

we use the notation Φρ(·). Small symbols denote the corresponding densities.

We consider measurements of a random multivariate process by assuming that unobserved

random factors exist that aﬀect the joint dependence of all measurements of each variable

as well as the joint dependence between every two variables. Speciﬁcally, we construct the

corresponding copula by restricting model (1) to a ﬁnite set of locations s1, . . . , sn ∈ Rd.

Let {(W1j, . . . , Wpj)}n

j=1 be measurements of a p-variate spatial process that is observed at

n diﬀerent locations and let

Wij = Zij + αU

i0E U

0 + αU

i E U

i − αL

i0E L

0 − αL

i E L
i

(j = 1, . . . , n, i = 1, . . . , p),

(2)

where E U

i , E L

i , E U

0 , E L

0 ∼i.i.d. Exp(1) are exponential common factors that are independent

of Zij and where Z = (Z11, . . . , Z1n, . . . , Zp1, . . . , Zpn)T has a multivariate standard normal

distribution with some covariance matrix, ΣZ. Exponential factors allow ﬂexible dependence

structures to be generated such that parameter estimation becomes quite fast. We discuss

how other distributions of these factors aﬀect the dependence properties of the resulting

copula in Section 5. The structure of ΣZ depends on the model for Z; for example, one may

use LMC. The correlation structure of W depends on that of Z. For the i-th variable,

cor(Wi,j1, Wi,j2) =

cor(Zi,j1, Zi,j2) + (αU

i0)2 + (αU

i )2 + (αL

i0)2 + (αL

i )2

1 + (αU

i0)2 + (αU

i )2 + (αL

i0)2 + (αL

i )2

,

and for the i1-th and i2-th variables (i1 6= i2),

cor(Wi1,j1, Wi2,j2) =

cor(Zi1,j1, Zi2,j2) + αU
i10)2}{(αU

i10)2 + (αL

i10αU
i20 + αL
i20)2 + (αL

i20αL
i20
i20)2}]1/2 .

[{(αU

5

Note that cov(Zi,j1, Zi,j2) = 1 implies cov(Wi,j1, Wi,j2) = 1; this corresponds to perfect co-

monotonic dependence.

Let W = (W11, . . . , W1n, · · · , Wp1, . . . , Wpn)T and let F W

n,p and f W

n,p respectively be the

cumulative distribution function and probability density function of the vector W. The

function f W

n,p can be obtained in a simple form; we provide more details for p = 2 in Appendix

A.1. Let F W

1,i and f W

1,i respectively be the cumulative distribution function and probability

density function of Wi1 (i = 1, . . . , p). Let

ξ(z; αL

i , αU

i , αL

i0, αU

i0) =

(αU

i )3 exp(cid:8)0.5/(αU

i0 + αU

{(αL

i )(αL

i )2 − z/αU
i + αU

i )(αU

i(cid:9) Φ(z − 1/αU

i0 − αU

i )}

i )

.

One can show that

1,i (z) = Φ(z) + ξ(z; αL
F W

i , αU

i , αL

i0, αU

i0) − ξ(−z; αU

i , αL

i , αU

i0, αL
i0)

+ ξ(z; αL

i0, αU

i0, αL

i , αU

i ) − ξ(−z; αU

i0, αL

i0, αU

i , αL

i ).

Because F W

1,i (z) takes a simple form, the inverse function, (F W

1,i )−1(z), can be easily calculated

using numerical methods. Let ui = (ui1, . . . , uin)T, 0 ≤ uij ≤ 1, j = 1, . . . , n. The copula

and its density corresponding to the distribution of W (C W

n,p and cW

n,p , respectively) can then

be obtained as follows:

C W

n,p(u1, . . . , up) = F W

cW
n,p(u1, . . . , up) =

f W

1,1)−1(u1), . . . , (F W

n,d(cid:8)(F W
1,1(cid:8)(F W

1,1)−1(u1), . . . , (F W

n,p(cid:8)(F W
1,1)−1(u1)(cid:9) × · · · × f W

1,p)−1(up)(cid:9) ,
1,p)−1(up)(cid:9)
1,p(cid:8)(F W

1,p)−1(up)(cid:9) .

f W

(3)

Spatial data often have strong dependence in the tails and therefore a model that can

handle strong tail dependence is necessary. One standard approach to measure tail depen-

dence for a bivariate copula, C, is to use the lower and upper tail dependence coeﬃcients,

λL and λU , respectively:

λL = lim
q→0

C(q, q)/q ∈ [0, 1] and λU = lim
q→0

¯C(1 − q, 1 − q)/q ∈ [0, 1],

6

where ¯C(u1, u2) = 1 − u1 − u2 + C(u1, u2) is the survival copula. Copula C is said to have

lower (upper) tail dependence if λL > 0 (λU > 0). For the Gaussian copula, λL = λU = 0.

Models based on multivariate normality, such as the classical LMC, are therefore not suitable

for modeling data with strong tail dependence.

Dependence properties of copula C W

n,p depend on the choice of the parameters, αL

i , αU

i , αL
i0,

αU

i0 (i = 1, . . . , p). For the i-th variable, the proposed copula simpliﬁes to the one introduced

in Krupskii et al. (2015), with the common factor V0 = αU

i0E U

0 + αU

i E U

i − αL

i0E L

0 − αL

i E L
i .

In particular, it follows that the bivariate copula, C W

2,i, corresponding to the distribution of

(ui1, ui2), has lower and upper tail dependence with λL = 2Φ(cid:2)−{(1 − ρi
λU = 2Φ(cid:2)−{(1 − ρi

i(cid:3), where ρi

1,2 = cor(Zi1, Zi2), ˜αL

1,2)/2}1/2/ ˜αU

i = max(αL

max(αU

i , αU

i0). We now investigate dependence between two diﬀerent variables. Without loss

1,2)/2}1/2/ ˜αL

i , αL

i0) and ˜αU

i(cid:3) and

i =

of generality, we consider copula C W

2,1:2, corresponding to the distribution F W

2,1:2 of (u11, u21)

with ρ1:2

1,2 := cov(Z11, Z21).

We deﬁne ℓn(x1, x2) := n[1 − F W

2,1:2{(F W

1,1)−1(1 − x1/n), (F W

1,2)−1(1 − x2/n)}]. The limit

ℓ(x1, x2) := limn→∞ ℓn(x1, x2) is called the stable upper tail dependence function of the

limiting extreme value copula; see Segers (2012). We next show when copula C W

2,1:2 has

upper tail dependence and compute the limit ℓ(x1, x2). For simplicity, we assume that

αL
10 = αL

20 = αL

1 = αL

2 = 0. A similar result holds in the general case and for the lower tail as

well; however, in the case of tail dependence, the formula for ℓ(x1, x2) is more complicated

when the coeﬃcients αL

10, αL

20, αL

1 and αL

2 are nonzero.

Proposition 1 Let δ1 = αU

10/αU

1 , δ2 = αU

20/αU

2 and δ12 = δ1 +δ2. Denote by yi = xi(1−1/δi)

and δ∗

i = (δi − 1)−1 − (δ12 − 1)−1 (i = 1, 2). If min(δ1, δ2) < 1, copula C W

2,1:2 has no upper

tail dependence and ℓ(x1, x2) = x1 + x2.

If min(δ1, δ2) > 1, copula C W

2,1:2 has upper tail

7

dependence and, with ρ12 := {(αU

10)2 − 2ρ1:2

1,2αU

10αU

20 + (αU

20)2}1/2/(αU

10αU

20),

ℓ(x1, x2) =

δ1y1
δ1 − 1

+yδ2

2 y1−δ2

1

+yδ1

1 y1−δ1

2

log(y2/y1)

ρ12

(cid:27)

2

+

δ∗

ρ12

log(y1/y2)

(cid:27) +
Φ(cid:26) ρ12
2 exp(cid:8)0.5δ2(δ2 − 1)ρ2
1 exp(cid:8)0.5δ1(δ1 − 1)ρ2

δ∗

δ2y2
δ2 − 1

Φ(cid:26) ρ12

2

+

12(cid:9) Φ(cid:26)ρ12(0.5 − δ2) +
12(cid:9) Φ(cid:26)ρ12(0.5 − δ1) +

log(y1/y2)

ρ12

log(y2/y1)

ρ12

(cid:27)
(cid:27) .

(4)

The proof is given in Appendix A.2.

Remark 1. The limiting extreme value copula corresponding to C W

2,1:2 is CW

2,1:2(u1, u2) =

exp{−ℓ(− log u1, − log u2)}. When αU

1 = αU

2 = 0 and min(δ1, δ2) > 1, CW

2,1:2 is the H¨usler-

Reiss copula with parameter λ = ρ12; see H¨usler and Reiss (1989) for more details on the

H¨usler-Reiss bivariate distribution. In the general case, CW

2,1:2 is permutation symmetric if

and only if δ1 = δ2; that is, it is permutation symmetric if αU

1 αU

20 = αU

2 αU

10. Permutation

asymmetry of the extreme-value copula can be useful in applications for modeling data that

are permutation asymmetric in the tails. We provide more details on diﬀerent types of

dependence structures that can be obtained in the proposed model in the next section.

3 Dependence Properties

In this section, we conduct some simulation studies to show diﬀerent dependence structures

that can be obtained in our model. For simplicity, we consider the bivariate case. In (1) with

p = 2 and d = 1, we assume cov{Z1(s1), Z2(s2)} = exp(−θ0|s1 − s2|), cov{Zi(s1), Zi(s2)} =

0.5{exp(−θi|s1 − s2|) + exp(−θ0|s1 − s2|)}, i = 1, 2 and s1, s2 = 1, . . . , 5. This covariance

structure corresponds to a simple model for the bivariate process:

Zi(s) = 2−1/2{Z0(s) + Z ∗

i (s)},

(i = 1, 2),

8

where Z0(s), Z ∗

1 (s) and Z ∗

2 (s) are independent Gaussian processes with unit variance and

exponential covariance functions. In applications, more ﬂexible covariance structures can be

selected if needed. The proposed structure is used for illustration purposes whereas similar

results can also obtained for diﬀerent covariance structures.

Deﬁne αU = (αU

10, αU

1 , αU

20, αU

2 )T, αL = (αL

10, αL

1 , αL

20, αL

2 )T and θ = (θ0, θ1, θ2)T. We

consider three sets of dependence parameters, αU , αL and θ, that result in three models with

very similar dependence structures within variables 1 and 2; however, cross-dependencies

between variables 1 and 2 for these models are signiﬁcantly diﬀerent:

1. αU = (1.40, 0.50, 0.80, 0.00)T, αL = (0.80, 1.00, 0.60, 0.20)T, θ = (0.75, 0.10, 0.40)T;

2. αU = (1.20, 1.00, 0.80, 0.20)T, αL = (1.00, 0.80, 0.60, 0.20)T, θ = (0.75, 0.10, 0.40)T;

3. αU = (1.15, 1.05, 0.75, 0.50)T, αL = (1.10, 0.20, 0.60, 0.00)T, θ = (0.75, 0.10, 0.45)T.

For these sets of parameters, we deﬁne Wij as in (2) with the distance between s1 and

sj equal |j − 1|, i = 1, 2, j = 1, . . . , 5. We assess the strength of the dependence between

W11 and W1j (dependence within the ﬁrst variable), between W21 and W2j (dependence

within the second variable) and between W11 and W2j (dependence between two variables),

j = 1, . . . , 5. Speciﬁcally, we compute for these pairs of variables the Spearman’s ρ and

λq
L = λq

L(C) = C(q, q)/q, λq

U = λq

U (C) = CR(q, q)/q, q = 0.01, 0.05, 0.10, where C is the

corresponding copula for a given pair and CR(u1, u2) = −1 + u1 + u2 + C(1 − u1, 1 − u2) is

the reﬂected copula. The quantities λq

L and λq

U with small values of q are approximations

of the tail dependence coeﬃcients, λL and λU , respectively; therefore, we use them to assess

the strength of the dependence in the tails. We plot these quantities to compare dependence

structures generated by these three sets of parameters; see Fig. 1.

9

d
a
s
h
e
d

a
n
d

d
o
t
t
e
d

l
i

n
e
s
,

r
e
s
p
e
c
t
i
v
e
l
y
)

F
i
g
u
r
e

1
:

S
p
e
a
r
m
a
n
’
s

ρ

(
g
r
e
y

l
i

n
e
)
,

λ
qL

f
o
r

m
o
d
e
l

m
o
d
e
l

2

(

i

m
d
d
l
e
)

a
n
d
m
o
d
e
l

3

(
b
o
t
t
o
m

)
.

1
0

1

(
t
o
p
)
,

value of measure

value of measure

value of measure

0.0

0.2

0.4

0.6

0.8

1.0

0.0

0.2

0.4

0.6

0.8

1.0

0.0

0.2

0.4

0.6

0.8

1.0

0

1

2

3

4

0

1

2

3

4

V
a
r
i

a
b
e

l

 

1

0.0

0.2

0.4

0.6

0.8

1.0

0.0

0.2

0.4

0.6

0.8

1.0

0.0

0.2

0.4

0.6

0.8

1.0

0

1

2

3

4

0

1

2

3

4

V
a
r
i

a
b
e

l

 

2

0.0

0.2

0.4

0.6

0.8

1.0

0.0

0.2

0.4

0.6

0.8

1.0

0.0

0.2

0.4

0.6

0.8

1.0

0

1

2

3

4

0

1

2

3

4

V
a
r
i

a
b
e

l

 

 

1
a
n
d
2

 

i

d
s
t

a
n
c
e

i

d
s
t
a
n
c
e

i

d
s
t
a
n
c
e

0

1

2

3

4

0

1

2

3

4

0

1

2

3

4

λ
qU

(
r
e
d

l
i

n
e
)

a
n
d

(
g
r
e
e
n

l
i

n
e
)
,

w
i
t
h

q

=

0
.
1
0
,
0
.
0
5
,
0
.
0
1

(
s
o
l
i

d

,

Because θ1 < θ2 and the parameters αU

i0, αU

i , αL

i0, αL

i are larger for i = 1, the de-

pendence within the ﬁrst variable is stronger, both in the middle of the distribution

and in the tails. For both variables, the dependence in the upper tail is stronger since

max(αU

i0, αU

i ) > max(αL

i0, αL

i ) for i = 1, 2. In all three models, dependencies within the ﬁrst

and second variables are similar. This can be achieved by decreasing αU

i0 (αL

i0) and increasing

αU
i (αL

i ), or vice versa. At the same time, the dependence between variables is diﬀerent. For

model 1, αL

10 < αL

1 and therefore copula C W

2,1:j, corresponding to the distribution of W11 and

W2j, has no lower tail dependence. For models 2 and 3, αL

i0 > αL

i and αU

i0 > αU

i and therefore

copula C W

2,1:j has both lower and upper tail dependence. However, dependence in the upper

tail is stronger than that in the lower tail in model 2, and it is weaker in model 3. To decrease

the upper tail dependence (increase the lower tail dependence) between variables 1 and 2,

one can increase the values of αU

1 and αU

2 (decrease the values of αL

1 and αL

2 ) corresponding

to independent factors E U

1 and E U

2 (E L

1 and E L

2 , respectively), which are used to control the

strength of the tail dependence between variables. Thus, the proposed model allows the

strength of the dependence to be controlled, both in the middle of the distribution and in

the tails, in each variable as well as between diﬀerent variables.

4 Maximum Likelihood Estimation and Interpolation

4.1 The likelihood function

We now show how to obtain the maximum likelihood estimates for the copula parameters

in model (2). We assume that we observe N independent samples, w1, . . . , wN , from model

(2), where wk = (w1,k, . . . , wp,k)T, wi,k = (wi1,k, . . . , win,k)T (i = 1, . . . , p, k = 1, . . . , N)

with essentially arbitrary marginals, not necessarily given by cdfs F W

1,i . Here, vector wi,k

represents the k-th replicate of the i-th variable measured at n diﬀerent locations. To

11

estimate the copula parameters, we need to transform the data to a uniform scale, e.g.,

non-parametrically, as follows:

for each i = 1, . . . , p and j = 1, . . . , n, we can deﬁne the

uniform scores, uij,k = {rank(wij,k) − 0.5}/N (k = 1, . . . , N). We let zk = (z1,k, . . . , zd,k)T,

zi,k = (zi1,k, . . . , zin,k)T, zij,k = (F W

1,i )−1(uij,k; θF,i), where θF,i is a vector of parameters for

F W

1,i (i = 1, . . . , p, j = 1, . . . , n, k = 1, . . . , N). Because we use data transformed to uniform

scores, they are an approximation to U(0, 1) data. Therefore, the dependence parameters

can be estimated via a pseudo-likelihood function. As the number of replicates goes to

inﬁnity, N → ∞, the likelihood estimates are consistent and asymptotically normal provided

that the copula is correctly speciﬁed; see chapter 5.9 of Joe (2014) for details. Let θF =

(θF,1, . . . , θF,p)T. From (3), the pseudo log-likelihood is:

l(z1, . . . , zN ) =

NXk=1

log f W

n,p(z1,k, . . . , zp,k; θF , θΣ) −

NXk=1

pXi=1

nXj=1

log f W

1,i(zij,k; θF,i),

(5)

where θΣ is a vector used to parameterize the correlation matrix, ΣZ.

4.2 A conditional copula and interpolation

Let bθF , bθΣ be estimates of θF and θΣ, respectively. For a given vector of data (u1, . . . , up)T

and the new vector (corresponding to a new, (n + 1)-th, location), u0 = (u1,n+1, . . . , up,n+1),

on the uniform scale, where ui = (ui1, . . . , uin)T, i = 1, . . . , p, we can obtain the following

conditional distribution:

where u∗

0 = (u∗

1,n+1, . . . , u∗

p,n+1)T and u∗

i = (uT

i , u∗

i,n+1)T. The conditional distribution for the

p;bθF ,bθΣ)du∗

0

,

n,p(u1, . . . , up;bθF ,bθΣ)

0|n,p(u0|u1, . . . , up) := R u0
bC W

1, . . . , u∗

n+1,p(u∗
0 cW
cW

i-th variable is

i,0|n,p(ui,n+1|u1, . . . , up) = bC W
bC W

i|n,p(ui|u1, . . . , up),

12

where ui is a vector of length p such that (ui)i = ui,n+1, (ui)m = 1 for m 6= i. Using

this conditional distribution, we can calculate diﬀerent quantities of interest, including the

conditional expectation, bmi, or the conditional median, bq0.5,i, of the i-th variable:

i,0|n,p(˜u0, u1, . . . , up) d˜u0,

i,0|n,p)−1(0.5|u1, . . . , up),

bmi :=Z 1

0

˜u0bcW

bq0.5,i := (bC W

where

bcW

i,0|n,p(˜u0, u1, . . . , up) =

i,0|n,p(ui,n+1|u1, . . . , up)

=

∂ui,n+1

∂bC W

where ˜ui = u∗

i and ˜um = (um, 1) for m 6= i.

cW

cW

n+1,p(ui,n+1, ˜u1, . . . , ˜up;bθF ,bθΣ)

n,p(u1, . . . , up;bθF ,bθΣ)

,

If bGi is the estimated univariate marginal
i (bq0.5,i).

0|n,p(u0|u1, . . . , up) and the inverse function

distribution function for the i-th variable, we can transform the uniform data to the original

scale. For example, the predicted median on the original scale will be bz0.5,i = bG−1

Numerical integration can be used to compute C W

(C W

i,0|n,p)−1(q|u1, . . . , un) can then be used for data interpolation.

4.3 A simpliﬁed likelihood function for bivariate spatial data and

assessing goodness of ﬁt

In this section, we give more details about the likelihood estimation for bivariate spatial data.

Consider the exponential factor model with the same covariance structure as in Section 3.

Even this simple model has three covariance parameters, θ0, θ1, θ2, and eight dependence

parameters αU

i0, αL

i0, αU

i , αL

i , i = 1, 2. It might be diﬃcult to estimate all these parameters,

particularly if the sample size is not very large. The main reason is that diﬀerent sets of these

parameters may result in models with similar dependence structures. We therefore suggest

that the two parameters, αU

2 and αL

2 , be set to zero to avoid possible overparametrization. By

doing this, we avoid possible convergence problems when estimating parameters and make

the estimation faster as the likelihood function simpliﬁes in this case.

13

To illustrate these ideas, we consider the following bivariate model:

αU = (1.1, 0.9, 0.9, 0.8)T, αL = (0.7, 1.1, 0.7, 0.4)T, θ = (2.2, 0.8, 1.0)T.

To simulate spatial data, we use a 5×5 grid on [0, 1]×[0, 1] so that there are n = 25 locations

and cov(Z1j1, Z2j2) = exp{−θ0dist(s1j1, s2j2)}, cov(Zij1, Zij2) = 0.5[exp{−θidist(sij1, sij2)} +

exp{−θ0dist(sij1, sij2)}], i = 1, 2 and j1, j2 = 1, . . . , 5, where dist(s1, s2) is the distance

between location s1 and s2. We simulate N = 500 replicates from this model and then

estimate parameters in this model using the constrained likelihood with αU

2 = αL

2 = 0

(model 1). We then change the order of variables from the simulated data and again apply

the restricted likelihood with αU

2 = αL

2 = 0 (model 2). We then select the model with the

best ﬁt.

To compare the ﬁtted dependence structure with the data, we calculated the Spearman’s

correlation matrices for the simulated data set and for the estimated model. We denote these

matrices as ρS and ρMLE

S

for the data and estimated model, respectively. However, the Spear-

man’s ρ is not a good measure of dependence in the tails of a multivariate distribution. To

compare the tail behavior of the two models, we therefore used the tail-weighted measures of

dependence proposed by Krupskii and Joe (2015b). These measures are applied to data con-

verted to uniform scores and deﬁned as correlations of the transformed data. The measures

provide useful summaries of the strength of the tail dependence for each pair of variables,

with values close to 0 or 1 corresponding to very weak (strong, respectively) dependence in

the tails. Unlike many goodness-of-ﬁt procedures studied in the literature, the tail-weighted

measures of dependence give information on how the model can be improved to ﬁt the data

in the tails better. We denoted the estimated tail-weighted measures of dependence in the

lower/upper tail for the data with nonparametric estimates and for the estimated models as

14

̺L/̺U and αMLE

L

/αMLE

U

, respectively. We obtained the model-based estimates by simulating

data from the estimated models; we used the sample size N = 100, 000. We calculated

∆ρ

:=

∆L :=

∆U :=

1

1

n2Xn
n2Xn
n2Xn

1

j1,j2=1

j1,j2=1

j1,j2=1

[ρS − ρMLE

S

]j1,j2,

|∆ρ| :=

[̺L − ̺MLE

L

]j1,j2,

|∆L| :=

[̺U − ̺MLE

U

]j1,j2,

|∆U | :=

1

1

n2Xn
n2Xn
n2Xn

1

j1,j2=1

j1,j2=1

j1,j2=1

|[ρS − ρMLE

S

]j1,j2|,

|[̺L − ̺MLE

L

]j1,j2|,

|[̺U − ̺MLE

U

]j1,j2|.

The quantities deﬁned above are computed for variable 1, variable 2 (using pairs of the

same variable at diﬀerent locations) and variables 1 and 2 (using pairs of diﬀerent variables

at diﬀerent locations). For comparison, we also used the further simpliﬁed model with

αU

1 = αL

1 = αU

2 = αL

2 = 0 (model 3). We found that model 1 ﬁts data slightly better than

does model 2, both in terms of Spearman’s ρ and the tail-weighted measures of dependence,

αL and αU . We therefore report the results for model 1 with the best ﬁt. We also include

model 3, which had quite a bad ﬁt in the lower tail; see Table 1.

Table 1: ∆ρ, |∆ρ|, ∆L, |∆L|, ∆U , |∆U | for models 1 and 3. Simulated data were used to calculate these
values; the sample size was N = 100, 000.

∆ρ/|∆ρ|

∆L/|∆L|

∆U /|∆U |

Model 1; loglikelihood = 28906

Variable 1
Variable 2
Variables 1 and 2

−0.00/0.01
−0.01/0.02
0.00/0.02

−0.01/0.03
−0.05/0.07
−0.00/0.05

−0.02/0.03
−0.02/0.03
0.02/0.04

Model 3; loglikelihood = 28788

−0.03/0.03
Variable 1
Variable 2
−0.06/0.07
Variables 1 and 2 −0.07/0.07

−0.04/0.04
−0.15/0.15
−0.06/0.07

0.02/0.03
−0.12/0.12
0.08/0.08

Model 1 ﬁts the data quite well,

including the joint dependence of each variable at

diﬀerent locations and the dependence between the two variables. At the same time, model

15

3 underestimated the dependence in the lower and upper tails for variable 2. This is because

the dependence in the lower (upper) tail in variable 1, variable 2 and between variables 1

and 2 cannot be controlled when using only two dependence parameters, αL

10, αL

20 (αU

10, αU
20,

respectively). At least three parameters are needed to correctly specify dependencies in each

tail. We obtained similar results in models with diﬀerent sets of parameters and therefore

we recommend using the simpliﬁed model with αU

2 = αL

2 = 0, which adequately assesses the

strength of the dependence in bivariate spatial data.

5 Non-Exponential Common Factors

Possible extensions of the proposed model include models with the same structure as in (1)

and (2) but with a diﬀerent distribution for the variables E L

0 , E U

0 , E L

i and E U

i . For p = 1,

Krupskii et al. (2015) showed that if this distribution has heavy tails (for example, the

Pareto distribution), the resulting bivariate marginal copula for each variable will have strong

tail dependence with the tail dependence coeﬃcient equal to one. On the other hand,

distributions with light tails are not suitable for modeling tail dependence.

For a non-exponential distribution of the common factors, it is diﬃcult to obtain the joint

copula density in an easy form. Multidimensional integration may be required to calculate

the likelihood function. This makes parameter estimation quite complicated, especially if

the number of locations and/or variables is large. Nevertheless, in this section, we provide

some details for the case when E L

0 , E U

0 , E L

i , E U

i ∼i.i.d. Pareto(1, k), where k > 1 is a shape

parameter of the Pareto distribution and the scale parameter is equal to 1 (that is, the cdf

FPareto(x) = 1 − x−k for x ≥ 1). This case can lead to models with desirable properties in

some applications. For simplicity, we again assume that αL

10 = αL

20 = αL

1 = αL

2 = 0 and

consider only the case of upper tail dependence.

16

Proposition 2 Let θi = (αU

i /αU

i0)k and let θ∗

i = 1/(1 + θi), i = 1, 2. Then, ℓ(x1, x2) =

x1 + x2 − min{θ∗

1x1, θ∗

2x2}. It follows that the limiting extreme value copula CW

2,1:2(u1, u2) =

u1u2 min{u−θ∗

1

1

, u−θ∗

2

2 }; that is we have the Marshall-Olkin copula with parameters θ∗

1 and θ∗
2.

The proof is given in Appendix A.3, and the properties of the Marshall-Olkin copula

are discussed by Joe (2014). This result implies that copula C W

2,1:2(u1, u2) is permutation

asymmetric and has tail dependence and that the tail dependence coeﬃcient is less than

one. Based on this result, we can construct a model for a univariate spatial process with a

common factor and i.i.d. “Pareto noise”.

Corollary 1 Let Wj = Zj + αU

0 V0 + αU

1 Vj, j = 1, . . . , n, where Z1, . . . , Zn have multivariate

normal distribution with covariance matrix ΣZ and V0, V1, . . . , Vn ∼i.i.d. Pareto(1, k). We

assume that V0, V1, . . . , Vn are independent of Z1, . . . , Zn. It follows that copula C W

2 , corre-

sponding to the distribution of W1 and W2, has upper tail dependence and the upper tail

dependence coeﬃcient is λU = 1/{1 + (αU

1 /αU

0 )k}.

In this model, the nugget eﬀect is equal to N0 = (αU

1 )2var(V1)/{1 + (αU

0 )2var(V0) +

(αU

1 )2var(V1)} = (αU

1 )2/[(k − 1)2(1 − 2/k) + {(αU

0 )2 + (αU

1 )2}] for k > 2. Both N0 and

λU can be controlled, depending on the choice of parameters αU

0 , αU

1 , k, to achieve greater

ﬂexibility in the model. The model can be readily extended to get both lower and upper

tail dependence. However, as the next proposition shows, not all heavy-tailed distributions

are suitable for generating ﬂexible tail dependence similar to that in the univariate process

model described above. For simplicity, we again assume that αL

10 = αL

20 = αL

1 = αL

2 = 0.

Proposition 3 Assume that E U

0 , E U

1 , E U

2 ∼i.i.d. FE where FE belongs to the class of subex-

ponential distributions (Chistyakov, 1964). Denote ¯FE(w) = 1 − FE (w). Assume that, for

17

α > 1, ¯FE(αc) = o( ¯FE(c)) as c → ∞. If αU

0i < αU
i

for i = 1 or i = 2, then copula C W

2,1:2(u1, u2)

has no tail dependence; that is, the upper tail dependence coeﬃcient is λU = 0. If αU

i0 > αi

for i = 1, 2, then λU = 1.

The proof is given in Appendix A.4. One example of FE that satisﬁes the assumptions

of Proposition 3 is the Weibull distribution with shape parameter 0 < κ < 1. This proposi-

tion implies that Weibull factors cannot generate ﬂexible tail dependence between diﬀerent

variables and therefore these factors may be unsuitable for modeling a multivariate spatial

process when the dependence between variables is generally weaker than that within each

variable.

6 Application to temperature and atmospheric pres-

sure data

6.1 Data and marginal models

In this section, we apply our model to estimate the joint dependence structure of daily mean

temperature and daily mean atmospheric pressure readings in Oklahoma, USA. We consider

17 stations in the central part of the state: Acme, Apache, Chandler, Chickasha, Fort Cobb,

Guthrie, Hinton, Marena, Minco, Ninnekah, OKC East, OKC North, Perkins, Shawnee,

Stillwater, Washington and Watonga. These stations are located close to each other with

the maximum distance between two stations being 170 kilometers. The area of interest has no

big mountains and the weather conditions remain consistent across the area. The proposed

copula-based LMC model 1 may therefore be suitable for modeling the joint dependence of

temperature and pressure data when unobserved factors aﬀect the temperature and pressure

at all stations in this area. The data are available at mesonet.org.

Weather patterns can change in winter and therefore we selected observations from May

18

1st to September 30th, 2015, 153 days in total. To remove serial dependence, we ﬁtted the

autoregressive model with 5 lags for both temperature and pressure data. We also included

a quadratic trend in the model for the temperature data, as temperatures are usually higher

in July and August. We found that spatial covariates (latitude and longitude) improved

the ﬁt of the marginal model for the pressure data but not for the temperature data. One

possible reason for spatial covariates to have no signiﬁcant eﬀect on the temperature data

is the proximity of the weather stations and a larger variability of these data depending on

the orography. We therefore can write the models for univariate marginals as follows:

temp s,t = β0 + β1t + β2t2 +

t−1Xm=t−5

prss s,t = β0 + β1 lats + β2 lons +

αm−t+6 temp s,m + ǫs,t ,

t−1Xm=t−5

αm−t+6 prss s,m + ηs,t ,

where temp s,t and prss s,t are average temperature and pressure, respectively, measured at

station s at day t; lats and lons are spatial coordinates (latitude and longitude) of station

s, s = 1, . . . , 17 and t = 1, . . . , 153. We found that the skew-t distribution of Azzalini and

Capitanio (2003) and the normal distribution, respectively, ﬁt residuals ǫs,t and ηs,t quite

well. We checked the ﬁtted residuals for uncorrelatedness using the Ljung-Box test.

6.2 Preliminary diagnostics of the data set

We convert the ﬁtted residuals, bǫs,t and bηs,t, from the marginal models to uniform scores.

For s = 1, . . . , 17, we deﬁne

u1

s,t = {rank(bǫs,t) − 0.5}/153,

u2

s,t = {rank(bηs,t) − 0.5}/153,

t = 1, . . . , 153.

If the marginal models ﬁt the data well, the uniform scores, u1

s,t, u2

s,t, t = 1, . . . , 153, should

have an approximate U(0, 1) distribution for any s = 1, . . . , 17. We can therefore convert

19

them to the normal scores using the inverse standard normal distribution function:

s,t = Φ−1(u1
z1

s,t),

s,t = Φ−1(u2
z2

s,t),

t = 1, . . . , 153.

Under the assumption of joint normality, the vector zt = (z1

1,t, . . . , z1

17,t, z2

1,t, . . . , z2

17,t)T has a

multivariate normal distribution. We can therefore draw the scatter plots for each pair of

variables from the vector zt to check if these plots have the expected elliptical shape for a

bivariate normal distribution. The use of the normal scores scatter plots to detect departures

from normality has been advocated by Nikoloulopoulos et al. (2012). We draw the normal

scores scatter plots for some pairs of the normal scores in Fig. 2.

Sharp tails in the normal scores scatter plots of the temperature data indicate that the

dependence in the tails of these data is stronger than that of the normal distribution. The

sharper lower tails of these scatter plots also indicate that the dependence in the temperature

data might be stronger in the lower tail. The ﬁgure shows the negative dependence between

the normal scores of the temperature and pressure, with a sharper lower right tail, so that

the joint distribution of z1

s,t and z2

s,t is clearly asymmetric. Models based on the multivariate

normality are therefore not suitable for modeling the joint dependence of the temperature

and pressure data.

To conﬁrm these ﬁndings, we compute the Spearman correlations and the tail-weighted

dependence measures, ̺L/̺U , from Section 4.2 for each pair of variables from the vector

ut = (u1

1,t, . . . , u2

17,t, 1 − u2

1,t, . . . , 1 − u2

17,t)T. We use the reﬂected pressure data, 1 − u2

s,t, to get

positive dependence between the temperature and pressure data. In addition, let ̺N (u1, u2)

be the value ̺L(u1, u2) = ̺U (u1, u2) for data generated from the bivariate normal copula

with the Spearman’s ρ equal to cor(u1, u2). If the bivariate copula for the pair (u1, u2) is a

normal copula, we expect to get close values for ̺L, ̺U and ̺N . If the dependence in the

20

distance = 27km

distance = 77km

distance = 153km

t
 
,

e
h
c
a
p
A

2

0

2
−

p
 
,
e
h
c
a
p
A

2

0

2
−

t
 
,
e
h
c
a
p
A

2

0

2
−

t
 
,

o
c
n
M

i

2

0

2
−

−2

0

2

Acme, t

−2

0

2

Guthrie, t

−2

0

2

Acme, p

−2

0

2

Guthrie, p

p
 
,
o
c
n
M

i

2

0

2
−

t
 
,
o
c
n
M

i

2

0

2
−

−2

0

2

Hinton, t

−2

0

2

Hinton, p

t
 
,

a
n
e
r
a
M

2

0

2
−

p
 
,
a
n
e
r
a
M

2

0

2
−

t
 
,
a
n
e
r
a
M

2

0

2
−

−2

0

2

Acme, p

−2

0

2

Guthrie, p

−2

0

2

Hinton, p

Figure 2: Scatter plots of normal scores for temperature data (top), pressure data (middle), pressure (x-
axis) and temperature (y-axis) data (bottom) for Acme, Apache (left), Guthrie, Minco (middle), and Hinton,
Marena (right) stations.

21

lower (upper) tail is stronger than that for the normal copula, then we expect the value of

̺L (̺U ) to be larger than ̺N . For i = 1, 2, we compute:

̺i

Si

ρ = Xs1<s2
N = Xs1<s2
L = Xs1<s2
U = Xs1<s2

̺i

̺i

cor(ui

s1,t, ui

s2,t)/136, S 12

̺N (ui

s1,t, ui

s2,t)/136,

̺L(ui

s1,t, ui

s2,t)/136,

̺U (ui

s1,t, ui

s2,t)/136,

̺12

ρ = Xs1≤s2
N = Xs1≤s2
L = Xs1≤s2
U = Xs1≤s2

̺12

̺12

cor(u1

s1,t, 1 − u2

s2,t)/153,

̺N (u1

s1,t, 1 − u2

s2,t)/153,

̺L(u1

s1,t, 1 − u2

s2,t)/153,

̺U (u1

s1,t, 1 − u2

s2,t)/153.

Here, the superscripts 1, 2, 12 indicate that the calculated measures are averaged for all

pairs of diﬀerent locations for variable 1 (temperature), variable 2 (pressure) and variables

1 and 2 (to measure cross dependencies). The results are presented in Table 2.

Table 2: Si

ρ, ̺i

N , ̺i

L, ̺i

U for i = 1, 2 and S 12

ρ , ̺12

N , ̺12

L , ̺12
U

Variable
Variable 1
Variable 2
Variables 1 and 2

Sρ
0.85
0.97
0.38

̺N
0.74
0.93
0.20

̺L
0.86
0.96
0.55

̺U
0.79
0.90
0.17

We see that the dependence for variable 1 is stronger than it is for the normal copula

in both lower and upper tails. In addition, the cross dependence between variable 1 and

(reﬂected) variable 2 is much stronger in the upper tail. We therefore need a model that can

handle tail dependence and asymmetric dependence for the temperature and pressure data.

6.3 Estimating the joint dependence

We apply the model (2) to the residuals obtained from the marginal models in Section 6.1

transformed to uniform scores u1

s,t and 1−u2

s,t, s = 1, . . . , 17 and t = 1, . . . , 153. Before ﬁtting

22

the model, we need to model the cross-covariance of Z = (Z1,1, . . . , Z1,17, Z2,1, . . . , Z2,17)T.

We select the following linear model of coregionalization:

Zi = ρi ˜Z0 +q1 − ρ2

i Z ∗
i ,

i = 1, 2,

(6)

where the Z0, Z ∗

1 , Z ∗

2 processes are independent with unit variance and have the powered

exponential covariance function, C(d; θ, α) = exp(−θdα) (θ > 0, 0 < α < 2), with param-

eters (θ0, α0), (θ1, α1) and (θ2, α2), respectively. Diﬀerent models can be used to model the

covariance structure of Z, including the bivariate Mat´ern model; we found however that these

models did not improve the ﬁt of model (6).

We set two parameters, αL

2 , αU

2 , to zero as discussed in Section 4.3 to avoid convergence

problems with the algorithm and to increase the speed of computation. With this restriction,

the maximum likelihood estimates were obtained in about ﬁve minutes on a Core i5-2410M

CPU@2.3 GHz. To assess the goodness of ﬁt of the estimated model (Model 1), we computed

the values ∆ρ, ∆L, ∆U , |∆ρ|, |∆L|, |∆U | deﬁned in Section 4.3 to evaluate the strength of the

dependence for the temperature and pressure data and the cross dependencies between these

variables. For comparison, we also ﬁt the LMC model (6) without exponential factors (Model

2, assuming αU

10 = αU

1 = αL

10 = αL

1 = αU

20 = αU

2 = αL

20 = αL

2 = 0). The results are presented

in Table 3.

We can see that both Model 1 and Model 2 ﬁt the covariance structure quite well;

however, Model 2 (with no exponential factors) signiﬁcantly underestimates the cross de-

pendence in the lower tail. Model 1 signiﬁcantly improves the ﬁt in the lower tail. Our

proposed model is an extension of any model based on multivariate normality, including

LMC (6). One can therefore apply likelihood ratio tests to check if the exponential factors

are needed to model tail dependence. For example, Model 1 and Model 2 (the latter is a

23

Table 3: ∆ρ, |∆ρ|, ∆L, |∆L|, ∆U , |∆U | for models 1 and 2. We simulated data from the estimated models 1
and 2 to calculate these values; we used N = 100, 000 replicates.

∆ρ/|∆ρ|

∆L/|∆L|

∆U /|∆U |

Model 1; loglikelihood = 8259.1

0.00/0.01
Variable 1
Variable 2
0.03/0.03
Variables 1 and 2 −0.05/0.06

−0.01/0.01 −0.02/0.02
0.06/0.07
−0.03/0.04
0.13/0.13
0.06/0.09

Model 2; loglikelihood = 8096.5

0.00/0.01
Variable 1
Variable 2
−0.03/0.03
Variables 1 and 2 −0.04/0.05

0.03/0.03
0.10/0.10
0.34/0.34

−0.03/0.03
0.02/0.05
−0.03/0.08

nested model) can be compared by calculating the test statistic, LR(Model 1, Model 2) =

2(8259.1 − 8096.5) = 325.3 > χ2(0.95, 6) = 12.59, where χ2(0.95, 6) is the 95% quantile of

a chi-squared distribution with six degrees of freedom (Model 1 has six additional parame-

ters, αU

10, αU

1 , αL

10, αL

1 , αU

20, αL

20), suggesting that the exponential factors used to model the tail

dependence signiﬁcantly improve the ﬁt. Similarly, covariance of the vector Z in (2) with a

diﬀerent model yields two nested models (with and without exponential factors) that can be

estimated and the likelihood ratio test can be applied to compare these models.

7 Conclusion

We proposed a new copula model for multivariate spatial data that can handle tail depen-

dence and asymmetric dependence within each variable as well as between diﬀerent variables.

This model is a generalization of any model based on multivariate normality. The widely

used linear model of coregionalization is an example. Parameters in the model can be es-

timated by likelihood and the formula for the joint copula density is quite simple so that

parameters can be computed fairly easily. The model allows simple interpretation when fac-

24

tors aﬀecting the joint dependence of multivariate spatial data exist. While we focused on

exponential factors used to model tail dependence and asymmetry in (2), we also discussed

how the choice of the distribution of these factors can aﬀect tail properties of the resulting

model.

While the proposed model can generate a wide range of dependence structures, it assumes

a linear structure when some exponential factors are added to the multivariate Gaussian pro-

cess. One direction for future research can therefore be to consider models with multiplicative

factors or more general models based on the multivariate process:

Wi(s) = fi{Zi(s), E0, Ei},

i = 1, . . . , p,

(7)

where {Z1(s), . . . , Zp(s)}T is a multivariate Gaussian process and E0, E1, . . . , Ep are factors

that do not depend on the location s (not necessarily exponential), introduced to increase

the ﬂexibility of the model. The choice of functions f1, . . . , fp and distributions of factors

E0, E1, . . . , Ep can deﬁne the dependence properties of the joint distribution and the resulting

copula. Another direction for future research is to study anisotropic factor copula models

when the joint dependence of the variables is aﬀected by a location or some other factors.

One way to introduce anisotropy can be, for example, by spatially varying functions f1, . . . , fp

in (7).

References

Aas, K., Czado, C., Frigessi, A., Bakken, H., 2009. Pair-copula constructions of multiple

dependence. Insurance: Mathematics and Economics 44, 182–198.

Apanasovich, T. V., Genton, M. G., 2010. Cross-covariance functions for multivariate

random ﬁelds based on latent dimensions. Biometrika 97, 15–30.

25

Azzalini, A., Capitanio, A., 2003. Distributions generated by perturbation of symmetry with

emphasis on a multivariate skew t-distribution. Journal of the Royal Statistical Society.

Series B 65, 367–389.

B´ardossy, A., 2006. Copula-based geostatistical models for groundwater quality parameters.

Water resources research 42.

B´ardossy, A., Li, J., 2008. Geostatistical interpolation using copulas. Water resources

research 44.

Chil´es, J.P., Delﬁner, P., 1999. Geostatistics: Modeling Spatial Uncertainty. John Wiley,

New York.

Chistyakov, V.P., 1964. A theorem on sums of independent, positive random variables and

its applications to branching processes. Theory of Probability and its Applications 9,

640–648.

Embrechts, P., Goldie, C. M., Veraverbeke, N., 1979. Subexponentiality and inﬁnite divisi-

bility. Z. Wahr. verw. Gebiete 49, 335–347.

Erhardt, T.M., Czado, C., Schepsmeier, U., 2014. R-vine models for spatial time series with

an application to daily mean temperature. Zentrum Mathematik Technische Universit¨at

M¨unchen .

Feller, W., 1970. An Introduction to Probability Theory and Its Applications. volume Volume

2. John Wiley & Sons, USA.

Furrer, R., Genton, M. G., 2011. Aggregation-cokriging for highly-multivariate spatial data.

Biometrika 98, 615–631.

26

Gelfand, A. E., Schmidt, A. M., Banerjee, S., Sirmans, C. F., 2004. Nonstationary multi-

variate process modeling through spatially varying coregionalization. Test 13, 263–312.

Genest, C., Favre, A.C., 2007. Everything you always wanted to know about copula modeling

but were afraid to ask. Journal of Hydrologic Engineering 12, 347–368.

Genton, M. G., Kleiber, W., 2015. Cross-covariance functions for multivariate geostatistics.

Statistical Science 30, 147–163.

Gneiting, T., 2002. Nonseparable, stationary covariance functions for space-time data. J.

Am. Statist. Assoc. 97, 590–600.

Gneiting, T., Genton, M. G., Guttorp, P., 2007. Geostatistical space-time models, station-

arity, separability and full symmetry. In Finkenstaedt, B., Held, L. and Isham, V.(eds),

Statistics of Spatio-Temporal Systems, Chapman & Hall / CRC Press, Monograph in

Statistics and Applied Probability, Boca Raton.

Goulard, M., Voltz, M., 1992. Linear coregionalization model: Tools for estimation and

choice of cross-variogram matrix. Mathematical Geology 24, 269–286.

Gr¨aler, B., 2014. Modelling skewed spatial random ﬁelds through the spatial vine copula.

Spatial Statistics 10, 87–102.

Gr¨aler, B., Pebesma, E., 2011. The pair-copula construction for spatial data: a new approach

to model spatial dependency. Procedia Environmental Sciences 7, 206–211.

H¨usler, J., Reiss, R. D., 1989. Maxima of normal random vectors: between independence

and complete dependence. Stat. Prob. Lett. 7, 283–286.

27

Joe, H., 2014. Dependence Modeling with Copulas. Chapman & Hall/CRC, Boca Raton,

FL.

Krupskii, P., Huser, R., Genton, M. G., 2015. Factor copula models for spatial data.

http://arxiv.org/abs/1511.03000 .

Krupskii, P., Joe, H., 2015a. Structured factor copula models: theory, inference and compu-

tation. Journal of Multivariate Analysis 138, 53–73.

Krupskii, P., Joe, H., 2015b. Tail-weighted measures of dependence. Journal of Applied

Statistics 42, 614–629.

Kurowicka, D., Cooke, R., 2006. Uncertainty Analysis with High Dimensional Dependence

Modelling. Wiley Series in Probability and Statistics.

Myers, D. E., 1991. Pseudo-cross variograms, positive-deﬁniteness, and cokriging. Mathe-

matical Geology 23, 805–816.

Nikoloulopoulos, A.K., Joe, H., Li, H., 2012. Vine copulas with asymmetric tail dependence

and applications to ﬁnancial return data. Computational Statistics & Data Analysis 56,

3659–3673.

Patton, A., 2006. Modeling asymmetric exchange rate dependence. International Economic

Review 47, 527–556.

Segers, J., 2012. Max-stable models for multivariate extremes. REVSTAT – Statistical

Journal 10, 61–82.

Sklar, A., 1959. Fonctions de r´epartition `a n dimensions et leurs marges. Publ. Inst. Statist.

Univ. Paris 8, 229–231.

28

Stroud, A., Secrest, D., 1966. Gaussian Quadrature Formulas. Prentice-Hall, Englewood

Cliﬀs, NJ.

Wackernagel, H., 2003. Multivariate Geostatistics: An Introduction with Applications.

Springer, Berlin. 2nd ed. edition.

Zhang, H., 2007. Maximum-likelihood estimation for multivariate spatial linear coregional-

ization models. Environmetrics 18, 125–139.

29

Appendix

A.1 Formula for f W

n,p for p = 2

Let w = (w1, w2)T , where wi = (wi1, . . . , win), i = 1, 2, and let ΣZ be a covariance matrix of

the vector Z = (Z11, . . . , Z1n, Z21, . . . , Z2n) as deﬁned in (2). One can show that the joint

pdf for vector W∗ = (W ∗

11, . . . , W ∗

1n, W ∗

21, . . . , W ∗

2n), where W ∗

ij = Zij + αU

i0E U

0 − αL

i0E L

0 , is

f W∗

n,2 (w1, w2) = Kw exp(cid:26)c2

1c22 + 2c1c2c12 + c2

2c11

2cδ

(cid:27) Φρ∗(cid:18)c1c22 + c2c12

(cδc22)1/2

,

c1c12 + c2c11

(cδc11)1/2 (cid:19) ,

where cδ = c11c22 − c2

12, Kw = (2π)1−n(cδ det(Σ))−1/2 exp{−wT Σ−1w/2}, Φρ∗ is the cdf of a

bivariate standard normal random variable with correlation ρ∗ and

c1 = c1(w) = αU

10s1(w) + αU

1 s2(w) − 1,

c2 = c2(w) = −αL

10s1(w) − αL

1 s2(w) − 1,

c11 = (αU

10)2s11 + 2αU

10αU

1 s12 + (αU

1 )2s22,

c22 = (αL

10)2s11 + 2αL

10αL

1 s12 + (αL

1 )2s22,

c12 = αU

10αL

10s11 + (αU

10αL

1 + αL

10αU

1 )s12 + αU

1 αL

1 s22,

s1 = s1(w) =

(Σ−1

Z w)j,

s2 = s2(w) =

(Σ−1

Z w)j,

nXj=1

2nXj1,j2=n+1

2nXj=n+1
nXj1=1

2nXj2=n+1

nXj1,j2=1

s11 =

(Σ−1

Z )j1,j2,

s22 =

(Σ−1

Z )j1,j2,

s12 =

(Σ−1

Z )j1,j2.

The pdf of Vi = αU

i E U

0 − αL

i E L

0 is fVi(w) = {exp{−w+/αU

i − (−w)+/αL

i }]/(αU

i + αL

i ). We

use the convolution formula to get

f W

n,2(w1, w2) =ZR2

f W∗
n,2 (w1 − v1, w2 − v2)fV1(v1)fV2(v2)dv1dv2.

If we assume that αU

2 = αL

2 = 0, the formula simpliﬁes to a one-dimensional integral:

f W

n,2(w1, w2) =ZR1

f W∗
n,2 (w1 − v1, w2)fV1(v1)dv1

n,2 (w1 − v1, w2) exp(−v1/αU

1 ) + f W∗

n,2 (w1 + v1, w2) exp(−v1/αL

1 )(cid:9) dv1.

1

=

αU

1 + αL

1 ZR1

+(cid:8)f W∗

30

This integral can be evaluated with very good accuracy via Gauss-Legendre quadrature using

25 − 30 quadrature points; see Stroud and Secrest (1966) for details.

A.2 Proof of Proposition 1

For simplicity, we omit indices for the correlation coeﬃcient ρ = ρ1:2

1,2. We have:

F W

2,1:2(z1, z2) =ZR3

+

Φρ(z1 − αU

10v0 − αU

1 v1, z2 − αU

20v0 − αU

2 v2) exp(−v0 − v1 − v2)dv0dv1dv2 .

We use the integration by parts formula with respect to v1 and v2 to ﬁnd that

F W

2,1:2(z1, z2) =ZR1

+

{I0(v0) − I1(v0) − I2(v0) + I12(v0)}dv0,

(8)

where I0(v0) = Φρ(z1 − αU

10v0, z2 − αU

20v0) exp(−v0), I1(v0) = Φρ(z1 − αU

10v0 − ρ/αU

2 , z2 −

αU
20v0 − 1/αU

2 ) exp{(δ2 − 1)v0 + 0.5/(αU

2 )2 − z2/αU

2 }, I2(v0) = Φρ(z1 − αU

10v0 − 1/αU

1 , z2 −

αU
20v0 − ρ/αU

1 ) exp{(δ1 − 1)v0 + 0.5/(αU

1 )2 − z1/αU

1 }, I12(v0) = Φρ(z1 − αU

10v0 − 1/αU

1 −

ρ/αU

2 , z2 − ρ/αU

2 − αU

20v0 − 1/αU

2 ) exp{(δ12 − 1)v0 + 0.5(ρ∗

12)2 − z1/αU

1 − z2/αU

2 }, and (ρ∗

12)2 =

{(αU

1 )2 + 2ραU

1 αU

2 + (αU

2 )2}/(αU

1 αU

2 )2.

For the marginal distribution, F W

1,i (z) = Φ(z)−[αU

i0 exp{−z/αU

i0+0.5/(αU

i0)2}Φ(z−1/αU

i0)−

αU
i exp{−z/αU

i + 0.5/(αU

i )2}Φ(z − 1/αU

i )]/(αU

i0 − αU

i ), i = 1, 2. Let δi 6= 1, α∗

i = max(αU

i0, αU
i )

and let zi = ci + α∗

i log n, where ci = 0.5/α∗

i + α∗

i log(α∗

i /|αU

i0 − αU

i |) − α∗

i log xi. This implies

that F W

1,i (zi) = 1 − xi/n + o(1/n).

Case 1: δ1 > 1, δ2 > 1. We get

Φρ{c1 − αU

10(v0 − log n), c2 − αU

20(v0 − log n)} exp(−v0)dv0

ZR1

+

= 1 −

I0(v0)dv0 =ZR1
k0ZR1
2Xk=1

1
n

αU

+

Φ( c3−k − ρck + (αU

(1 − ρ2)1/2

3−k,0 − ραU

k0)v

) φ(ck + αU

n(cid:19) .
k0v) exp(v)dv + o(cid:18) 1

(9)

31

To compute the integrals in (9), we use the following equality:

ZR1

exp(θv)φ(v)Φ(qv)dv = exp(0.5θ2)Φ(cid:26)

θq

(q2 + 1)1/2(cid:27) .

(10)

This equality can be obtained by diﬀerentiating the integral on the left-hand side with respect

to the parameter q. We apply (10) to (9) and, after combining all terms, we get:

log(y2/y1)

(cid:27) + o(cid:18) 1
n(cid:19) .

and c∗

2 = c2 − ρ
αU
1

− 1
αU
2

,

We use (10) to compute other terms in (8). Let c∗

+

I0(v0)dv0 = 1 −

ZR1
and let c12 = expn− c1
n ZR1
ZR1
Φ( c∗

I12(v0)dv0 =

k0ZR1

c12
n

αU

c12

αU
1

=

2Xk=1

+

y1
n

Φ(cid:26) ρ12

2

+ 0.5(ρ∗

10v + c∗

− c2
αU
2

Φ(cid:0)αU

3−k − ρc∗

k + (αU
(1 − ρ2)1/2

ρ12

2

+

+

1
αU
1

ρ12

1 , αU

y2
n

− ρ
αU
2

log(y1/y2)

Φ(cid:26) ρ12

1 = c1 − 1
αU
1
− c∗
2
αU

2o. We get
n(cid:19)
2(cid:1) exp{−(δ12 − 1)v}dv + o(cid:18) 1

(cid:27) −
12)2o = expn− c∗
) φ(cid:0)αU
12(cid:9) Φ(cid:26)ρ12(0.5 − δ1) +
1 exp(cid:8)0.5δ1(δ1 − 1)ρ2
12(cid:9) Φ(cid:26)ρ12(0.5 − δ2) +
2 exp(cid:8)0.5δ2(δ2 − 1)ρ2

3−k,0 − ραU

k0v + c∗

20v + c∗

k0)v

=

1
n
1
n

(δ12 − 1)−1yδ1

1 y1−δ1

2

(δ12 − 1)−1yδ2

2 y1−δ2

1

δ∗

δ∗

n(cid:19)
k(cid:1) exp{−(δ12 − 1)v}dv + o(cid:18) 1
(cid:27)
n(cid:19) .
(cid:27) + o(cid:18) 1

log(y1/y2)

log(y2/y1)

ρ12

ρ12

Similarly, we can calculate the two remaining terms in (8), and, after combining terms and

taking limit as n → ∞, we can show that (4) holds.

Case 2: δ1 > 1, δ2 < 1. Denote α∗

2 = αU

2 − αU

20 > 0. We get:

Φρ{c1 − αU

10(v0 − log n), c2 − αU

20(v0 − log n) + α∗

2 log n} exp(−v0)dv0

I0(v0)dv0 =ZR1
nZ ∞

− log n

1

+

Φ(c1 − αU

10v) exp(−v)dv + o(cid:18) 1

n(cid:19) = 1 −

1
n

ZR1

+

=

ZR1

+

= 1 −

(11)

x1

(αU

c1
αU

10)2 −
1

10(cid:27) + o(cid:18) 1
n(cid:19)
exp(cid:26) 0.5
n (cid:18)1 −
n(cid:19) ,
δ1(cid:19) + o(cid:18) 1
2 log n(cid:1) exp{−(δ12 − 1)v}dv
n(cid:19) = o(cid:18) 1
n(cid:19) .

(12)

1(cid:1) exp{−(δ12 − 1)v}dv + o(cid:18) 1

32

I12(v0)dv0 =

10v + c∗

1 , αU

20v + c∗

2 + α∗

2/αU

c12
n1+α∗
c12
n1+α∗

2/αU

−∞

2 Z log n
Φ(cid:0)αU
2 ZR1
Φ(cid:0)αU

10v + c∗

=

Similarly, we ﬁnd that

ZR2

+

I1(v0)dv0 =

x2
n

n(cid:19) ,
+ o(cid:18) 1

ZR2

+

I1(v0)dv0 =

x1
nδ1

+ o(cid:18) 1
n(cid:19) .

Therefore, ℓ(x1, x2) = x1 + x2. This implies that C W

2,1:2 as well as the limiting extreme-value

copula CW

2,1:2 has no upper tail dependence. The remaining two cases when δ1 < 1, δ2 > 1

and when δ1 < 1, δ2 < 1 are considered analogously.

(cid:3)

A.3 Proof of Proposition 2

For ci → ∞, we use the asymptotic property of the sum of two independent Pareto variables

with regular varying tails (see Feller (1970)) to get:

pr{Wi1 = Zi1 + αU

i0E0 + αU

i Ei < ci} = pr{αU

i0E0 + αU

i Ei < ci} + o(c−k
i )

= 1 − {(αU

i0)k + (αU

i )k}c−k

i + o(c−k

i ),

i = 1, 2.

Let ci := (n/xi)1/k · {(αU

i0)k + (αU

i )k}1/k. This implies pr{Wi1 < ci} = 1 − xi/n + o(1/n),

i = 1, 2. We have

pr{W11 < c1, W21 < c2} = pr{αU

10E0 + αU

1 E1 < c1, αU

20E0 + αU

= kZ Q

1 (1 −(cid:18)c1 − αU

αU
1

10v0

(cid:19)−k)(1 −(cid:18) c2 − αU

αU
2

20v0

(cid:19)−k) v−k−1

0

2 E2 < c2} + o(cid:18) 1
n(cid:19)
dv0 + o(cid:18) 1
n(cid:19) ,

where Q = min{(c1 − αU

1 )/αU

10, (c2 − αU

2 )/αU

20}. Let x1θ∗

1 > x2θ∗

2 so that Q = (c1 − αU

1 )/αU

10

as n → ∞. We ﬁnd that pr{W11 < c1, W21 < c2} = I1 + I2 + I12 + o(1/n), where

S1 = kZ Q
S2 = −kZ Q

1 (1 −(cid:18)c1 − αU
1 (cid:18) c2 − αU

αU
1

αU
2

20v0

10v0

0

(cid:19)−k) v−k−1
(cid:19)−k

v−k−1
0

dv0 = pr{αU

dv0 = (δ∗)−kkZ Q

10E0 + αU

1 E1 < c1} = 1 − x1/n + o(cid:18) 1
n(cid:19) ,
2 (cid:19)−k) v−k−1

1 (1 −(cid:18)c2 − αU

δ∗αU

20v0

dv0

0

33

−(δ∗)−kZ Q

1

v−k−1
0

dv0 = (δ∗)−k Pr{αU

20E0 + δ∗αU

2 E2 < c2} − (δ∗)−k(1 −(cid:18)c1 − αU

10 (cid:19)−k)

αU

1

= (δ∗)−k"(cid:18)c1 − αU
10 (cid:19)−k

αU

1

− c−k

2 {(αU

20)k + (δ∗αU

2 )k}# + o(cid:18) 1
n(cid:19) ,

where δ∗ = (c2 − αU

20Q)/αU

2 . It follows that

S2 =

x1
n

·

(αU
10/δ∗)k
10)k + (αU

1 )k −

(αU

x2
n

·

(αU

20/δ∗)k + (αU
(αU

20)k + (αU

Lastly, S12 = kR Q

2 )kx2/{(αU

(αU

1 (cid:16) c1−αU

αU
1

10v0

(cid:17)−k(cid:16) c2−αU

αU
2

20v0

20)k + (αU

2 )k} = x1 + x2 − θ∗

·

(αU

2 )k

2 )k

x2
n

2 )k + o(cid:18) 1
(cid:17)−k

n(cid:19) = −
dv0 = o(cid:0) 1

n(cid:19) .
2 )k + o(cid:18) 1
n(cid:1). Therefore, ℓ(x1, x2) = x1 +

20)k + (αU

v−k−1
0

2x2, we get ℓ(x1, x2) =

2x2. Similarly, if θ∗

1x1 < θ∗

(αU

x1 + x2 − θ∗

1x1 so that ℓ(x1, x2) = x1 + x2 − min(θ∗

1x1, θ∗

2x2).

(cid:3)

A.4 Proof of Proposition 3

We have λU = limn→∞ n Pr(W11 > cn

1 , W21 > cn

2 ), where F W

1,i (cn

i ) = 1 − 1/n + o(1/n). First,

consider the case when αU

i0 > αU

i , i = 1, 2. By Embrechts et al. (1979), Pr(Wi1 > cn

i ) =

pr(αU

i0E U

i0 > cn

i ) + o(1/n) = ¯FE (cn

i /αU

i0) + o(1/n), where ¯FE(s) = 1 − FE(s). This implies that

cn
i = αU
i0

¯F −1

E (1/n) can be selected and

pr(W11 > cn

1 , W21 > cn

2 ) ≤ pr(W11 > cn

1 ) = 1/n + o(1/n),

pr(W11 > cn

1 , W21 > cn

2 ) ≥ pr{E U

0 + min(Z11/αU

10, Z21/αU

20) > ¯F −1

E (1/n)} = 1/n + o(1/n),

so that λU = 1.

Now let αU

10 > αU

1 and αU

20 < αU

2 (other cases are considered analogously). We get

cn
1 = αU

10

¯F −1
E (1/n) and cn

2 = αU

2

¯F −1
E (1/n). For any ǫ > 0, Pr{E U

0 > (1+ǫ) ¯F −1

E (1/n)} = o(1/n)

and therefore

pr(W11 > cn

1 , W21 > cn

2 ) = pr{W11 > cn

1 , W21 > cn

2 , Z21/αU

20+E U

0 < (1+ǫ) ¯F −1

E (1/n)}+o(1/n)

≤ pr{W11 > cn

1 , αU

2 E U

2 > αU

2

¯F −1
E (1/n) − αU

20(1 + ǫ) ¯F −1

E (1/n)} + o(1/n)

34

= pr(W11 > cn

1 )pr[αU

2 E U

2 > ¯F −1

E (1/n){αU

2 − αU

20(1 + ǫ)}] + o(1/n) = o(1/n)

for ǫ > 0 small enough such that αU

2 − αU

20(1 + ǫ) > 0. This implies λU = 0.

(cid:3)

35

