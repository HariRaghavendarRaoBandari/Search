Using Peer Feedback to Promote Reﬂection on Open-Ended

Problems

Daniel L. Reinholz∗

Center for STEM Learning, University of Colorado Boulder, Boulder, CO 80309, USA

Dimitri R. Dounas-Frazer†

Department of Physics, University of Colorado Boulder, Boulder, CO 80309, USA

(Dated: March 14, 2016)

6
1
0
2

 
r
a

 

M
1
1

 
 
]
h
p
-
d
e
.
s
c
i
s
y
h
p
[
 
 

1
v
6
8
6
3
0

.

3
0
6
1
:
v
i
X
r
a

1

I.

INTRODUCTION AND BACKGROUND

This paper describes a new approach for learning from homework, called Peer-Assisted

Reﬂection (PAR).1 PAR involves students using peer feedback to improve their work on

open-ended homework problems. Collaborating with peers and revising one’s work based on

the feedback of others are important aspects of doing and learning physics.2 While notable

exceptions exist,3–7 homework and exams are generally individual activities that do not sup-

port collaboration and reﬁnement, which misses important opportunities to use assessment

for learning.8 In contrast, PAR provides students with a structure to iteratively engage with

challenging, open-ended problems and solicit the input of their peers to improve their work.

Speciﬁcally, students are required to: (1) complete a homework problem outside of class,

(2) reﬂect on their solution attempt by indicating their level of conﬁdence in their solution

and optionally identifying topics to discuss with their peers, (3) trade their initial attempt

with a peer and exchange feedback during class, and (4) revise their work outside of class

to create a ﬁnal solution. PAR activities engage students both in and out of the classroom,

with the peer feedback portion of the cycle typically taking around 10 minutes of class time.

All other activities are completed outside of class. At the end of each week-long PAR cycle,

students are required to submit a packet containing their initial attempt, reﬂection, peer

feedback, and revised work.

PAR was designed using principles of formative assessment, which focuses on eliciting

information during the learning process and using that information to improve learning ac-

tivities in real time.8 Of particular relevance to PAR is peer assessment,1 a type of formative

assessment where students—rather than teachers—take responsibility for assessing and im-

proving the learning process. Peer assessment is a powerful tool for learning because it helps

students learn from their peers and develop the ability to assess their own work.9 The PAR

cycle provides a structure for peer assessment, supporting students to provide feedback to

each other and revise their solutions based on feedback from their peers. Engaging with

PAR on a regular basis supports students to improve in their communication, collaboration,

and persistence.10 This is consistent with the Next Generation Science Standards, which em-

phasize scientiﬁc practices like communicating information in addition to content mastery

and conceptual understanding.11

PAR was initially developed in the context of introductory college calculus,10 but has

2

since been used in a variety of settings in both mathematics and the sciences.

In the

present work, we focus on how we adapted PAR to support pre-service physics teachers

to iteratively improve on their solutions to introductory physics problems. We provide

examples of student work to illustrate diﬀerent types of iterative improvement. We also

provide practical guidelines for teachers who wish to implement PAR in their own teaching.

II. COURSE CONTEXT

We adapted PAR for use in an upper-division physics course for students considering

a career teaching physics or other physical sciences. The course employed the Modeling

Instruction approach to teaching physics,12 a popular teaching strategy that emphasizes

looking at similar physical situations with increasingly sophisticated models (e.g., constant

velocity versus constant acceleration). Twelve students were enrolled in the course: ﬁve

were Physics majors, four were majors in other STEM disciplines, and three were Liberal

Studies majors (i.e., future K-8 teachers). One of the authors (DRDF) co-taught the course.

In adapting PAR to this setting, several key features of the original design10 were kept the

same: use of open-ended problems, format of worksheets, implementation of peer-to-peer

conferences, and whole-class discussions of sample student work. However, our implementa-

tion diﬀered from the original design in two ways. First, because our students were future

teachers, some out-of-class readings focused on physics pedagogy, instructor feedback, and

learning more generally. Second, to leverage the iterative nature of Modeling Instruction,

some PAR problems used identical physics scenarios that students analyzed using diﬀerent

physics models (as described herein).

Given the iterative nature of PAR, it is a complementary approach to Modeling Instruc-

tion. Moreover, Modeling units are initiated with inquiry-based lab activities that are both

open-ended and phenomenological in nature. These in-class open-ended activities support

the out-of-class PAR homework assignments. PAR focuses on iterative reﬁnements on the

scale of a single homework problem; Modeling complements this approach by emphasiz-

ing longer-term revisions, as students iteratively develop more sophisticated models as the

course progresses. While PAR and Modeling are synergistic approaches, both of them can

also be used eﬀectively in isolation.

3

III. EXAMPLES OF STUDENT WORK

To illustrate the synergy between PAR and Modeling, we provide student responses to

two similar PAR problems. Both PAR problems involve three runners racing in a 100 m dash

(Fig. 1). The ﬁrst PAR problem was assigned when students were working with Constant

Velocity (CV) models. This problem asked students to: compute the speeds of Runners A

and B; deﬁne a “fair” head start for Runner B; determine which runners ﬁnished in ﬁrst,

second, and third place; and, plot each runner’s position as a function of time.

Later in the quarter, students revisited the 100 m dash scenario in a follow-up PAR

problem that was assigned when students were working with Uniform Acceleration (UA)

models. In class, the instructors mentioned that races typically require competitors to start

from rest, and so CV models fail to describe this scenario completely. In the second PAR

problem, students were asked to: determine a “fair” head start for Runner B using a UA

model; plot each runners’ position, velocity, and acceleration as functions of time; compare

the initial, average, and ﬁnal speeds of the accelerating runners to the speeds computed in

the ﬁrst PAR problem; and, describe the tradeoﬀs of using CV or UA models to describe

this scenario.

In both cases, students were required to iterate on their homework solutions using the

PAR approach. Thus, students were able to iterate on the 100 m dash problem at two

timescales: PAR provided opportunities for revision on small timescales while Modeling

allowed for a larger arc of iteration and revision in the course.

The open-ended nature of the problem gave rise to a breadth of responses. For example,

each student articulated a diﬀerent deﬁnition of “fair,” resulting in diﬀerent values for the

head start. For the CV version of the problem, there were nine distinct recommended

distances for the dead start, ranging from 8–17 m. In addition, one student argued that any

head start would be inherently unfair, and that Runner B would simply not be able to win

the race.

To illustrate how our students responded to these activities, we present responses from

three students: Alex, Bobbie, and Corey. These students were chosen because their work

demonstrates a diversity of responses to our open-ended prompts. Using Alex’s and Bobbie’s

work as examples, we show how peer feedback can help students clarify their reasoning as

well as their position, velocity, and acceleration graphs. Corey’s work illustrates how PAR

4

provides opportunities for students to iterate on their reasoning over the course of successive

Modeling units. For each student, we show how responses did or did not change when taking

into account the runners’ nonzero acceleration.

A. Example 1: Alex

In his initial solution to the CV PAR problem, Alex wrote the following:

A fair head start should be 17 meter ahead of the start line. That way according

to Runner A’s and B’s rates they will ﬁnish at the same time.

Here Alex deﬁned a fair head start such that the two runners A and B tie the race. Alex

assumed both runners run their slowest, though he did not articulate this assumption.

Moreover, his explanation did not explicate how his deﬁnition was used to compute a head

start of 17 m, an omission which caught the attention of his peer reviewer:

I am confused that they will ﬁnish at the same time. Show how you got 17

meters.

Alex responded to this feedback by elaborating his reasoning in his revised solution:

A fair head start for runner B would be 17 meters ahead of the start line. This

is because in ten seconds Runner A can go 100 meters and in 10 seconds Runner

B can go 83 meters based on their average times. So, if Runner B is 17 meters

ahead of Runner A, they will both get to the ﬁnish at the same time.

By choosing a head start of 17 m, Alex reasons that Runners B will only have to run 83 m

and will therefore ﬁnish the race at the same time as Runner A, in alignment with Alex’s

deﬁnition of a fair head start. This is an example of a PAR revision cycle: given feedback

from a peer reviewer that his reasoning was not clear, Alex provided further elaboration in

his solution.

Later in the semester when working on the UA PAR problem, Alex’s deﬁnition of “fair”

was unchanged:

A fair head start would be a distance advantage for runner B such that A and

B arrive at the ﬁnish line at the same time. Assuming Runner A and B run

5

their personal best times of 10 sec and 12 sec respectively the head start line

should be placed 30.55 m from the start line. This is farther of a gap than I had

given runner B on my previous assessment. This result is dramatically diﬀerent

because we are no longer assuming that the runners begin the race at maximum

velocity and maintain it through the race. We are taking into consideration the

runners’ speeding up, and Runner A speeds up faster than runner B.

Despite using the same deﬁnition of “fair,” Alex nevertheless computes a much larger head

start using a UA model than when using a CV model (30.55 m compared to 17 m). Alex

correctly attributes this change to the fact that Runner A has a larger acceleration than

Runner B.

B. Example 2: Bobbie

Whereas Alex used a tie condition to determine a fair head start for Runner B, Bobbie

used proportional reasoning to infer the head start based on the distances in the diagram in

Fig 1. For example, in her solution to the CV PAR problem, Bobbie wrote:

Judging from the diagram, I gave runner B a head start of 20 m in part (a).

After running through the calculations, I think this head start is too generous.

A head start of 10–15 m is more appropriate as it would put runner B at second

place. This gives B the chance to win or lose.

After determining that 20 m was too generous, Bobbie modiﬁed her suggested head start.

Bobbie’s reasoning was that a head start should help Runner B, but should not make him

win. Unlike for Alex, Bobbie’s reasoning resulted in the same head start for Runner B even

when using a diﬀerent kinematic model for the UA PAR problem:

Runner B should have the same head start that I set before ∼12.5 m because all
of the runners still ﬁnish in the same amount of time despite having to accelerate

from rest.

In both the CV and UA cases, the PAR cycle did not result in Bobbie revising her reasoning.

Nevertheless, through the UA PAR problem, Bobbie was prompted to revise her velocity

and acceleration graphs, as can be seen in Fig. 2. In her initial solution to the UA PAR

6

problem, Bobbie’s velocity and acceleration graphs were qualitatively inconsistent with her

position graph. In addition to marking on the graphs (Fig. 2), Bobbie’s peer reviewer also

made the following comment:

in your V vs t and A vs t graphs you show inconsistency in who ﬁnishes ﬁrst,

2nd, & 3rd

In response to this feedback, Bobbie revised her work accordingly, generating position, ve-

locity, and acceleration graphs that were consistent with one another (Fig. 2).

C. Example 3: Corey

While Alex and Bobbie used the same reasoning to determine Runner B’s head start in

both the CV and UA versions of the PAR problem, Corey changed his deﬁnition of “fair,”

leading him to use very diﬀerent mathematical approaches to solving the same problem in

these diﬀerent contexts.

In the CV PAR problem, Corey determined that the head start should be only 8 m:

As stated before in one of my assumptions, Runner Bs head start was intended

to reduce his time by about 1 second. Since he can run 8 meters in one second,

his head start time was set 8 meters ahead of the usual line.

Here Corey decided that “fair” meant shaving a second oﬀ of Runner B’s average time.

However, in the UA PAR problem, Corey embraced a diﬀerent deﬁnition of “fair”:

I’ll deﬁne “fair” such that Runner B, at his best (100 m in 12 seconds), would

ﬁnish the altered race in 10.5 seconds, which is the average or “typical” time for

the other runner (or at least a good estimate thereof ). This will encourage all

runners to do their best to try to win.

In the UA PAR problem, Corey’s deﬁnition of “fair” involved comparing Runner B’s fastest

speed to Runner A’s average speed. In this example, PAR and Modeling complement each

other quite nicely: Modeling provides opportunities to revisit similar scenarios using increas-

ingly sophisticated models, and the open-ended nature of PAR problems provides oppor-

tunities for students to modify their underlying assumptions and hence the mathematical

reasoning they bring to bear on the problem.

7

D. Discussion

As Alex, Bobbie, and Corey’s solutions demonstrate, PAR facilitates reﬂection on diverse

approaches to solving physics problems. Students diﬀered in their reasoning about what it

means to have a fair head start, and they also diﬀered in their approaches to computing

the head start. These are just three of numerous responses illustrating how the open ended

prompt of a fair head start allowed students to provide a variety of solutions. This is espe-

cially important in the context of PAR, because when students enter a peer conference with

diﬀerent solutions, it provides them with a productive space for discussing their diﬀerences.

For example, some students’ deﬁnition of “fair” led them to compare the slowest speed of

Runner A to the fastest time of Runner B while others’ deﬁnitions resulted in comparing the

runners’ average speeds. Through peer conferences, PAR provided a space for students to

discuss these diﬀerent choices and the interpretations of minimum, maximum, and average

race times.

Moreover, some students modiﬁed their responses with the new model while others did

not. Importantly, the PAR problems created explicit opportunities for students to revisit

their initial models, make revisions, and make comparisons between models. Using open-

ended homework problems such as this in the context of Modeling provided space for students

to explore the relationship between the assumptions made in a model and how to deﬁne an

ambiguous concept such as “fair.” In general, revision helped students improve the depth

and clarity of their responses.

IV. GUIDELINES FOR TEACHERS

Having illustrated the potential of PAR and modeling to engage students with conceptual

reasoning, we now provide guidelines for teachers who wish to use these techniques together

in their classroom.

A. Setup and Logistics

Typically students are expected to complete a single PAR problem each week. This

involves completing an initial solution, bringing that solution to class for peer conferencing,

and then turning in a revised solution during a later class period (one or two days later).

8

It is important that students turn in their revised solutions at a later date, to avoid the

temptation that some students may have of simply “getting the problem done” and turning

it in at the end of the same class period.

Prior studies of PAR showed that students beneﬁt from engaging with a variety of partners

in PAR.10 This means that students should be encouraged to frequently work with new

partners. One way to achieve this is by assigning random partners each week. Logistically,

this can also be accomplished by having students sit in a diﬀerent seat each time before

engaging with PAR.

There are a variety of ways that PAR assignments can be graded. In our own work, we

have generally assigned completion points for the self-reﬂection, peer feedback, and revision

portions of the activity. This provides accountability to students to actually engage in the

PAR process. For grading students’ ﬁnal work, we have used both standard grading and

completion grading in diﬀerent contexts.

B. Framing

To make PAR a successful activity for students, framing is crucial. Assessing the work

of their peers and providing feedback is generally not an activity that students have much

experience with. Accordingly, there can often be resistance insofar that students feel that

they do not have the expertise to provide feedback to their peers. One way to help with this

is to emphasize the importance of communication: if you do not understand the problem,

a well-explained solution should help you understand it. In this way, it is also possible to

provide feedback no matter what your understanding is. A teacher can also emphasize that

this is an opportunity to collaborate to come up with solutions, and that in real physics

settings, there is no answer book.

It is also important to discuss the types of skills that PAR aims to develop: communica-

tion, collaboration, and persistence. A potent framing for the physics contexts is that these

are skills that employers highly desire yet physics graduates are often lacking with. It is

important than students understand that PAR is aimed both to help them succeed on these

given problems and to help them become better at learning physics.

9

C. Discussing Sample Work

Given the novelty of the PAR activity, students can beneﬁt greatly from training on how

to give better feedback. In the original studies, this involved weekly class discussions (ap-

proximately 10 minutes long) around samples of student work related to the weekly PAR

problem. The task for students was to provide helpful feedback to the students who had

written the sample solutions, and then the solutions and how to give feedback was discussed

as a whole class. This helped students learn to give better feedback, because they had

opportunities to practice and discuss with their instructor and peers. As a result of such

training, student success in calculus improved greatly, as did the quality of student con-

versations;13 rather than focusing primarily on getting the “right answer,” students focused

more on communication and underlying reasoning.

In the context of our physics work, we constructed a variety of activities in which students

looked at a variety of solutions from their peers. For instance, with the runners problem,

we compiled all of the diﬀerent handicaps that students suggested and on what basis they

determined the handicap. This provided students with chances to see how many diﬀerent

ways one could reason about the problem, and also to learn from the work of their peers.

D. Discussing Student Feedback

In addition to training students, it is also very helpful to allocate class time for talking

about the types of feedback that students actually give to one another. First and foremost,

this communicates to students that the teacher does care about what they are writing, and

is willing to devote class time to it. Also, it provides opportunities to speak with students

about what feedback they are actually giving and how it can be improved.

V. CONCLUSION

PAR and Modeling are both approaches to teaching physics that support iteration and

reﬁnement of one’s work. As this paper highlights, these approaches are complementary and

can be used to eﬀectively help students iteratively improve their solutions to open-ended

physics problems. As students engage with these approaches, they not only learn physics,

they learn how to better learn physics.

10

ACKNOWLEDGMENTS

The authors acknowledge Chance Hoellwarth and Christine Lindstrøm for contributions

to the design of physics PAR activities and feedback on drafts of the paper, respectively.

These materials were designed and implemented in the Cal Poly San Luis Obispo Physics

Department. DLR and DRDF are supported by the AAU Undergraduate STEM Education

Initiative and NSF grant DUE-1323101, respectively. DLR and DRDF contributed equally

to this work.

∗ daniel.reinholz@colorado.edu
† dimitri.dounasfrazer@colorado.edu
1 Daniel Reinholz, “The assessment cycle: a model for learning through peer assessment,” As-

sessment & Evaluation in Higher Education , 1–15 (2015).

2 National Research Council, Discipline-Based Education Research: Understanding and Improv-

ing Learning in Undergraduate Science and Engineering, edited by Susan R. Singer, Natalie R.

Nielsen, and Heidi A. Schweingruber (National Academies Press, 2012).

3 Binod Nainabasti, David T. Brookes, Yuehai Yang, and Yuhfen Lin, “Connection between

participation in interactive learning environment and learning through teamwork,” in Physics

Education Research Conference 2015, PER Conference (College Park, MD, 2015) pp. 231–234.

4 Michael Epstein, Amber Lazarus, Tammy Calvano, Kelly Matthews, Rachel Hendel, Beth Ep-

stein, and Gary Brosvic, “Immediate Feedback Assessment Technique Promotes Learning and

Corrects Inaccurate First Responses,” The Psychological Record 52 (2010).

5 Andrew Mason and Chandralekha Singh, “Helping students learn eﬀective problem solving

strategies by reﬂecting with peers,” American Journal of Physics 78, 748–754 (2010).

6 Eugenia Etkina, Sahana Murthy, and Xueli Zou, “Using introductory labs to engage students

in experimental design,” American Journal of Physics 74, 979–986 (2006).

7 Jean W. Pierce and Deborah L. Kalkman, “Applying Learner-Centered Principles in Teacher

Education,” Theory into Practice 42, 127–132 (2003).

8 P. Black and D. Wiliam, “Developing the theory of formative assessment,” Educational Assess-

ment, Evaluation and Accountability 21, 5–31 (2009).

11

9 D.R. Sadler, “Formative assessment and the design of instructional systems,” Instructional

science 18, 119–144 (1989).

10 Daniel Reinholz, “Peer-assisted reﬂection: A design-based intervention for improving success in

calculus,” International Journal of Research in Undergraduate Mathematics Education , 1–34

(2015).

11 NGSS Lead States, “The Next Generation Science Standards,” (2013).

12 Eric Brewe, “Modeling theory applied: Modeling instruction in introductory physics,” American

Journal of Physics 76, 1155–1160 (2008).

13 Daniel Reinholz, “Peer conferences in calculus: the impact of systematic training,” Assessment

& Evaluation in Higher Education , 1–17 (2015).

12

FIG. 1.

Image used for two diﬀerent PAR problems. For each PAR problem, the caption of this

ﬁgure read: “Three runners are competing in the 100 meter dash. Runner A is faster than Runners

B and C. Runner B is new to the sport, and the other runners have agreed to give him a head

start in the race. Thus, Runner B starts the race at the head start line rather than the start line.

The ﬁrst runner to pass the ﬁnish line wins the race. In previous races, Runner A ﬁnished the

100 meter dash in about 10–11 seconds. Runner B, on the other hand, has generally taken 12–13

seconds to run this same distance.”

13

ABCStartHead StartFinishFIG. 2. Example of student work before (top) and after (bottom) receiving peer feedback (using a

UA model). Bobbie’s velocity and acceleration graphs were initially inconsistent with her position

graph. After receiving feedback from a peer (orange marks), Bobbie revised her graphs.

14

Bobby's initial solution, with peer feedback:Bobby's revised solution: