6
1
0
2

 
r
a

 

M
9
1

 
 
]

.

R
P
h
t
a
m

[
 
 

1
v
1
7
0
6
0

.

3
0
6
1
:
v
i
X
r
a

OPTIMAL CONTROL AND ZERO-SUM STOCHASTIC DIFFERENTIAL GAME

PROBLEMS OF MEAN-FIELD TYPE

BOUALEM DJEHICHE AND SAID HAMAD `ENE

ABSTRACT. We show existence of an optimal control and a saddle-point for respectively a
control problem and zero-sum differential game associated with payoff functionals of mean-
ﬁeld type, under dynamics driven by weak solutions of stochastic differential equations of
mean-ﬁeld type.

CONTENTS

1.
Introduction
2. Preliminaries
3. Diffusion process of mean-ﬁeld type
4. Optimal control of the diffusion process of mean-ﬁeld type
4.1. Existence of an optimal control
5. The zero-sum game problem
5.1. Existence of a saddle-point for the zero-sum game
References

1
3
4
5
8
10
12
13

1. INTRODUCTION

In this note we establish existence of an optimal control and a saddle-point for a zero-
sum game associated with a payoff functional of mean-ﬁeld type, under a dynamics driven
by the weak solution of a stochastic differential equation (SDE) of mean-ﬁeld type. The
obtained results extend in a natural way those obtained in [HL95] for standard payoffs
associated with standard diffusion processes.
Given a control process u with values in some compact metric space U, the controlled SDE
of mean-ﬁeld type we consider in this paper is of the following functional form:

dxt = f (t, x., Pu ◦ x−1

t

, ut)dt + σ(t, x.)dW Pu
t

,

x0 = ξ ∈ Rd,

i.e. the f and σ depend on the whole path x., where Pu ◦ x−1
is the marginal probability
t
distribution of xt under the probability measure Pu and W Pu
is a standard Brownian motion
under Pu. The payoff functional J(u), u ∈ U , associated with the controlled SDE is of the
form

where Eu denotes the expectation w.r.t. Pu.
As an example the functions f , g and h can have the following forms f (t, x., Eu[xt], u),
g(x, Eu[xT]) and h(t, x., Eu[xt], u) respectively. Taking h = 0 and g(x, y) = x2 − y2, the

Date: March 22, 2016.
2010 Mathematics Subject Classiﬁcation. 60H10, 60H07, 49N90.
Key words and phrases. mean-ﬁeld, nonlinear diffusion process, backward SDEs, optimal control, zero-sum game,

saddle-point.

1

J(u) := Eu(cid:20)Z T

0

h(t, x., Pu ◦ x−1

t

, ut)dt + g(xT, Pu ◦ x−1

T )(cid:21) ,

2

BOUALEM DJEHICHE AND SAID HAMAD `ENE

cost functional reduces to the variance, J(u) = Eu[X2

T] − (Eu[XT])2.

In the ﬁrst part of this note we establish existence of an optimal control associated with

J(u): Findbu with values in U such that

Extension of our result to payoffs

J(u).

J(bu) = min

u

J(u) := Eu(cid:20)Z T

0

h(t, x., Pu ◦ x−1

t

, Pu ◦ u−1

t

, ut)dt + g(xT, Pu ◦ x−1

T )(cid:21) ,

that also depend on the marginal law Pu ◦ u−1
vided some minor adjustments.

t of the underlying control is immediate, pro-

The recent paper by Carmona and Lacker [CL15] discusses a similar problem but for the
so-called mean-ﬁeld game problem (where they further consider the marginal laws of the
control process) which has the following structure (cf. [CL15]):

(1) Fix a probability measure µ on path space and a ﬂow ν : t −→ νt of measures on

the control space;

(2) With µ and ν frozen, solve the standard optimal control problem:

( infu EuhR T

0 h(t, x., µ, ν, ut)dt + g(xT, µ)i ,

dxt = f (t, x., µ, ut)dt + σ(t, x.)dW Pu
t

,

x0 = ξ ∈ Rd,

(1.1)

(3) Standard optimization: Find an optimal control u, inject it into the dynamics of
(1.1), and ﬁnd the law Φx(µ, ν) of the optimally controlled state process and the
ﬂow Φu(µ, ν) of marginal laws of the optimal control process;

(4) Matching: Find a ﬁxed point µ = Φx(µ, ν), ν = Φu(µ, ν).

Hence, while our problem is a control problem of the whole dynamics of x and its controlled
ﬂow of marginals, the mean-ﬁeld game approach is a two-steps approach which ﬁrst solves
a standard optimization problem for frozen marginals, and then solves a matching (ﬁxed
point) problem that determines the law of the optimally controlled process. For further
details about the two approaches see [BFY13] and [CL15] and the references therein.

The zero-sum game we consider is between two players with controls u with values
in some compact metric space U and v with values in some compact metric space V, re-
spectively. The dynamics and the payoff function associated with the game are both of
mean-ﬁeld type and are given by

dxt = f (t, x., Pu,v ◦ x−1

t

, ut, vt)dt + σ(t, x.)dW Pu,v

t

,

x0 = ξ ∈ Rd,

and

where Pu,v ◦ x−1
t
sure Pu,v, W Pu,v
w.r.t. Pu,v.

J(u, v) := Eu,v(cid:20)Z T

0

h(t, x., Pu,v ◦ x−1

t

, ut, vt)dt + g(xT, Pu,v ◦ x−1

T )(cid:21) ,

is the marginal probability distribution of xt under the probability mea-
is a standard Brownian motion under Pu,v and Eu,v denotes the expectation

In the zero-sum game, the ﬁrst player (with control u) wants to minimize the payoff
J(u, v) while the second player (with control v) wants to maximize it. The zero-sum game
boils down to investigating the existence of a saddle point for the game i.e. to show exis-

tence of a pair (bu,bv) of strategies such that

for each (u, v) with values in U × V.

J( ˆu, v) ≤ J(bu,bv) ≤ J(u,bv),

OPTIMAL CONTROL AND ZERO-SUM GAMES OF MEAN-FIELD TYPE

3

In Section 3, we account for existence and uniqueness of the weak solution of the SDE of
mean-ﬁeld type. In Section 4, we prove existence of an optimal control. Finally, in Section
5, we establish existence of a saddle point for a two-persons zero-sum game.

2. PRELIMINARIES

Let Ω := C([0, T]; Rd) be the space of Rd-valued continuous functions on [0, T] endowed
with the metric of uniform convergence on [0, T]; |w|t := sup0≤s≤t |ws|, for 0 ≤ t ≤ T. De-
note by F the Borel σ-ﬁeld over Ω. Given t ∈ [0, T] and ω ∈ Ω, let x(t, ω) be the position
in Rd of ω at time t. Denote by F 0
:= σ(xs, s ≤ t), 0 ≤ t ≤ T, the ﬁltration generated by x.
t
Below, C denotes a generic positive constant which may change from line to line.

Let σ be a function from [0, T] × Ω into Rd×d such that

t -progressively measurable ;

(A1) σ is F 0
(A2) There exists a constant C > 0 such that
(a) For every t ∈ [0, T] and w, ¯w ∈ Ω,

|σ(t, w) − σ(t, ¯w)| ≤ C|w − ¯w|t.

(b) σ is invertible and its inverse σ−1 satisﬁes |σ−1(t, w)| ≤ C(1 + |w|α

t ), for some

constant α ≥ 0.

(c) For every t ∈ [0, T] and w ∈ Ω, |σ(t, w)| ≤ C(1 + |w|t).

Next, let P be a probability on Ω such that (Ω, P) carries a Brownian motion (Wt)0≤t≤T
and such that the coordinates process (xt)0≤t≤T is the unique solution of the following
stochastic differential equation:

dxt = σ(t, x.)dWt,

x0 = ξ ∈ Rd.

(2.1)

Such a triplet (P, W, x) exists due to Proposition 4.6 in ([KS12], p.315) since σ satisﬁes (A2).
Moreover, for every p ≥ 1,

E[|x|p

(2.2)
where Cp depends only on p, T, the initial value ξ and the linear growth constant of σ (see
[KS12], p. 306). Again, since σ satisﬁes (A2), then F 0
is the same as σ{Ws, s ≤ t} for any
t
t ≤ T.
We denote by F := (Ft)0≤t≤T the completion of (F 0

t )t≤T with the P-null sets of Ω.

T] ≤ Cp,

Let P (Rd) denote the set of probability measures on Rd and P2(Rd) the subset of mea-
sures with ﬁnite second moment. For µ, ν ∈ P (Rd), the total variation distance is deﬁned
by the formula

d(µ, ν) = 2 sup

|µ(B) − ν(B)|.

(2.3)

Furthermore, let P2(Ω) the space of probability measures P on Ω such that kPk2
E[|x|2
Deﬁne on F the total variation metric

T] < +∞, where |x|t := sup0≤s≤t |xs|, 0 ≤ t ≤ T.

2 :=RΩ |w|2

TP(dw) =

B∈B(Rd)

d(P, Q) := 2 sup
A∈F

|P(A) − Q(A)|.

(2.4)

Similarly, on the ﬁltration F, we deﬁne the total variation metric between two probability
measures P and Q as

Dt(P, Q) := 2 sup
A∈Ft

|P(A) − Q(A)|,

0 ≤ t ≤ T.

(2.5)

It satisﬁes

(2.6)
Endowed with the total variation metric DT, P2(Ω) is a complete metric space. Moreover,
DT carries out the usual topology of weak convergence.

Ds(P, Q) ≤ Dt(P, Q),

0 ≤ s ≤ t.

4

BOUALEM DJEHICHE AND SAID HAMAD `ENE

For P, Q ∈ P2(Ω) with time marginals Pt := P ◦ x−1
distance between Pt and Qt satisﬁes

t

and Qt := Q ◦ x−1

t

, the total variation

d(Pt, Qt) ≤ Dt(P, Q),

0 ≤ t ≤ T.

(2.7)

Indeed, we have

d(Pt, Qt) := 2 supB∈B(Rd) |Pt(B) − Qt(B)|

= 2 supB∈B(Rd) |P(x−1
≤ 2 supA∈Ft

(B))|
|P(A) − Q(A)| = Dt(P, Q).

(B)) − Q(x−1

t

t

3. DIFFUSION PROCESS OF MEAN-FIELD TYPE

Hereafter, a process θ from [0, T] × Ω into a measurable space is said to be progressively
measurable if it is progressively measurable w.r.t. F.

Let b be a measurable from [0, T] × Ω × P2(Rd) into Rd such that

(A3) For every Q ∈ P2(Ω), the process ((b(t, x., Q ◦ x−1
(A4) For every t ∈ [0, T], w ∈ Ω and µ, ν ∈ P2(Rd),

t

))t is progressively measurable.

|b(t, w, µ) − b(t, w, ν)| ≤ Cd(µ, ν).

(A5) For every t ∈ [0, T], w ∈ Ω and µ ∈ P2(Rd),

|b(t, w, µ)| ≤ C(1 + |w|t +Z |y|µ(dy)).

Let PQ be the measure on (Ω, F ) deﬁned by

dPQ := LQ

T dP

with

LQ
t

:= Et(cid:18)Z ·

0

σ−1(s, x·)b(s, x·, Q ◦ x−1

s )dWs(cid:19) ,

where, for any (F, P)-continuous local martingale M = (Mt)0≤t≤T, E (M) denotes the
Doleans exponential E (M) := (exp Mt − 1
2 hMit)0≤t≤T. Thanks to assumptions (A2) and
(A5), PQ is a probability measure on (Ω, F ). A proof of this fact follows the same lines of
the proof of Proposition A.1 in [EKH03]. Hence, in view of Girsanov’s theorem, the process
(W Q

t , 0 ≤ t ≤ T) deﬁned by

(3.1)

(3.2)

0 ≤ t ≤ T,

W Q
t

:= Wt −Z t

0

σ−1(s, x.)b(s, x., Q ◦ x−1

s )ds,

0 ≤ t ≤ T,

is an (F, PQ)-Brownian motion. Furthermore, under PQ,
)dt + σ(t, x.)dW Q
t ,

dxt = b(t, x., Q ◦ x−1

t

x0 = ξ ∈ Rd.

(3.3)

Next, we will show that there is ¯Q such that P ¯Q = ¯Q, i.e., ¯Q is a ﬁxed point.

Theorem 3.1. The map

Φ : P2(C) −→ P2(C)

Q −→ Φ(Q) := PQ;

dPQ := LQ

T dP

admits a unique ﬁxed point.

Proof. First, we show that if Q ∈ P2(C) then Φ(Q) ∈ P2(C), i.e.

ZC

|x|2
T

Φ(Q)(dx) = EΦ(Q)[|x|2

T] < +∞,

where, under Φ(Q),

dxt = b(t, x., Qt)dt + σ(t, x.)dW Q,

x0 = ξ ∈ Rd,

OPTIMAL CONTROL AND ZERO-SUM GAMES OF MEAN-FIELD TYPE

5

and Qt := Q ◦ x−1
and Burkholder-Davis-Gundy inequalities yield

t

. Indeed, in view of assumptions (A2) and (A5), the Cauchy-Schwarz

(3.4)

|x|2

0

we obtain

2) < +∞.

≤ EQ[|x|2

T] = kQk2

2 and Gronwall’s inequality,

EΦ(Q)[|x|2

T] ≤ C(1 + kQk2

EΦ(Q)h|x|2

under Φ(Q), dxt = b(t, x., Qt)dt + σ(t, x.)dW Q
t ,

t dt(cid:21) + sup

0≤t≤T(cid:18)Z |y|Qt(dy)(cid:19)2! .

of the Hellinger process associated with the coordinate process x under the probability

Ti ≤ C 1 + EΦ(Q)(cid:20)Z T
Using the fact that(cid:16)sup0≤t≤TR |y|Qt(dy)(cid:17)2
It remains to show the contraction property of the map Φ. To this end, given Q, bQ ∈ P2(Ω),
we use an estimate of the total variation distance DT(Φ(Q), Φ(bQ)) in terms of a version
measures Φ(Q) and Φ(bQ), respectively. Indeed, since by (3.3),
under Φ(bQ), dxt = b(t, x., bQt)dt + σ(t, x.)dWbQ
∆bt(Q, bQ)dt,
∆bt(Q, bQ) := b(t, x., Qt) − b(t, x., bQt)
DT(Φ(Q), Φ(bQ)) ≤ 8qEΦ(Q) [ΓT].

and at
estimate (4.22) of Theorem V.4.21 in [JS03], to obtain

:= (σσ†)(t, x.) and M† denotes the transpose of the matrix M. We may use the

in view of Theorem IV.1.33 in [JS03], a version of the associated Hellinger process is

∆bt(Q, bQ)†a−1

By (A2), (A4) and (3.4), we have

x0 = ξ ∈ Rd,

x0 = ξ ∈ Rd,

1

8Z T

0



ΓT :=

where

(3.5)

t ,

t

(3.6)

(3.7)

EΦ(Q)h∆bt(Q, bQ)†a−1

t

which together with (3.6) yield

t (Q, bQ),

D2

T(Φ(Q), Φ(bQ)) ≤ CZ T

∆bt(Q, bQ)i ≤ Cd2(Qt, bQt) ≤ CD2
t (Q, bQ)dt.
t (Q, bQ)dt ≤

(T − t)N−1
(N − 1)!

D2

D2

0

CNTN

N!

D2

T(Q, bQ),

Iterating this inequality, we obtain, for every N > 0,

D2

T(ΦN (Q), ΦN(bQ)) ≤ CNZ T

0

where ΦN denotes the N-fold composition of the map Φ. Hence, for N large enough, ΦN is
a contraction which entails that Φ admits a unique ﬁxed point.
(cid:3)

4. OPTIMAL CONTROL OF THE DIFFUSION PROCESS OF MEAN-FIELD TYPE

Let (U, δ) be a compact metric space with its Borel ﬁeld B(U) and U the set of F-
progressively measurable processes u = (ut, 0 ≤ t ≤ T) with values in U. We call U
the set of admissible controls.

Let f and h be two measurable functions from [0, T] × Ω × P2(Rd) × U into Rd and R,

respectively, and g be a measurable functions from Rd × P2(Rd) into R such that

(B1) For any u ∈ U and Q ∈ P2(Ω), the processes ( f (t, x., Q ◦ x−1

x−1
t

, ut))t are progressively measurable. Moreover, g(xT, Q ◦ x−1

t

, ut))t and (h(t, x., Q ◦
T ) is FT-measurable.

where

Lu

0

t := Et(cid:18)Z ·
:= Wt −Z t

0

Wu
t

By Girsanov’s theorem, the process (Wu

t , 0 ≤ t ≤ T) deﬁned by

σ−1(s, x.) f (s, x., Pu ◦ x−1

s

, us)ds,

0 ≤ t ≤ T,

6

BOUALEM DJEHICHE AND SAID HAMAD `ENE

(B2) For every t ∈ [0, T], w ∈ Ω, u, v ∈ U and µ, ν ∈ P2(Rd),

|φ(t, w, µ, u) − φ(t, w, ν, v)| ≤ C(d(µ, ν) + δ(u, v)).

for φ ∈ { f , h, g}.

(B3) For every t ∈ [0, T], w ∈ Ω, u ∈ U and µ ∈ P2(Rd),

| f (t, w, µ, u)| ≤ C(1 + |w|t +Z |y|µ(dy)).

(B4) h and g are uniformly bounded

For u ∈ U , let Pu be the probability measure on (Ω, F ) which is a ﬁxed point of Φu
deﬁned in the same was as in Theorem 3.1 except that the drift term b(.) depends moreover
on u but this does not rise a major issue. Thus we have:

dPu := Lu

TdP,

σ−1(s, x.) f (s, x., Pu ◦ x−1

s

, us)dWs(cid:19) ,

(4.1)

(4.2)

0 ≤ t ≤ T.

is an (F, Pu)-Brownian motion. Moreover, under Pu,

dxt = f (t, x, Pu ◦ x−1
Let Eu denote the expectation w.r.t. Pu.

t

, ut)dt + σ(t, x)dWu
t ,

We have, for every u ∈ U ,

kPuk2

2 = Eu[|x|2

T] ≤ C < +∞,

x0 = ξ ∈ Rd.

(4.3)

(4.4)

where the constant C depends only on T, ξ and the linear growth constants of f and σ.
Indeed, in view of assumptions (A2) and (B3), the Cauchy-Schwarz and Burkholder-Davis-
Gundy inequalities yield

0≤s≤t(cid:18)Z |y|Pu

s (dy)(cid:19)2# dt! .

t + sup

Euh|x|2

Ti ≤ C 1 +Z T
Using the fact that(cid:16)sup0≤s≤tR |y|Pu
Euh|x|2

Eu"|x|2
s (dy)(cid:17)2
Ti ≤ C(cid:18)1 + 2Z T

0

0

Gronwall’s inequality yields (4.4).

≤ Eu[|x|2

t ], we obtain

Euh|x|2

ti dt(cid:19) .

We have the following estimate of the total variation between Pu and Pv.

Lemma 4.1. For every u, v ∈ U , it holds that

D2

T(Pu, Pv) ≤ C sup
0≤t≤T

Eu[δ2(ut, vt)].

(4.5)

In particular, the function u −→ Pu from U into P2(Ω) is Lipschitz continuous: for every u, v ∈ U,
(4.6)

DT(Pu, Pv) ≤ Cδ(u, v).

Moreover,

for some constant C > 0 that depends only on T, ξ and the linear growth constants of f and σ.

KT := sup
u∈U

kPuk2 ≤ C < ∞,

(4.7)

OPTIMAL CONTROL AND ZERO-SUM GAMES OF MEAN-FIELD TYPE

7

Proof. Using a similar estimate as (3.6), we have

DT(Pu, Pv) ≤ 8qEu(cid:2) ˜Γu,v
T (cid:3),
8Z T

∆ ft(u, v)†a−1

1

0

t

∆ ft(u, v)dt,

˜ΓT :=

where ˜Γ is the following version of the Hellinger process associated with Pu and Pv:

(4.8)

(4.9)

(4.10)

(4.11)

(4.12)

where

∆ ft(u, v) := f (t, x., Pu ◦ x−1

t

, ut) − f (t, x., Pv ◦ x−1

t

, vt).

Using (B2) and (4.4), we obtain

Euh∆ ft(u, v)†a−1

t

∆ ft(u, v)i ≤ C(d2(Pu ◦ x−1

≤ C(D2

t

t (Pu, Pv) + δ2(ut, vt)).

, Pv ◦ x−1

t

) + δ2(ut, vt))

Hence, in view of (4.8), Gronwall inequality yields

D2

T(Pu, Pv) ≤ CEu(cid:20)Z T

0

δ2(ut, vt)dt(cid:21) ≤ C sup

0≤t≤T

Eu[δ2(ut, vt)].

Inequality (4.6) follows from (4.5) by letting ut ≡ u ∈ U and vt ≡ v ∈ U.
It remains to show (4.7). But, this follows from (4.4) and the continuity of the function
u −→ Pu from the compact set U into P2(Ω).
(cid:3)

The cost functional J(u), u ∈ U associated with the controlled SDE (4.3) is

J(u) := Eu(cid:20)Z T

0

h(t, x., Pu ◦ x−1

t

, ut)dt + g(xT, Pu ◦ x−1

T )(cid:21) ,

is called optimal control. The corresponding optimal dynamics is given by the probability

where h and g satisfy (B1)-(B4) above.

Anybu ∈ U satisfying
measure bP on (Ω, F ) deﬁned by
dbP = E(cid:18)Z ·
dxt = f (t, x,bP ◦ x−1

under which

0

t

J(u)

u∈U

J(bu) = min

,bus)dWs(cid:19) dP,

x0 = ξ ∈ Rd.

s

σ−1(s, x.) f (s, x.,bP ◦ x−1
,but)dt + σ(t, x)dWbu

t ,

We want to ﬁnd such an optimal control and characterize the optimal cost functional J(bu).

For (t, w, µ, p, u) ∈ [0, T] × Ω × P2(Rd) × Rd × U we introduce the Hamiltonian associated
with the optimal control problem (4.3) and (4.9)

H(t, w, µ, p, u) := h(t, w, µ, u) + p · σ−1(t, w) f (t, w, µ, u).

(4.13)

In view of (A2) and (B2), the Hamiltonian H satisﬁes

|H(t, w, µ, p, u) − H(t, w, ν, p, v)| ≤ C(1 + |w|α

t )|p|(d(µ, ν) + δ(u, v)).

(4.14)

Moreover,

|H(t, w, µ, p, u) − H(t, w, µ, p′, u)| ≤ C(1 + |w|1+2α

t

+ kµk2)|p − p′|.

(4.15)

Indeed, in view of assumptions (A2) and (B3), we have

|H(t, w, µ, p, u) − H(t, w, µ, p′, u)| ≤ |σ−1(t, w) f (t, w, µ, u)||p − p′|
+ kµk2)|p − p′|.

≤ C(1 + |w|1+2α

t

8

BOUALEM DJEHICHE AND SAID HAMAD `ENE

Next, we show that the cost functional J(u), u ∈ U , can be expressed by means of solutions
of a linear BSDE.

Proposition 4.2. For every u ∈ U , there exists a unique F-progressively measurable process
(Yu, Zu) such that

t = H(t, x., Pu ◦ x−1

t

, Zu

t , ut)dt − Zu

t dWt,

(cid:26) −dYu

T = g(xT, Pu ◦ x−1
Yu
T ),

and

Moreover, Yu

0 = J(u).

E(cid:20)|Yu|2

T +Z T

0

|Zu

s |2ds(cid:21) < +∞.

0 ≤ t < T,

(4.16)

(4.17)

Proof. Since the Hamiltonian H(t, w, µ, p, u) is linear in p, existence and uniqueness of so-
lutions of the BSDE (4.16) satisfying (4.17) follows from (4.15), (2.2), the boundedness of
g(xT, Pu ◦ x−1
, 0, ut) which follows from (B3) and
(B4) (see [HL95] for more details).
It remains to show that Yu

T ) and the boundedness of H(t, x., Pu ◦ x−1

0 = J(u). Indeed, in terms of the (F, Pu)-Brownian motion

t

Wu
t

σ−1(s, x.) f (s, x., Pu ◦ x−1

s

, us)ds,

0 ≤ t ≤ T,

the process (Yu, Zu) satisﬁes

t = g(xT, Pu ◦ x−1
Yu

0

:= Wt −Z t
T ) +Z T

t

Therefore,

In particular,

Yu

t

t = Eu(cid:20)Z T
0 = Eu(cid:20)Z T

Yu

0

h(s, x., Pu ◦ x−1

, us)ds + g(xT, Pu ◦ x−1

s

h(s, x., Pu ◦ x−1

s

, us)dt + g(xT, Pu ◦ x−1

h(s, x., Pu ◦ x−1

s

, us)dt −Z T

t

s dWu
Zu
s ,

0 ≤ t ≤ T.

T )(cid:12)(cid:12)Ft(cid:21) Pu − a.s.
T )(cid:21) = J(u).

4.1. Existence of an optimal control. In the remaining part of this section we want to ﬁnd

(cid:3)

bu ∈ U such thatbu = arg minu∈U J(u). A way to ﬁnd such an optimal control is to proceed as

in Proposition 4.2 and introduce a linear BSDE whose solution Y∗ satisﬁes Y∗
0 = infu∈U J(u).
Then, by the comparison theorem for BSDEs, the problem can be reduced to minimizing the
corresponding Hamiltonian w.r.t the control u.
We may use (2.7), (4.6) and (4.14) to see that the function u −→ H(t, w, Pu ◦ w−1
, p, u) is
continuous on the compact set U. Thus, for each (t, w, p), H∗(t, w, p) := infu∈U H(t, w, Pu ◦
w−1

, p, u) is ﬁnite. Moreover, the set of minima of H,

t

t

U(t, w, p) := {u ∈ U, H∗(t, w, p) = H(t, w, Pu ◦ w−1

t

, p, u)},

(4.18)

is not empty.
Furthermore, by (2.7), (4.6) and (B2), the function u −→ g(wT, Pu ◦ w−1
Therefore, g∗(wT) := infu∈U g(wT, Pu ◦ w−1

T ) is ﬁnite and the set of minima of g,

T ) is continuous.

is not empty.

eU(wT) := {u ∈ U, g∗(wT) = g(wT, Pu ◦ w−1

T )}

(4.19)

We have the following

OPTIMAL CONTROL AND ZERO-SUM GAMES OF MEAN-FIELD TYPE

9

Lemma 4.3. For every (t, w) ∈ [0, T] × Ω, the function p −→ H∗(t, w, p) from Rd into R is
Lipschitz continuous. More precisely, we have

|H∗(t, w, p) − H∗(t, w, p′)| ≤ C(1 + |w|1+2α

t

kPuk2)|p − p′|.

(4.20)

+ sup
u∈U

Proof. We have

|H∗(t, w, p) − H∗(t, w, p′)| =(cid:12)(cid:12)(cid:12)(cid:12) inf

u∈U
≤ sup

H(t, w, Pu ◦ w−1

t

u∈U(cid:12)(cid:12)(cid:12)H(t, w, Pu ◦ w−1

≤ C(1 + |w|1+2α

t

t

, p, u) − inf
u∈U

H(t, w, Pu ◦ w−1

, p, u) − H(t, w, Pu ◦ w−1

t

+ supu∈U kPuk2)|p − p′|,

t

, p′, u)(cid:12)(cid:12)(cid:12)(cid:12)
, p′, u)(cid:12)(cid:12)(cid:12)

by estimate (4.7), where by the continuity of u −→ Pu, KT := supu∈U kPuk2 is ﬁnite.

(cid:3)

By Beneˇs selection theorem ([Ben71]) applied to the sets of minima U(t, w, p) and eU(wT),

there exists a progressively measurable function u∗

1 from [0, T) × Ω × Rd into U such that
(4.21)

u∗
1(t, w, p) ∈ U(t, w, p).

Moreover, there exits an FT-measurable process u∗

2 from Rd into U such that

(4.22)
Combining (4.21) and (4.22), it is easily seen that the progressively measurable function u∗
deﬁned by

2(wT) ∈ eU(wT).

u∗

bu(t, w, p) :=(cid:26) u∗
H∗(t, w, p) = H(t, w, Pbu ◦ w−1

t

1(t, w, p),
u∗
2(wT),

t < T,

t = T,

, p,bu), g∗(wT) = g(wT, Pbu ◦ w−1

T ).

In the next theorem we characterize the set of optimal controls associated with (4.10)

under the dynamics (4.3).

Theorem 4.4. There exists a unique F-progressively measurable process (Y∗, Z∗) such that

(4.23)

(4.24)

(4.25)

(4.26)

satisﬁes

and

t )dt − Z∗

t dWt,

0 ≤ t < T,

Y∗
T = g∗(xT),

(cid:26) −dY∗ = H∗(t, x, Z∗
T +Z T

E(cid:20)|Y∗|2

0

|Z∗

s |2ds(cid:21) < +∞.

Moreover, for every t ∈ [0, T], Y∗
the process u∗
dynamics (4.3).

t := bu(t, x., Z∗

t = ess infu∈U Yu

t , where Yu is solution of the BSDE (4.16), and
t ) given by (4.23) is an optimal control for the problem (4.10) under the

Proof. Existence and uniqueness of solutions (Y∗, Z∗) of (4.25) satisfying (4.26) follow from
the estimates (4.20) and the boundedness of the function H∗(t, x., 0) which follows from (B4)
and the boundedness of g∗(xT) which also follows from (B4) (see [HL95] for more details).
Furthermore, since g∗(xT) ≤ g(xT, Pu ◦ x−1
, p, u), by
the comparison theorem for BSDEs, it holds that Y∗
t . In
view of (4.23), (4.24) and the uniqueness of the solution of (4.25), we have Y∗
t ≥
ess infu∈U Yu
t .
Therefore,

T ) and H∗(t, x., p) ≤ H(t, x., Pu ◦ x−1

t ≤ ess infu∈U Yu
t = Yu∗

t . Hence, Y∗

t ≤ Yu

t

In particular, Y∗

0 = infu∈U J(u) = J(u∗). This ﬁnishes the proof of the theorem.

(cid:3)

Yu∗
t = Y∗

t = ess infu∈U Yu
t .

10

BOUALEM DJEHICHE AND SAID HAMAD `ENE

5. THE ZERO-SUM GAME PROBLEM

In this section we consider a two-players zero-sum game. Let U (resp. V) be the set of
admissible U-valued (resp. V-valued) control strategies for the ﬁrst (resp. second) player,
where (U, δ1) and (V, δ2) are compact metric spaces.

For (u, v), ( ¯u, ¯v) ∈ U × V, we set

The distance δ deﬁnes a metric on the compact space U × V.

δ((u, v), ( ¯u, ¯v)) := δ1(u, ¯u) + δ2(v, ¯v).

(5.1)

Let f and h be two measurable functions from [0, T] × Ω × P2(Rd) × U × V into Rd and R,
respectively, and g be a measurable functions from Rd × P2(Rd) into R such that

(C1) For any (u, v) ∈ U × V and Q ∈ P2(Ω), the processes ( f (t, x., Q ◦ x−1

, ut, vt))t are progressively measurable. Moreover, g(xT, Q ◦ x−1

t

, ut, vt))t and
T ) is

(h(t, x., Q ◦ x−1
FT-measurable.

t

(C2) For every t ∈ [0, T], w ∈ Ω, (u, v), ( ¯u, ¯v) ∈ U × V and µ, ν ∈ P2(Rd),

|φ(t, w, µ, u, v) − φ(t, w, ν, ¯u, ¯v)| ≤ C(d(µ, ν) + δ((u, v), ( ¯u, ¯v)),

for φ ∈ { f , h, g}.

(C3) For every t ∈ [0, T], w ∈ Ω, (u, v) ∈ U × V and µ ∈ P2(Rd),

| f (t, w, µ, u, v)| ≤ C(1 + |w|t +Z |y|µ(dy)).

(C4) h and g are uniformly bounded (this assumption can be weakened).

For (u, v) ∈ U × V, let Pu,v be the measure on (Ω, F ) deﬁned by

dPu,v := Lu,v

T dP,

(5.2)

where

Lu,v
t

:= Et(cid:18)Z ·

0

σ−1(s, x.) f (s, x., Pu,v ◦ x−1

s

0 ≤ t ≤ T.

(5.3)

, us, vs)dWs(cid:19) ,

In view of assumptions (C1) and (C3), Pu,v is a probability measure on (Ω, F ). Hence, by
Girsanov’s theorem, the process (Wu,v

, 0 ≤ t ≤ T) deﬁned by

t

Wu,v

t

:= Wt −Z t

0

σ−1(s, x.) f (s, x., Pu ◦ x−1

s

, us, vs)ds,

0 ≤ t ≤ T,

is an (F, Pu,v)-Brownian motion. Moreover, under Pu,v,

dxt = f (t, x, Pu,v ◦ x−1

t

, ut, vt)dt + σ(t, x)dWu,v

t

,

x0 = ξ ∈ Rd.

(5.4)

Let Eu,v denote the expectation w.r.t. Pu,v.
The performance functional J(u, v), (u, v) ∈ U × V, associated with the controlled SDE (5.4)
is

h(t, x., Pu,v ◦ x−1

t

, ut, vt)dt + g(xT, Pu,v ◦ x−1

(5.5)

J(u, v) := Eu,v(cid:20)Z T

0

T )(cid:21) .

The zero-sum game we consider is between two players, where the ﬁrst player (with control
u) wants to minimize the payoff (5.5), while the second player (with control v) wants to
maximize it. The zero-sum game boils down to showing existence of a saddle-point for the

game i.e. to show existence of a pair (bu,bv) of strategies such that

J( ˆu, v) ≤ J(bu,bv) ≤ J(u,bv)

(5.6)

under which

x0 = ξ ∈ Rd.

(5.8)

OPTIMAL CONTROL AND ZERO-SUM GAMES OF MEAN-FIELD TYPE

11

for each (u, v) ∈ U × V.

The corresponding optimal dynamics is given by the probability measure bP on (Ω, F ) de-

ﬁned by

(5.7)

0

dbP = E(cid:18)Z ·
dxt = f (t, x,bP ◦ x−1

t

s

σ−1(s, x.) f (s, x.,bP ◦ x−1
,but,bvt)dt + σ(t, x)dWbu,bv

t

,

,bus,bvs)dWs(cid:19) dP

For (t, w, µ, p, u, v) ∈ [0, T] × Ω × P2(Rd) × Rd × U × V, we introduce the Hamiltonian
associated with the game (5.4)-(5.5):

H(t, w, µ, p, u, v) := h(t, w, µ, u, v) + p · σ−1(t, w) f (t, w, µ, u, v).

(5.9)

In view of (A2) and (C2), the Hamiltonian H satisﬁes

|H(t, w, µ, p, u, v) − H(t, w, ν, p, ¯u, ¯v)| ≤ C(1 + |w|α

t )|p|(d(µ, ν) + δ((u, ¯u), (v, ¯v)).

(5.10)

Moreover,

|H(t, w, µ, p, u, v) − H(t, w, µ, p′, u, v)| ≤ C(1 + |w|1+2α

t

+ kµk2)|p − p′|.

(5.11)

Deﬁnition 5.1. (Isaacs’ condition). We say that the Isaacs’ condition holds for the game if,
for (t, w, p) ∈ [0, T] × Ω × Rd,

min
u∈U

max
v∈V

H(t, w, Pu,v ◦ w−1

t

, p, u, v) = max
v∈V

min
u∈U

H(t, w, Pu,v ◦ w−1

t

, p, u, v),

(5.12)

min
u∈U

max
v∈V

g(wT, Pu,v ◦ w−1

T ) = max
v∈V

min
u∈U

g(wT, Pu,v ◦ w−1

T ).

In view of (2.7), (4.6), (5.10) and (C3) the functions

(u, v) −→ H(t, w, Pu ◦ w−1

t

, p, u, v), g(wT, Pu,v ◦ w−1
T )

are continuous on the compact set U × V. Thus, both sides of (5.12) are ﬁnite.

Using Beneˇs selection theorem ([Ben71]), with a similar construction that yielded (4.23),
Isaacs’ condition is equivalent with the following condition.

(S) There exist progressively measurable functions u∗ from [0, T] × Ω × Rd into U and

v∗ from [0, T] × Ω × Rd into V such that

t

◦ w−1

◦ w−1
T ),

(cid:26) eH(t, w, p) ≤ H(t, w, Pu,v∗
eg(wT) ≤ g(wT, Pu,v∗
(cid:26) eH(t, w, p) ≥ H(t, w, Pu∗,v ◦ w−1
eg(wT) ≥ g(wT, Pu∗,v ◦ w−1
eH(t, w, p) := H(t, w, Pu∗,v∗

T ),

t

, p, u, v∗(t, w, p)),

∀u ∈ U,

, p, u∗(t, w, p), v),

∀v ∈ V,

◦ w−1

, p, u∗(t, w, p), v∗(t, w, p))

t

T ).

◦ w−1

eg(wT) := g(wT, Pu∗,v∗
eH(t, w, p) = minu∈U maxv∈V H(t, w, Pu,v ◦ w−1
eg(wT) = minu∈U maxv∈V g(wT, Pu∗,v∗

t
T ).

◦ w−1

where

and

Equivalently,

, p, u, v),

(5.13)

12

BOUALEM DJEHICHE AND SAID HAMAD `ENE

5.1. Existence of a saddle-point for the zero-sum game. In the remaining part of this sec-

tion, we want to ﬁnd (bu,bv) ∈ U × V which satisﬁes the relation (5.6). A way to ﬁnd such

a saddle-point is to proceed as in Proposition 4.2 and introduce a linear BSDE associated
with each of the Hamiltonians and end-values involved in the inequality (S). Then, by the
comparison theorem for BSDEs, we show that (u∗, v∗) satisﬁes (5.6) i.e. it is a saddle-point
for the game.

We start by showing that the performance functional J(u, v), (u, v) ∈ U × V, can be ex-
pressed by means of solutions of a linear BSDE.

Proposition 5.2. For every (u, v) ∈ U × V, there exists a unique F-progressively measurable
process (Yu,v, Zu,v) such that

t = H(t, x., Pu,v ◦ x−1

t

, Zu,v

t

, ut, vt)dt − Zu,v

t dWt,

0 ≤ t < T,

(cid:26) −dYu,v

Yu,v
T = g(xT, Pu,v ◦ x−1
T ),

and

Moreover, Yu,v

0 = J(u, v).

E(cid:20)|Yu,v|2

T +Z T

0

|Zu,v

s

|2ds(cid:21) < +∞.

(5.14)

(5.15)

Proof. Since the Hamiltonian H(t, w, µ, p, u) is linear in p, existence and uniqueness of so-
lutions of the BSDE (5.14) satisfying (5.15) follows from (5.11), (2.2) and the boundedness
of H(t, x., Pu,v ◦ x−1
, 0, ut, vt) which follows from (C3) and (C4) and the boundedness of g.
The remaining proof is similar to the one of Proposition 4.2.
(cid:3)

t

We have the following

Lemma 5.3. For every (t, w) ∈ [0, T] × Ω, the function

p −→ H(t, w, Pu∗,v∗

◦ w−1

t

, p, u∗(t, w, p), v∗(t, w, p))

from Rd into R is Lipschitz continuous.

Proof. Using (5.11), the proof is similar to that of Lemma 4.3. We omit it.

(cid:3)

In the next theorem, we characterize the set of saddle-points of the zero-sum game associ-
ated with (5.5) under the dynamics (5.4).

Theorem 5.4. There exists a unique F-progressively measurable process (bY,bZ) such that

0 ≤ t < T,

(5.16)

(5.17)

and

where

and

0

T +Z T

(cid:26) −dbY = bH(t, x.,bZt)dt −bZtdWt,
bYT =bg(xT),
|bZs|2ds(cid:21) < +∞,
E(cid:20)|bY|2
bH(t, x.,bZt) := H(t, x., Pbu,bv ◦ x−1
,bZt,but,bvt),
bg(xT) := g(xT, Pbu,bv ◦ x−1
(but,bvt) := (u∗(t, x.,bZt), v∗(t, x.,bZt)).

T )

t

Moreover,bY0 = J(bu,bv).
Furthermore, the process (bu,bv) is a saddle-point for the zero-sum game associated with (5.5) under

the dynamics (5.4).

OPTIMAL CONTROL AND ZERO-SUM GAMES OF MEAN-FIELD TYPE

13

t dWt,

0 ≤ t < T,

, ¯Zu

t , ut,bvt)dt − ¯Zu

By Proposition 5.2, this BSDE has a unique solution ( ¯Yu, ¯Zu) for which ¯Yu

(cid:26) −d ¯Yu = H(t, x., Pu,bv ◦ x−1

T ).

¯Yu

t

by (S), H(t, x., Pu,bv ◦ x−1
g(xT, Pu,bv ◦ x−1

t

Proof. Existence and uniqueness of solutions (bY,bZ) of (5.16) satisfying (5.17) follow from
Lemma 5.3 and the boundedness of bH(t, x., 0) which follows from (2.2), (C3) and (C4).
We will now show that (bu,bv) is a saddle-point. Let u ∈ U and consider the following
T = g(xT, Pu,bv ◦ x−1
0 = J(u,bv). Since,
T ) ≥bg(xT) P-a.s., we may apply the comparison theorem for BSDEs to obtain
t ≥ bYt, P-a.s. Hence, J(u,bv) ≥ J(bu,bv).
(cid:26) −dYv = H(t, x., Pbu,v ◦ x−1
T = g(xT, Pbu,v ◦ x−1
T ) ≤bg(xT) yields J(bu, v) ≤ J(bu,bv).

t ,but, vt)dt − Zv
Then, in a similar fashion, the inequalities H(t, x., Pbu,v ◦ x−1
g(xT, Pbu,v ◦ x−1

that ¯Yu
Now, let v ∈ U and consider the following BSDE

,bZt,but, vt) ≤ bH(t, x.,bZt) and

,bZt, ut,bvt) ≥ bH(t, x.,bZt) and

t dWt,

0 ≤ t < T,

, Zv

t

T ).

t

(cid:3)

BSDE

Yv

A ﬁnal remark

(1) Assumptions (B4) and (C4) on the boundedness of the functions g and h can be
substantially weakened by using subtle arguments on existence of solutions of one
dimensional BSDEs which are by now well known in the BSDEs literature.

(2) Similar results for risk-sensitive payoff functionals of mean-ﬁeld type, extending

the ﬁndings of [EKH03], can be obtained following the same techniques.

REFERENCES

[Ben71] V. E. Beneˇs, Existence of optimal stochastic control laws, SIAM J. Control 9 (1971), 446–472.
[BFY13] A. Bensoussan, J. Frehse, and P. Yam, Mean ﬁeld games and mean ﬁeld type control theory, Vol. 101, Springer,

2013.

[CL15] R. Carmona and D. Lacker, A probabilistic weak formulation of mean ﬁeld games and applications, The Annals of

Applied Probability 25 (2015), no. 3, 1189–1231.

[EKH03] N. El-Karoui and S. Hamad`ene, BSDEs and risk-sensitive control, zero-sum and nonzero-sum game problems of

stochastic functional differential equations, Stochastic Process. Appl. 107 (2003), no. 1, 145–169.

[HL95] S. Hamad`ene and J. P. Lepeltier, Backward equations, stochastic control and zero-sum stochastic differential games,

Stochastics Stochastics Rep. 54 (1995), no. 3-4, 221–231.

[JS03] J. Jacod and A. N. Shiryaev, Limit theorems for stochastic processes, 2nd ed., Grundlehren der Mathematischen
Wissenschaften [Fundamental Principles of Mathematical Sciences], vol. 288, Springer-Verlag, Berlin, 2003.
[KS12] I. Karatzas and S. Shreve, Brownian motion and stochastic calculus, 2nd ed., Vol. 113, Springer Science & Busi-

ness Media, 2012.

DEPARTMENT OF MATHEMATICS, KTH ROYAL INSTITUTE OF TECHNOLOGY, 100 44, STOCKHOLM, SWEDEN
E-mail address: boualem@math.kth.se

UNIVERSIT ´E DU MAINE, LMM, AVENUE OLIVIER MESSIAEN, 72085 LE MANS, CEDEX 9, FRANCE
E-mail address:

hamadene@univ-lemans.fr

