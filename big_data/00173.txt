Noname manuscript No.
(will be inserted by the editor)

Pattern recognition on the quantum Bloch sphere

Giuseppe Sergioli · Enrica Santucci ·
Luca Didaci · Jaros(cid:32)law A. Miszczak ·
Roberto Giuntini

6
1
0
2

 
r
a

M
1

 

 
 
]
h
p
-
t
n
a
u
q
[
 
 

1
v
3
7
1
0
0

.

3
0
6
1
:
v
i
X
r
a

Received: date / Accepted: date

Abstract We introduce a framework suitable for describing pattern recogni-
tion task using the mathematical language of density matrices. In particular,
we provide a one-to-one correspondence between patterns and density opera-
tors, represented by mixed states when the uncertainty comes into play. The
classiﬁcation process in the quantum framework is performed by the introduc-
tion of a normalized trace distance between density operators in place of the
Euclidean distance between patterns. We provide a comparison of the intro-
duced method in the case of 2D data classiﬁcation.

Keywords Bloch sphere · pattern recognition · geometry of quantum states

PACS 03.67.Ac · 03.65.Aa

Giuseppe Sergioli
Universit`a di Cagliari, Via Is Mirrionis 1, I-09123 Cagliari, Italy.
E-mail: giuseppe.sergioli@gmail.com

Enrica Santucci
Universit`a di Cagliari, Via Is Mirrionis 1, I-09123 Cagliari, Italy.
E-mail: enrica.santucci@gmail.com

Luca Didaci
Universit`a di Cagliari, Via Is Mirrionis 1, I-09123 Cagliari, Italy.
E-mail: didaci@diee.unica.it

Jaros(cid:32)law A. Miszczak
Institute of Theoretical and Applied Informatics, Polish Academy of Sciences,
Ba(cid:32)ltycka 5, 44-100 Gliwice, Poland
Universit`a di Cagliari, Via Is Mirrionis 1, I-09123 Cagliari, Italy.
E-mail: miszczak@iitis.pl

Roberto Giuntini
Universit`a di Cagliari, Via Is Mirrionis 1, I-09123 Cagliari, Italy.
E-mail: giuntini@unica.it

2

1 Introduction

Giuseppe Sergioli et al.

Quantum machine learning aims at merging the methods from quantum infor-
mation processing and pattern recognition to provide new solutions for prob-
lems in the areas of pattern recognition and image understanding [45,57,55].
In the ﬁrst aspect the research in this area is focused on the application of the
methods of quantum information processing [37] for solving problems related
to classiﬁcation and clustering [53,10]. One of the possible directions in this
ﬁeld is to provide a representation of computational models using quantum
mechanical concepts. From the other perspective the methods for classiﬁca-
tion developed in computer engineering are used to ﬁnd solutions for problems
like quantum state discrimination [23,11,22,34], which ares tightly connected
with the recent developments in quantum cryptography.

Using quantum states for the purpose of representing patterns is naturally
motivated by the possibility to exploit quantum algorithms to boost the com-
putational intensive parts of the classiﬁcation process. In particular, it has
been demonstrated that quantum algorithms can be used to improve the time
complexity of the k−nearest neighbor (kNN) method. Using the algorithms
presented in [55] it is possible to obtain polynomial reductions in query com-
plexity in comparison to the corresponding classical algorithm.

Another motivation comes from the possibility of using quantum-inspired
algorithms for the purpose of solving classical problems. Such an approach
has been exploited by various authors. In [52] authors propose an extension
of Gaussian mixture models by using the statistical mechanics point of view.
In their approach the probability density functions of conventional Gaussian
mixture models are expressed by using density matrix representations. On the
other hand, in [41] authors utilize the quantum representation of images to
construct measurements used for classiﬁcation. Such approach might be par-
ticularly useful for the physical implementation of the classiﬁcation procedure
on quantum machines.

In the last few years, many eﬀorts to apply the quantum formalism to
non-microscopic contexts [1,2,17,38,40,48, 51] and to signal processing [18]
have been made. Moreover, some attempts to connect quantum information
to pattern recognition can be found in [45,46,47]. Exhaustive survey and bib-
liography of the developments concerning applications of quantum computing
in computational intelligence is provided in [35,57]. Even if these results seem
to suggest some possible computational advantages of an approach of this sort,
an extensive and universally recognized treatment of the topic is still missing
[45,33,32].

The main contribution of our work is the introduction of a convenient
framework to describe pattern recognition by means of the mathematical lan-
guage of density matrices [6,5]. Representing patterns as quantum objects
allows us to naturally deal with situations where some sort of uncertainty (i.e.
incomplete information) comes into play.

Pattern recognition on the quantum Bloch sphere

3

Density patterns (i.e. quantum objects that represent patterns) allow to
provide a natural representation of the incomplete information about the fea-
tures.

There are two main advantages of the proposed approach. Firstly, our
representation allows us to exploit the power of quantum computers for data
processing. Since patterns are encoded as quantum states, the well known
computational speed up of quantum computer can be fully applied to our
model. Secondly, our model could be reasonably considered as a ﬁrst attempt
to treat in a uniform way the problem of some form of ignorance about data.
The paper is organized as follows. In Section 2 basic notions of quantum
information and pattern recognition are introduced. In Section 3 we introduce
the correspondence between arbitrary two-feature patterns and pure density
operators and we deﬁne the notion of density pattern. In Section 4 we utilize
density patterns to introduce a quantum version of the classiﬁcation process. In
Section 5 we propose an extension of the model where the density patterns are
aﬀected by uncertainty. In Section 6 we describe a geometrical generalization
of the model to arbitrary n-feature patterns. Finally, in Section 7 concluding
remarks and further developments are proposed.

2 Preliminaries

2.1 State description in quantum mechanics

In the standard quantum information theory [7, 50], the states of physical sys-
tems are described by unit vectors and their evolution is expressed in term
of unitary matrices (i.e. quantum gates). However, this representation can be
applied for an ideal case only, because it does not take into account some un-
avoidable physical phenomena, such as interactions with the environment and
irreversible transformations. In modern quantum information theory [24,25,
56], another approach is adopted. The states of physical systems are described
by density operators – also called mixed states [3,13,19] – and their evolu-
tion is described by quantum operations. The space Ωn of density operators
for n-dimensional system consists of positive semideﬁnite matrices with unit
trace.

A quantum state can be pure or mixed. We say that a state of a physical
system is pure if it represents “maximal” information about the system, i.e.
an information that can not be improved by further observations. Otherwise,
the state is said to be mixed. Formally, a state is pure iﬀ tr(ρ)2 = 1 and it is
mixed iﬀ tr(ρ)2 < 1.

Density operators formalism is extremely reliable in describing real physical
situations where one needs to deal with the interactions with the environment.
In such cases, a loss of information may occur in the system. For this reason we
say that the density operator represents a non-maximal kind of information.
On the other hand, pattern recognition [54, 15] is the scientiﬁc discipline
which deals with theories and methodologies for designing algorithms and ma-

4

Giuseppe Sergioli et al.

chines capable of automatically recognizing “objects” (i.e. patterns) in noisy
environments 1. Some typical applications are multimedia document classiﬁca-
tion, remote-sensing image classiﬁcation, people identiﬁcation using biometrics
traits as ﬁngerprints. In a real environment, the process of classiﬁcation can
individuate the observed object not with certainty but with some probability
only. This may be due to intrinsic limitations of the representation space of
the objects, or to the fact that the noise causes a loss of information. This
suggests to tackle the pattern recognition problems with the quantum frame-
work. It has a probabilistic structure and thus allows the natural treatment of
the uncertanity.

2.2 Representing classical and quantum information quantities

A pattern is a representation of an object. The object could be concrete (i.e.,
an animal, and the pattern recognition task could be to identify the kind of
animal) or an abstract one (i.e. a facial expression, and the task could be
to identify the emotion expressed by the facial expression). The pattern is
characterized via a set of measurements called features. Features can assume
the forms of categories, structures, names, graphs, or, most commonly, a vector
of real number (feature vector) x = (x1, x2, . . . , xd) ∈ Rd. Intuitively, a class
is the set of all similar patterns. For the sake of simplicity, and without loss of
generality, we assume that each object belongs to one and only one class, and
we will limit our attention to 2-class problems. For example, in the domain
of ‘cats and dogs’ we can consider the classes Ccats (the class of all cats) and
Cdogs (the class of all dogs). The pattern at hand is either a cat or a dog, and
a possible representation of the pattern could consist in the height of the pet
and the length of its tail. In this way, the feature vector x1 = (x11, x12) is the
pattern representing a pet whose height and length of the tail are x11 and x12,
respectively.

Now, let us consider an object xt whose membership class is unknown. The
basic aim of the classiﬁcation process is to establish which class xt belongs
to. To reach this goal, standard pattern recognition designs a classiﬁer that,
given the feature vector xt, has to determine the true class of the pattern. The
classiﬁer should take into account all the available information about the task
at hand (i.e., information about the statistical distributions of the patterns
and information obtained from a set of patterns whose true class is known).
This set of patterns is called ‘training set’, and it will be used to deﬁne the
behavior of the classiﬁer.

If no information about the statistical distributions of the patterns is avail-
able, an easy classiﬁcation algorithm that could be used is the Nearest Mean
Classiﬁer (NMC) [36,21], or minimum distance classiﬁer. The NMC

1 Quoting Duin et al. “Pattern recognition can be deﬁned as the scientiﬁc discipline that
studies theories and methods for designing machines able to recognise patterns in noisy
data”[16].

Pattern recognition on the quantum Bloch sphere

5

(cid:80)

– computes the centroids of each class, using the patterns on the training set
x where ni is the number of patterns of the training set

µ∗
i = 1
ni
belonging to the class Ci;

x∈Ci

– assigns the unknown pattern xt to the class with the closest centroid.

It is important to emphasize that in this work the classiﬁer NMC has been
taken into account for simplicity, but the adopted results and methodology
are quite general and can be applied to other classiﬁers based on diﬀerent
algorithms and diﬀerent metrics.

By deﬁnition, a pattern is an object characterized by the knowledge of
its features. Analogously, in quantum mechanics a state of a physical system
is represented by a density operator, characterized by the knowledge of its
observables. Formally speaking, a density operator is a positive and Hermitian
operator (with unitary trace) living in a n-dimensional complex Hilbert space
H.
If we conﬁne ourselves in the 2-dimensional Hilbert space H, a suitable
representation of an arbitrary density operator ρ ∈ Ω2 is provided by

(I + r1σ1 + r2σ2 + r3σ3) =

ρ =

=

1
2
1
2

(cid:18) 1 + r3 r1 − ir2

r1 + ir2 1 − r3

(cid:19)

,

(1)

Pauli components) are ri (with (cid:80)

where σi are the Pauli matrices. This expression comes to be useful in order
to provide a geometrical representation of ρ. Indeed, each density operator
ρ ∈ Ω2 can be geometrically represented as a point of a radius-one sphere
centered in the origin (the so called Bloch sphere), whose coordinates (i.e.
i ≤ 1). By using the generalized Pauli
i r2
matrices [8,29] it is also possible to provide a geometrical representation for
an arbitrary n-dimensional density operator, as it will be showed in Section 6.
For any density operator ρ ∈ Ω2 it is possible to deﬁne a measure of

mixedness, given by the normalized linear entropy [43]

SL(ρ) =

2n
2n − 1

(1 − tr(ρ)2).

(2)

By a straightforward calculation, one can verify that SL(ρ) = 0 iﬀ ρ is
pure and SL(ρ) = 1 iﬀ ρ is maximally mixed. Again, by restricting to a
2-dimensional Hilbert space, the points on the surface of the Bloch sphere
represent pure state, while the inner points represent mixed states.

3 Representation of 2-dimensional patterns
Let xi = (xi1, . . . , xik) be a generic pattern, i.e. a point in Rk. By the means
of this representation, we consider all the k features of xi as perfectly known.
Therefore, xi represents a maximal kind of information, and its natural quan-
tum counterpart is provided by a pure state. For the sake of simplicity, we will

6

Giuseppe Sergioli et al.

conﬁne ourselves to an arbitary two-feature pattern indicated by x = (x, y)2.
In this section, a one-to-one correspondence between each pattern and its cor-
responding pure density operator is provided.

The pattern x can be represented as a point in R2. The stereographic
projection [12] allows unequivocal mapping of any point r = (r1, r2, r3) of
the surface of a radius-one sphere S2 (except for the north pole) onto a point
x = (x, y) of R2 as

(cid:18) r1

(cid:19)

SP : (r1, r2, r3) (cid:55)→

1 − r3

,

r2
1 − r3

.

(3)

The inverse of the stereographic projection is given by

SP −1 : (x, y) (cid:55)→

2x

x2 + y2 + 1

,

2y

x2 + y2 + 1

x2 + y2 − 1
x2 + y2 + 1

,

(cid:18)

(cid:19)

.

(4)

(5)

Therefore, by using the Bloch representation given by Eq. (1) and placing

r1 =

2x

x2 + y2 + 1

,

r2 =

2y

x2 + y2 + 1

,

r3 =

x2 + y2 − 1
x2 + y2 + 1

,

we obtain the following deﬁnition.

Deﬁnition 1 (Density Pattern) Given an arbitrary pattern x = (x, y), the
density pattern (DP) ρx associated to x is the following pure density operator

(cid:18) 1 + r3 r1 − ir2

r1 + ir2 1 − r3

(cid:19)

=

ρx =

1
2

(cid:18)x2 + y2 x − iy

(cid:19)

1

x2 + y2 + 1

x + iy

1

.

(6)

It is easy to check that tr(ρ2

x) = 1. Hence, ρx always represents a pure state

for any value of the features x and y.
that ri = tr (ρx · σi), with i ∈ {1, 2, 3} and σi are Pauli matrices.

Following the standard deﬁnition of the Bloch sphere, it can be veriﬁed

Example 1 Let us consider the pattern x = (1, 3). The corresponding ρx reads

(cid:18) 10

ρx =

1
11

1 − 3i

1 + 3i

1

(cid:19)

.

2 In the standard pattern recognition theory, the symbol y is generally used to identify
the label of the pattern. In this paper, for the sake of semplicity, we agree with a diﬀerent
notation.

Pattern recognition on the quantum Bloch sphere

7

4 Classiﬁcation process for density patterns

As introduced in Section 2, the NMC classiﬁer is based on the computation
of the minimal Euclidean distance between the pattern to be classiﬁed and
the centroids of each class. In the previous Section, a quantum counterpart
of an arbitrary “classical” pattern was provided. In order to obtain a com-
plete quantum counterpart of the standard classiﬁcation process, we need to
provide a suitable deﬁnition of distance d between DPs. In addition to satis-
fying the standard conditions of metric, the distance d also needs to satisfy
the preservation of the order : given three arbitrary patterns a, b, c such that
dE(a, b) ≤ dE(b, c), if ρa, ρb, ρc are the DPs related to a, b, c respectively, then
d(ρa, ρb) ≤ d(ρb, ρc). In order to fulﬁll all the previous conditions, we obtain
the following deﬁnition.

Deﬁnition 2 (Normalized Trace Distance) The normalized trace dis-
tance dtr between two arbitrary density patterns ρa and ρb is given by formula

(cid:80)
(7)
i |λi|, with
where dtr(ρa, ρb) is the standard trace distance, dtr(ρa, ρb) = 1
λi representing the eigenvalues of ρa − ρb [4,39], and Ka,b is a normalization
2
factor given by Ka,b =
, with ra3 and rb3 representing σ3 Pauli

dtr(ρa, ρb) = Ka,bdtr(ρa, ρb),

√

2

(1−ra3 )(1−rb3 )
components of ρa and ρb, respectively.

Proposition 1 Given two arbitrary patterns a = (xa, ya) and b = (xb, yb) and
their respective density patterns, ρa and ρb, we have that

(8)
Proof It can be veriﬁed that the eigenvalues of the matrix ρa − ρb are given by

dtr(ρa, ρb) = dE(a, b).

Using the deﬁnition of trace distance, we have

Eig(ρa − ρb) = ±

tr(cid:112)(ρa − ρb)2 =
(cid:112)(1 − ra3)(1 − rb3)

2

(cid:112)(1 + x2
(cid:112)(1 + x2
(cid:113)

=

dE(a, b)

a + y2

a)(1 + x2

b + y2
b )

dE(a, b)

a + y2

a)(1 + x2

b + y2
b )

.

.

(9)

(10)

(11)

By applying formula (5) to both ra3 and rb3 , we obtain that

Ka,b =

(1 + x2

a + y2

a)(1 + x2

b + y2

b ).

Using Proposition 1, one can see that the normalized trace distance dtr

satisﬁes the standard metric conditions and the preservation of the order.
Let us now consider two classes, CA and CB, and the respective centroids3
a∗ = (xa, ya) and b∗ = (xb, yb). The classiﬁcation process based on NMC
3 Let us remark that, in general, a∗ and b∗ do not represent true centroids, but centroids
estimated on the training set.

8

Giuseppe Sergioli et al.

consists of ﬁnding the space regions given by the points closest to the ﬁrst
centroid a∗ or to the second centroid b∗. The patterns belonging to the ﬁrst
region are assigned to the class CA, while patterns belonging to the second
region are assigned to the class CB. The points equidistant from both the
centroids represent the discriminant function (DF), given by

fDF(x, y) = 2(xa − xb)x + 2(ya − yb)y + (|b∗|2 − |a∗|2) = 0.

(12)

Thus, an arbitrary pattern c = (x, y) is assigned to the class CA (or CB)

if fDF(x, y) > 0 (or fDF(x, y) < 0).
Let us notice that the Eq. (12) is obtained by imposing the equality be-
tween the Euclidean distances dE(c, a∗) and dE(c, b∗). Similarly, we obtain the
quantum counterpart of the classical discriminant function.
Proposition 2 Let ρa∗ and ρb∗ be the DPs related to the centroids a∗ and b∗
respectively. Then, the quantum discriminant function (QDF) is deﬁned as

fQDF(r1, r2, r3) = F(ra∗ , rb∗ )T · r + ˜K 2 − 1 = 0

(13)

where

– r = (r1, r2, r3),
– {ra∗
}, {rb∗
– ˜K = ˜K(ra∗

i

i

3

3

} are Pauli components of ρa∗ and ρb∗ respectively,
, rb∗

,

(cid:114) 1−ra∗

) = Ka∗ z
=
Kb∗ z
− ˜K 2rb∗

1

, ra∗

2

1

3

1−rb∗
− ˜K 2rb∗

3

2

− ˜K 2rb∗

3

).

, ra∗

3

– F(ra∗ , rb∗ ) = (ra∗

Proof In order to ﬁnd the QDF , we use the equality between the normalized
trace distances Kc,a∗ dtr(ρc, ρa∗ ) and Kc,b∗ dtr(ρc, ρb∗ ), where ρc is a generic
DP with Pauli components r1, r2, r3. We have

(cid:115)
(cid:115)

Kc,a∗ dtr(ρc, ρa∗ ) =

Kc,b∗ dtr(ρc, ρb∗ ) =

)2 + (r3 − ra∗

)2

,

3

)(1 − r3)

(r1 − ra∗

1

(r1 − rb∗

1

2

)2 + (r2 − ra∗
(1 − ra∗
)2 + (r2 − rb∗
(1 − rb∗

3

3

2

)(1 − r3)

)2 + (r3 − rb∗

3

(14)

)2

.

(cid:16) 3(cid:88)

3(cid:88)

1 − ra∗
1 − rb∗

3

3

r2
i +

− 2

r2
b∗

i

i=1

i=1

(cid:17)

rirb∗

i

3(cid:88)

i=1

. (15)

The equality Kc,a∗ dtr(ρc, ρa∗ ) = Kc,b∗ dtr(ρc, ρb∗ ) reads

r2
i +

− 2

r2
a∗

i

3(cid:88)
(cid:80)3

i=1

3(cid:88)
=(cid:80)3

i=1

i

=

i=1

rira∗

3(cid:88)
=(cid:80)3
i=1 r2
(cid:16)
− 1 − ra∗
1 − rb∗

ra∗

3

i

3

i

3(cid:88)

i=1

(cid:17)

In view of the fact that ρa∗ , ρb∗ and ρc are pure states, we use the conditions
i=1 r2
a∗

i = 1 and we get

i=1 r2
b∗

i

ri +

1 − ra∗
1 − rb∗

3

3

− 1 = 0.

(16)

rb∗

i

Pattern recognition on the quantum Bloch sphere

9

Similarly to the classical case, we assign the DP ρc to the class CA (or
CB) if fQDF(r1, r2, r3) > 0 (or fQDF(r1, r2, r3) < 0). Geometrically, Eq. (13)
represents the plane symmetry between the two DPs ρa∗ and ρb∗ .
} and
Let us remark that, if we express the Pauli components {ra∗
{ri} in terms of classical features by Eq. (5), then Eq. (13) exactly corre-
sponds to Eq. (12). As a consequence, given an arbitrary pattern c = (x, y), if
fDF(c) > 0 (or fDF(c) < 0) then its relative DP ρc will satisfy fQDF(ρc) > 0
(or fQDF(ρc) < 0, respectively).

}, {rb∗

i

i

The comparison between the classical and quantum discrimination pro-
cedures for two datasets is presented in Fig. 1. Plots in Figs. 1(a) and 1(b)
present the classical and quantum discrimination for the Gaussian dataset.
Analogous results for the moon dataset are depicted in Figs. 1(c) and 1(d).

It is worth noting that the correspondence between pattern expressed as a
feature vector (according to the standard pattern recognition approach) and
pattern expressed as a density operator is quite general. Indeed, it is not related
to a particular classiﬁcation algorithm (NMC, in the previous case) nor to the
speciﬁc metric at hand (the Euclidean one). Therefore, it is possible to develop
a similar correspondence by using other kinds of metrics and/or classiﬁcation
algorithms, diﬀerent from NMC, adopting exactly the same approach.

5 Modeling the uncertainty

In Section 3, we have introduced the case in which the features of an arbitrary
pattern x = (x1, . . . , xk) are perfectly known. For this reason the feature vector
provides complete knowledge (i.e. maximal information) on the pattern. In a
more general case, a feature can be aﬀected by some kind of error (for instance
given by a non-perfect sensitivity of the measurement apparatus). In this case
we no longer deal with maximal information, and a kind of uncertainty occurs.
Standard pattern recognition theory uses diﬀerent approaches to address this
problem in diﬀerent research ﬁelds. Widely used and general approaches are
the classical Dempster-Shafer Theory [49, 20, 59] and the fuzzy set approach
to pattern recognition problems [9,42,27]. Other attempts have been made
in speciﬁc ﬁelds, trying to compensate missing data using information given
by patterns to classify [14] instead of using only training data. Another more
recent approach consider the problem of classiﬁcation of uncertain objects
whose locations are uncertain and described by probability density functions
[58].

In this section, let us consider a classical situation where the knowledge of
the features of a two-dimensional pattern x is not complete, i.e. their measure
is aﬀected by an error .

As introduced in Section 2, when the knowledge on a given physical system
is not maximal, the corresponding state is formally expressed by a mixed
state, whose measure of mixedness is given by the normalized linear entropy.
Therefore, we consider a function

u :  (cid:55)→ [0, 1]

(17)

10

Giuseppe Sergioli et al.

(a)

(b)

(c)

(d)

Fig. 1 Comparison between the results of discrimination procedures for the Gaussian
dataset ((a) and (b)) and the moon dataset ((c) and (d))) in R2 ((a) and (c)) and in
the Bloch sphere S2 ((b) and (d)).

such that i) if  = 0 then u = 0 (and the information is maximal); ii) if 
assumes its maximal value, then u = 1.

Deﬁnition 3 (Uncertain Density Pattern) Let us consider an arbitrary
pattern x whose features x and y are aﬀected by an error . The uncertain
density pattern (UDP) ρxu associated to x is the following density operator
deﬁned as

(cid:18) 1 + αr3 αr1 − iαr2

(cid:19)

,

(18)

ρxu =

1
2

αr1 + iαr2

1 − αr3

(cid:45)5(cid:45)4(cid:45)3(cid:45)2(cid:45)1012(cid:45)6(cid:45)4(cid:45)202(cid:45)1.0(cid:45)0.50.00.51.0(cid:45)1.0(cid:45)0.50.00.51.0(cid:45)1.0(cid:45)0.50.00.51.0(cid:45)1.0(cid:45)0.50.00.51.01.52.0(cid:45)1.5(cid:45)1.0(cid:45)0.50.00.51.01.5(cid:45)1.0(cid:45)0.50.00.51.0(cid:45)1.0(cid:45)0.50.00.51.0(cid:45)1.0(cid:45)0.50.00.51.0Pattern recognition on the quantum Bloch sphere

11

where α =

√

1 − u.

Geometrically, an uncertain density pattern corresponds to an inner point of
the Bloch sphere. This representation can be interpreted as an homogeneous
reduction by a factor α of the Bloch sphere.

Proposition 3 Given an arbitrary uncertain DP ρxu , we have

where SL is the normalized linear entropy introduced in Eq. (2).

SL(ρxu) = u,

Proof It can be veriﬁed that tr(ρ2
xu

) = 1

(cid:16)

2 (1 + α2). Therefore we have
1 − 1
2

(1 + α2)

.

(cid:17)

u = SL(ρxu ) = 2

(19)

(20)

Example 2 Let us consider two patterns a = (0, 1) and b = (0, 3). Their re-
spective DPs are given by

(cid:18)1 −i
(cid:19)

i 1

,

ρb =

1
10

(cid:18) 9 −3i
(cid:19)

3i 1

.

(21)

1
2
Now, let c = (0, 1 ± 

ρa =

2 ) be a pattern such that only the second feature y
is aﬀected by an error  = 2. Let us also consider that y ranges within the
interval I = [−10, 10], hence |I| = 20.

Generally, in order to a provide an appropriate quantum representation of
a classical situation, a crucial step is to deﬁne the function in Eq. (17). In this
case, we could reasonably deﬁne u = |I| = 1
10 .

Therefore, by Eq. (3), the uncertain density pattern related to c reads

1 + 3√

6√
10

ρc =

1
2

10

y2+1 − 6√
y2−1
1 − 3√

10

iy

y2+1

iy

y2+1

y2−1
y2+1

10

 .

Now, by using Deﬁnition (1), we expect that

dtr(ρa, ρc) ≤ dtr(ρb, ρc)

(22)
for any y ∈ [0, 2]. In particular, dtr(ρa, ρc) (cid:39) dtr(ρb, ρc) for y = 2, where the
diﬀerence between dtr(ρa, ρc) and dtr(ρb, ρc) could be u-dependent. In what
follows, we prove the validity of these requirements.

It can be seen that

Ka,c =

Kb,c =

2
1 − 3√
10
2

(cid:113)
(cid:113) 1
5 (1 − 3√

y2−1
y2+1 )

10

y2−1
y2+1

,

(23)

(cid:113) 2

(cid:118)(cid:117)(cid:117)(cid:116) 19
(cid:113)

1
2

tr(cid:112)(ρa − ρc)2 =
tr(cid:112)(ρb − ρc)2 =

5 y
− 6
1 + y2 ,
10
√
95 − 24
10 + 12

√

10(4−3y)
1+y2

Giuseppe Sergioli et al.

.

(24)

12

and

√

2

10

Now, let f (y) = dtr(ρa, ρc) = Ka,c tr(cid:112)(ρa − ρc)2 and g(y) = dtr(ρb, ρc) =
Kb,c tr(cid:112)(ρb − ρc)2. The Figure 2(a) shows that g(y) < f (y) for any y ∈ [0, 2].

Let us notice that the diﬀerence f (y) − g(y) for y = 2 does not assume value
0, but it is approximately equal to 0.013 and it is given by the presence of the
uncertainty u. Replacing the same example for an arbitrary value of u, it can
be shown that the diﬀerence between f (y) and g(y) in y = 2 is given by

(cid:112)

√
50 − 48

1 − u − 25u −(cid:112)
(cid:112)

√
5 − 3

1 − u

√
10 − 8

f (u) − g(u) =

1 − u − 5u

.

(25)

The plot in Figure 2(b) demonstrates that d(u) is an increasing function on
u ∈ [0, 1]. In particular, u = 0 ⇔ d(u) = 0.

(a)

(b)

Fig. 2 (a) Comparison between f (y) = dtr(ρa, ρc) and g(y) = dtr(ρb, ρc). (b) Diﬀerence
between f (2) and g(2) depending on u.

6 Geometrical generalization of the model

In Section 3 we provided a representation of an arbitrary two-feature pattern
x in the terms of a point on the surface of the Bloch sphere S2, i.e. a density
operator ρx. A geometrical extension of this model to the case of n-feature
patterns inspired by quantum framework is possible.

In this section we introduce a method for representing an arbitrary n-
dimensional real pattern as a point in the radius-one hypersphere Sn, centered
in the origin.

0.00.51.01.52.00.00.51.01.52.02.53.0ygyfy0.00.20.40.60.81.00.00.20.40.60.81.01.2uPattern recognition on the quantum Bloch sphere

13

n2−1(cid:88)

1
n

1
2

A quantum system described by a density operator ρ in an n-dimensional
Hilbert space H, can be represented by a linear combination of the n-dimensional
identity I and 2n n × n-square matrices {σi} (i.e. generalized Pauli matrices
[8,29]):

i=1

I +

ρ =

riσi,

(26)
where the real numbers {ri} are the Pauli components of ρ. Hence, by Eq. (26),
a density operator ρ acting on an n-dimensional Hilbert space can be geo-
metrically represented as a (n2 − 1)-dimensional point P = (r1, r2, . . . , r˜n)
in the Bloch hypersphere S˜n−1, with ˜n = n2 − 1. Therefore, by using the
generalization of the stereographic projection [28] we obtain the vector x =
(x1, x2, . . . , x˜n−1), that is the correspondent of P in Rn2−2. In fact, the gen-
eralization of Eqs. (3)–(4) are given by
SP(˜n) : (r1, r2, . . . , r˜n) (cid:55)→

= (x1, x2, . . . , x˜n−1)

(cid:19)

, . . . ,

1 − r˜n

,

r2
1 − r˜n

r˜n−1
1 − r˜n

(cid:18) r1
(cid:32)

SP −1

(˜n) : (x1, x2, . . . , x˜n−1) (cid:55)→

2x1(cid:80)˜n

i=1 x2

i + 1
= (r1, r2, . . . , r˜n).

(cid:80)˜n

2x˜n−1
i=1 x2

i + 1

,

, . . . ,

i=1 x2
i=1 x2

i − 1
i + 1

=

(cid:80)˜n
(cid:80)˜n

(27)

(cid:33)

(28)

Hence, by Eq. (27), a 2-dimensional density matrix is determined by three
Pauli components and it can be mapped in to a 2-dimensional real vector.
Analogously, a 3-dimensional density matrix is determined by eight Pauli com-
ponents and it can be mapped into a 7−dimensional real vector. Generally, an
n-dimensional density matrix is determined by n2 − 1 Pauli components and
it can be mapped into an n2 − 2 dimensional real vector.
Now, let consider an arbitrary vector x = (x1, x2, . . . , xm) with (n − 1)2 −
1 < m < n2−2. In this case Eq. (28) can not be applied because m (cid:54)= n2−2. In
order to represent a in an n-dimensional Hilbert space, it is suﬃcient to involve
only m + 1 Pauli components (instead of all the n2 − 1 Pauli components of
the n-dimensional space). Hence, we need to project the Bloch hypersphere
Sn2−2 onto the hypersphere Sm. We perform this projection by using Eq. (28)
and by assigning some ﬁxed values to a number of Pauli components equal to
n2 − m − 2. In this way, we obtain a representation in Sm that involves m + 1
Pauli components and it ﬁnally allows the representation of an m-dimensional
real vector.

Example 3 Let us consider a vector x = (x1, x2, x3). By Eq. (28) we can map
x onto a vector rx = (r1, r2, r3, r4) ∈ S3. Hence, we need to consider a 3-
dimensional Hilbert space H. Then, an arbitrary density operator ρ ∈ Ω3 can
be written as

(cid:32)

ρ =

1
3

√

8(cid:88)

i=1

(cid:33)

I +

3

riσi

(29)

Giuseppe Sergioli et al.

i ≤ 1 and {σi} generalized Pauli
matrices. In this case {σi} is the set of eight 3 × 3 matrices also known as
Gell-Mann matrices, namely

i=1 r2

14

with {ri} Pauli components such that(cid:80)8
0 −i 0
 , σ3 =
0 0 −i
 , σ6 =
1 0 0
 .

 , σ2 =
 , σ5 =
 , σ8 =

0 1 0
0 0 1
0 0 0

i 0 0
0 0 0

0 0 0
i 0 0

1 0 0
0 0 0

0 0 0
1 0 0

σ1 =

σ4 =

σ7 =

1√
3

0 1 0
0 0 −2

0 0 −i
0 i 0

1 0 0
 ,
0 0 0
 ,

0 −1 0
0 0 0

0 0 1
0 1 0

Consequently, the generic form of a density operator ρ in the 3-dimensional

Hilbert space is given by

√

ρ =

1
3

√
3(r1 + ir2) −√
√

√
3r3 + r8 + 1
√

3(r4 + ir5)

3(r1 − ir2)
3r3 + r8 + 1
3(r6 + ir7)

√
√

3(r4 − ir5)
3(r6 − ir7)
1 − 2r8

 .

Then, for any ρ it is possible to associate an 8-dimensional Bloch vector r =
(r1, . . . , r8) ∈ S7. However, by taking rj = 0 for j = 5, . . . , 8 we obtain

 √

√

√
3(r1 + ir2) −√
3r3 + 1
√

3(r1 − ir2)
3r3 + 1
0

3r4

√

3r4
0
1



ρx =

1
3

(cid:32)

(30)

(31)

(32)

(cid:33)

.

(33)

that, by Eq. (28), can be seen as point projected in S3, where

SP −1

(4) (x) = rx =

2x1(cid:80)3

i=1 x2

i + 1

,

2x2(cid:80)3

i=1 x2

i + 1

2x3(cid:80)3

i=1 x2

i + 1

,

,

(cid:80)3
(cid:80)3

i=1 x2
i=1 x2

i − 1
i + 1

The generalization introduced above, allows the representation of arbitrary
patterns x ∈ Rn as points ρx ∈ Sn. Also the classiﬁcation procedure introduced
in Section 4 can be naturally extended for an arbitrary n-feature pattern where
the normalized trace distance between two DPs ρa and ρb can be expressed
using Eq. (27) in terms of the respective Pauli components as

dtr(ρa, ρb) =

i=1[(rai − rbi) − (rairan+1 − rbiran+1)]2

(1 − ran+1)(1 − rbn+1 )

.

(34)

(cid:113)(cid:80)n

Pattern recognition on the quantum Bloch sphere

15

7 Conclusions and further developments

The main purpose of this work has been to provide a coherent geometrical rep-
resentation of the classical objects used in pattern recognition. Our approach
has been inspired by the methods of quantum information theory. In particular,
we have introduced a one-to-one correspondence between two-feature patterns
and pure density operators by using the concept of density patterns (DP).
We have also provided a quantum counterpart of the classical discrimination
process, where the discrimination function has been replaced by a plane that
intersects the Bloch sphere. The equation of this plane is obtained by using
the distance between DPs, where the metric is given by the normalized trace
distance.

We have shown how the standard way to represent non-maximal informa-
tion in the quantum context, i.e. by using mixed states in place of pure states,
can be applied to classical situations. To achieve this goal we have introduced
uncertain density patterns. We have considered a signiﬁcative case where the
density operator machinery provides a consistent representation of a classical
system. We have also presented a generalization of the model that allows us
to express arbitrary n-feature patterns as points on the hypersphere Sn, ob-
tained by using the generalized stereographic projection. However, even if it
is possible to associate points of a n-hypersphere to n-feature patterns, those
points do not generally represent density operators. In [29,26,30] the authors
found some conditions that guarantee the one-to-one correspondence between
points on particular regions of the hypersphere and density matrices. A full
development of our work is therefore intimately connected to the study on the
geometrical properties of the generalized Bloch sphere.

Finally, a long-term development of this investigation could be also focused
on the implementation of general and not ad hoc quantum classiﬁcation algo-
rithms and on the enhancement of such algorithms in terms of eﬃciency and
computational accuracy.

Acknowledgements This work has been partly supported by the project “Computational
quantum structures at the service of pattern recognition: modeling uncertainty” [CRP-
59872] funded by Regione Autonoma della Sardegna, L.R. 7/2007, Bando 2012.

References

1. D. Aerts, B. D’Hooghe. Classical logical versus quantum conceptual thought: examples
in economics, decision theory and concept theory. Quantum interaction, Lecture Notes
in Comput. Sci., 5494: 128–142. Springer, Berlin (2009).

2. D. Aerts, L. Gabora, S. Sozzo. Concepts and their dynamics: A quantum-theoretic

modeling of human thought. Topics in Cognitive Science, 5(4): 737–772 (2013).

3. D. Aharonov, A. Kitaev, N. Nisan. Quantum circuits with mixed states. In Proceedings

of the 30th Annual ACM Symposium on Theory of Computing, 20–30. ACM (1998).

4. S.M. Barnett. Quantum information, 16, Oxford Master Series in Physics. Oxford
University Press, Oxford. Oxford Master Series in Atomic, Optical, and Laser Physics
(2009).

16

Giuseppe Sergioli et al.

5. E. Beltrametti, M. L. Dalla Chiara, R. Giuntini, R. Leporini, G. Sergioli. A quantum
Int. J.

computational semantics for epistemic logical operators. part ii: Semantics.
Theor. Phys., 53(10): 3293–3307 (2014).

6. E. Beltrametti, M.L. Dalla Chiara, R. Giuntini, R. Leporini, G. Sergioli. A quantum
computational semantics for epistemic logical operators. part i: epistemic structures.
Int. J. Theor. Phys., 53(10): 3279–3292 (2014).

7. C.H. Bennett, P.W. Shor. Quantum information theory. IEEE Trans. Inform. Theory,

1998.

8. R.A. Bertlmann, P. Krammer. Bloch vectors for qudits. J. Phys. A, 41(23):235303, 21

(2008).

9. J.C. Bezdek Pattern Recognition with Fuzzy Objective Function Algorithms. Boston,

MA: Springer US (1981).

10. S. Caraiman and V. Manta. Image processing using quantum computing. In System
Theory, Control and Computing (ICSTCC), 2012 16th International Conference on,
1–6, IEEE (2012).

11. A. Cheﬂes.

Quantum state discrimination.

Contemp. Phys., 41(6):401–424,

arXiv:quant-ph/0010114 (2000).

12. H.S.M. Coxeter. Introduction to geometry. John Wiley & Sons, Inc., New York-London-

Sydney, 2nd edition (1969).

13. M.L. Dalla Chiara, R. Giuntini, R. Greechie. Reasoning in quantum theory: sharp and

unsharp quantum logics, volume 22. Springer Science & Business Media (2004).

14. L. Didaci, G. Marcialis, F. Roli. Analysis of unsupervised template update in biometric

recognition systems. Pattern Recognition Letters, 37(1):151–160 (2014).

15. R.O. Duda, P.E. Hart, D.G. Stork. Pattern Classiﬁcation. Wiley Interscience, 2nd

edition (2000).

16. R.P.W Duin, F. Roli, D. de Ridder. A note on core research issues for statistical pattern

recognition. Pattern recognition letters, 23(4):493–499 (2002).

17. J. Eisert, M. Wilkens, and M. Lewenstein. Quantum games and quantum strategies.

Phys. Rev. Lett., 83(15):3077 (1999).

18. Y.C. Eldar and A.V. Oppenheim. Quantum signal processing. Signal Processing Mag-

azine, IEEE, 19(6):12–32 (2002).

19. H. Freytes, G. Sergioli, and A. Aric`o. Representing continuous t-norms in quantum

computation with mixed states. J. Phys. A, 43(46):465306, 12 (2010).

20. J. Gordon, E.H. Shortliﬀe. The Dempster-Shafer theory of evidence. Morgan Kaufmann

Publishers Inc. San Francisco, CA, USA, 529-539 (1990).

21. T. Hastie, R. Tibshirani, J. Friedman. The Elements of Statistical Learning. Springer

(2001).

22. A. Hayashi, M. Horibe, and T. Hashimoto. Quantum pure-state identiﬁcation. Phys.

Rev. A, 72(5):052306 (2005).

23. C.W. Helstrom. Quantum detection and estimation theory. Academic Press (1976).
24. G. Jaeger. Quantum information. Springer, New York, An overview, With a foreword

by Tommaso Toﬀoli (2007).

25. G. Jaeger. Entanglement, information, and the interpretation of quantum mechanics.

Frontiers Collection. Springer-Verlag, Berlin (2009).

26. L. Jak´obczyk and M. Siennicki. Geometry of bloch vectors in two-qubit system. Phys.

Lett. A, 286(6):383–390 (2001).

27. A. Kandel. Introduction to pattern recognition: statistical, structural, neural, and fuzzy

logic approaches, 32, World Scientiﬁc (1999).

28. B. Karlıˇga. On the generalized stereographic projection. Beitr¨age Algebra Geom.,

37(2):329–336 (1996).

29. G. Kimura. The Bloch vector for N-level systems. Phys. Lett. A, 314(56):339–349

(2003).

30. G. Kimura and A. Kossakowski.

The Bloch-vector space for N-level systems:
the spherical-coordinate point of view. Open Systems & Information Dynamics,
12(03):207–229, arXiv:quant-ph/0408014 (2005).

31. D. Kolossa and R. Haeb-Umbach. Robust speech recognition of uncertain or missing

data: theory and applications. Springer Science & Business Media (2011).

32. S. Lloyd, M. Mohseni, and P. Rebentrost. Quantum algorithms for supervised and

unsupervised machine learning. arXiv:1307.0411 (2013).

Pattern recognition on the quantum Bloch sphere

17

33. S. Lloyd, M. Mohseni, and P. Rebentrost. Quantum principal component analysis.

Nature Physics, 10(9):631–633 (2014).

34. S. Lu, S.L. Braunstein. Quantum decision tree classiﬁer. Quantum Inf. Process.,

13(3):757–770 (2014).

35. A. Manju, M.J. Nigam. Applications of quantum inspired computational intelligence: a

survey. Artiﬁcial Intelligence Review, 42(1):79–156 (2014).

36. C.D Manning, P. Raghavan, and H. Sch¨utze.

Introduction to information retrieval,

volume 1. Cambridge university press Cambridge (2008).

37. J.A. Miszczak. High-level Structures for Quantum Computing, 6 Synthesis Lectures on

Quantum Computing. Morgan & Claypool Publishers (2012).

38. E. Nagel. Assumptions in economic theory. The American Economic Review, 211–219

(1963).

39. M.A. Nielsen and I.L. Chuang. Quantum computation and quantum information. Cam-

bridge University Press, Cambridge (2000).

40. M. Ohya and I. Volovich. Mathematical foundations of quantum information and com-
putation and its applications to nano- and bio-systems. Theoretical and Mathematical
Physics. Springer, Dordrecht (2011).

41. M. Ostaszewski, P. Sadowski, P. Gawron. Quantum image classiﬁcation using princi-
pal component analysis. Theoretical and Applied Informatics, 27:3 arXiv:1504.00580
(2015).

42. W. Pedrycz. Fuzzy sets in pattern recognition: Methodology and methods. Pattern

Recognition, 23(1): 121-146 (1990).

43. N.A. Peters, T.-C. Wei, P.G. Kwiat. Mixed-state sensitivity of several quantum-

information benchmarks. Phys. Rev. A, 70(5):052309 (2004).

44. M.G.R. Sause, S. Horn. Quantiﬁcation of the uncertainty of pattern recognition ap-
proaches applied to acoustic emission signals. Journal of Nondestructive Evaluation,
32(3):242–255 (2013).

45. M. Schuld, I. Sinayskiy, F. Petruccione. An introduction to quantum machine learning.

Contemp. Phys., 56(2), arXiv:1409.3097 (2014).

46. M. Schuld, I. Sinayskiy, F. Petruccione. Quantum computing for pattern classiﬁcation.

In PRICAI 2014: Trends in Artiﬁcial Intelligence, 208–220, Springer (2014).

47. M. Schuld, I. Sinayskiy, F. Petruccione. The quest for a Quantum Neural Network.

Quantum Inf. Process., 13(11):2567–2586 (2014).

48. J.M. Schwartz, H.P. Stapp, M. Beauregard. Quantum physics in neuroscience and psy-
chology: a neurophysical model of mind-brain interaction. Philosophical Transactions
of the Royal Society B: Biological Sciences, 360(1458):1309–1327 (2005).

49. G. Shafer. A Mathematical Theory of Evidence. Princeton University Press (1976).
50. C.E. Shannon. A mathematical theory of communication. Bell System Tech. J., 27:379–

423, 623–656 (1948).

51. H.P. Stapp. Mind, matter, and quantum mechanics. Springer-Verlag, Berlin (1993).
52. K. Tanaka, K. Tsuda. A quantum-statistical-mechanical extension of gaussian mixture

model. Journal of Physics: Conference Series, 95(1):012023 (2008).

53. C.A. Trugenberger. Quantum pattern recognition. Quantum Inf. Process., 1(6):471–493

(2002).

54. A.R. Webb, K.D. Copsey. Statistical Pattern Recognition. Wiley, 3rd edition (2011).
55. N. Wiebe, A. Kapoor, K.M. Svore. Quantum nearest-neighbor algorithms for machine

learning. Quantum Inform. Comput., 15(34):0318–0358 (2015).

56. M.M. Wilde. Quantum information theory. Cambridge University Press, Cambridge

(2013).

57. P. Wittek. Quantum Machine Learning: What Quantum Computing Means to Data

Mining. Academic Press (2014).

58. L. Xu, E. Hung. Improving classiﬁcation accuracy on uncertain data by considering

multiple subclasses. Neurocomputing, 145: 98-107 (2014).

59. R.R. Yager, L. Liu Classic Works of the Dempster-Shafer Theory of Belief Functions,

219, Berlin, Heidelberg: Springer Berlin Heidelberg (2008).

