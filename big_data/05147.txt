Non-dissipative eﬀects in nonequilibrium systems

Christian Maes, Instituut voor Theoretische Fysica, KU Leuven

Time-symmetric kinetic quantities constitute the non-dissipative part of nonequi-

librium physics. That frenetic contribution counts among features of nonequilibrium

that have traditionally not been much included in statistical mechanics. Yet it is

crucial in ﬂuctuation and response theory to complement the entropic component.

Frenesy refers to a measure of volatility or of excess dynamical activity deﬁned on

system trajectories corresponding to a given reduced description. Its properties can

be linked to general localization eﬀects such as the presence of negative diﬀerential

conductivity, of jamming or glassy behavior or of the slowing down of thermalization.

Their recurrence in theoretical considerations invites a more operational understand-

ing and statistical forces outside equilibrium appear to provide such a frenometry.

Lecture notes for the Eindhoven Winter school

on Complexity, 14-18 December 2015

I.

INTRODUCTORY COMMENTS

Nonequilibrium statistical mechanics wants to ﬁnd explanations of irreversible phenom-

ena in the combination of ﬂuctuation theory with mechanics. There are a great many of

such nonequilibria, and it is probably naive to think there is a simple unique framework.

That in contrast with equilibrium where the Gibbs formalism provides such a frame and

the thermodynamic potentials preside over all considerations. That is made possible

by the existence of entropy in the sense of Clausius, a state function of the equilibrium

system whose diﬀerential gives the reversible heat over temperature in the reservoir. That

entropy is not only related to heat. An extension of it as given by Boltzmann also governs

the macroscopic static ﬂuctuations and it gives an H-functional for the return towards

equilibrium.

In fact, the relaxation of macroscopic quantities follows gradient ﬂow in a

thermodynamic landscape. Similarly, linear response around equilibrium is related to that

same entropy in the ﬂuctuation–dissipation theorem, where the (Green-)Kubo formulae

universally correlate the observable under investigation with the excess in entropy ﬂux

6
1
0
2

 
r
a

 

M
6
1

 
 
]
h
c
e
m

-
t
a
t
s
.
t
a
m
-
d
n
o
c
[
 
 

1
v
7
4
1
5
0

.

3
0
6
1
:
v
i
X
r
a

2

as caused by the perturbation. And of course, statistical forces are gradients of thermo-

dynamic potentials with the entropic force being the prime example of the power of numbers.

For nonequilibrium it is rather conservative to believe that extensions involving only

notions such as time anti-symmetric currents and entropy production, even trajectory de-

pendent and ﬂuctuating, would suﬃce to describe the physics1. It is not because stationary

dissipation is almost equivalent with steady nonequilibrium, or that dissipation is ubiquitous

in complex phenomena that all nonequilibrium properties would be determined by the

time-antisymmetric ﬂuctuation sector or by energy–entropy considerations, or that typical

nonequilibrium features would be uniquely caused by dissipative aspects. That is not very

surprising, but still it may be useful to get simple reminders of the role of time-symmetric

and kinetic aspects in the construction of nonequilibrium statistical mechanics. The plan

of this note is then to list a number of non-dissipative aspects, summarized in what we call

the frenetic contribution and secondly, to discuss the measurability of that.

Since this is part of a general course on complexity, we have avoided complications and

the examples are kept very simple. The level of exposition is introductory. Yet, the mate-

rial or the concepts are quite new compared to the traditional line of extending standard

thermodynamics to the irreversible domain [1].

Contents

I. Introductory comments

II. Transport properties

A. Current direction decided by time-symmetric factors

B. Negative diﬀerential conductivity

III. Non-dissipative eﬀects on the stationary distribution

A. Population inversion

B. From the uniform to an atomic distribution

C. Recent examples

1 let alone biophysical processes.

1

3

3

6

8

12

13

14

1. Demixing

2. No thermodynamic pressure for active particles

IV. Response

A. Standard ﬂuctuation–dissipation relation

B. Enters dynamical activity

C. Second order response

V. Relaxation: “ergodicity” as dynamical activity

VI. Frenometry

A. Reactivities, escape rates

B. Non-gradient aspects are non-dissipative

VII. Symmetry breaking

VIII. Conclusion

References

3

14

15

15

16

18

19

21

23

24

25

27

29

29

II. TRANSPORT PROPERTIES

Transport is usefully characterized in terms of response coeﬃcients such as conductivities.

We discuss them in Section IV, while here we deal with the question of what determines the

direction of the current and how it could decrease by pushing harder.

A. Current direction decided by time-symmetric factors

Consider the metal rod in Fig. 1 which is connected at its ends with a hot and a cold ther-

mal bath. The environment exchanges energy with the system but at diﬀerent temperatures

for the two ends of the rod.

In that case we can, on the appropriate scale of time, think of the system as being in

steady nonequilibrium. It is stationary alright, not changing its macroscopic appearance,

but a current is maintained through it. Therefore the system is not in equilibrium. In fact

there is a constant production σ of entropy in the environment, in the sense that energy is

4

FIG. 1: Example of a simple stationary current for which the direction is decided by the positivity

of the entropy production.

dissipated in the two thermal baths. We apply the usual formula

σ = J1/T1 + J2/T2

with Ji the energy ﬂux into the i−th bath at temperature Ti. Stationarity (conservation of
energy) implies that J1 + J2 = 0 so that we can ﬁnd the direction of the energy current J1

by requiring

σ = J1(1/T1 − 1/T2) ≥ 0

(second law)

Similar scenario’s can be written for chemical and mechanical baths that frustrate the

system. Those are typical examples where, to ﬁnd the direction of the current, we can

apply the second law stating that the stationary entropy production be positive2.

It is however not uncommon in nonequilibrium to ﬁnd a system where the direction of the

current is essentially not decided by the entropy production. We could have various cycles

in the system, and depending on the cycle a particular current would go one way or the

other, and yet both directions show exactly the same entropy production. We illustrate

that now [2].

Suppose a Markov jump process with six states K = {D, x, v, T, w, y}; see Fig. 2(a)

reproduced from [2]. The rates for the transitions D → v → T → y → D are taken to be

k(D, v) = a,

k(v, T ) = ψ1,

k(T, y) = ψ2 es2,

k(y, D) = d es3

k(v, D) = a es0,

k(T, v) = ψ1 e

−s1,

k(y, T ) = ψ2,

k(D, y) = d

The s0, s1, s2, s3 are entropy ﬂuxes (always per kB) over the corresponding jumps. They are

thermodynamically decided by the reactions involving the diﬀerent chemical potentials of the

2 In the presence of multiple currents we can only require that the matrix of Onsager response coeﬃcients

is positive.

5

various substances or molecules plus some extra chemical driving to make it a nonequilibrium
system. Similarly, for transitions D → w → T → x → D, we have

k(D, w) = b,

k(w, T ) = ψ1,

k(T, x) = ψ2 es2

k(x, D) = c es3

k(w, D) = b es0,

k(T, w) = ψ1 e

−s1,

k(x, T ) = ψ2,

k(D, x) = c

The numbers a, b, c, d, ψ1, ψ2 are an essential ingredient in the reactivities. We have also

included some symmetry at least concerning dissipative aspects of the transitions; over the

dotted line in Fig. 2: for example k(w, T )/k(T, w) = k(v, T )/k(T, v) = exp s1.

Look now at the two rings in Fig. 2(a) touching each other at the states D and T . They

are R1 = (D, v, T, y, D) and R2 = (D, w, T, x, D), each other’s reﬂection over the dotted

horizontal line in Fig. 2(a).

(a)

D

x

v

w

y

T

FIG. 2: (a) Cycles over R1 (green and clockwise) and R2 (red and counter-clockwise). (b) The

parameters are ψ1,2 = 1, b = c, s0 = s1 = 1 and s3 = −1. The vertical axis shows the counter-
clockwise minus the clockwise current as a function of a = d.

Note that the entropy ﬂuxes S1 and S2 respectively for going through R1 and for going

through R2, are exactly equal:

S1 = −s0 + s1 + s2 + s3 = S2

(1)

and similarly, for the reversed cycles in each ring. As a consequence, the sign of the entropy

ﬂux does not determine here the direction of the current: S1 > 0 whenever S2 > 0 but the

corresponding currents cycle in opposite directions. Just from the perspective of dissipation,

as a positive entropy ﬂux can be equally realized by clockwise or by counter-clockwise

turning, we cannot conclude the direction of the current. What truly decides here the

012345a00.060.12JR2-JR1c=1, s2=2c=1, s2=4c=2, s2=2c=2, s2=4(b)6

direction is not-entropic; it is frenetic, see Fig. 2(b). We see how the direction of the current

is entirely decided by the prefactors, which are time-symmetric:

for a = d > b = c the

system cycles over R1, and for a = d < b = c it is instead cycle R2 which is preferred.

The asymmetry between the two cycles resides in the prefactors of the reaction rates, e.g.
a (cid:54)= b for the transition D → v versus D → w. When there is detailed balance, i.e.
for
s0 = s1 + s2 + s3, the discrepancy a (cid:29) b or c (cid:54)= d etc. is irrelevant and the stationary regime
would be equilibrium-dead showing no orbiting whatsoever. Those activity considerations

for the nonequilibrium statistical mechanical aspects of Myosin V motion are discussed in

[2]. General considerations on how dynamical activity plays in determining the direction of

ratchet currents are found in [3].

B. Negative diﬀerential conductivity

The usual way random walks are discussed is by giving the rates for the walker to move to

its neighbors. Let us then take the simple 1-dimensional walk, x ∈ Z, with rates k(x, x+1) =
p and k(x, x − 1) = q. The fact that p > q would mean that there is a bias to move to the
right. But suppose we now have a real motion of quasi-independent particles moving a in

tube with some obstacles, much like in Fig. 3.

FIG. 3: Trajectories of driven particles, more and more trapped in the obstacles as the driving

gets bigger.

We see there the trajectories of particles being pushed to the right, while Joule heating

the environment. We imagine periodic boundary conditions so that the constant external

ﬁeld is rotational (and hence cannot be derived from a potential, which causes the breaking

of detailed balance). There are hooks on the ﬂoor and at the ceiling of the tube what are

obstacles for the particles’ motion. Suppose we want to relate that situation to a random

walk; what would we choose for p and q? The external ﬁeld delivers a certain work W per

unit time to each particle, which is dissipated in the environment at inverse temperature β.

Locally, we can take the system to obey detailed balance and thus we require

7

p
q

= eβW

That does not quite determine the rates p, q. What appears important here also is to know

how the escape rates depend on W ; that is the dependence

p + q = ψ(W )

From the situation in Fig. 3 it is clear that a large driving ﬁeld or what amounts to the

same thing, large W , causes trapping. The particles are being pushed against the hooks, or

caught and have much diﬃculty in escaping from the trap as they are constantly pushed

back on them. Hence the escape rates and the function ψ will be decreasing in W . In fact,
we can expect that here ψ(W ) ∼ exp−βW ; see [4].

Let us see what that means for the current; the random walker has a current

J = p − q = ψ(W )

1 − e−βW
1 + e−βW

(2)

We clearly see that for large W , in fact basically outside the linear regime in W , the current

becomes decreasing in W (whenever ψ is decreasing in W ); the more you push the more

the particles get trapped and the current goes down; see also [5]

The above mechanism, described here in the simplest possible terms, is an instance of

negative diﬀerential conductivity, the current showing a negative derivative with respect to

the driving ﬁeld. It is physically interesting and also very important, but for us it suﬃces

to remark that the eﬀect is clearly non-dissipative. Of course one needs a current in the

ﬁrst place but what happens with it is related to time-symmetric ﬂuctuations, here in the

form of waiting time distributions. The dynamical activity is a function of W and cannot

be ignored, and is even essential in the understanding of the eﬀect of negative diﬀerential

conductivities. We have a general response–approach to that eﬀect coming up in Section

IV; see (15)–(16).

As a ﬁnal remark, the trapping eﬀect in the above is trivially caused by the geometry.

There are other mechanisms like in the Lorentz gas where the obstacles are random placed

8

or even moving slightly, [6–8]. But we can also imagine that that trapping and caging is

not caused by external placements but by the interaction itself between the driven particles.

In that case we speak about jamming and glass transitions [9], or even about many body

localization [10].

III. NON-DISSIPATIVE EFFECTS ON THE STATIONARY DISTRIBUTION

Static ﬂuctuations refer to the occurrence of single time events that are not typical for

an existing condition. For example, in this room there is a certain air density which is

quite homogeneous and as a result we have a constant index of refraction of light etc. That

is typical for the present equilibrium condition here for air at room temperature and at

atmospheric pressure. Yet, there are ﬂuctuations, meaning little regions where the density

locally deviates. We can expect these regions to be very small; otherwise we would have

noticed before. That is why such ﬂuctuations are called large deviations; they are very

unlikely when they take macroscopic proportions and they are exponentially small in the

volume of the ﬂuctuation. The rate of ﬂuctuations, i.e., what multiplies that volume, is given

by the appropriate free energy diﬀerence (at least in equilibrium); for the local air density

we would have the grand canonical potential. Similarly, the energy EV in a subvolume V

ﬂuctuates. The total energy is conserved in an isolated system, but there will be exchanges

through the boundary; see Fig. 4.
It could be that the particle number N is also ﬁxed
inside V , in which case the ﬂuctuations are governed by the Helmholtz free energy F, in the
following sense. When the system is in thermal equilibrium and away from phase coexistence
regimes3 the local ﬂuctuations of the energy density EV /V satisfy the asymptotic law

(cid:21)

(cid:20) EV

V

Prob

= e

(cid:39) exp−βV [F(e) − Feq]

where the variational functional is F(e) = e− T S(e, V, N ) with S being the entropy density
at that energy density e, and Feq(T, V, N ) being the equilibrium free energy density at
temperature T (and β−1 = kBT ).

It is only a slight variation to ask for the probability of proﬁles, i.e., to estimate the plau-

sibility of given spatial variations of a particular quantity. We then need spatially extended

systems, most interestingly with interacting components. Clearly the precise formulae will

3 Otherwise, we must introduce also surface tensions and the scaling could be with the surface of the

subsystem and not with its volume.

9

FIG. 4: Fluctuations in a subvolume V in weak contact with an equilibrium bath at ﬁxed temper-

ature T are described in the canonical Gibbs ensemble.

be diﬃcult to get analytically4, but we can turn to some model systems of interacting parti-

cles to get a good idea of what can happen. One example is the symmetric exclusion process

driven via open boundaries at the edges of a one-dimensional interval. In the macroscopic

limit, the stationary proﬁle ﬂuctuations are derived in [13].

In general, the ﬂuctuation functions, describing the macroscopic static ﬂuctuations are called

Boltzmann entropies or also just, free energies5.

ProbN [ρ(r), r ∈ [0, 1]] (cid:39) exp(−N I[ρ(r), r ∈ [0, 1]])

To calculate them is one thing, and is not so easily done — we only have few examples

with analytic solutions6. Here it is for the open symmetric exclusion process, [13], just for

completeness,

I[ρ(r), r ∈ [0, 1]] =

(cid:20)

(cid:90) 1

0

dr

ρ(r) log

ρ(r)
F (r)

+ (1 − ρ(r)) log

1 − ρ(r)
1 − F (r)

+ log

F (cid:48)(r)
ρ1 − ρ0

(cid:21)

4 But there is some algorithm, where the static ﬂuctuation functional becomes the solution of a Hamilton-

Jacobi equation, see [11, 12].

5 That last terminology is rather confusing in general and it arises from the situation in equilibrium. As we
have seen above, in equilibrium the free energy functionals not only determine the probabilities of rare
events; they also relate to heat or work. That was the big insight of Boltzmann, Planck and Einstein
around using the formula S = kB log W in two directions. It is still very instructive to read the ﬁrst pages
of [14] to get an early review. Later reviews for the macroscopic ﬂuctuation theory in equilibrium are for
example [15–17].

6 In fact, for such exclusion processes, a great number of results have been obtained in the last decades,

especially from the use of matrix product states; see e.g. [18].

V,NT10

where the function F is the unique solution of

ρ(r) = F (r) +

F (r)(1 − F (r))F (cid:48)(cid:48)(r)

(F (cid:48)(r))2

, F (0) = ρ0, F (1) = ρ1

Note that on that hydrodynamic scale the ﬂuctuations do not appear to depend on the

details of the kinetics in terms of the exit and entry parameters at the edges; only the

densities of the particle reservoirs count in the ﬂuctuation functional I, no matter whether

the reservoirs contain champagne or water – that changes on the mesoscopic scale as we

see next but it would also change on the macroscopic scale when considering models for

reservoirs which have time-scales comparable to the system’s particles diﬀusion.

We do not always need to imagine big volumes V . There are other ways to set up static
ﬂuctuations7. The easiest is of course to take independent particles and to ask for the prob-

ability that a fraction of the independent copies resides in some given conﬁguration. That

is the ﬁrst thing we mean when considering the stationary distribution of some Markov

process; probabilities refer to imagining independent copies of the same small system which

is subject to ﬂuctuations by external inﬂuences. To be speciﬁc consider again the driven

exclusion process as above but now for only two sites, very far from the diﬀusive hydro-

dynamic regime. So two cells can each be either vacant or occupied (by one particle), in

contact with equilibrium particle reservoirs. The dynamics is a Markov process with states
{00, 01, 10, 11} where the pair refers to a vacancy 0 or an occupation 1 for each cell. The
transition rates are

k(01, 10) = 1,

k(10, 01) = 1

k(0x, 1x) = α,

k(1x, 0x) = γ,

k(x0, x1) = δ,

k(x1, x0) = κ

where x = 0, 1 to be substituted.

The physical meaning of the parameters is as before. The thermodynamics enters in the

ratios α/γ = exp βµ(cid:96) and δ/κ = exp βµr, determined by the chemical potentials µ(cid:96) and

µr from the two chemical reservoirs (at inverse temperature β = 1). That is an example

of requiring local detailed balance for the transition rates when dealing with (spatially and

temporally) well-separated equilibrium reservoirs. The stationary distribution, which gives

7 We forget here about quantum ﬂuctuations which require yet additional considerations. Yet, models of
the type that will follow can arise from applying a Fermi Golden Rule type description to open quantum
systems.

11

the histogram of occupations for many repeated observations, has

Prob[00] = (κ2 + γ2(1 + κ) + γκ(2 + α + δ + κ))/z

Prob[01] = (α(γ + δγ + κ) + δ(κ + γ(1 + δ + γ + κ)))/z

Prob[10] = ((α + δ)γ + (δ + α(1 + α + δ + γ))κ + ακ2)/z

Prob[11] = (δ2 + α2(1 + δ) + αδ(2 + δ + γ + κ))/z

for normalization z := (α + δ + γ + κ)(δ + γ + κ + γ(δ + κ) + α(1 + δ + κ)). Clearly, from

symmetries and from normalization, that distribution is completely decided by

Prob[01]/Prob[00] =: B

(3)

only.

FIG. 5: The driven two-cell system for which the ratio B is deﬁned in (3). When ﬁxing the densi-

ties/chemical potentials of the baths, the kinetics in terms of the entry/exit rates, here represented

by the product αγ, changes B when µ(cid:96) (cid:54)= µr.

Under equilibrium at chemical potential µ(cid:96) = µ = µr, when ακ = γδ, the formulae

give B = exp βµ as it should for the grand-canonical distribution, completely determined
by the thermodynamic speciﬁcation of the environment. Not so when µ(cid:96) (cid:54)= µr, i.e., under
nonequilibrium driving conditions: even when ﬁxing µ(cid:96) and µr, but changing say the product

αγ we get diﬀerent values for the ratio B, see Fig. 5. One of the major challenges of

nonequilibrium statistical mechanics is to bring order in these probabilities — what is the

best parameterization for a physically relevant characterization?

05101520αγ6.577.58Bµl=1µl=2µl=3012345µl6912Bαγ=1αγ=9αγ=16(a)eµrµreµr(b)A. Population inversion

12

Thermal equilibrium occupation statistics is completely determined by energy-entropy

arguments.

In the simplest case of a nondegenerate multilevel system, we have relative

occupations determined by temperature and energy diﬀerence. However, when adding

kinetic eﬀects, like introducing a symmetrizer between two levels we break detailed balance

and we can basically select any desired (even high) energy level to have the largest

occupation. In that way, like for lasers, under nonequilibrium conditions but via changes in

non-dissipative factors, we can establish an inversion of the population with respect to the

usual Boltzmann statistics.

Consider a system with K energy levels where the lowest and highest levels are connected
by an equalizer and an additional energy barrier F exists between the K and K − 1th level.
Denote the number of particles at level (cid:96) by n(cid:96) and let the rate at which a single particle
jumps from level (cid:96) to level (cid:96)(cid:48) be k((cid:96), (cid:96)(cid:48)) with

− 1
T (E(cid:96)+1−E(cid:96)),

∀(cid:96) (cid:54)= K − 1, K

∀(cid:96) (cid:54)= K, 1
− 1
T (EK−EK−1),

− F

T e

k((cid:96), (cid:96) + 1) = n(cid:96) e
k((cid:96), (cid:96) − 1) = n(cid:96),

k(K − 1, K) = nK−1 e
− F
k(K, K − 1) = nK e
T ,

k(1, K) = b n1

k(K, 1) = b nK

(4)

The equalizing symmetric prefactor b > 0 between the highest and lowest energy level
along with the factor e−F/T gives rise to the desired population inversion [19]. That can be
witnessed by the “eﬀective temperature”

(cid:20)

(cid:21)−1

Teﬀ = (EK − E1)

log

ρ1
ρK

(5)

Fig. 6(a) (reproduced from [20]) shows that eﬀective temperature Teﬀ increasing with

the strength of the equalizer b. For a ﬁxed F, the curve of Teﬀ corresponding to a lower

thermodynamic temperature T crosses that of a higher temperature from below signifying

population inversion. The barrier F facilitates that phenomenon — crossing occurs for

smaller b when F is increased.

13

(b)

be−ε/2

3

beε/2

2

ceε/2

ce−ε/2

aeε/2

ae−ε/2

1

FIG. 6: (a) Eﬀective temperature Teﬀ as function of the symmetrizer b for diﬀerent environment

temperatures T and barrier strengths F for K = 3 levels. For b = 0 there is no dependence on F .

For lower T and b > 0 the dependence on F shows more. (b) Graph-representation of the 3-state

Markov process (6). Changing the non-dissipative parameters a, b, c can select a state when ε > 0

is big enough.

B. From the uniform to an atomic distribution

Suppose a three-state Markov process with state space {1, 2, 3} and transition rates

k(x, y) ≡ k(x → y)

k(1, 2) = aeε/2,
−ε/2,

k(1, 3) = ce

k(2, 3) = beε/2,
−ε/2,

k(3, 2) = be

k(3, 1) = ceε/2,
−ε/2

k(2, 1) = ae

(6)

parameterized by the external ﬁeld ε ≥ 0 and numbers 0 < a < b ≤ c (let us call them
reactivities); see Fig. 6(b).

If ε = 0, there is detailed balance with the equilibrium distribution being uniform on
{1, 2, 3}, whatever the a, b, c. From the moment ε > 0, the asymptotic behavior is that of
steady nonequilibrium where the driving ε does not as such distinguish between the three
states. However, the prefactors a, b, c, while time-symmetric over the jumps 1 ↔ 2 ↔ 3,
now determine the stationary condition as illustrated in Fig. 7(b). Moreover and as is easy

to understand, for large ε the stationary distribution concentrates on that state from which

the escape rate is minimal; see Fig. 7(a).

That is an instance of what is sometimes called the Landauer blowtorch theorem [21, 22].

It is typical indeed in nonequilibrium systems that we cannot (partially) order states de-

00.511.5b0102030TeffF=2,T=1F=2,T=5F=3,T=1F=3,T=5(a)pending on whether heat is being released over all paths connecting them, or being absorbed

over all paths connecting them. In fact we can prove that in such a case, when depending
on what path we choose heat is absorbed or released in going x → y, then we can change
the relative weight ρ(x)/ρ(y) in the stationary distribution ρ from being greater than one to

being smaller than one, just by an appropriate change in the reactivities (here, the a, b, c).

14

FIG. 7: (a) Stationary occupations in the 3-state Markov process as function of ε for the choice

a = 1, b = c = 20. (b) For ﬁxed ε = 2 the stationary occupations as function of b = c for a = 1.

The above kinetic selection of a particular state is probably at work in a variety of bio-

chemical systems for getting a more reliable reproduction or copy of certain proteins, cf. the

idea of kinetic proofreading [23]. It illustrates a time-symmetric aspect, non-dissipative, but

of course it works only out-of-equilibrium to select a state or conﬁguration.

C. Recent examples

1. Demixing

The above examples are extremely simple, but the heuristics can easily be moved towards

more interesting applications. Suppose indeed that we have a macroscopic system with two

types of particles and we must see whether a condition with phase separation between the

two types is most plausible. In equilibrium that would be called a low-entropy condition

which can only be obtained at suﬃciently low temperature and with the appropriate interac-

tions. In nonequilibrium opens the possibility of a totally diﬀerent physics, that the demixed

conﬁguration gets more plausible whenever it is a trap in the sense that the escape rates

to leave from it are rather low. For that to be eﬀective, we need, as above, that the mixed

012345ε00.20.40.60.8105101520b00.20.40.60.8(a)(b)ρ1ρ2ρ1ρ2ρ3ρ315

and the demixed condition are dynamically connected through both positive dissipative as

well as negative dissipative paths. In the end it will be the conﬁguration with lowest escape

possibilities that will dominate.

An example of that phenomenon is shown in [24, 25]. The importance of life-time consider-

ations especially at low temperatures is discussed in [19].

2. No thermodynamic pressure for active particles

Suppose we have active particles in a container, like for active Brownians or for self-

propelled particles etc. The pressure on a wall is obtained from calculating the mechanical

force on the wall and to average over the stationary ensemble. Since that stationary ensem-

ble could depend on kinetic details, we cannot expect the pressure to be thermodynamically

determined. It means that details of the interaction between particles and wall can matter

and that, unless we have symmetries that cancel the kinetic dependencies, we will not have

an equation of state relating that wall pressure to bulk properties such as global density or

temperature. The simple reason is that the stationary distribution is itself not thermody-

namically energy-entropy characterized.

We ﬁnd an analysis of that eﬀect in [26].

IV. RESPONSE

We come to the meaning and the extension of the ﬂuctuation–dissipation theorem. The

general aim is the physical understanding of the statistical reaction of a system to an

external stimulus. In that sense we look at averages of certain quantities, for example over

many repeated measurements. We start from a stationary condition and we perturb the

system over some time period. The question is to ﬁnd a good representation of the response

of the system: we want to learn what determines the susceptibility in terms of the original

(unperturbed) system.

For the above purpose and especially for nonequilibrium systems, working on space-time

is more convenient than directly working on the single-time distribution. The path-space

distribution is local in space-time and has often explicit representations; we speak then

about dynamical ensembles and it is part of nonequilibrium statistical mechanics to learn

how they are speciﬁed and what they determine.

A. Standard ﬂuctuation–dissipation relation

We start by describing the path-space approach for characterizing the response in equi-

librium.

A dynamical ensemble gives the weight of a trajectory of system variables. Let ω denote

16

such a system trajectory over time-interval [0, t]. We consider a path–observable O = O(ω)

with expectation

(cid:104)O(cid:105) =

(cid:90)

(cid:90)

D[ω] P (ω) O(ω) =

D[ω] e

−A(ω) Peq(ω) O(ω)

(7)

Here D[ω] is the notation, quite formally, for the volume element on path–space. The
perturbed dynamical ensemble is denoted by P and gets speciﬁed by an action A with
respect to the reference equilibrium ensemble Peq:

P (ω) = e

−A(ω) Peq(ω).

At the initial time, say t = 0, the system is in equilibrium and the path-probability distri-

butions P and Peq diﬀer (only) because P is the dynamically perturbed ensemble. Time-

reversibility of the equilibrium condition is the invariance Peq(θω) = Peq(ω) under time-
reversal θ, deﬁned on paths ω = (xs, 0 ≤ s ≤ t) via
(θω)s = πxt−s

with kinematical time-reversal π (e.g. ﬂipping the sign of velocities) as in Fig. 8.

FIG. 8: Time-reversal in free fall.

We decompose the action A into a time-antisymmetric S(ω) and a time-symmetric D(ω)

part,

with Sθ = −S and Dθ = D. These are the entropic S and frenetic D components of the
action and they respectively give excesses in entropy ﬂuxes and in dynamical activity as

A = D − S/2

(8)

17

caused by the perturbation. In that way S(ω) and D(ω) depend on time t because they

are deﬁned on paths ω in the time-interval [0, t]. For the present linear response around

equilibrium, all will be decided by S (as we will see below). The reason why that S is

related to the entropy ﬂux amounts to understanding the origin of the detailed balance

condition; see e.g. [27]. For example, in case of a potential perturbation of strength ε, where
we change the energies E(x) → E(x)− εV (x), we would have S(ω) = εβ [V (xt)− V (x0)]. In
case of an external ﬁeld ε which induces a single current J, we would have S(ω) = ε J(ω).

Expanding (7) to linear order around equilibrium yields

(cid:104)O(cid:105) = (cid:104)O(cid:105)eq − (cid:104)A(ω) O(ω)(cid:105)eq

(cid:90)

D[ω] Peq(ω) g(ω)

in terms of equilibrium expectations

(cid:104)g(ω)(cid:105)eq :=
For the time-reversed observable that gives

(cid:104)Oθ(cid:105) = (cid:104)O(cid:105)eq − (cid:104)A(θω) O(ω)(cid:105)eq

(9)

(10)

where we have used Peq(θω) = Peq(ω) so that (cid:104)g(ω)(cid:105)eq = (cid:104)g(θω)(cid:105)eq. Subtracting (10) from
(9) gives

(cid:104)O − Oθ(cid:105) = −(cid:104)[A(ω) − A(θω)] O(ω)(cid:105)eq

always to linear order in the perturbation. Now use that A(ω) − A(θω) = −S(ω), to get

For an observable O(ω) = O(xt) that depends on the ﬁnal time, we have Oθ(ω) = O(πx0).

(cid:104)O − Oθ(cid:105) = (cid:104)S(ω) O(ω)(cid:105)eq

(11)

Since (cid:104)O(πx0)(cid:105)eq = (cid:104)O(x0)(cid:105)eq = (cid:104)O(xt)(cid:105)eq we receive

(cid:104)O(xt)(cid:105) − (cid:104)O(xt)(cid:105)eq = (cid:104)S(ω) O(xt)(cid:105)eq

(12)

In other words, the response is completely given by the correlation with the dissipative part

in the action, the entropy ﬂux S. That is the Kubo formula.
When the observable is odd under time-reversal, O(θω) = −O(ω) like O(ω) = S(ω) the
entropy ﬂux itself or O(ω) = J(ω), some time-integrated particle or energy current, we get

from (11) the Green–Kubo formula

(cid:104)J(cid:105) =

1
2 (cid:104)S(ω) J(ω)(cid:105)eq,

and (cid:104)S(cid:105) =

1
2

Vareq[S]

(13)

18

That the linear order gets expressed as a correlation between the observable in question and

the entropic component S only is the very essence of the ﬂuctuation–dissipation relation.

Obviously, in the time-correlation functions that enter the response, there are kinetic aspects

and non-dissipative contributions are thus present already in ﬁrst order. Yet, there is no

explicit presence of non-dissipative observables. Even when the perturbation depends on

kinetic and time-symmetric factors, the linear response (12) and (13) erases that detailed

dependence and only picks up the thermodynamic dissipative part S.

B. Enters dynamical activity

The previous section discussed the linear response around equilibrium. Yet, the line

of reasoning is essentially unchanged when doing linear response around nonequilibrium

regimes. That is, up to equation (9) nothing changes:

(cid:104)O(cid:105) = (cid:104)O(cid:105)ref − (cid:104)A(ω) O(ω)(cid:105)ref

(14)

where the subscript in the right-hand side expectation simply replaces the equilibrium ones.

That new reference is for example steady nonequilibrium where (in the left-hand side) we

investigate the response; see [28] for more details.

We still do the decomposition (8) where the S respectively the D now refer to excesses

in entropy ﬂux and in dynamical activity with respect to the unperturbed nonequilibrium

steady condition. Substituting that into (14) we simply get

(cid:104)O(cid:105) − (cid:104)O(cid:105)ref =

1
2(cid:104)S(ω) O(ω)(cid:105)ref − (cid:104)D(ω) O(ω)(cid:105)ref

(15)

and a frenetic contribution with D = Dθ enters as second term in the linear response. That

is a non-dissipative term as it involves time-symmetric changes, in particular related to

dynamical activity and time-symmetric currents.

If the observable is a current J which is caused by an external ﬁeld W , and we change

W → W + dW so that S = dW J(ω), then

d(cid:104)J(cid:105)
dW

=

1
2(cid:104)J 2(ω)(cid:105)ref − (cid:104)D(ω) J(ω)(cid:105)ref

(16)

which shows that negative diﬀerential conductivity can only be the result of a (large) positive

correlation in the unperturbed system between the current and the excess dynamical activity.

19

FIG. 9: Schematic representation of the open zero range process with respective transition rates

as they depend on the local particle number n. The chemical potential µ of the environment is

given in (18) but does not fully determine the entry and exit rates.

For the simple random walk under (2) the excess dynamical activity is essentially minus the
change in escape rate ψ(cid:48)(W ) times the number of jumps. If that change in escape rate is
suﬃciently negative, we get negative diﬀerential conductivity, because the number of jumps

correlates positively with the current.

C. Second order response

We consider next the extension to second order of the traditional Kubo formula. For

order-bookkeeping we suppose that the perturbation or external stimulus is of strength
ε (cid:28) 1 and is present in the action A = Aε, depending smoothly on ε. We restrict us here
also to the case where the perturbation is time-independent (after the initial time).

Furthermore we assume that the perturbation enters at most linearly in S, i.e., higher
derivatives like S(cid:48)(cid:48)
ﬁeld. We refer to [29] for the details.

ε=0 = 0 are zero; it means that the Hamiltonian is linear in the perturbing

The result that extends (12) is

(cid:104)O(xt)(cid:105) − (cid:104)O(xt)(cid:105)eq = ε(cid:104)S

(cid:48)
0(ω) O(xt)(cid:105)eq − ε2 (cid:104)D

(cid:48)
0(ω) S

(cid:48)
0(ω) O(xt)(cid:105)eq+O(ε3).

(17)

where the primes refer to ε−derivatives at ε = 0. We see that at second order around
equilibrium the excess dynamical activity D(cid:48)
0(ω) enters the response, and will of course
have its consequences as non-dissipative eﬀect.

For an example we take the zero range model, representing a granular gas in one dimen-

sion. There are L sites and each is occupied with ni number of particles, see Fig. 9. In the

bulk a particle hops from site i to its right or left neighbor at rate u(ni). The boundary

αui(n)ui(n)δκuL(2)u1(3)γu1(3)uL(2)20

sites are connected with particle reservoirs, their action being modeled via entrance and

exit rates at the left and right boundary sites i = 1 and i = L. Entry rates are α and δ

respectively; exit rates are γ u(n1) from the ﬁrst site and κ u(nL) at the last site. We have

global detailed balance and no stationary current when ακ = γδ. Then, the environment is

thermodynamically speciﬁed by the chemical potential µ and inverse temperature β via

α/γ = δ/κ = eβµ.

(18)

Yet, just as for our random walker above, the jump rates α, δ, γ and κ are not completely

speciﬁed by β µ; the coupling with the environment indeed depends on more kinetic elements.

We want to investigate the response to a change in chemical potential µ → µ + ε. The
dissipative or entropic component to the response is completely speciﬁed, no matter how
that change is implemented via the entry and exit rates. We always have S(cid:48)
0 = βJin in terms
of the net number Jin of particles transferred into the system from the environment during

the time interval [0, t]. However, starting from second order, the non-dissipative component
enters and we must see for D(cid:48)
0. A ﬁrst possibility is that only the entry rates at both edges
are changing α → ˜α = αeβε, δ → ˜δ = δeβε for an increase in the chemical potential of
˜µ = µ + ε. Then, we can calculate

(cid:48)
0 = β(α + δ)t −
D

β
2 I.

(19)

Here I is the total number of particle exchanges between the system and the reservoir during
[0, t], again non-dissipatively, time-symmetric. We also see the explicit dependence on the

entry rate α + δ.

The second order response is obtained by inserting (19) into (17),

(cid:48)
0(ω)D

(cid:48)
0(ω)O(t)(cid:105)eq = β2

(cid:104)S

(α + δ)t(cid:104)Jin O(t)(cid:105)eq −

1
2(cid:104)Jin I O(t)(cid:105)eq

(cid:21)

.

(20)

If we consider a diﬀerent perturbation where both the entry and the exit rates are modiﬁed

α → ˜α = αeβε/2/(1 + βε), γ → ˜γ = γe−βε/2/(1 + βε) and δ → ˜δ = δeβε/2/(1 + βε), κ →
˜κ = κe−βε/2/(1 + βε), while we get the same shift in the chemical potential ˜µ = µ + ε, the
frenetic part now has

(cid:20)

(cid:20)

(cid:20)

(cid:90) t

0

3
2

(cid:48)
0(ω) = β

D

and

1
2

I −

(α + δ)t −

ds [γu(n1(s)) + κu(nL(s))]

(cid:48)
0(ω)D

(cid:104)S

(cid:48)
0(ω)O(t)(cid:105) = β2

(cid:104)JinI; O(cid:105)eq −

1
2

(α + δ)t(cid:104)Jin; O(t)(cid:105)eq

(cid:21)

(cid:90) t

0

3
2

−

ds (cid:104)[γu(n1(s)) + κu(nL(s))] Jin; O(t)(cid:105)eq

21

(cid:21)

Here we see the explicit appearance of time-symmetric observables from second order re-

sponse on. The linear order response is exactly the same for the two types of perturbations,

indistinguishable because that is purely dissipative.

V. RELAXATION: “ERGODICITY” AS DYNAMICAL ACTIVITY

The historically ﬁrst big problem of nonequilibrium statistical mechanics is to characterize

the relaxation to equilibrium and to establish its dynamical stability. The main part of the

history of nonequilibrium physics since Boltzmann’s time has been devoted to that question

and still today these eﬀorts very much continue for example in derivations of diﬀusion

equations.

It is understandable that entropy diﬀerences, hence dissipative eﬀects, play a

role there. We start by recalling the heuristic picture.

Equilibrium is characterized ﬁrst for closed isolated and macroscopic systems. Consider

a physical partition of the classical phase space at ﬁxed energy E, volume V and particle

number N . We have in mind to coarse grain fast degrees of freedom or to follow proﬁles of

globally conserved quantities. Abstractly, there is a many-to-one map

X → M (X)

from the phase space point X, collecting all the positions and momenta of the many particles

all equally plausible when compatible with (E, V, N ), to the set of macroscopic values M

such as for the (kinetic) energy and density proﬁles or for other macroscopic quantities.

Since these macroscopic observables involve a huge amount of particles, with arithmetic

averages over space or over particles, we can apply the law of large numbers with respect to

the Liouville measure to say that there exist typical values for M , that one should meet and

see in other words with overwhelming probability upon randomly picking a point X in the
constant (E, V, N )−phase space. These are the equilibrium values M = Meq and the phase
space region where they are realized is called the equilibrium (condition). The entropy (`a

la Boltzmann) is the log of the phase space region for a macroscopic condition and hence

equilibrium is the condition of maximum entropy; cf. Fig. 10.

It may seem that we have not used at all the dynamics, and in particular equilibrium got

no dynamical characterization. That is not entirely true. First, we speciﬁed E, V, N which,

22

FIG. 10: The Boltzmann picture of relaxation to equilibrium, amended by the inﬂuence of “surface

eﬀects” of the phase space region. Higher dynamical activity or escape rates on the reduced or

coarsed grained level of description decreases relaxation times.

especially through ﬁxing the value E of the energy, of course depends on the interactions

of the particles. Secondly we made a choice of macroscopic variables. It should be clear

that not all choices are very interesting or even reasonable. Also there we can expect

dependencies on the interaction and speciﬁcations of the time-evolution. For example, we

would hope that the macroscopic variables will jointly give rise to an autonomous dynamics

on the macroscopic (thermodynamic or hydrodynamic) level of description. That again

depends on the microscopic dynamics. But of course, dynamics will matter essentially

in the relaxation towards equilibrium; how trajectories starting in a region/condition of

small volume/entropy would typically reach equilibrium. A still often claimed condition is

that of ergodicity. The latter is essentially a postulate on the dynamics (only) and hence

cannot in fact be very relevant to the question of relaxation to equilibrium. Indeed, the

so called ergodicity postulate plays no big role in the foundations of statistical mechanics

or in the elucidation of the zero-th law of thermodynamics; equilibrium and the return

to equilibrium is not only a dynamical question. Ergodicity is there neither suﬃcient

nor necessary8. Yet, the notion of dynamical activity which is a statistical mechanical

8 It is not suﬃcient as it ignores mostly the essential role of initial conditions and of the macroscopic limit;
the notion of typicallity which characterizes equilibrium is of course absent for ergodic systems with only
few degrees of freedom. Ergodicity is also not necessary for the microscopic dynamics as we want to take
ﬁrst the large size (thermodynamic) limit and consider the time-evolution for reduced variables. The
Poincar´e recurrences are then physically irrelevant and even systems which are periodic for every ﬁnite
number of degrees of freedom can show relaxation to equilibrium in the right physical sense.

Equilibrium23

one and the absence of kinetic constraints, comes close to the heuristics traditionally

associated to ergodicity when emphasizing the possibility of the system to “explore” the

phase space. So it is probably a good suggestion to keep the intuition behind ergodicity

and mixing conditions but to apply them on the physical coarse-grained or reduced

level of description and to think rather about the absence of kinetic constraints and the

necessity of having dynamical activity to escape from nonequilibrium regions of phase space.

Concerning the main point of these lectures indeed, it should be clear that non-dissipative

aspects should play a role also. Especially when starting well away from equilibrium, visit-

ing phase space regions with smaller volume, it appears not unreasonable to imagine that

also “surface” eﬀects and not only volume eﬀects will contribute to determine the pathways

to equilibrium. The exit and entrance rates from a macroscopic condition are not deter-

mined by its volume (entropy) solely. That is the ﬁrst heuristics behind suspecting that

time-symmetric quantities, like time-symmetric currents, will also appear essentially outside

equilibrium.

In fact, on the same level of discussion we can easily imagine that the interaction between

various components lead to eﬀective kinetic constraints such that the relaxation becomes

very diﬃcult. That “breaking of ergodicity” is studied in various models and sometimes is

referred to as glassy behavior or as many body localization [10]. The kinetic constraints are

basically involving non-dissipative aspects, having to do with trapping and caging eﬀects

in phase space, which is just an abstraction of what happens in Fig. 3 (replacing there the

external ﬁeld by thermodynamic forces and replacing the obstacles by either disorder in the

interaction or by speciﬁc many body eﬀects).

VI. FRENOMETRY

The question arises how non-dissipative aspects can be isolated and/or measured.

Is

there something like measuring excesses in dynamical activity, as we encounter for example

in the frenetic contribution to response functions? Let us ﬁrst see what that means for

thermodynamic potentials.

Entropy is of course not directly measured — it is obtained via measurements of heat

capacity or from heat measurements. Similarly, free energies are measured from work, as

we remember from the following type of calculation. Suppose that the states x of a system

24

are coupled to some real variable q, say the position of a probe, via the interaction energies
E(x, q). The mechanical force on q is −∇qE(x, q). For a quasi-static probe we can take the
statistical average over the equilibrium distribution,

feq(q) =

1
Zq

e

−βE(x,q) (−∇qE(x, q)) =

1
β∇q log Zq = −∇qF(q)

(cid:88)

x

In other words, the statistical force is gradient with potential given by the free energy (now

depending on q). It is then clear how reversible transformations will have changes in free

energy given by the work done on the probe.

The idea for measuring non-dissipative aspects can proceed similarly.

In general we have that statistical forces out-of-equilibrium are given by

(cid:88)

x

f (q) =

ρq(x) (−∇qE(x, q))

where ρq(x) is the stationary distribution of a nonequilibrium medium which is coupled via

interaction energy E(x, q) to a quasi-static probe. Clearly, as we have seen throughout these

notes, the distribution ρq(x) will contain non-dissipative aspects. Therefore, measuring the

work done by the statistical force f (q) on a probe will reveal aspects of dynamical activity,

changes in escape rates or in time-symmetric parts of reactivities. That is the general idea,

but of course we need to implement it in speciﬁc situations. Paradoxically, as the system

dissipates more, more non-dissipative features become visible.

A. Reactivities, escape rates

Look again at the situation depicted in Fig. 3.

Suppose you would like to measure the dependence of the escape rate ψ(W, x) on the external

driving ﬁeld. What we will do is to couple the walker to a probe with position q for example

as a load connected to the walker via a spring,

E(x, q) =

λ
2

(x − q)2

The stationary distribution of the driven particles for high ﬁeld W can be approximated by

dividing an elementary interval length L, say between two major obstacles, in three diﬀerent

states, one for the walker being directly behind the obstacle, another for being in the middle

of the interval and yet a third state for being in front of an obstacle; see Fig. 3. We then

25

write ρq(x) (cid:39) z/ψ(W, x), independent of probe position q for very small λ. That is similar
to what we saw already in Fig. 7, how the reactivities determine the stationary distribution.

The statistical force on the probe (load) is then approximated by

(cid:90) L

0

f (q; W, λ) = z λ

(q − x)

1

ψ(W, x)

dx

telling us about the escape rate ψ(W, x). When we ﬁnd the position of the probe where
the statistical force is zero, f (q∗; W ) = 0, we will get information about the escape rate
proﬁle. For example, if we take ψ(W, x) = e−aW x, x ∈ [0, L], then the stationary position
of the probe will be at q∗ = L − 1/(aW ) + . . . for large W , from which we would ﬁnd

the slope coeﬃcient a. The probe will ﬁnd itself in a harmonic well for eﬀective potential
λ(q − L + 1/(aW ))2/2.

B. Non-gradient aspects are non-dissipative

Another tool to derive information about non-dissipative aspects of a nonequilibrium

medium is to look at the rotational part in the statistical force induced on a probe.

In

fact, the very presence of a rotational component to the statistical force is produced by the

simultaneous appearance of excess entropy ﬂux and excess dynamical activity when the

medium relaxes to a new stationary condition after displacing the probe.

The simplest example of how the statistical force can pick up the dependence of reactiv-

ities on the driving goes as follows; see also [31].
We follow a probe on the unit circle, q ∈ S1, in contact with a thermal bath at inverse
temperature β = 1, modeled via the overdamped Langevin dynamics

(cid:114)2γ

γ ˙q = −

∂
∂q

E(x, q) +

ξt

β

for ξt standard white noise, γ is the damping coeﬃcient and there is an interaction with an
‘internal’ degree of freedom x = −1, 0, 1 with potential

E(x, q) = x sin q + 2x2 cos q

The x is the fast degree of freedom, driven with transition rates

kq(x, x

(cid:48)) = e

− β
2 [E(x(cid:48),q)−E(x,q)] φ(x, x

(cid:48)) e

1

2 s(x,x(cid:48))

The drive is uniform, with s(−1, 1) = s(1, 0) = s(0,−1) = βε but we assume that also the
symmetric φ(x, x(cid:48)) = φ(x(cid:48), x) are aﬀected via φ(−1, 1) = φ(1,−1) = φ0(1 + a|ε|) for some
a ≥ 0, while φ(0,±1) = φ(±1, 0) = 1. Detailed balance is achieved at ε = 0, where φ0 picks
up the relative importance of the dynamical activity over the transitions 1 ↔ −1.

The statistical force on the probe is

26

and can be calculated exactly. The rotational part of the force frot =(cid:72) f (q) dq is plotted

f (q) = −(cid:104)x(cid:105)q cos q + 2(cid:104)x2(cid:105)q sin q

(21)

versus ε in Fig. 11(a). Observe that the rotational force depends on the coeﬃcient a, and
hence picks up information about that non-dissipative part φ(x, x(cid:48)) in the reaction rates. In
fact, we see clearly, take a = 1/2, that the rotational force is maximal for an intermediate
ε (cid:39) 4. For larger a ≥ 0 we get less rotational force on the probe, because the medium gets
more jammed, in fact similarly again to what happens in Fig. 7(b) for large b.

FIG. 11: (a) The rotational part frot =(cid:72) f (q) dq of the statistical force (21) on the probe and how

it depends on the excess in time-symmetric reactivities for intermediate values of ε only. (b) The

current in the driven three-state process rescaled by exp ε/2.

Fig. 11(b), where we see the current in the medium process, must be compared with

Fig. 11(a): there is no simple relation between the rotational power in the probe and the

entropy production in the medium.

051015ε00.511.52frota=0a=0.5a=2051015ε00.20.40.60.8Ja=0a=0.5a=2~(a)(b)VII. SYMMETRY BREAKING

27

We ﬁnally come to a major inﬂuence of non-dissipative aspects on nonequilibrium struc-

tures. To put it in contradictory terms and in line with the recent [32]: purely dissipative

trajectory ensembles are wrong because they do not allow dissipation. By a purely dissi-

pative trajectory ensemble we mean a probability distribution on trajectories, as in Section

IV, where however the action with respect to equilibrium only contains the entropy ﬂux. In
other words, looking back at (7) and (8), we would have an action A = λ S proportional to
the entropy ﬂux only, thus forgetting about the frenetic contribution D. Such ensembles are

often considered for modeling nonequilibrium in the spirit of maximum entropy or maximum

caliber assumptions9. The point is that these mutilated ensembles

Prob[ω] ∝ Probeq[ω] eλS(ω)

(22)

often have additional symmetries which are unwanted. The main mathematical consequence

of (22) is that under time-reversal θ (deﬁned in Section IV A),

Prob[θω] ∝ Probeq[ω] e

−λS(ω)

while there may be other involutions Γ leaving invariant the equilibrium ensemble for which
S(Γω) = −S(ω) and hence, for the mutilated ensemble (22),

Prob[Γθω] = Prob[ω]

(see equation (12) in [32] or equations (6)–(9) in [33]).

Indeed, it is easy to imagine for

example how spatial reﬂection inverts S in exactly the same way as does time-reversal (and

leaving the equilibrium reference invariant). It implies that we could exchange time-reversal

with spatial reﬂection, or more generally that we could induce time-reversal by reversing

the thermodynamic forces. Then, the dynamical ensemble of a diﬀusion driven by some
non-conservative ﬁeld E would have a time-reversal which is obtained by simply ﬂipping
E → −E. Now, since the stationary (single time) distribution of the process is identical to
the stationary distribution of the time-reversed process, we would have that the stationary
distribution is left invariant by ﬂipping the ﬁeld E → −E, which of course is often very

9 More positively, such maximum entropy principles can teach us what observables or quantities are missing
in the variational formulation. Here we learn that there is more than the values of currents or of entropy
ﬂux alone that characterize the nonequilibrium ensemble.

28

wrong. But even forgetting about that last point10, all expectations of time-symmetric
observables would be invariant under E → −E, (cid:104)ΓO(cid:105) = (cid:104)O(cid:105) when θO = O, and all
expectations of time-antisymmetric observables would be antisymmetric under E → −E,
(cid:104)ΓO(cid:105) = −(cid:104)O(cid:105) when θO = −O. For example, from the last equality, for an energy current
J we would have (cid:104)ΓJ(cid:105) = −(cid:104)J(cid:105) but often ΓJ = J so that we would need to conclude that
(cid:104)J(cid:105) = 0, no dissipation!

In other words, such nonequilibrium ensemble (22), lacking non-dissipative terms in the

action, would not be able to break certain symmetries. That point was ﬁrst stressed in

the theory of [33]. Also an example was given there of a viscous ﬂuid under inﬂuence of

a pressure diﬀerence in some tube.

In the laminar ﬂow regime (left part of Fig. 12) we

indeed cannot distinguish between reversal of time and reversal of pressure diﬀerence. Yet,

at higher pressure diﬀerences (right part of Fig. 12), when things get really nonequilibrium,

the laminar pattern breaks up, the ﬂow becomes turbulent and time-reversal deﬁnitely diﬀers

from ﬁeld-reversal. Another and older example where such symmetry breaking is essential is

found in [34]. There a turbulent boundary layer ﬂow is considered over a smooth symmetric

hump; see Fig. 12. For the ensemble (22) there would never be a possibility to break that

FIG. 12: Flow of particles driven by a ﬁeld E. Left: for small driving we get a laminar ﬂow without
symmetry breaking. Time-reversal equals ﬁeld reversal. Right: For appreciable ﬁeld strength

turbulent ﬂow develops and the spatial symmetry gets broken essentially by the non-dissipative

frenetic contribution in the action, which is absent in the ensemble (22).

symmetry. Yet, true nonequilibrium does create a weak symmetry breaking, indeed visible

10 After all, the idea of stationary distribution has lost most of its meaning now since the trajectories

distributed by (22) are not associated to a Markovian time-evolution.

ε(cid:28)1ε29

for aeolian sand transport and dune formation.

Note still that the ensemble (22) is compatible with the Kubo formula and linear response

around equilibrium, exactly for the (same) reasons that lead to (11) and (13). Moreover, so

called ﬂuctuation symmetries [27] are trivially true. Yet, they lack the non-dissipative ele-

ments that are essential for creating interesting nonequilibria. To maintain the paradoxical

phrasing, dissipative structures crucially depend on non-dissipative aspects.

VIII. CONCLUSION

The inﬂuence of non-dissipative and kinetic aspects cannot be ignored in the construction

of nonequilibrium statistical mechanics. The time-symmetric ﬂuctuation sector gets mod-

iﬁed by the driving and that excess plays a role in response and relaxation theory. What

is called dynamical activity or the frenetic contribution complements entropic/dissipative

arguments for the physical understanding of the nature of the stationary distribution, for

determining the direction of currents, for nonlinear response behavior and for the emergence

of so called dissipative structures.

Acknowledgment: I am grateful to the organizers of the Winter school on Complexity at

the TU Eindhoven for inviting me to give an introductory course on those less emphasized

aspects of nonequilibrium statistical mechanics. Special thanks to Mark Peletier for encour-

aging me to write it down. I am also very indebted to my collaborators of which the joint

papers appear below in the references.

[1] S. De Groot, and P. O. Mazur, Non-Equilibrium Thermodynamics, Dover Pub. (1962).

[2] C. Maes and W. O’Kelly de Galway, On the kinetics that moves Myosin V. Physica A: Sta-

tistical Mechanics and its Applications 436, 678–685 (2015).

[3] W. De Roeck and C. Maes, Symmetries of the ratchet current. Phys. Rev. E 76, 051117 (2007).

[4] P. Baerts, U. Basu, C. Maes and S. Safaverdi, The frenetic origin of negative diﬀerential

response, Phys. Rev. E 88, 052109 (2013).

[5] R.K.P. Zia, E. L. Præstgaard, and O.G. Mouritsen, Getting more from pushing less: Negative

speciﬁc heat and conductivity in nonequilibrium steady states. Am. J. Phys. 70, 384 (2002).

30

[6] U. Basu and C. Maes, Mobility transition in a dynamic environment. J. Phys. A: Math. Theor.

47, 255003 (2014).

[7] O. B´enichou, P. Illien, G. Oshanin, A. Sarracino, R. Voituriez, Microscopic theory for negative

diﬀerential mobility in crowded environments. Phys. Rev. Lett. 113, 268002 (2014).

[8] M. Baiesi, A. Stella, and C. Vanderzande, Role of trapping and crowding as sources of negative

diﬀerential mobility. Phys. Rev. E92, 042121 (2015).

[9] R. Jack, J.P. Garrahan, and D. Chandler, Space-time thermodynamics and subsystem ob-

servables in kinetically constrained models of glassy materials. J. Chem. Phys. 125, 184509

(2006).

[10] J. M. Hickey, S. Genway, J.P. Garrahan, Signatures of many-body localisation in a system

without disorder and the relation to a glass transition. arXiv:1405.5780v1.

[11] R. Kubo, K. Matsuo, K. Kitahara, Fluctuation and relaxation of macrovariables. J. Stat.

Phys. 9, 5–95 (1973).

[12] L. Bertini, A. De Sole, D. Gabrielli, G. Jona-Lasinio, and C. Landim, Macroscopic ﬂuctuation

theory. Rev. Mod. Phys. 87, 593 (2015).

[13] B. Derrida, J.L. Lebowitz, E.R. Speer, Large deviation of the density droﬁle in the steady

state of the symmetric simple exclusion process. J. Stat. Phys. 107, 599–634 (2002).

[14] A. Einstein, Theorie der Opaleszens von homogenen Fl¨ussigkeiten und Fl¨ussigkeitsgemischen

in der N¨ahe des kritischen Zustandes. Annalen der Physik 33, 1275 (1910).

[15] O. E. Lanford, Entropy and equilibrium states in classical statistical mechanics. Statistical

Mechanics and Mathematical Problems, Springer Lecture Notes 20, 1-113, 1973.

[16] A. Martin L¨of, Statistical Mechanics and the Foundations of Thermodynamics, Volume 101

Lecture Notes in Physics Series, Springer-Verlag, 1979.

[17] R. Ellis, Entropy, Large Deviations, and Statistical Mechanics, Springer, 2006.

[18] B. Derrida, M.R. Evans, V. Hakim, V. Pasquier, Exact solution of a 1d asymmetric exclusion

model using a matrix formulation. J.Phys. A26, 1493–1518 (1993).

[19] C. Maes, K. Netoˇcn´y and W. O’Kelly de Galway, Low temperature behavior of nonequilibrium

multilevel systems. J. Phys. A: Math. Theor. 47, 035002 (2014).

[20] U. Basu and C. Maes, Nonequilibrium Response and Frenesy. J. Phys.: Conf. Ser. 638, 012001

(2015).

[21] R. Landauer, Inadequacy of entropy and entropy derivatives in characterizing the steady state.

31

Phys. Rev. A. 12, 636–638 (1975).

[22] C. Maes and K. Netoˇcn´y, Heat bounds and the blowtorch theorem. Ann. H. Poincar´e 14,

1193–1202 (2013).

[23] J.J. Hopﬁeld, Kinetic Proofreading: A New Mechanism for Reducing Errors in Biosynthetic

Processes Requiring High Speciﬁcity. Proc. Nat. Acad. Sci. 71, 4135–4139 (1974).

[24] S. N. Weber, C. A. Weber and E. Frey, Binary Mixtures of Particles with Diﬀerent Diﬀusivities

Demix. Phys. Rev. Let. 116, 058301 (2016).

[25] A. Y. Grosberg, J.-F. Joanny, Nonequilibrium statistical mechanics of mixtures of particles in

contact with diﬀerent thermostats. Phys. Rev E92, 032118 (2015).

[26] A. P. Solon, Y. Fily, A. Baskaran, M. E. Cates, Y. Kafri, M. Kardar, and J. Tailleur, Pressure

is not a state function for generic active ﬂuids. Nature Physics 11, 673–678 (2015).

[27] C. Maes, On the origin and the use of ﬂuctuation relations for the entropy. In: J. Dalibard, B.

Duplantier, V. Rivasseau (Eds.), S´eminaire Poincar´e, vol. 2, Birkhuser, Basel, 2003, pp. 2962.

[28] M. Baiesi, C. Maes and B. Wynants, Fluctuations and response of nonequilibrium states.

Phys. Rev. Lett. 103, 010602 (2009).

[29] U. Basu, M. Kr¨uger, A. Lazarescu, and C. Maes, Frenetic aspects of second order response.

Phys. Chem. Chem. Phys. 17, 6653 (2015).

[30] E. Levine, D. Mukamel and G.M. Sch¨utz, Zero-Range Process with Open Boundaries. J. Stat.

Phys. 120, 759–778 (2005).

[31] U. Basu, C. Maes, K. Netoˇcn´y, How Statistical Forces Depend on the Thermodynamics and

Kinetics of Driven Media. Phys. Rev. Lett. 114, 250601 (2015).

[32] R.L. Jack and R.M.L. Evans, Absence of dissipation in trajectory ensembles biased by currents.

arXiv:1602.03815v1 [cond-mat.stat-mech].

[33] C. Maes and M.H. van Wieren, Time-symmetric ﬂuctuations in nonequilibrium systems. Phys.

Rev. Lett. 96, 240601 (2006).

[34] G. Sauermann, K. Kroy and H.J. Herrmann, Continuum saltation model for sand dunes. Phys.

Rev. E64, 031305 (2001).

