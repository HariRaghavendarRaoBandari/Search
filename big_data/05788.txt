6
1
0
2

 
r
a

 

M
8
1
 
 
]

.

R
G
h
t
a
m

[
 
 

1
v
8
8
7
5
0

.

3
0
6
1
:
v
i
X
r
a

THE COMPLEXITY OF THE EQUATION

SOLVABILITY PROBLEM OVER SEMIPATTERN

GROUPS

ATTILA FÖLDVÁRI

Abstract. The complexity of the equation solvability problem is
known for nilpotent groups, for not solvable groups and for some
semidirect products of Abelian groups. We provide a new polyno-
mial time algorithm for deciding the equation solvability problem
over certain semidirect products, where the ﬁrst factor is not nec-
essarily Abelian. Our main idea is to represent such groups as ma-
trix groups, and reduce the original problem to equation solvability
over the underlying ﬁeld. Further, we apply this new method to
give a much more eﬃcient algorithm for equation solvability over
nilpotent rings than previously existed.

1. Introduction

One of the oldest problems of algebra is the equation solvability prob-
lem over a given algebraic structure. Nowadays, many such classical
problems arise in a new perspective, namely to consider their compu-
tational complexity. In this paper we investigate the complexity of the
equation solvability problem over ﬁnite groups and rings.

The equation solvability problem over a ﬁnite group G asks whether
or not two group expressions (i.e. products of variables and elements
of G) can attain the same value for some substitution over G.
In
other words, for the equation solvability problem, one needs to ﬁnd if
there exists at least one substitution satisfying the equation. Another
interesting problem is whether or not all substitutions satisfy the equa-
tion. The equivalence problem over a ﬁnite group G asks whether or
not two group expressions f and g are equivalent over G (denoted by
G |= f ≈ g), that is whether or not f and g determine the same
function over G.

First Burris and Lawrence [2] investigated the complexity of the
equivalence problem over ﬁnite groups. They proved that if a group G

Date: 15 March, 2016.
2010 Mathematics Subject Classiﬁcation. 20F10, 20G40, 16N40, 68Q17.
Key words and phrases. semipattern groups, pattern groups, equivalence, equa-
tion solvability, computational complexity, polynomial time algorithm, nilpotent
rings, matrix rings.

This research was partially supported by the Hungarian National Foundation for

Scientiﬁc Research grant no. K109185.

1

2

A. FÖLDVÁRI

is nilpotent or G ≃ Dn, the dihedral group for odd n, then the equiva-
lence problem for G has polynomial time complexity. They conjectured
that the equivalence problem for G is in polynomial time if G is solv-
able, and coNP-complete otherwise. Horváth and Szabó [11] conﬁrmed
the conjecture for G ≃ A ⋊ B, where A and B are Abelian groups such
that the exponent of A is squarefree and (|A|, |B|) = 1. Later Horváth
[8] generalized this result to semidirect products A ⋊ B, where A and
B/CB(A) are Abelian groups (here CB(A) denotes the centralizer of
A in B). Horváth, Lawrence, Mérai and Szabó [10] proved the coNP-
complete part of the conjecture. But the complexity of the equivalence
problem over many solvable, not nilpotent groups is not determined,
yet. Three of the smallest groups, for which this complexity is not
known, are S4, SL (2, Z3) and a non-commutative group of order 54.
See [8] for a more comprehensive list.

Even less is known about the equation solvability problem. Gold-
mann and Russel [4, 5] proved that if G is nilpotent then the equation
solvability problem over G is solvable in polynomial time, while if G
is not solvable, then the equation solvability problem is NP-complete.
Little is known for solvable, not nilpotent groups. Horváth proved in
[8, Corollary 2] that the equation solvability problem over G is solv-
able in polynomial time for certain groups G ≃ A ⋊ B, where A ≃ Z
pk
or Z
p and B is commutative. Note that all results for both
the equivalence and the equation solvability problem over solvable, not
nilpotent groups are about groups A ⋊ B, where A is Abelian.

2pk or Zk

One of the groups of small order, for which the equation solvability
problem is unknown, is the group U (3, Z3) ⋊ Z×
3 . Here, U (3, Z3) de-
notes the noncommutative group of 3 × 3 upper unitriangular matrices
over Z3. Horváth explicitly asks in [8, Problem 4] the complexity of
the equivalence and equation solvability problems over this group. The
group U (3, Z3) ⋊ Z×
3 is isomorphic to a special subgroup of the 3 × 3
upper triangular matrices over Z3. Motivated by the deﬁnition of pat-
tern groups from [3, 13], we call a group A ⋊ B a semipattern group,
if A is a subgroup of the group of upper unitriangular matrices, and B
is a subgroup of the diagonal matrices. We give the precise deﬁnition
of semipattern groups in Section 2.1. The main result of the paper is
the following.

Theorem 1.1. The equation solvability problem over semipattern groups
is solvable in polynomial time.

The group U (3, Z3) ⋊ Z×

3 deﬁned in [8, Problem 4] is in fact a
semipattern group, thus Theorem 1.1 answers Horváth’s question com-
pletely. Further, from Theorem 1.1 the equivalence problem over semi-
Indeed, it is
pattern groups is solvable in polynomial time, as well.

EQUATION SOLVABILITY OVER SEMIPATTERN GROUPS

3

known that for a group G if the equation solvability problem is solv-
able in polynomial time, then the equivalence problem is solvable in
polynomial time, as well.

In the proof of Theorem 1.1 we reduce the solvability of the input
equation over a matrix group over a ﬁnite ﬁeld to the solvability of a
system of equations over the same ﬁeld. Then we apply some results
over ﬁnite rings. Therefore, we summarize the known results over rings.
The equation solvability problem over a ﬁnite ring R asks whether or
not two polynomials can attain the same value for some substitution
over R. The equivalence problem over a ﬁnite ring R asks whether or
not two polynomials are equivalent over R i.e. if they determine the
same function over R.

The complexity of these questions was completely characterized in
the past two decades. Hunt and Stearnes [12] investigated the equiva-
lence problem for ﬁnite commutative rings. Later Burris and Lawrence
[1] generalized their result to non-commutative rings. They proved that
the equivalence problem for R is solvable in polynomial time if R is
nilpotent, and is coNP-complete otherwise.

The proof of Burris and Lawrence reduces the satisﬁability (SAT)
problem to the equivalence problem by using long products of sums
of variables. Nevertheless, if we expand this polynomial into a sum of
monomials then the length of the new polynomial may become expo-
nential in the length of the original polynomial. Such a change in the
length suggests that the complexity of the equivalence problem might
be diﬀerent if the input polynomials are restricted to be written as sums
of monomials. This motivated Lawrence and Willard [15] to introduce
the sigma equivalence and sigma equation solvability problems, where
the input polynomials are given as sums of monomials. Lawrence and
Willard conjectured that if the factor by the Jacobson radical is com-
mutative then the sigma equivalence problem is solvable in polynomial
time, and is coNP-complete otherwise. Szabó and Vértesi proved the
coNP-complete part of the conjecture in [16]. Horváth conﬁrmed the
conjecture for commutative rings in [7]. The polynomial part of this
conjecture is completely proved in the manuscript [9].

Most of the results for the [sigma] equation solvability problem fol-
low from the corresponding result for the [sigma] equivalence problem.
In particular, from the argument of Szabó and Vértesi follows that if
the factor by the Jacobson radical is not commutative then the sigma
equation solvability problem is NP-complete. Horváth, Lawrence and
Willard [9] proved that if this factor is commutative then the sigma
equation solvability problem is solvable in polynomial time. Thus, the
sigma equation solvability problem is completely characterized.

4

A. FÖLDVÁRI

For the general equation solvability, arguments of Burris and Lawrence
from [1] yield that if the ring is not nilpotent then the problem is NP-
complete. Horváth in [6] proved that the equation solvability problem
is solvable in polynomial time otherwise.

Theorem 1.2 ([6, Theorem 1.2]). If R is a ﬁnite, nilpotent ring then
the equation solvability problem over R is solvable in polynomial time.

Horváth uses Ramsey’s theorem in the proof of Theorem 1.2. He
deﬁnes a number r that depends only on the ring R. Then he proves
that the image of every polynomial can be obtained by substituting
0 into all but r-many variables. Thus one can decide whether or not
f = 0 is solvable over R in O (||f ||r) time. However, this number r is
huge in the size of the ring. In fact, r is greater than |R||R|...|R|
, where
the height of the tower in the exponent is the nilpotency class of R.
Horváth speciﬁcally asks in [6, Problem 3] whether or not this number
r can be decreased.

In the second half of the paper we give a new proof of Theorem 1.2.
Our algorithm is much more eﬃcient than Horváth’s. Wilson [17] char-
acterizes nilpotent rings with the help of special kind of nilpotent ma-
trix rings. We can decide the equation solvability problem over these
special matrix rings similarly as we do over semipattern groups in The-
orem 1.1. In particular, we show that over a nilpotent ring R we can

decide in O(cid:16)||f |||R|2 log R log5 |R|(cid:17) time whether or not f = 0 is solvable,

thus providing a partial answer to Problem 3 in [6], as well. We mention
that in a completely independent way, Károlyi and Szabó also found a
way to decrease the exponent r in [14].

In Section 2 we summarize the notations, deﬁnitions and theorems,
that we use in the paper. In particular, in Section 2.1 we review the
deﬁnition of pattern groups, then we deﬁne semipattern groups.
In
Section 2.2 we discuss the generalization of the equation solvability
problem over rings for systems of equations. We are going to apply
these results in order to prove Theorems 1.1 and 1.2. In Section 2.3
we lay the groundwork for the proof of Theorem 1.2. In Section 3 we
prove Theorem 1.1. We use ideas of this proof in Section 4, where we
prove Theorem 1.2.

2. Preliminaries

2.1. Semipattern groups. Let Fq denote the ﬁnite ﬁeld of q elements.
Let us consider the group T (m, Fq) of m×m upper triangular matrices,
that is those matrices whose elements under the diagonal are zero and
the elements in the diagonal are non-zero:

EQUATION SOLVABILITY OVER SEMIPATTERN GROUPS

5

T (m, Fq) =

: si ∈ F×

q , ai,j ∈ Fq, 1 ≤ i < j ≤ m

.



s1 a1,2 a1,3
a2,3
0
s3
0
...
...
0
0

s2
0
...
0

. . . a1,m
. . . a2,m
. . . a3,m
...
. . .
sm
. . .






Here the group operation is the matrix multiplication.

Let the m × m identity matrix denoted by I. Let Ii,j denote the
m × m matrix whose elements are all zero except for the jth element
in the ith row, which is 1. Let P ⊆ {(i, j) : 1 ≤ i < j ≤ m}. Let

NP = {I + X(i,j)∈P

ai,jIi,j : ai,j ∈ Fq}.

Thus, NP contains all those upper triangular matrices, where every
element in the diagonal is 1, and every element whose position is not
occurring in P has to be 0.
If NP is a subgroup of T (m, Fq), then
we call NP a pattern group. For more details on pattern groups, see
e.g. [3, 13]. Let S1, S2, . . . , Sm be subgroups of F×
q and let D be the set
of m × m matrices over Fq whose ith element in the diagonal is from Si
(1 ≤ i ≤ m):

s1
0
0
...
0




0
s2
0
...
0

0
0
s3
...
0

. . .
. . .
. . .
. . .
. . .

0
0
0
...
sm





D =

: s1 ∈ S1, s2 ∈ S2, . . . , sm ∈ Sm

.

If NP is a pattern group then NP D is a subgroup of T (m, Fq).
Then we call NP D a semipattern group and we denote such a group by
SP(m, Fq). Further, we note that NP ✁NP D and NP D ∼= NP ⋊D. The
group U (3, Z3) ⋊ Z×
3 deﬁned in [8, Problem 4] is in fact a semipattern
group:

U (3, Z3) ⋊ Z×

3 =

1 a b
0 s c


0 0 1  : s ∈ Z×

3 , a, b, c ∈ Z3

.

2.2. Further notations. Let R be a commutative, unital ring, S1, . . .
. . . , Sm be subsets of R. For nonnegative integers n, l1, . . . lm, let X =
{ x1, . . . , xn }, Y1 = { y1,1, . . . , y1,l1 }, . . . , Ym = { ym,1, . . . , ym,lm } be
pairwise disjoint sets of variables. We say that f = g is solvable over R
for substitutions from R, S1, . . . , Sm (and write f |R,S1,...,Sm = g|R,S1,...,Sm
is solvable over R) if there exist a1, . . . an ∈ R, s1,1, . . . s1,l1 ∈ S1, . . . ,
sm,1, . . . , sm,lm ∈ Sm such that the two polynomials attain the same

6

A. FÖLDVÁRI

value on this substitution:

f (a1, . . . an, s1,1, . . . s1,l1, . . . , sm,1, . . . ,sm,lm) =

g(a1, . . .an, s1,1, . . . s1,l1, . . . , sm,1, . . . , sm,lm)

For proving Theorem 1.1, we will directly apply the following result of
Horváth [8].

Theorem 2.1 ([8, p. 221, case (d)]). Let Fq be a ﬁnite ﬁeld. Let
S1, . . . , Sm be subgroups of F×
be a polynomial, written as a sum of monomials. Then it can be decided
whether the system of equations

q . Let f1, . . . , fk ∈ Fq[x1, . . . xn, y1,1, . . . , ym,lm]

f1|Fq,S1,...,Sm = 0

...

fk|Fq,S1,...,Sm = 0

is solvable over Fq in O(cid:0)max1≤i≤k||fi||k·q(cid:1) time.

To prove Theorem 1.2 we are going to use the following from [9].

Theorem 2.2 ([9]). Let f1, . . . , fk ∈ Zpα[y1, . . . , yn] be polynomials,
written as sums of monomials. Then it can be decided whether the
system of equations

f1 = 0

...

fk = 0

is solvable over Zpα in O(cid:16)max1≤i≤k||fi||α2k·p2α2(cid:17) time.

2.3. Equation solvability problem over nilpotent rings. The com-
plexity of the equation solvability problem over ﬁnite nilpotent rings
is known. Horváth [6] proved that the equation solvability problem is
solvable in polynomial time. We give a new algorithm in Section 4
that is much more eﬃcient than Horváth’s. In this part we show that
we can characterize the complexity of the equation solvability problem
over nilpotent rings using the sigma equation solvability problem over
special kind of nilpotent matrix rings. Hence we can apply the same
ideas that we used in the proof of Theorem 1.1.

Horváth proved Theorem 1.2 using Ramsey’s theory. He deﬁned a
number r that depends only on the ring R. Then he proved that the
image of every polynomial can be obtained by substituting 0 into all
but r-many variables. Thus one can decide whether or not f = 0 is
solvable over R in O(||f ||r) time. But the number r is huge in the size

EQUATION SOLVABILITY OVER SEMIPATTERN GROUPS

7

of the ring. Let c be the characteristic of R and t be the nilpotency
class of R. Let furthermore m = (t − 1)! · c. Then r is greater than
mm...m
, where the height of the tower in the exponent is t. We give a
new proof of Theorem 1.2 in Section 4. Our algorithm is much more

eﬃcient than Horváth’s. We prove that O(cid:16)||f |||R|2 log |R| log5 |R|(cid:17) time is

enough.

First, we show that we can handle the equation solvability problem
over nilpotent rings using the sigma equation solvability problem over
special kind of nilpotent matrix rings.
If R is a nilpotent ring then
the complexity of the general equation solvability problem over R is
the same as the complexity of the sigma equation solvability over R.
Indeed, we can rewrite every polynomial f over R as a sum of mono-
mials in O (||f ||t) time, where t is the nilpotency class of R. Now,
t = O (log |R|). Hence, at the cost of an extra log |R| factor in the ex-
ponent, we may assume that every input polynomial is given as a sum
of monomials. Furthermore it is enough to consider the equation solv-
ability problem over nilpotent rings with prime power characteristic,
because every ring is a direct sum of rings of prime power characteristic,
and the equation solvability problem can be handled componentwise.
Wilson [17] characterizes ﬁnite nilpotent rings with prime power char-
acteristic.

Theorem 2.3 (Wilson). Let R be a ﬁnite nilpotent ring with charac-
teristic pα, and let R have an independent generating set consisting of
m generators over Zpα. Then R is a homomorphic image of a ring
M(m, Zpα) of matrices over Zpα where every entry on or below the
main diagonal is a multiple of p.

In fact for nilpotent rings it is enough to consider the equation solv-
ability problem over such a matrix ring M, since if the equation solv-
ability problem is solvable in polynomial time for M, then it is solvable

nomial over M/I and f be any polynomial over M whose factor by I

in polynomial time for a factor M/I, as well. Indeed, let ef be a poly-
is ef . Then ef = 0 is solvable over M/I if and only if f = a is solvable
m = O (log |R|). Thus, |I| = O(cid:16)|R|log2|R|(cid:17), which only depends on

over M for some a ∈ I. This gives an extra |I| factor to the run-
ning time. However, |I| ≤ |M| ≤ (pα)m2
, and we have pα = O (|R|),

R, and thus can be forgotten about.

Thus it is enough to consider the sigma equation solvability problem
over such a matrix ring of matrices over Zpα where every entry on or
below the main diagonal of each matrix is a multiple of p. We can
handle such matrix rings similarly as we do with the semmipattern
groups. Hence we can use ideas of the proof described in Section 3.
We give a new, eﬃcient algorithm that decides the equation solvability
problem over nilpotent matrix rings in Section 4.

8

A. FÖLDVÁRI

3. Equation solvability problem over semipattern groups

In this section we consider the equation solvability problem over sem-
mipattern groups. First we characterize the multiplication of matrices
from T (m, Fq) in Lemma 3.1. We use this formula in our algorithm.

Lemma 3.1. Let n be a natural number. For every 1 ≤ k ≤ n let

Ak =

∈ T (m, Fq) .

s1,k a1,2,k a1,3,k
0
a2,3,k
s3,k
0
...
...
0
0

s2,k
0
...
0

. . . a1,m,k
. . . a2,m,k
. . . a3,m,k
. . .
. . .

...
sm,k





Let

Then

A1A2 . . . An =

σ1 α1,2 α1,3
σ2 α2,3
0
0
0
σ3
...
...
...
0
0
0



. . . α1,m
. . . α2,m
. . . α3,m
...
. . .
σm
. . .

.



• for every i = 1, 2, . . . , n we have

σi =

si,k;

nYk=1

• for every 1 ≤ i < j ≤ m we have

αi,j =

(1)

· · ·

k2−1Xk1=1 k1−1Yc0=1

j−i−1Xb=0 Xi<l1<···<lb<j
  k2−1Yc1=k1+1
. . . alb−1,lb,kb  kb+1−1Ycb=kb+1

si,c0! ai,l1,k1
kb+1−1Xkb=b
k3−1Xk2=2
nXkb+1=b+1
sl3,c3!
sl2,c2! al2,l3,k3  k4−1Yc3=k3+1
sl1,c1! al1,l2,k2  k3−1Yc2=k2+1
sj,cb+1 .
slb,cb! alb,j,kb+1

nYcb+1=kb+1+1

The length of (1) is O (nm), and in particular is polynomial in n.

Proof. The lemma can be proved by induction on n. However, instead
of giving the technical induction proof, we explain how one can arrive
at this formula.

Let us consider the jth element of the ith row αi,j of the matrix
A1A2 . . . An (1 ≤ i < j ≤ m) . We can express this element αi,j with a
sum of some appropriate products. In every such product we multiply
one element from each matrix Ak (1 ≤ k ≤ n). (In the notation the
index k appears as the last index.) Furthermore the index of the column

EQUATION SOLVABILITY OVER SEMIPATTERN GROUPS

9

of a term must equal with the index of the row of the following term
in every such product. (Therefore a term of the form slc,. or alc,lc+1,.
follows the term of the form slc,. or alc−1,lc,..) The row index of the
ﬁrst term is i, the column index of the last term is j. The matrices
A1, A2, . . . , An are upper triangular matrices, hence the row index of
every term of every product is less than or equal to the column index.
(Thus for every term of the form alc,lc+1,., that are above the diagonal,
we have lc < lc+1.) Thus the jth element of the ith row αi,j of the matrix
A1A2 . . . An is a sum of products of n terms such that

• the row index of the ﬁrst term is i, the column index of the last

term is j;

• the column index of every term equals to the row index of the

next term;

• the row index of a term is at most the row index of the next

term.

Notice, that every n-term product is uniquely determined by those
terms where the row index diﬀers from the column index. Let two such
consecutive terms of the product be alc−1,lc,kc and alc,lc+1,kc+1.
(Here
i ≤ lc−1 < lc < lc+1 ≤ j and 1 ≤ kc < kc+1 ≤ n.) The product of the
terms between these two terms have row and column index lc and their
last index is more than kc and less than kc+1. Thus between the terms
alc−1,lc,kc and alc,lc+1,kc+1 can only be the product slc,kc+1 · slc,kc+2 · . . . ·
slc,kc+1−1. Thus formula (1) is proved.

Now, we calculate the length of formula (1). Formula (1) is a sum
of products. The length of every product is n, thus we need to calcu-
late the number of products. Notice, that every product is uniquely
determined by the column indices of the terms. More exactly we need
to know the column indices of the ﬁrst n − 1 terms, because the col-
umn index of the last term is j. We can choose these indices from the
set {i, i + 1, . . . , j − 1, j}. The order of the selected elements does not
matter. We only need to determine how many indices are equal to i
or to i + 1, etc, or to j. Thus we need to choose n − 1 element from a
set of j − i + 1 elements such that repetitions are allowed. Hence the
number of products is

j − i

Thus the length of αi,j is at most O (nm) for every index 1 ≤ i < j ≤
m.
(cid:3)

Let SP(m, Fq) be a semipattern group. Let F = T1T2 . . . Tn be
a polynomial over SP(m, Fq). Thus Tk can indicate a constant or a

Since every product has length n, the length of αi,j is

n − 1

(cid:18)n − 1 + j − i + 1 − 1
(cid:18)n + j − i − 1

(cid:19).
(cid:19) =(cid:18)n + j − i − 1
(cid:19) · n = O(cid:0)nj−i+1(cid:1) = O (nm) .

j − i

10

A. FÖLDVÁRI

variable over SP(m, Fq) (1 ≤ k ≤ n). Of course Tk and Tl can indicate
the same constant or variable. Let

Tk =



y1,k x1,2,k x1,3,k
0
x2,3,k
y3,k
0
...
...
0
0

y2,k
0
...
0

. . . x1,m,k
. . . x2,m,k
. . . x3,m,k
. . .
. . .

...
ym,k

.



If Tk ∈ SP(m, Fq) indicates constant then yi,k is a constant in Si ≤
F×
q and xi,j,k is a constant in Fq (1 ≤ i < j ≤ m). If Tk ∈ SP(m, Fq) is
a variable, then yi,k is a variable, that we can substitute from Si, and
xi,j,k is a variable that we can substitute from Fq. Furthermore Tk = Tl
if and only if yi,k = yi,l (for every 1 ≤ i ≤ k) and xi,j,k = xi,j,l for every
1 ≤ i < j ≤ m.

We can rewrite the polynomial F with this notation as

y1,2 x1,2,2 x1,3,2
x2,3,2
0
y3,2
0
...
...
0
0

y2,2
0
...
0

. . . x1,m,2
. . . x2,m,2
. . . x3,m,2
. . .
. . .

...
ym,2



. . .

F =

. . .




y1,1 x1,2,1 x1,3,1
x2,3,1
0
y3,1
0
...
...
0
0

y2,1
0
...
0

. . . x1,m,1
. . . x2,m,1
. . . x3,m,1
. . .
. . .

...
ym,1

y1,n x1,2,n x1,3,n
x2,3,n
0
y3,n
0
...
...
0
0

y2,n
0
...
0

. . . x1,m,n
. . . x2,m,n
. . . x3,m,n
. . .
. . .

...
ym,n





.

After multiplying these matrices using Lemma 3.1 we obtain

f1 g1,2 g1,3
g2,3
0
f3
0
...
...
0
0

f2
0
...
0



F =

where

fi =

gi,j =

yi,k, and

nYk=1
j−i−1Xb=0 Xi<l1<···<lb<j
  k2−1Yc1=k1+1

nXkb+1=b+1

kb+1−1Xkb=b
yl1,c1! xl1,l2,k2 . . .  kb+1−1Ycb=kb+1

· · ·

,

. . .
. . .
. . .
. . .
. . .

g1,m
g2,m
g3,m
...
fm


k2−1Xk1=1 k1−1Yc0=1
k3−1Xk2=2
ylb,cb! xlb,j,kb+1

yi,c0! xi,l1,k1
nYcb+1=kb+1+1

yj,cb+1 .

EQUATION SOLVABILITY OVER SEMIPATTERN GROUPS

11

The polynomial F can attain the unit matrix for a substitution if
and only if fi attains 1 (1 ≤ i ≤ m) and gi,j attains 0 for the same
substitution (1 ≤ i < j ≤ m). Thus F = I is solvable over SP(m, Fq)
if and only if the system of equations

fi|Fq,S1,...,Sm = 1
gi,j|Fq,S1,...,Sm = 0

(1 ≤ i ≤ j)

(1 ≤ i < j ≤ m)

is solvable over Fq. This is a system of equations over Fq where the
polynomials are given as sums of monomials. Hence we can decide
the solvability of this system of equations in polynomial time by The-
orem 2.1.

The rewriting of F over SP(m, Fq) into the system of equations

fi|Fq,S1,...,Sm = 1
gi,j|Fq,S1,...,Sm = 0

(1 ≤ i ≤ j)

(1 ≤ i < j ≤ m)

over Fq can be done in O (nm) time by Lemma 3.1, and the length
of each equation is O (nm). The number of equations is m·(m+1)
=
O (m2), which does not depend on n, only on the group SP(m, Fq).
By Theorem 2.1 one can decide whether this system has a solution in

2

O(cid:16)nm3·q(cid:17) time.

4. The complexity of equation solvability problem over

nilpotent matrix rings

Let M be a ring of m × m matrices over Zpα where every entry on
or below the main diagonal of each matrix in M is a multiple of p. Let
F be a polynomial over M given as a sum of monomials. Let T1 . . . Tn
denote a monomial in the sum. Let

Tk =

a1,1,k · p
a2,1,k · p
a3,1,k · p

...

s1,2,k

a2,2,k · p
a3,2,k · p

...

s1,3,k
s2,3,k

. . .
. . .
a3,3,k · p . . .
. . .

...

s1,m,k
s2,m,k
s3,m,k

...

am,1,k · p am,2,k · p am,3,k · p . . . am,m,k · p



.



If Tk ∈ M indicates constant then ai,j,k, si,j,k are constants in Zpα.
If Tk ∈ M is a variable, then ai,j,k, si,j,k are variables, that we can
substitute from Zpα. Furthermore, Tk = Tl if and only if ai,j,k·p = ai,j,l·p
and si,j,k = si,j,l for every i, j ∈ {1, . . . , m}.

12

A. FÖLDVÁRI

We can rewrite the monomial T1 . . . Tn with this notation as

T1 . . . Tn =

a1,1,1 · p
a2,1,1 · p
a3,1,1 · p

s1,2,1

a2,2,1 · p
a3,2,1 · p

...

s1,3,1
s2,3,1

. . .
. . .
a3,3,1 · p . . .
. . .

...

s1,m,1
s2,m,1
s3,m,1

...

am,1,1 · p am,2,1 · p am,3,1 · p . . . am,m,1 · p
a1,1,n · p
s1,m,n
s2,m,n
a2,1,n · p
a3,1,n · p
s3,m,n

a2,2,n · p
a3,2,n · p

s1,3,n
s2,3,n

s1,2,n

. . .
. . .
a3,3,n · p . . .
. . .

...

...

...

am,1,n · p am,2,n · p am,3,n · p . . . am,m,n · p

. . .




...

...

. . .




.

.



{z

After multiplying these matrices we obtain

T1 . . . Tn =

g1,2
g2,2
g3,2
...

g1,1
g1,3
g2,1
g2,3
g3,1
g3,3
...
...
gm,1 gm,2 gm,3

. . .
. . .
. . .
. . .
. . .

g1,m
g2,m
g3,m
...
gm,m



We could compute the expressions for every gi,j, similarly as in Lem-
ma 3.1. However, we do not need to know the actual formulas, we only
need to understand how they look like.

First gi,j is a polynomial given as a sum of monomials over Zpα.
In every such monomial we multiply one term from each matrix Tk
(1 ≤ k ≤ n). Hence the length of every monomial is n. There are at
most mn−1 monomials in every polynomial gi,j according to the usual
multiplication of matrices. However, every nonzero monomial contains
at most α − 1 terms from on or below the main diagonal, since the
characteristic of Zpα is pα. Therefore every nonzero monomial is of the
form

si,i1,1 · sii,i2,2 . . . sik1−1,ik1

,k1

·aik1

,l1,k1+1 · p · sl1,¯i1,k1+2 · s¯i1,¯i2,. . . . s¯ik2−1,¯ik2

|

{z

k1- many terms

k2- many terms

· a¯ik2

,l2,. · p . . . aˆikb−1

,lb−1,. · p · slb−1,˜i1,. . . . s˜ikb−1,˜ikb

,n

,.

}

}

|

|

{z

kb- many terms

}

where 1 ≤ b ≤ α and 0 ≤ k1, k2, . . . kb. Notice that k1, k2, . . . kb ≤
m − 1 holds as well. Indeed, every term si,j,k is from above the main
diagonal, hence i < j. Therefore 1 < i1 < i2 < · · · < ik1 ≤ m and
thus k1 ≤ m − 1. Similarly k2, . . . , kb ≤ m − 1. Hence the length of
every nonzero monomial is at most (m − 1) · α + α − 1 = mα − 1.
In particular, if mα − 1 < n then every monomial in gi,j equals 0.
Therefore there are at most mmα−2 monomials in every polynomial gi,j
and thus ||gi,j|| ≤ (mα − 1) · mmα−2 ≤ α · mmα−1.

F =

f1,2
f2,2
f3,2
...

f1,1
f1,3
f2,1
f2,3
f3,1
f3,3
...
...
fm,1 fm,2 fm,3

. . .
. . .
. . .
. . .
. . .

f1,m
f2,m
f3,m
...
fm,m

.



Then fi,j is the sum of at most ||F ||-many polynomials gi,j for every
i, j ∈ {1, . . . m}. Thus ||fi,j|| ≤ ||F || · αmmα−1 = O (||F ||), as α and m
depend only on the ring R.

The polynomial F can attain the zero matrix for a substitution if
and only if fi,j attains zero for the same substitution for every i, j ∈
{1, . . . , m}. Thus F = 0 is solvable over M if and only if the system
of equations

fi,j = 0

i, j ∈ {1, . . . , m}

is solvable over Zpα. This is a system of equations over Zpα where
the polynomials are given as sums of monomials. Hence we can de-
cide the solvability of this system of equations in polynomial time by
Theorem 2.2.

The rewriting of F over M into the system of equations

fi,j = 0

i, j ∈ {1, . . . , m}

can be done in O (||F ||) time, and ||fi,j|| = O (||F ||). The number of
equations is m2, which does not depend on ||F ||, only on the ring M.
By Theorem 2.2 one can decide whether this system has a solution in

EQUATION SOLVABILITY OVER SEMIPATTERN GROUPS

13

The input polynomial F is a sum of at most ||F || monomials T1 . . . Tn.

Let

O(cid:16)||F ||α2·m2·p2α2(cid:17) time.

Finally, we explain how this result can be applied to determine if
an equation f = 0 is solvable over an arbitrary nilpotent ring R of
characteristic pα. Let M be the matrix ring as in Theorem 2.3, and let
R ∼= M/I. Further, let F denote the polynomial in M correspond-
ing to f . Notice, that pα was the characteristic of R in Theorem 2.3,
hence α = O (log |R|). Furthermore m = O (log |R|) and pα = O (|R|).

time. Thus, one can decide if the equation f = 0 is solvable over
=

Therefore α2 · m2 · p2α2 = O(cid:0)|R|2 log R log4 |R|(cid:1). Hence, one can de-
cide if F = 0 is solvable over R ∼= M/I in O(cid:16)||F |||R|2 log R log4 |R|(cid:17)
R in O(cid:16)|I| · ||F |||R|2 log R log4 |R|(cid:17) time. Now, |I| ≤ |M| ≤ (pα)m2
O(cid:16)|R|log2|R|(cid:17), which only depends on R. Therefore, if f is given as a
an arbitrary nilpotent ring R in O(cid:16)||f |||R|2 log R log4 |R|(cid:17) time, as well.
as a sum of monomials we have ||F || = O(cid:16)||f ||log|R|(cid:17), giving an extra

sum of monomials, then ||F || = O (||f ||), and one can decide f = 0 over

If, however, f is an arbitrary polynomial over R, then after rewriting it

14

A. FÖLDVÁRI

log |R| factor in the exponent. Thus, one can decide f = 0 over an

arbitrary nilpotent ring R in O(cid:16)||f |||R|2 log R log5 |R|(cid:17) time.

EQUATION SOLVABILITY OVER SEMIPATTERN GROUPS

15

References

[1] Stanley Burris and John Lawerence. The equivalence problem for ﬁnite rings.

Journal of Symbolic Computation, 15:67–71, 1993.

[2] Stanley Burris and John Lawrence. Results on the equivalence problem for

ﬁnite groups. Algebra Universalis, 52(4):495–500, 2005.

[3] Persi Diaconis and I.M. Isaacs. Counting characters of upper triangular groups.

Trans. Amer. Math. Soc., 360:2359–2392, 2008.

[4] Mikael Goldmann and Alexander Russell. The complexity of solving equations
over ﬁnite groups. In Proceedings of the 14th Annual IEEE Conference on
Computational Complexity, pages 80–86, Atlanta, Georgia, 1999.

[5] Mikael Goldmann and Alexander Russell. The complexity of solving equations

over ﬁnite groups. Information and Computation, 178:253–262, 2002.

[6] Gábor Horváth. The complexity of the equivalence end equation solvability
problems over nilpotent rings and groups. Algebra Universalis, 66(4):391–403,
2011.

[7] Gábor Horváth. The complexity of the equivalence problem over ﬁnite rings.

Glasgow Mathematical Journal, 54(1):193–199, 2012.

[8] Gábor Horváth. The complexity of the equivalence end equation solvability

problems over meta-abelian groups. Journal of Algebra, 433:208–230, 2015.

[9] Gábor Horváth, John Lawerence, and Ross Willard. The equation solvability

problem over ﬁnite rings. 2016. manuscript.

[10] Gábor Horváth, John Lawrence, László Mérai, and Csaba Szabó. The complex-
ity of the equivalence problem for non-solvable groups. Bulletin of the London
Mathematical Society, 39(3):433–438, 2007.

[11] Gábor Horváth and Csaba Szabó. The complexity of checking identities over
ﬁnite groups. International Journal of Algebra Computation, 16(5):931–940,
2006.

[12] H. Hunt and R. Stearns. The complexity for equivalence for commutative rings.

Journal of Symbolic Computation, 10:411–436, 1990.

[13] I.M. Isaacs. Counting characters of upper triangular groups. Journal of Alge-

bra, 315(2):698–719, 2007.

[14] Gyula Károlyi and Csaba Szabó. The complexity of the equation solvablity

problem over nilpotent rings. 2016. submitted.

[15] John Lawrence and R. Willard. The complexity of solving polynomial equations

over ﬁnite rings. 1997. manuscript.

[16] Csaba Szabó and V. Vértesi. The equivalence problem over ﬁnite rings. Inter-

nat. J. Algebra Comput., 21(3):449–457, 2011.

[17] Robert S. Wilson. On the stucture of ﬁnite rings. Compositio Mathematica,

26(1):79–93, 1973.

University of Debrecen, Institute of Mathematics, Pf. 400, Debre-

cen, 4002, Hungary

E-mail address: foldvari.attila@science.unideb.hu

