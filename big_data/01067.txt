Modeling the Sequence of Brain Volumes by Local

Mesh Models for Brain Decoding

Itir Onal, Member, IEEE, Mete Ozay, Member, IEEE, Eda Mizrak, Ilke Oztekin,

and Fatos T. Yarman Vural, Senior Member, IEEE,

1

(MVPA). Following the pioneering study of Haxby et al. [2],
machine learning techniques have been used for MVPA for
diagnosing disorders [3], [4], hypothesis validation [5] and
classifying cognitive states which is a method for predicting
cognitive states called brain decoding. In the context of ma-
chine learning, encoding the brain activities is formalized by
training a classiﬁer using a training set of fMRI measurements,
whereas a cognitive state is decoded by assigning a label to a
test fMRI measurement recorded during one of the prescribed
cognitive stimuli.

6
1
0
2

 
r
a

M
3

 

 
 
]

G
L
.
s
c
[
 
 

1
v
7
6
0
1
0

.

3
0
6
1
:
v
i
X
r
a

Abstract—We represent the sequence of fMRI (Functional
Magnetic Resonance Imaging) brain volumes recorded during a
cognitive stimulus by a graph which consists of a set of local
meshes. The corresponding cognitive process, encoded in the
brain, is then represented by these meshes each of which is
estimated assuming a linear relationship among the voxel time
series in a predeﬁned locality.

First, we deﬁne the concept of locality in two neighborhood
systems, namely, the spatial and functional neighborhoods. Then,
we construct spatially and functionally local meshes around each
voxel, called seed voxel, by connecting it either to its spatial
or functional p-nearest neighbors. The mesh formed around a
voxel is a directed sub-graph with a star topology, where the
direction of the edges is taken towards the seed voxel at the
center of the mesh. We represent the time series recorded at
each seed voxel
in terms of linear combination of the time
series of its p-nearest neighbors in the mesh. The relationships
between a seed voxel and its neighbors are represented by the
edge weights of each mesh, and are estimated by solving a
linear regression equation. The estimated mesh edge weights
lead to a better representation of information in the brain for
encoding and decoding of the cognitive tasks. We test our model
on a visual object recognition and emotional memory retrieval
experiments using Support Vector Machines that are trained
using the mesh edge weights as features. In the experimental
analysis, we observe that the edge weights of the spatial and
functional meshes perform better than the state-of-the-art brain
decoding models.

Keywords—fMRI; voxel connectivity; brain decoding; object

recognition; classiﬁcation

I. INTRODUCTION

Functional Magnetic Resonance Imaging (fMRI) is used
as the primary modality to capture neural activations in the
brain due to its high spatial resolution and reasonable temporal
resolution [1]. It measures the Blood Oxygenation Level
Dependent (BOLD) responses to a stimulus for about 10-12
seconds in an event-related design experiment. This approach
generates a brain volume for approximately each time instance.
The smallest unit of this volume, called voxel, consists of
the time series of intensity values which approximate the
hemodynamic response (HDR).

The techniques employed to learn the brain activity patterns
from the BOLD signals are called Multi Voxel Pattern Analysis

I. Onal and F. T. Yarman Vural are with the Department of Computer
Engineering, Middle East Technical University, Ankara, Turkey. e-mails:
{itir,vural}@ceng.metu.edu.tr

M. Ozay is with Graduate School of Information Sciences,Tohoku Univer-

sity,Sendai, Miyagi, Japan. e-mail: ozay.mete.b4@tohoku.ac.jp
sity, Istanbul, Turkey. e-mails: {emizrak, ioztekin}@ku.edu.tr

E. Mizrak and I. Oztekin are with Department of Psychology, Koc Univer-

In state-of-the-art MVPA approaches, cognitive states are
usually represented by concatenating the selected voxel in-
tensity values to construct a vector in a feature space. The
time series recorded for each voxel can be represented by
various methods, such as computing maximal or mean values.
Also, some of the inactive voxels can be eliminated by Princi-
pal Component Analysis, Independent Component Analysis,
Searchlight and GLM analysis to reduce the dimension of
the feature space. Then, a classiﬁer such as Support Vector
Machine (SVM), k-Nearest Neighbor (k-NN) or Naive Bayes
is employed using the feature vectors.

While some of the state-of-the-art methods [6], [7], [8],
[9], [10] are designed to extract only spatial patterns from
the BOLD responses, the others [11], [12] focus on modeling
temporal
information to form features for brain decoding.
A popular method for extracting a spatial feature for brain
decoding from fMRI data is computing the average BOLD
response for each voxel to represent a stimulus [6], [7], [8].
A recent work, suggested by [9], [10], considers each brain
volume as a sample. On the other hand, Mitchell et al. [11]
and Ng et al. [12] concatenate the BOLD responses within
the same trial to extract features that include spatio-temporal
information.

In order to extract the temporal information from the fMRI
data, various studies [13], [14], [15], [16], [17] compute
the pairwise correlations between the responses of voxels or
brain regions. Among these studies, Pantazatos et al. [13]
model temporal relationships by using pairwise correlations
between brain regions as features for brain decoding. More-
over, Richiardi et al. [14] model a functional connectivity
graph using the pairwise correlations between brain regions,
and they decode the brain states using graph matching al-
gorithms. Also, edge weights of their proposed brain graphs
are generally selected using the correlation between pairs of
selected voxels, and vertices or edge weights of these brain
graphs are used as features for cognitive state classiﬁcation
[18]. Contrary to the coarse-level functional connectivity, Firat

et al. [15] use pairwise correlations of voxels as features
while Baldassano et al. [16] extract the functional connectivity
structures by modeling pairwise connectivity among voxels.
Also, a minimum spanning tree of a graph structure deﬁned
using a functional connectivity matrix is employed using all
voxels for each stimulus for brain decoding [17]. Note that,
the aforementioned temporal methods are designed to model
only the pairwise relationships between voxels and employ
these relationships for brain decoding. Although these methods
represent the spatio-temporal information to a certain degree,
none of them propose a model to formalize the relationships
among the brain volumes, recorded along the time course of
a cognitive stimulus. In other words, spatial models mostly
lack the temporal information while the temporal ones lose
the spatial relationships among the voxel BOLD responses.

The major motivation of this study follows the observations
of the functional and spatial similarities of voxel BOLD
responses in a pre-deﬁned locality. As an example, Bazargani
et al. [19] state that neighboring voxels belonging to a homoge-
neous ROI have Hemodynamic Response Function (HRF) with
the same shape, possibly with slightly varying amplitude. In
other words, spatially close voxels tend to give similar BOLD
responses to the same stimuli. Moreover, Kriegeskorte et al.
[20] report that a univariate model of activations fails to beneﬁt
from local spatial combination of signals, and performs worse
than Searchlight methods for detection of informative regions.
They observe that spatially remote voxels may also exhibit
functionally similar time series.

Furthermore, Ozay et al. [21] observe that the voxel time
series do not differ signiﬁcantly to discriminate the different
cognitive states, but there exist slight variations among the
voxel intensity values of voxels located in a spatial neighbor-
hood. They propose a set of Local Meshes (LMM) to model
the relationship among the spatially close voxels. They show
that the LMM features perform better than the voxel intensity
values for the classiﬁcation of cognitive states. However, in
[21], only the brain volume which is obtained 6 seconds
after the stimulus presentation is used for the construction of
a model while the remaining ones are discarded under the
canonical HRF assumption.

Finally, Firat et al. [22] propose a Functional Mesh Model
(FMM) which is used to construct a set of local meshes
by selecting the nearest neighbors of voxels deﬁned within
a functional neighborhood. Their experimental results show
that their features are more discriminative than the features
obtained within a spatial neighborhood. Yet, they also estimate
the mesh weights using only a single intensity value for each
voxel.

In none of the above mentioned models, the time series
recorded at all the voxels are fully employed to represent the
spatial relationships among the voxels of the fMRI data. The
available approaches either use the active voxels, the most
crucial time instances or both. Although these approaches
smooth the noise in voxel time series, and represent the huge
amount of data in a more compact way, it may result in
losing important information embedded in time series of brain
volumes, recorded under a stimulus.

The massively interconnected and dynamic nature of human

2

brain cannot be represented by considering only a collection of
selected voxels and/or time instances which are obtained from
fMRI data. In addition, the above mentioned studies indicate
that the relationship among the voxels is more informative than
the information provided by the individual voxels. Therefore,
it is desirable to develop a model which represents the rela-
tionship among the brain volumes, recorded during a stimulus.
Furthermore, if this model incorporates the local similarities
among the voxel time series, then it is possible to represent
the sequence of brain volumes, recorded during a cognitive
stimulus, by a graph which consists of a set of subgraphs each
of which is represented by a local linear regression model.

In this study, we employ the voxel time series measured dur-
ing a cognitive task to create a local mesh around each voxel
which models the relationship among the BOLD responses.
The concept of locality is deﬁned over a neighborhood system.
In this study, we introduce two types of neighborhoods,
namely, spatial and functional neighborhoods. The local mesh
around each voxel is constructed by using either a spatial
[23] or functional neighborhood system to generate a set of
spatially or functionally local meshes. We form a local mesh
around each voxel by connecting the voxel to its p-nearest
neighbors under a star topology. In each mesh, BOLD response
of a voxel is represented by a weighted linear combination
of BOLD responses of its spatially or functionally nearest
neighbors. The weights are estimated by solving a linear
regression equation, and are assigned to the edges of the mesh.
The mesh edge weights estimated for each voxel enable us to
represent the fMRI brain volumes recorded during a stimulus
by a directed graph which consists of an ensemble of local
meshes.

The proposed local mesh models are different from the
connectivity models deﬁned over pairwise similarities between
voxels and/or regions in the sense that the connectivity is
deﬁned over a local neighborhood of voxels. We employ the
estimated weights of mesh edges as features to train and
test the state-of-the-art Support Vector Machines (SVM) for
encoding and decoding a set of cognitive processes measured
by fMRI signals.

Our approach is employed for modeling the sequence of
fMRI brain volumes, recorded during an event-related design
experiment. We assume that the voxel time series approximate
the hemodynamic response for each stimulus. Unfortunately,
block design lacks this information due to the overlaps be-
tween consecutive hemodynamic responses. Therefore, we test
our approach in two event-related design experiments namely
visual object recognition and emotional memory retrieval
experiments. We observe that the classiﬁers which employ the
proposed local mesh ensembles outperform the state of the art
MVPA models.

In Fig. 1, the steps of the proposed method are summarized.
First, we preprocess the fMRI measurements and obtain voxel
intensity values. Then, we select voxels or ROI to eliminate the
redundant voxels and to reduce the noise in our dataset. After
that, we deﬁne spatial and functional neighborhood systems,
and construct meshes, accordingly. Finally, we estimate edge
weights of meshes, and employ them as features for cognitive
state classiﬁcation.

3

III. PRE-PROCESSING OF ANALYSIS OF NEUROIMAGING

DATA

SPM8 was used for pre-processing and data analysis1.
Preprocessing of images consisted of (a) correction of slice
acquisition timing across slices, (b) realigning the images
to the ﬁrst volume in each fMRI run to correct for head
movement, (c) normalization of functional and anatomical
images to a standard template EPI provided by SPM2, and
(d) smoothing images with a 6-mm full-width half-maximum
isotropic Gaussian kernel. Finally, we extract 116 Automated
Anatomical Labeling (AAL) regions [25] using Marsbar [26].
For the visual object recognition experiment, active voxels
were identiﬁed using the General Linear Model implemented
in SPM and occipital lobe was selected as our region of interest
(ROI). The task engaged visual cortex activity, where pattern
analyses were employed. For the emotional memory retrieval
experiment we selected ﬁrst 3000 most discriminative voxels
from the whole brain analysis, using ReliefF [27].

In the visual object recognition experiment, 36 measure-
ments are recorded in each of the 6 runs, and there are
216 samples. We design our datasets by taking the ﬁrst 12
samples per each class from each run for training, and the
last 6 samples per each class from each run for validation
and testing. On the other hand, for the emotional memory
retrieval experiment, 35 measurements are recorded within
each run. Measurements recorded during the encoding phase
are employed as training data and the ones obtained during
retrieval phase are used as validation and test data.

IV. SPATIAL AND FUNCTIONAL LOCAL MESHES

The local mesh model proposed in this study is constructed
using a collection of voxels located within a neighborhood of
each voxel. For this purpose, ﬁrst we make a formal deﬁnition
of locality. This task is achieved by deﬁning spatial and
functional neighborhood systems. Then, we deﬁne two types
of local meshes, namely, spatial and functional meshes.

In the following sub-sections, we provide the formal deﬁ-

nition of neighborhood systems and local meshes.

A. Neighborhood Systems

One of the most important tasks of this study is to construct
a linear relationship among the BOLD responses of voxels
by employing “locality” properties of the voxels. In order
to achieve this goal, we deﬁne two types of neighborhood
systems, namely, spatial and functional neighborhoods.
Deﬁnition 1: Spatial Neighborhood: Let V = {vj} be
a set of nodes each of which corresponds to a voxel located
at a coordinate ¯lj. Spatially nearest neighbor of a voxel vj
is deﬁned as the voxel vk which has the smallest Euclidean
distance to the seed voxel vj, as given below:

ηspat
1

[vj] = {vk : (cid:107) ¯lj − ¯lk(cid:107) ≤ (cid:107) ¯lj − ¯lo(cid:107),∀ ¯lo}.

(1)

1http://www.ﬁl.ion.ucl.ac.uk/spm/

Fig. 1: The ﬂowchart of the proposed approach for obtaining
local meshes and classiﬁcation of cognitive states.

II. NEUROIMAGING DATA COLLECTION

A. Visual Recognition Experiment

In this experiment, fMRI measurements wee recorded while
participants performed a one-back repetition detection task.
The stimuli consisted of gray-scale images belonging to two
categories, namely, birds and ﬂowers. Each stimulus was
presented for 4 seconds, and followed by a rest period of 8
seconds.

B. Emotional Memory Retrieval Experiment

In this experiment, the stimuli consisted of two neutral
(Kitchen utensils and Furniture) and two emotional (Fear and
Disgust) categories of images. Each trial started with a 12
seconds ﬁxation period followed by a 6 seconds encoding
period. In the encoding period, participants were presented
with 5 images from the same category, each image lasting 1200
on the screen. Following the ﬁfth image, a 12 seconds delay
period was presented in which participants solved three math
problems consisting of addition or subtraction of two randomly
selected two-digit numbers. Following the third math problem,
a 2 seconds retrieval period started in which participants were
presented with a test
image from the same category and
indicated whether the image was a member of the current study
list or not. For a similar experimental setting, please refer to
[24]. For classiﬁcation, we employed measurements obtained
during the encoding and retrieval phase as our training and
test data, respectively.

 fMRI Measurement ROI selection Construction of spatial meshes Construction of functional meshes Estimation of edge weights of meshes Cognitive state classification using edge weights Preprocessing Voxel selection fMRI Dataset (BOLD Responses) Definition of spatial neighborhood Definition of functional neighborhood 4

(a) An ensemble of spatially local meshes.

(b) An ensemble of functionally local meshes.

Fig. 2: Ensemble of meshes formed using (a) spatial neighbors and (b) functional neighbors of seed voxels. In both of the
ensembles, the voxels denoted with red color are the seed voxels. Orange voxels denote the spatially nearest neighbors of the
red voxel in (a), and the functionally nearest neighbors of the red voxel in (b). Green voxels are the spatially nearest neighbors
of the corresponding orange voxels in (a), and functionally nearest neighbors of the corresponding orange voxels in (b). Only
the highest edge weights are displayed for simplicity.

p-spatially nearest neighbors of voxel vj located at ¯lj are

deﬁned recursively as

ηspat
p

[vj] = {vk ∪ ηspat

p−1 [vj] : (cid:107) ¯lj − ¯lk(cid:107) ≤ (cid:107) ¯lj − ¯lo(cid:107),

p−1 [vj]c},
p−1 [vj]c is the set complement of the set ηspat

∀vo ∈ ηspat

p−1 [vj].

(2)

where ηspat

In the above deﬁnition of p-spatially nearest neighborhood,
when p = 6, 6-nearest neighbors of a voxel correspond to
the adjacent voxels at the right, left, up, down, front and
back of that voxel (see Fig. 2a). As we increase p, the set
of the neighboring voxels gets larger. The voxels which are
adjacent to the nearest neighbors are included recursively, with
an increasing p.

Deﬁnition 2: Functional Neighborhood: Let R(vj) denote
the vector with the entries of BOLD signal measurements at
voxel vj which are recorded as the response of a series of
stimulus during the entire experiment. A functionally nearest
neighbor of a voxel vj, is deﬁned as the voxel vk when the
vector R(vk) is maximally correlated with R(vj) measured at
voxel vj. In order to ﬁnd the functionally nearest neighbor of
a voxel vj, Pearson correlation between R(vj) and R(vk) is
computed for all the voxels vk in the brain volume using the
following criterion:

cor(R(vj), R(vk)) =

cov(R(vj), R(vk))
σ(R(vj))σ(R(vk))

,

(3)

where covariance between responses R(vj) and R(vk) is,

cov(R(vj), R(vk)) =

(cid:0)v(si, td, ¯lj) − µ(R(vj))(cid:1)∗(cid:0)v(si, td, ¯lk) − µ(R(vk))(cid:1) .

N ∗ D

∗

1

(cid:88)

∀i,d

(4)

Based upon the neighborhood systems introduced in the
previous section, the concept of locality is represented by

and standard deviation of response σ(R(vj)) is deﬁned as

(cid:0)v(si, td, ¯lj) − µ(R(vj)(cid:1)2

;

(5)

σ(R(vj)) =

(cid:115)(cid:88)

∀i,d

and mean of response µ(R(vj) is deﬁned as

µ(R(vj)) =

1

N ∗ D

v(si, td, ¯lj);

(cid:88)

∀i,d

(6)

is

Then, a functionally nearest neighbor of a voxel vj

deﬁned as:

ηf unc
1

[vj] = {vk : cor(R(vj), R(vk)) ≤ cor(R(vj), R(vo)),
(7)

∀vo}.

Finally, p-functionally nearest neighbors of the voxel vj is

recursively deﬁned as follows;

ηf unc
p

[vj] = {vk ∪ ηf unc

p−1 [vj] :

cor(R(vj), R(vk)) ≤ cor(R(vj), R(vo)),∀vo ∈ ηf unc

p−1 [vj]c}.

(8)
To this end, we select the functional neighbors of the voxel
vj as the voxels having p of the highest Pearson correlation
with that voxel.

Note that functionally p-nearest neighbors of a voxel may
or may not be the same as the spatially p-nearest neighbors.
Practical evidence indicates that most of the spatially close
voxels are also functionally close, i.e., they are highly corre-
lated. However, some of the voxel pairs are spatially far apart,
yet they are functionally close to each other (see Fig. 2b).

B. Construction of Local Meshes

5

Fig. 3: Design of a spatially local mesh for modeling the relationship among the BOLD responses of voxels. (a) For simplicity,
a seed voxel is depicted in an axial slice at the center of a mesh (red) with its four spatially nearest neighbors (yellow).
Neighboring voxels are selected within a 3D brain volume. For example, if p = 6, then we would include the voxels above
and below the seed voxel. (b) fMRI time series are recorded at each voxel, for each stimulus for bird and ﬂower classes. (c)
A local mesh is computed using the responses obtained from a seed voxel ¯r(sN , ¯lj) and its four nearest neighbors for the last
sample sN . We also visualize voxel intensity values of a sample response ¯r(sN , ¯lo) obtained from a voxel at ¯lo.

a set of meshes deﬁned over a sequence of brain volumes.
For this purpose, two types of meshes, namely, spatially and
functionally local meshes, are established.

Both types of meshes are constructed around each voxel
of the brain volume using a predeﬁned neighborhood system.
Once we select the neighborhood system, we form a local
mesh around each voxel by connecting the voxel to its p-
nearest neighboring voxels in a star topology. The voxel
located at the center of a mesh is called the seed voxel. If a
voxel resides within the neighborhood of a seed voxel, then we
connect it to the seed voxel with an edge, directed towards the
seed voxel. As the name implies, the spatially local meshes are
constructed by using the p-spatially nearest neighbors, whereas
the functionally local meshes are constructed by using the p-
functional nearest neighbors of the seed voxels. Since we form
the meshes around all of the voxels in the brain volume, the
meshes deﬁned over a neighborhood system may overlap. A
seed voxel in a mesh may become a neighboring voxel of a
seed voxel in a different mesh.

The formal deﬁnition of the local meshes are given below:
Deﬁnition 3: Spatially Local Meshes (SLM): For each
voxel vj in the brain volume, a spatially local mesh, formed
around that voxel, called the seed voxel, is deﬁned as a directed
graph Mspat
[vj]}
represents a set of the nodes of the mesh, and
[vj]}

= {ejk : ∀vk ∈ ηspat

j = (V spat

) where V spat

= {vj∪ηspat

,E spat

E spat

jk

p

j

j

p

j

represents the edges formed between the seed voxel vj of
the mesh Mspat
and its p-spatially nearest neighbors. The

j

direction of the edges is taken towards the seed voxel (see
Fig. 3).

Deﬁnition 4: Functionally Local Meshes (FLM): For each
voxel vj in the brain volume, a functionally local mesh which
is constructed around that voxel is deﬁned as a directed graph
Mf unc
[vj]}
represents a set of the nodes of the mesh, and
[vj]}

= {ejk : ∀vk ∈ ηf unc

= {vj ∪ ηf unc

) where V f unc

= (V f unc

,E f unc

E f unc

jk

p

j

j

j

p

j

represents the edges formed between vj and its p-functionally
nearest neighbors (see Fig. 4).

Notice that, for both neighborhood systems, a seed voxel
located at the center of a mesh becomes a neighboring voxel
in another mesh. Therefore, there may be two directed edges
between two neighboring voxels, vj and vk,
in opposite
directions. The edge weights in each mesh are estimated by
minimizing the mean square error of a linear model, as will
be explained in the next section. In the proposed linear model,
the seed voxel is represented in terms of linear combination
of its p-nearest neighbors. The same star topology is deﬁned
for all meshes and employed in the experiments with a ﬁxed
mesh size p. In other words, the voxels and the edges formed
between them in a mesh do not change in time. However,
the weights of nodes which correspond to the intensity values
measured for each entry of the time-series representing the
BOLD response, change in time. Since we estimate a set of
edge weights for each cognitive stimulus, the edges remain the
same for the duration of a stimulus and only changes across
the stimuli.

6

Fig. 4: Design of a functionally local mesh using the voxel time series. (a) A sample functional connectivity matrix formed
using Pearson correlation. p-functionally nearest neighbors of a voxel are denoted as the ones with the darkest red color. (b)
fMRI measurements are recorded for each stimulus for bird and ﬂower classes. (c) We depict a functional mesh formed around
a seed voxel, in star topology. The direction of the edges are taken towards the seed voxel, indicating that the seed voxel is
represented by the linear combination of its neighbors. The edge weights are computed by using the response obtained from
a seed voxel ¯r(sN , ¯lj) and the responses of its four functionally nearest neighbors, ¯r(sN , ¯li) , ¯r(sN , ¯ln), ¯r(sN , ¯lm), ¯r(sN , ¯lo),
for the last sample sN . We also visualize voxel intensity components of a sample response ¯r(sN , ¯lo) obtained from a voxel
located at ¯lo.

The size of each mesh is deﬁned by the order of the
neighborhood system, p. As p gets larger, the size of a mesh
constructed around each voxel increases, resulting in more
and more overlaps among the meshes. Therefore, p can be
considered as a measure of the degree of locality of the
proposed mesh model where we represent the BOLD response
of a seed voxel as the linear combination of the BOLD
responses of the neighboring voxels of the seed voxel.

Once we deﬁne a mesh around each voxel, we address the
problem of estimating the edge weights. The proposed edge
estimation method is explained next.

C. Estimation of Edge Weights of Meshes

Suppose that we record the BOLD response at each voxel vj
that is located at coordinate ¯lj during a stimulus si in order to
measure the brain activation for a predeﬁned cognitive state
with label c. We denote each intensity value of the BOLD
response measured at a voxel vj at time instance td for a
stimulus si as v(si, td, ¯lj). For each stimulus presentation, we
record D measurements at each voxel, where d = 1, 2, . . . , D.
For a given stimulus si, let us denote weight of an edge ej,k
as wi(ejk). We approximate the weight of an edge wi(ejk)
directed from a voxel vk to vj for stimulus si by estimating
the value ai,j,k when vj is considered as the seed voxel of a
mesh.

We estimate the edge weights for both spatially and func-
tionally local meshes in the same way. First, we obtain a
BOLD response vector ¯r(si, ¯lj) ∈ RD by concatenating the

voxel intensity values v(si, td, ¯lj), for all time instances that
are recorded during a single stimulus, si, such that:

¯r(si, ¯lj) = [v(si, t1, ¯lj), v(si, t2, ¯lj), . . . , v(si, tD, ¯lj)]T ,

(9)

where d = 1, 2, . . . , D. When we concatenate the BOLD
responses of all the stimuli, we obtain a vector of BOLD
responses measured from a voxel vj for all training samples
as follows;

R(vj) = [¯r(s1, ¯lj), ¯r(s2, ¯lj), . . . , ¯r(sN tr , ¯lj)],

(10)

where N tr denotes the number of training samples. Notice
that R(vj) is used to ﬁnd the p-functionally nearest neighbors
(see (3)).

We estimate the edge weights of a mesh formed around a
voxel vj located at coordinate lj for a stimulus si by a linear
model formed among the BOLD response of a seed voxel of
the mesh ¯r(si, ¯lj), and the BOLD responses of its p-nearest
neighbors {¯r(si, ¯lk) : vk ∈ ηp[vj]} as follows;

¯r(si, ¯lj) =

ai,j,k ¯r(si, ¯lk) + ¯εi,j,

(11)

(cid:88)

vk∈ηp[vj ]

where ¯εi,j is an error vector deﬁned as

¯εi,j = (εi,1,j, εi,2,j, . . . , εi,K,j)T .

(12)

Notice that ηp corresponds to ηspat

if BOLD meshes are
formed considering spatial neighborhood, and corresponds
to ηf unc
if the meshes are formed considering functional
neighborhood.

p

p

In (11), a BOLD response obtained from a seed voxel,
¯r(si, ¯lj), is modeled using a weighted linear combination of
the BOLD responses obtained from its p-nearest neighbors.
A weight ai,j,k represents the relationship between responses
obtained from a seed voxel vj and a neighboring voxel at vk.
In addition, each entry v(si, td, ¯lj) of ¯r(si, ¯lj) is represented
by the same weighted combination of its neighboring entries
v(si, td, ¯lk) of ¯r(si, ¯lk) in (11). Therefore, (11) can be equiv-
alently represented as follows:



v(si, t1, ¯lj)
v(si, t2, ¯lj)

...

(cid:16)

(¯εi,j)2(cid:17)

E

v(si, t1, ¯lk)
v(si, t2, ¯lk)

ai,j,k

¯lb∈ηp

(cid:88)


 =

¯r(si, ¯lj) − (cid:88)

= E

...

v(si, tD, ¯lj)
(13)
The weights ai,j,k of a mesh edge ej,k, ∀vk ∈ ηp[vj], are
estimated by minimizing the expected square error deﬁned as

v(si, tD, ¯lk)

 +



εi,1,j
εi,2,j
...
εi,D,j

 .
2 ,

ai,j,k ¯r(si, ¯lk)

vk∈ηp

(14)
where E(·) is the expectation operator applied over the time
elapse of a BOLD response corresponding to a stimulus period
D. We compute an edge vector ¯ai,j = [ai,j,1, ai,j,2, . . . , ai,j,p]
using ridge regression as

i,jQi,j + λI)−1QT

i,j ¯r(si, ¯lj),

¯ai,j = (QT

(15)
where λ ∈ R is a regularization parameter which is estimated
during the training phase, and Qi,j is a D×p matrix consisting
of BOLD responses obtained from p-nearest neighbors of a
seed voxel vj during the presentation of sample si such that
(16)

Qi,j = [¯r(si, ¯lk)], ∀vk ∈ ηp[vj].

One of the crucial tasks of forming local meshes is the
identiﬁcation of the degree of locality for each mesh. The
number of the nearest neighbors, p, deﬁnes the size of each
mesh.

• For a spatially local mesh, when p is small, the seed voxel
of the mesh is related only to a few very spatially close
voxels. As we increase p, the mesh includes larger areas
in the brain volume to take into account the contribution
of distant voxels to the seed.

• On the other hand, for a functionally local BOLD mesh,
small p implies that only a few most correlated voxels
are related to the seed voxel. As we increase the mesh
size, we include the contribution of the voxels that are
relatively less correlated to the seed voxel.

Identiﬁcation of the “optimal” mesh size, p, is a crucial
issue. In this study we optimize the mesh size using a
validation set. This task can also be achieved by using an
Information Theoretic function, such as Akaike’s information
criterion (AIC) [28], Bayesian Information Criterion (BIC)
[29] or Rissannen’s Minimum Description Length (MDL) [30]
to estimate the model order. It is possible to deﬁne a different
mesh size for each seed voxel by using one of the approaches
mentioned above. The interested reader is referred to [31]. In

7

this study, we select a ﬁxed mesh size for the entire brain
volume, for each stimulus.

V. CLASSIFICATION OF COGNITIVE STATES FOR BRAIN

DECODING

The representation power of the proposed mesh ensemble
is analyzed in the fMRI recordings during brain encoding and
decoding tasks. For this purpose, we employ machine learning
methods where encoding of a cognitive state is represented
by the training phase and the decoding state corresponds to
the recognition phase of a classiﬁcation algorithm. The major
question is then how well a cognitive state can be represented
by the ensemble of meshes? The answer to this question can
be partly observed from the performance of the classiﬁer.

Recall that for each cognitive stimulus si with a label c,
we record a sequence of brain volumes, where the number of
brain volumes D, in this sequence depends on the duration
of the stimulus. This sequence of brain volumes is considered
as one sample with a label c, in the training set. In order
to represent a cognitive state corresponding to a stimulus si
by the mesh ensembles, we estimate the edge weights of all
local meshes extracted from the corresponding sequence of
the brain volumes. The sequence of brain volumes recorded
during the stimulus si is then represented by a brain graph,
which consists of the ensemble of local meshes. Finally, each
sample in the dataset is represented by a vector with the entries
of the estimated mesh arc weights in the input space of a
classiﬁer.
Formally speaking, for each sample si with label c, the edge
weights ¯ai,j ∈ R1×p are used to construct a feature vector
Fi = [¯ai,1, ¯ai,2, . . . , ¯ai,M ] by concatenating all edge vectors
¯ai,j, ∀j = 1, 2, . . . , M, where M is the number of voxels. We
denote a feature vector of a sample si belonging to training
is a feature vector of a sample s(cid:48)
set as F tr
i
i
belonging to test set. Then, we construct a set of features of
i }N tr
training samples Str = {F tr
i=1 and a set of features of test
samples Ste = {F te
i=1 to train and test the classiﬁers for
classiﬁcation of cognitive states.

, while F te
i

i }N te

VI. BRAIN DECODING EXPERIMENTS PERFORMED ON

THE FMRI DATASETS

In order to observe the validity of the proposed mesh
models, we perform two groups of experiments. In the ﬁrst
group, we train and test a Support Vector Machine (SVM)
classiﬁer by using the labeled fMRI data recorded using the
experimental setups explained in Section II. In this group
of experiments, we examine the power of the models for
representing brain encoding and decoding tasks. In the second
group of experiments, we analyze the validity of the local
meshes by exploring the similarities among the voxel time
series in each mesh, and the distribution of the error of the
proposed linear regression model.

A. Comparison of the Spatial and Functional Mesh Models
with State-of-the-Art Methods

In order to compare the proposed spatial and functional
meshes with the state-of-the-art MVPA methods, we measure

the encoding and decoding performances of the models. The
encoding process is performed by training an SVM classiﬁer
with linear kernel, and decoding process corresponds to classi-
ﬁcation of an unknown stimulus with class label c. We perform
seven sets of computer experiments on two different groups
of fMRI datasets:

• In the ﬁrst and second set of experiments, we represent
a cognitive stimulus using the spatial and functional
meshes. The classiﬁcation performances are measured
by using the edge weights obtained using the spatially
(SLM) and functionaly local mesh (FLM) models.

• In the third and fourth set of experiments, we tested
the classiﬁcation performances by employing Local Mesh
Model (LMM) and Functional Mesh Model(FMM). Re-
call that both LMM and FMM keep only a single value
from the BOLD response for each voxel omitting the rest
of the signals measured during a stimulus.

• In the ﬁfth group of experiments, we test the perfor-
mance of SVM classiﬁers which employ features that are
computed using pairwise Pearson correlation (FC-mesh).
First, we compute the pairwise correlations between the
voxel BOLD responses given by seed voxels and each
of their p-nearest neighbors for each stimulus. In other
words, ﬁrst meshes are constructed around seed voxels,
and then pairwise correlations are computed between
voxel pairs within meshes instead of estimating the
edge weights within a neighborhood. Then, we form our
feature vector by concatenating the correlation values
within all meshes. Note that, we obtain feature vectors
whose sizes are equal to that of SLM and FLM by
concatenating only the distances within meshes to make
a fair comparison.

• In the sixth set of experiments, we analyze the classiﬁca-
tion performance of the classiﬁers for the state-of-the-art
MVPA methods in which raw voxel intensity values are
used as features to train and test classiﬁers. For MVPA-
peak, we only used the third instance v(si, t3, ¯lj) of a
BOLD response ¯r(si, ¯lj) following our assumption that
if a voxel becomes active, then its HRF reaches to its
peak value after 5-6 seconds (around t3). On the other
hand, MVPA-mean depicts the case where we employed
the average of d measurements of ¯r(si, ¯lj). We also con-
catenate each of the d measurements of BOLD response
{v(si, td, ¯lj)}D
d=1 to obtain results for MVPA-all. The
dimension of a feature vector constructed for MVPA-
peak and MVPA-mean equals to 1254 for visual object
recognition experiment, and 3000 for emotional memory
retrieval experiment. Moreover, since we concatenate all
measurements for MVPA-all,
the size of the feature
vectors used for MVPA-all equals to d times the size
of features vectors for MVPA-mean and MVPA-peak.
• In the seventh set of experiments, we selected the sur-
rounding voxels in the mesh as the random voxels to test
the importance of locality. In LM-rand, we form meshes
deﬁned over a sequence of brain volumes with random
voxels.

8

TABLE I: Classiﬁcation performance (%) of SVM classiﬁer
computed in visual object recognition experiment.

FLM
SLM
FMM-mean
FMM-peak
LMM-mean
LMM-peak
LM-rand
FC-mesh
MVPA-mean
MVPA-peak
MVPA-all

P1

93(16)
80(5)
77(19)
63(26)
73(21)
73(23)

74
65
70
68
68

P2
83(5)
81(30)
67(27)
69(23)
67(27)
72(28)

81
74
71
67
76

P3

89(16)
81(14)
72(23)
72(14)
69(30)
78(29)

81
61
72
69
78

P4

81(17)
72(10)
75(18)
75(30)
69(25)
58(19)

72
58
78
83
69

P5
61(4)
69(6)
64(15)
67(11)
64(22)
69(10)

69
50
69
72
68

Avg
81.4
76.6
71.0
69.2
68.4
70.0
75.4
61.8
72.0
71.8
71.8

B. Classiﬁcation Results for Brain Decoding

We perform intra-subject classiﬁcation using SVM classi-
ﬁers, and features that are extracted from samples collected
in the proposed visual object recognition experiment for ﬁve
participants, and emotional memory retrieval experiment for
thirteen participants. The same mesh size is used for each
mesh that was computed using the data collected for the same
participant.

Visual Object Recognition Experiment: Table I provides
the classiﬁcation performance of SVM using the models
described in the previous subsection. The regularization pa-
rameter λ is selected experimentally as λ = 0.5. We computed
meshes using various mesh sizes p ∈ P = {2, 3, . . . , 30}. In
order to optimize the mesh size within this interval, we
randomly split a part of test data as our validation set. We
ensured that our validation and test sets are balanced. We
selected the optimal mesh sizes as the ones that maximizes
the validation performances.

Classiﬁcation results of visual object recognition experiment
are given in Table I. Additionally, the performances obtained
on test set using the optimal mesh size ˆp obtained from
validation sets are given in Table I for each method employed
by each classiﬁer and for each participant. For example, we
obtain 93% accuracy for FLM when the mesh size ˆp is 16 for
the ﬁrst participant P1. It can be observed that, the mesh size ˆp
which leads to the maximum performance varies for different
participants and methods. In addition, classiﬁers which employ
the features extracted for FLM and SLM perform the best
among others, where the features extracted for FLM perform
slightly better than the features extracted for SLM. Note that,
selecting random voxels in LM-rand performs worse than
employing spatial or functional neighbors.

Emotional Memory Retrieval Experiment: We provided
results for 2-class and 4-class classiﬁcation experiments. In
these experiments, λ is selected experimentally as λ = 4, and
we computed meshes with mesh sizes p ∈ S = {5, 6, . . . , 15}.
In the ﬁrst case, we provided two-class classiﬁcation results
where classes correspond to neutral and emotional categories
(see Table II). In the second case, four classes correspond
to kitchen utensil, furniture, fear and disgust, where kitchen
utensil and furniture belong to the neutral category, and fear
and disgust belong to the emotional category (see Table III).

9

TABLE II: Classiﬁcation performance (%) of SVM classiﬁer computed in emotional memory retrieval experiment (2-class).

FLM
SLM
FMM-mean
FMM-peak
LMM-mean
LMM-peak
LM-rand
FC-mesh
MVPA-mean
MVPA-peak
MVPA-all

P1

71(12)
72(5)
50(8)
66(15)
51(7)
58(12)

53
55
57
72
66

P2
75(5)
75(5)
61(5)
67(9)
60(7)
65(7)
63
53
58
66
61

P3
73(7)
78(12)
66(5)
69(9)
62(5)
62(8)
65
57
68
67
60

P4

82(12)
75(6)
63(5)
78(14)
70(9)
81(15)

65
59
63
77
69

P5
81(8)
78(5)
62(10)
72(12)
69(12)
70(15)

60
56
61
70
59

P6
79(5)
74(6)
64(5)
63(11)
54(7)
69(7)
50
56
50
69
73

P7
88(9)
88(5)
82(9)
76(6)
86(8)
83(14)

77
58
81
83
80

P8

78(10)
78(11)
63(6)
69(6)
66(7)
66(10)

59
63
60
70
65

P9

81(13)
81(11)
75(7)
75(14)
74(9)
74(13)

74
57
76
82
74

P10
79(9)
82(14)
72(5)
68(5)
70(5)
68(5)
64
57
47
67
72

P11
72(5)
81(15)
60(5)
75(15)
58(5)
71(9)
53
62
55
78
72

P12
84(14)
70(11)
63(5)
91(14)
58(7)
83(14)

64
67
54
81
63

P13
66(8)
66(15)
54(5)
60(11)
70(7)
76(14)

54
56
61
73
71

Avg
77.6
76.8
64.2
71.5
65.2
71.2
61.6
55.7
60.8
73.4
68.1

TABLE III: Classiﬁcation performance (%) of SVM classiﬁer computed in emotional memory retrieval experiment (4-class).

FLM
SLM
FMM-mean
FMM-peak
LMM-mean
LMM-peak
LM-rand
FC-mesh
MVPA-mean
MVPA-peak
MVPA-all

P1
59(6)
58(13)
38(5)
42(10)
38(11)
42(9)
37
31
37
49
43

P2

54(10)
53(13)
42(8)
46(6)
46(6)
36(12)

43
35
40
45
41

P3
62(6)
63(8)
46(14)
44(9)
50(8)
44(12)

37
26
44
44
40

P4

68(13)
67(14)
44(14)
54(15)
47(12)
45(11)

42
33
45
55
44

P5
60(6)
63(8)
49(10)
40(14)
47(14)
47(15)

40
32
45
41
34

P6
66(6)
62(5)
42(5)
46(5)
42(5)
48(7)
40
30
37
51
43

P7
75(9)
78(11)
74(15)
58(7)
68(12)
58(11)

63
36
67
64
57

P8

59(15)
62(5)
36(5)
37(12)
42(6)
32(8)
44
34
41
41
39

P9
67(5)
75(5)
57(7)
58(11)
51(8)
61(15)

59
31
58
57
53

P10
74(13)
74(9)
52(6)
57(7)
52(7)
57(7)
51
39
40
49
41

P11
64(7)
58(9)
42(9)
58(13)
38(7)
47(10)

39
38
40
57
35

P12
62(14)
58(12)
32(5)
43(14)
35(5)
46(11)

45
41
33
52
38

P13
58(5)
57(12)
35(7)
45(13)
38(6)
47(10)

39
33
34
46
42

Avg
63.7
63.7
45.1
48.3
45.7
47.0
44.6
33.7
43.2
50.1
42.4

obtain better performance for FMM-peak, LMM-peak and
MVPA-peak than for FMM-mean, LMM-mean and MVPA-
mean, respectively.

First of all, the results show that employing a set of BOLD
responses for the computation of meshes provides the most
discriminate representations of cognitive states. Moreover,
we observe that estimating functional relationships within a
neighborhood provides better performance than using pairwise
functional relationships as utilized for FC-mesh. Features
extracted for FC-mesh perform the worst among the others
since computation of correlation among voxels using only a
few voxel intensity values for each stimulus presentation is
not enough to represent the real correlation among voxels
computed considering the whole dataset. Therefore, we ob-
tain better classiﬁcation performance by computing a single
functional connectivity matrix for all training data, and using
the matrix to select functionally nearest neighbors, instead
of computing the functional connectivity matrices for each
sample and using their elements as features. Finally, we
obtained worse classiﬁcation performance using the classiﬁers
which employ MVPA features consisting of individual voxel
intensity values compared to our proposed methods.

We have provided the mean and standard deviations of
classiﬁcation performances using different meshes that are
constructed with p ∈ P for visual object recognition ex-
periment in Fig. 5, and with p ∈ S for emotional memory
retrieval experiment in Fig. 6 and Fig. 7. In Fig. 5, bars
represent the mean classiﬁcation performance averaged over
all p ∈ P, whereas in Fig. 6 and Fig. 7, bars represent the
mean classiﬁcation performance averaged over all p ∈ S. In

Fig. 5: Mean and standard deviation of classiﬁcation per-
formances of SVM compute din visual object recognition
experiment.

Similar to visual object recognition experiment, optimal
mesh sizes are selected as the ones that maximize validation
set accuracy within the interval S. Table II and Table III
provide classiﬁcation performance obtained using the optimal
mesh sizes. The results of 2-class and 4-class classiﬁcation ex-
periments show that we obtain signiﬁcantly better performance
using features extracted for FLM and SLM than the other
features. Employing random voxels in LM-rand performs
signiﬁcantly worse than employing spatial or functional neigh-
bors. We have also observed that we obtain better performance
using the features extracted by the employment of the peak
values of BOLD responses than using the features extracted by
computing the average of BOLD responses. In other words, we

40506070809012345Classification PerformanceParticipantsFLMSLMFMM-peakLMM-peakFMM-meanLMM-mean10

Fig. 6: Mean and standard deviation of classiﬁcation performances of SVM computed in emotional memory retrieval experiment
(2-class).

Fig. 7: Mean and standard deviation of classiﬁcation performances of SVM computed in emotional memory retrieval experiment
(4-class).

these ﬁgures, each error bar represents standard deviations of
the corresponding performance value. For each participant, the
ﬁrst two bars depict performances of the methods that employ
functional and spatial meshes, whereas the last four bars depict

performances obtained using mesh models which do not con-
sider whole BOLD responses. We have observed that standard
deviation of performance values obtained using various mesh
sizes decreases when temporal measurements are considered

455055606570758085909512345678910111213Classification PerformanceParticipantsFLMSLMFMM-peakLMM-peakFMM-meanLMM-mean2030405060708012345678910111213Classification PerformanceParticipantsFLMSLMFMM-peakLMM-peakFMM-meanLMM-mean11

(a) Random voxels.

(b) Spatial Neighbors.

(c) Functional Neighbors.

Fig. 8: BOLD responses of voxel sets.

for statistical learning of the models. In other words, the
methods employing temporal measurements recorded within
neighborhoods are more robust to changes of mesh size p than
the methods which do not employ temporal measurements.

of seed voxels. First, we compute correlations between ten
surrounding voxels and the seed voxel. Then, we depict the
histograms of all correlations computed for all voxels with
their surrounding voxels in meshes.

C. Analysis of Local Meshes

In the proposed local mesh models, we assume that the
BOLD responses of voxels that are located in a neighborhood
are similar to each other so that a BOLD response of a voxel
can be represented by a linear combination of the BOLD
responses of its nearest neighbors. In other words, we assume
that the error of a linear regression model is small enough
such that a cognitive stimulus can be represented by a set of
local meshes, where the edge weights of the meshes can be
estimated by minimizing the expected square error.

1) Statistical Analysis of Correlations of Voxels: In order
to understand how voxels within a neighborhood behave, and
how their behavior differs from the behavior of random voxel
sets, we plot a seed voxel with i) a set of randomly selected
voxels (Fig. 8a), ii) its ten spatially (Fig. 8b) and iii) ten
functionally (Fig. 8c) nearest neighbors. We observe that, sam-
ple voxels located within spatial and functional neighborhoods
perform similar under presentation of the same stimuli.

In the analysis, Pearson correlation is used to compute
pairwise relationship (i.e. correlation) between the seed voxels
and the surrounding voxels. In our analysis, surrounding
voxels are selected as (a) random voxels, (b) spatially nearest
neighbors of seed voxels and (c) functionally nearest neighbors

We observe that if meshes are formed with random voxels,
then the mean of distribution of correlations lie around 0.4
(see Fig. 9a), in other words, the randomly selected voxels may
not have a statistically signiﬁcant linear relationship with each
other. On the other hand, the results show that correlation val-
ues of the voxels observed with the highest frequency are close
to 0.9 when the histograms are computed for meshes formed
using spatially (see Fig. 9b) and functionally (Fig. 9c) close
voxels. These observations indicate that the voxels modeled
in the same mesh have better statistical relationship with each
other than the randomly selected meshes. Therefore, one may
expect that the linear relationship among the BOLD responses
observed in voxels located in a proposed neighborhood system
provides a reasonable ﬁt to the data.

2) Statistical Analysis of Models: Recall that, we represent
the voxel intensity values each voxel as a linear combination
of those values of its p-nearest neighbors in our models. Yet,
we obtain a regression error for each mesh for the estimation
of seed voxels considering its neighbors. In the next set
of experiments, we analyze how well the seed voxels are
represented in terms of their nearest neighbors by exploring
the model estimation error of the proposed representation.

For this purpose, we employ a goodness of ﬁt measure
called R2 deﬁned as one minus the residual variation divided

(a) Random voxels.

(b) Spatial Neighbors.

(c) Functional Neighbors.

Fig. 9: Histograms of correlations between seed voxels and surrounding voxels.

12

(a) Random voxels.

(b) Spatial Neighbors.

(c) Functional Neighbors.

Fig. 10: Histograms of R2 values.

by total variation, where residual variation (SSr) is the sum-
mation of square errors obtained from regression model, and
total variation (SSt) is the variance of the distribution of the
actual data.

More precisely, we compute the residual variation as,

SSr

i,j =

ε2
i,d,j,

(17)

where εi,d,j denotes the error in (13), and D represents
the number of measurements recorded during each stimulus
representation. On the other hand, total variance is computed
as

D(cid:88)

d=1

D(cid:88)

SSt

i,j =

v(si, td, ¯lj)2.

d=1
Then, the R2 is computed as
i,j = 1 −
R2

(cid:32)

(cid:33)

.

SSr
i,j
SSt
i,j

(18)

(19)

Notice that the R2 measure takes values between 0 and 1
such that the values closer to one represent better ﬁt of models.
In the analysis, we computed R2 values for all meshes of a
participant formed for all samples and around all voxels. In
Fig. 10, we plot the histograms for R2 values computed when
the meshes are formed using (a) random voxels, (b) spatially
nearest voxels, and (c) functionally nearest voxels.

In the experiments, if seed voxels of meshes formed using
spatial or functional neighbors are represented in terms of their
neighbors, then we observe that the mean values of histograms
for R2 are 0.57 and 0.54, respectively (Fig. 10.b and c). On
the other hand, if we represent seed voxels in terms of random
voxels, then we observe larger estimation errors, and the mean
value reduces to 0.29 (Fig. 10.a). Therefore, employing spatial
or functional neighbors during the construction of meshes
results in better model ﬁt compared to selecting random
voxels.

VII. CONCLUSION

In this study, we propose a method which maps a sequence
of brain volumes, recorded during a cognitive stimulus to a
brain graph consisting of a set of local meshes. The proposed
model, called ensemble of local meshes, deﬁnes two types

of local meshes around each voxel, namely spatially local
mesh (SLM) and functionally local mesh (FLM). While SLM
models the relationship among voxel BOLD responses in a
spatial neighborhood system, FLM models the relationship
among voxel BOLD responses in functional neighborhood
deﬁned by Pearson correlation. We have observed that are
considering the whole BOLD responses recording during a
cognitive stimulus for the employment of spatial and func-
tional relationship among voxels enables us to model
the
discriminative information in fMRI data. When we represent
the brain encoding and decoding precess by a machine learn-
ing algorithm, namely Support Vector Machines (SVM), we
observe that FLM features perform substantially better among
the features that use the state-of-the-art MVPA models.

We have observed that classiﬁcation performances of SVM
depend on the mesh size p, and varies for each participant.
We have also observed that employment of temporal mea-
surements for modeling of mesh edge weights results in less
standard deviation over various mesh sizes. Therefore, models
which employ temporal measurements are more robust to the
effect of using different mesh sizes for the extraction and
classiﬁcation of features. A future research direction will be
the development of algorithms to generalize the ensemble of
local meshes to model resting state or disease fMRI data.

ACKNOWLEDGMENT

We thank Orhan Firat, Baris Nasir, Arman Afrasiyabi, Burak
Velioglu, Hazal Mogultay, Emre Aksan and Sarper Alkan for
insightful discussions and fMRI data gathering. We also thank
UMRAM for fMRI recordings. This work is supported by
TUBITAK under the grant number 112E315.

REFERENCES

[1] M. Kefayati, H. Sheikhzadeh, H. Rabiee, and A. Soltani-Farani, “Semi-
spatiotemporal fmri brain decoding,” in PRNI, Philadelphia, PA, USA,
June 2013, pp. 182–185.

[2] J. V. Haxby, M. I. Gobbini, M. L. Furey, A. Ishai, J. L. Schouten, and
P. Pietrini, “Distributed and overlapping representations of faces and
objects in ventral temporal cortex,” Science, vol. 293, no. 5539, pp.
2425 – 2429, 2001.

[3] S. Kloppel, A. Abdulkadir, C. R. Jack, N. Koutsouleris, J. Mourao-
Miranda, and P. Vemuri, “Diagnostic neuroimaging across diseases,”
NeuroImage, vol. 61, no. 2, pp. 457 – 463, 2012.

13

[31] I. Onal, E. Aksan, B. Velioglu, O. Firat, M. Ozay, I. Oztekin, and F. T.
Yarman Vural, “Modeling the brain connectivity for pattern analysis,”
in ICPR, Stockholm, Sweden, 2014.

[4] G. Orru, W. Pettersson-Yeo, A. F. Marquand, G. Sartori, and
A. Mechelli, “Using support vector machine to identify imaging
biomarkers of neurological and psychiatric disease: A critical review,”
Neurosci. Biobehav. Rev., vol. 36, no. 4, pp. 1140 – 1152, 2012.

[5] I. Oztekin and D. Badre, “Distributed patterns of brain activity that lead

to forgetting.” Front Hum Neurosci, vol. 5, no. 86, 2011.

[6] D. D. Cox and R. L. Savoy, “Functional magnetic resonance imaging
(fmri) brain reading: detecting and classifying distributed patterns of
fmri activity in human visual cortex,” NeuroImage, vol. 19, no. 2, pp.
261 – 270, 2003.

[7] Y. Kamitani and F. Tong, “Decoding the visual and subjective contents
of the human brain,” Nat Neurosci, vol. 8, no. 5, pp. 679 – 685, 2005.
[8] ——, “Decoding seen and attended motion directions from activity in
the human visual cortex.” Curr Biol, vol. 16, no. 11, pp. 1096 – 1102,
2006.

[9] B. Ng, A. Vahdat, G. Hamarneh, and R. Abugharbieh, “Generalized
sparse classiﬁers for decoding cognitive states in fmri,” in MLMI,
Beijing, China, 2010, vol. 6357, pp. 108–115.

[10] B. Ng and R. Abugharbieh, “Generalized group sparse classiﬁers with
application in fmri brain decoding,” in CVPR, Colorado Springs, USA,
2011, pp. 1065–1071.

[11] T. M. Mitchell, R. Hutchinson, R. Niculescu, F. Pereira, X. Wang,
M. Just, and S. Newman, “Learning to decode cognitive states from
brain images,” Machine Learning, vol. 57, no. 1-2, pp. 145–175, 2004.
[12] B. Ng and R. Abugharbieh, “Modeling spatiotemporal structure in fmri
brain decoding using generalized sparse classiﬁers,” in PRNI, Korea,
Seoul, 2011, pp. 65–68.

[13] S. P. Pantazatos, A. Talati, P. Pavlidis, and J. Hirsch, “Decoding
unattended fearful faces with whole-brain correlations: An approach to
identify condition-dependent large-scale functional connectivity,” PLoS
Comput Biol, vol. 8, no. 3, p. e1002441, 2012.

[14] J. Richiardi, H. Eryilmaz, S. Schwartz, P. Vuilleumier, and D. V. D. Ville,
“Decoding brain states from fmri connectivity graphs,” NeuroImage,
vol. 56, no. 2, pp. 616 – 626, 2011.

[15] O. Firat, I. Onal, E. Aksan, B. Velioglu, I. Oztekin, and F. T. Y. Vural.,
“Large scale functional connectivity for brain decoding,” in BioMed,
Zurich, Switzerland, 2014.

[16] C. Baldassano, M. C. Iordan, D. M. Beck, and L. Fei-Fei, “Voxel-
level functional connectivity using spatial regularization,” NeuroImage,
vol. 63, no. 3, pp. 1099 – 1106, 2012.

[17] O. Firat, M. Ozay, I. Onal, I. Oztekin, and F. Yarman Vural, “Represen-
tation of cognitive processes using the minimum spanning tree of local
meshes,” in EMBC, Osaka, Japan, July 2013, pp. 6780–6783.

[18] J. Richiardi, S. Achard, H. Bunke, and D. V. de Ville, “Machine learn-
ing with brain graphs: Predictive modeling approaches for functional
imaging in systems neuroscience,” IEEE Signal Process. Mag, 2013.

[19] N. Bazargani and A. Nosratinia, “Joint maximum likelihood estimation
of activation and hemodynamic response function for fmri,” Med Image
Anal, vol. 18, no. 5, pp. 711 – 724, 2014.

[20] N.Kriegeskorte, R. Goebel, and P. Bandettini, “Information-based func-
tional brain mapping,” PNAS, vol. 103, no. 10, pp. 3863 – 3868, 2006.
[21] M. Ozay, I. Oztekin, U. Oztekin, and F. T. Yarman-Vural, “Mesh learning

for classifying cognitive processes,” CoRR, vol. abs/1205.2382, 2012.

[22] O. Firat, M. Ozay, I. Onal, I. Oztekiny, and F. Vural, “Functional mesh
learning for pattern analysis of cognitive processes,” in ICCI*CC, New
York City, USA, July 2013, pp. 161–167.

[23] I. Onal, M. Ozay, and F. Yarman Vural, “Modeling voxel connectivity

for brain decoding,” in PRNI, Stanford, CA, USA, 2015, pp. 5 – 8.

[24] E. Mizrak and I. Oztekin, “Relationship between emotion and forget-

ting,” Emotion, 2015.

[25] N. Tzourio-Mazoyer, B. Landeau, D. Papathanassiou, F. Crivello,
O. Etard, N. Delcroix, B. Mazoyer, and M. Joliot, “Automated anatom-
ical labeling of activations in spm using a macroscopic anatomical
parcellation of the mni mri single-subject brain,” NeuroImage, vol. 15,
pp. 273–289, 2002.

[26] M. Brett, J.-L. Anton, R. Valabregue, and J.-B. Poline., “Region of
interest analysis using an spm toolbox,” in 8th International Conference
on Functional Mapping of the Human Brain, Sendai, Japan, 2002.

[27] M. Robnik-Sikonja and I. Kononenko, “Theoretical and empirical anal-
ysis of relieff and rrelieff,” Machine Learning, vol. 53, pp. 23 – 69,
2003.

[28] H. Akaike, “Information theory and an extension of the maximum
likelihood principle,” in ISIT, Budapest, Hungary, 1973, pp. 267 – 281.
[29] G. E. Schwarz, “Estimating the dimension of a model,” Ann. Stat, vol. 6,

no. 2, pp. 461 – 464, 1978.

[30] J. Rissanen, “Modeling by shortest data description,” Automatica,

vol. 14, no. 5, pp. 465 – 471, 1978.

