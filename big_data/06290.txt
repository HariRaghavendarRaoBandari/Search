6
1
0
2

 
r
a

 

M
6
2
 
 
]

.

O
C
h
t
a
m

[
 
 

2
v
0
9
2
6
0

.

3
0
6
1
:
v
i
X
r
a

A new bijection on m-Dyck paths

with application to random sampling

Axel Bacher

March 29, 2016

Abstract

We present a new bijection between variants of m-Dyck paths (paths
with steps in {+1, −m} starting and ending at height 0 and remaining at
non-negative height), which generalizes a classical bijection between Dyck
preﬁxes and pointed Łukasiewicz paths. As an application, we present
a new random sampling procedure for m-Dyck paths with a linear time
complexity and using a quasi-optimal number of random bits. This out-
performs Devroye’s algorithm, which uses O(n log n) random bits.

1

Introduction

Dyck paths—paths with steps in {ր,ց} which start and end at height 0 and
remain above the x-axis—are a cornerstone object in combinatorics. They are
counted by the ubiquitous Catalan numbers and are in bijection with hundreds
of other objects, among them binary plane trees (see [14] for a list).

What makes Dyck paths especially interesting is their rich combinatorics.

For instance, the classical proof of the formula 1
relies on the Cycle Lemma, which operates on Dyck paths. Many bijections exist
between variants of Dyck paths (such as Dyck preﬁxes, which are not constrained
to end at zero), for instance relying on the Catalan decomposition illustrated in
Figure 1. Many examples can be found, among others, in [11, Chapter 9].

n(cid:1) for the Catalan numbers

n+1(cid:0)2n

Figure 1: A Dyck preﬁx of height h = 4 with its Catalan decomposition
q0u · ·· uqh, where q0, . . . , qh are (possibly empty) Dyck paths.

A natural generalization of Dyck paths are paths with steps in {+1,−m} for
some integer m ≥ 1. These are called m-Dyck paths [8] and are in bijection with
m + 1-ary trees. Their counting sequence is called the Fuss-Catalan numbers,
(cid:1). The goal of this paper is to present a new bijection on
equal to
m-Dyck paths, which corresponds in the case m = 1 to a well-known bijection
between variants of Dyck paths (Dyck preﬁxes and pointed Łukasiewicz paths),
based on the Catalan decomposition.

mn+1(cid:0)(m+1)n

n

1

1

As an application of our bijection, we present a random sampling procedure
for m-Dyck paths. Random sampling—ﬁnding an algorithm that outputs an el-
ement of a given combinatorial class with a prescribed (usually uniform among
the objects of a given size) random distribution, as eﬃciently as possible—is an
important area of combinatorics with many theoretical and practical applica-
tions (for instance, it can lead to conjectures on the properties of large objects,
or enable testing programs on random large inputs). The random sampling of
Dyck-like paths (or equivalently, plane trees) has attracted a lot of attention.
In the case of Dyck paths (or Motzkin paths, which allow → steps), eﬃcient
techniques include anticipated rejection [4, 5] and Rémy’s algorithm [13, 2]. In
a more general case, including m-Dyck paths, we have Devroye’s algorithm [7]
based on the Cycle Lemma.

The eﬃciency of a random sampling algorithm is measured in time, space
and random bits. The random bit complexity (as opposed to, for instance, the
number of calls to a uniform continuous random variable) is a realistic model of
the randomness consumed by the algorithm, developped for instance in [10]. By
that measure, Devroye’s algorithm uses O(n log n) random bits, since it involves
drawing a uniform permutation. We show that our algorithm has a linear cost
with all three respects. In fact, we show that it is asymptotically entropic in the
sense that the number of random bits consumed is asymptotically equivalent
to the entropy of the m-Dyck paths, which is an information-theoretical lower
bound on the random bit complexity.

This article is organized as follows. In Section 2, we deﬁne the classes of
paths between which our bijections operates. The folding bijection itself is
presented in Section 3. In Section 4, we show our random sampling algorithm
and prove that it has linear complexity. Finally, in Section 5, we study the limit
distribution of the time complexity, which turns out to have unusual properties.

2 Deﬁnitions

Throughout the paper, let m ≥ 1 be an integer. We consider paths with two
kinds of steps, u and d, with respective heights 1 and −m. The height of a
path is deﬁned as the sum of the heights of its steps. In the rest of the section,
we consider a path w with length n and height h. We introduce the Euclidean
divisions of n and h by m + 1:

n = (m + 1)n′ + r;

h = (m + 1)h′ + r.

The remainders are the same since the heights of both steps u and d are congru-
ent to 1 modulo m + 1. The height h is therefore determined by the quotient h′,
that we call the reduced height of w.

We say that the path w is an m-Łukasiewicz path if every proper preﬁx p
of w satisﬁes h(p) ≥ 0 but the whole path satisﬁes h(w) < 0. The ﬁnal height h
ranges between −m and −1, as determined by r (the reduced height h′ is −1).
In particular, no m-Łukasiewicz path exists with a length divisible by m + 1.

Finally, we say that the path w is an m-Dyck preﬁx if every preﬁx p of w
satisﬁes h(p) ≥ 0. If r 6= 0, we call decoration of w a sequence a0, . . . , ah′ of

2

integers satisfying:

(1 ≤ ai ≤ m,
1 ≤ ah′ ≤ r.

i = 0, . . . , h′ − 1;

We call the path w thus equipped a decorated path. From the constraints, we
see that the number of possible decorations of w is rmh′
. In the case of Dyck
preﬁxes (m = 1), there is only one possible decoration for every Dyck preﬁx of
odd length and zero for preﬁxes of even length.

3 The folding bijection

The goal of this section is to provide a bijection between the two objects deﬁned
above, decorated m-Dyck preﬁxes and pointed m-Łukasiewicz paths (i.e., with
a distinguished step). We then provide an enumeration result as a ﬁrst applica-
tion. In the case m = 1, our bijection reduces to a well-known bijection between
Dyck preﬁxes of odd length and pointed Łukasiewicz paths [11, Chapter 9].

Let w be an m-Dyck preﬁx equipped with a decoration (a0, . . . , ak). Write w

in the form:

(1)
where, for i = 0, . . . , k, the path qi is an m-Dyck preﬁx of height ai − 1 (this is
done by identifying ﬁrst the factor uqk as the smallest suﬃx of w of height ak
and working backwards to get the other factors). Let φ(w) be the path:

w = puq0 ··· uqk,

φ(w) = pq0d··· qkd,

(2)

pointed on the ﬁrst step of q0d. We call this operation folding the path w.

To recover the path w from the pointed path φ(w), let pq be the factorization
of φ(w) obtained by cutting before the pointed step. Let q0d be the smallest
m-Łukasiewicz preﬁx of q; repeat this process to get the factorization (2). The
path w is then recovered as (1) and the decoration a0, . . . , ak as the heights of
the factors uqi. We call this operation unfolding the pointed path φ(w). The
folding operation is illustrated in Figure 2.

a2 = 2

a1 = 3
a0 = 1

puq0uq1uq2

pq0dq1dq2d

Figure 2: Left: a decorated 3-Dyck preﬁx of length 22 and height 10 (n′ = 5,
h′ = 2 and r = 2). Right:
its image by the folding operator φ, a pointed
3-Łukasiewicz path.

Theorem 1. The folding operation φ is a bijection from decorated m-Dyck
preﬁxes to pointed m-Łukasiewicz paths.

3

Proof. Let w be an m-Dyck preﬁx of height h written as (1) and, for i = 0, . . . , k,
let ai be the height of uqi (for now, without any constraint on k or the ai’s).
The proof of the lemma hinges on the three following facts.

• For i = 0, . . . , k, the path qid is m-Łukasiewicz if and only if ai ≤ m.
• Since φ(w) is obtained from w by turning k + 1 up steps into down steps,

we have h′(φ(w)) = −1 if and only if h′(w) = k.

• If the factors qid are m-Łukasiewicz and if h′(φ(w)) = −1, the folded
path φ(w) is m-Łukasiewicz if and only if the starting height of the fac-
tor qkd is nonnegative. Since the ﬁnal height is r−m−1, this is equivalent
to ak ≤ r.

Together, these facts show that the folding of a decorated m-Dyck preﬁx is
an m-Łukasiewicz path and, conversely, that unfolding a pointed m-Łukasiewicz
path yields a decorated m-Dyck preﬁx. Moreover, the ﬁrst fact shows that the
folding and unfolding operations are inverse.

Proposition 2. The number Ln of m-Łukasiewicz paths of length n is:

Ln =

r

n(cid:18) n
n′(cid:19).

(3)

Let Pn(u) =Pw uh′(w) where the sum runs over all m-Dyck preﬁxes of length n.

We have:

Pn(m) =(cid:18) n
n′(cid:19).

(4)

When m = 1, one recovers the well-known results on the enumeration of

Dyck paths (the evaluation Pn(1) is simply the number of Dyck preﬁxes).

Proof. Let qd be an m-Łukasiewicz path of length n. We transform it into the
path uq, which is a path of height r staying strictly above its origin. This ﬁts
the conditions of the Cycle Lemma, which states that a proportion r/n of the
paths with n′ down steps have that property. This gives the formula for Ln.

To enumerate m-Dyck preﬁxes, we use our bijection when r 6= 0. There
are nLn pointed m-Łukasiewicz paths and therefore nLn decorated m-Dyck
preﬁxes. Every preﬁx with reduced height h′ has rmh′
possible decorations,
which gives the result.

If r = 0, this breaks down because there are no m-Łukasiewicz paths. The
m-Dyck preﬁxes of length n are then the preﬁxes of length n− 1 plus a single d
or u step. This gives Pn(u) = (1 + u)Pn−1(u), which implies the formula.

4 Random sampling

In this section, we show how to use the unfolding bijection to build a very
eﬃcient random sampling algorithm for m-Dyck paths. In fact, our algorithm
returns a uniformly distributed m-Łukasiewicz path; to draw an m-Dyck path
of length n, it suﬃces to draw an m-Łukasiewicz path of length n + 1 and delete
the ﬁnal d step. In the case m = 1, the algorithm already appeared in [2], but
the time complexity analysis is new.

4

Algorithm 1: Random m-Łukasiewicz path

Input: A length n not divisible by m + 1
Output: A random m-Łukasiewicz path of length n

1 w ← ε
2 for i = 1, . . . , n do

3

4

5

6

m+1 , wd with probability

w ←(cid:0)wu with probability m

if h(w) < 0 then

draw uniformly a point in w
w ← φ−1(w) (forget the decoration)

1

m+1(cid:1)

7 draw uniformly a decoration of w
8 w ← φ(w) (forget the point)
9 return w

Theorem 3. Algorithm 1 returns a uniformly distributed m-Łukasiewicz path
of length n.

Before proving the theorem, we state our results on the complexity. We
choose two models of complexity, which account for the overwhelming majority
of the execution time in practice: the number Rn of random bits drawn and
the number Mn of memory accesses. We show that both complexities are linear
and derive their limit laws.

Let β be the number of random bits necessary to draw a Bernoulli variable of
m+1 . Moreover, let S be an inhomogeneous Poisson process on (0, 1]

parameter

1

with density λ(x) = 1(cid:14)2x. Let X be the random variable:

Unif[0, x],

X = Xx∈S

where all uniforms are independent from each other and from S. Let U ∼
Unif[0, 1] independent from S.

Theorem 4. The random variables Rn and Mn satisfy, as n tends to inﬁnity:

Rn
n

d−→ β;

Mn
n

d−→ 1 + X + U .

The cost β of drawing a Bernoulli variable is bounded from below by its

entropy:

β ≥ η,

η = − 1

m+1 log2(cid:0) 1

m+1(cid:1) − m

m+1 log2(cid:0) m
m+1(cid:1).

With Knuth and Yao’s algorithm [10], it is possible, with suﬃcient grouping, to
reach a value of β as close to η as desired. Since an m-Dyck path of length n
has entropy asymptotically ηn (as can be seen from (3)), the number of random
bits drawn by the algorithm can thus be made to be asymptotically optimal.

The random variable X is studied in more detail in Section 5; there, we
show that E(X) = 1/4 and V(X) = 1/12. With the values E(U ) = 1/2 and
V(U ) = 1/12, this entails estimates for the expectation and variance of Mn:

E(Mn) ∼

7n
4

;

V(Mn) ∼

n2
6

.

5

The crucial point in the proof of both theorems is a loop invariant given in the
lemma below. Consider a uniformly distributed decorated m-Dyck preﬁx; let w
be its underlying path. Since there are rmh′(w) possible decorations of w and r
depends only on n, the path w is distributed with a probability proportional
to mh′(w). We denote by Πn that distribution on the m-Dyck preﬁxes.

Lemma 5. Let 0 ≤ i ≤ n and let r = i mod m + 1. After i iterations of the for
loop, the path w is distributed according to Πi. Moreover, let Bi be the event
that the if branch is taken. The events Bi are independent and satisfy:

P(Bi) =

r

mi + r

.

Proof. We work by induction on i. First, consider the path w after adding a
random step. Since a u step is m times as likely to be drawn than a d step, the
probability of a given path w to appear is proportional to mh′(w).

We now study the distribution of w after the if branch, distinguishing

whether or not it was taken.

• If the if branch is not taken, the path w is an m-Dyck preﬁx, distributed

according to Πi+1.

• If the if branch is taken, the path w is a uniformly distributed m-Łukasie-
wicz path since h′(w) = −1. After pointing and unfolding, it is therefore
a uniformly distributed decorated m-Dyck preﬁx, which means that it is
distributed like Πi+1 after forgetting the point.

This shows that w is distributed like Πi+1. Moreover, the probability that the
branch is taken and not taken are proportional to Lnm−1 and Pn(m), respec-
tively (see Proposition 2), which gives the value of P(Bi). The independence
comes from the fact that w does not depend on whether the branch is taken.

Proof of Theorem 3. According to Lemma 5, after the execution of the for loop,
the path w is distributed like Πn. Drawing a random decoration therefore yields
a uniformly distributed decorated m-Dyck preﬁx. After folding, the result is
thus a uniformly distributed m-Łukasiewicz path.

Proof of Theorem 4. Let us begin with the random bit cost. There are three
places in the algorithm which contribute to it and we analyse them separately.

• Drawing steps (Line 3). This costs nβ random bits.
• Randomly pointing the path (Line 5). This costs O(log i) if done at the ith
iteration of the loop. According to Lemma 5, this happens with probability
O(1/i). Summing for i = 1, . . . , n, the average total cost is O(log2 n).

• Randomly decorating the path (Line 7). This costs O(h), where h is the
height of w. To estimate this, we use [3, Theorem 6]. Since the probability
of a path w is proportional to m raised to the power of its number of up
steps, that path is distributed like a random meander with drift zero (see

the reference for details), which proves that the average height is O(√n).

Overall, only the cost of Line 3 is signiﬁcant. Let us move on to the cost in
memory accesses, which also occur in three places.

6

• Writing steps (Line 3). This costs n memory accesses.
• Unfolding the path (Line 6). Unfolding a pointed path pq of length i only
requires accessing the part q. Since the point is uniformly drawn, the
cost is uniformly distributed in {1, . . . , i}. Moreover, observe that the
probability for this to occur given in Lemma 5, when averaged over m + 1
consecutive values of i, is equivalent to 1(cid:14)2i.

Let Sn be the set of sizes i such that Bi holds. Since the Bi’s are indepen-
dent, the set Sn/n converges to the Poisson point process S. Therefore,
the number of memory accesses divided by n tends in distribution to X.

• Folding the path (Line 8). Folding a path into a pointed m-Łukasiewicz
path pq only requires to access the part q. Since that path is uniformly
distributed, the length of q is uniformly distributed in {1, . . . , n}.

Summing all three contributions (which are independent) yields the result.

5 Properties of the limit distribution

This last section consists in the study of the limit law X involved in Theorem 4.

Theorem 6. The cumulants of the variable X are:

κn(X) =

1

2n(n + 1)

.

In particular, we have E(X) = κ1(X) = 1/4 and V(X) = κ2(X) = 1/12.
Moreover, the theorem can be reformulated in terms of the cumulant generating
function of X:

dy.

(5)

K(z) =Z z

0

ey − 1 − y

2y2

Proof. We compute the cumulant generating function of X from its deﬁnition,
knowing that the moment generating function of Unif[0, x] is (exz − 1)/(xz):

K(z) =Z 1

0 (cid:18) exz − 1

xz − 1(cid:19) dx

2x

,

which is equivalent to (5) by a change of variables. The cumulants are extracted
by Taylor expansion around z = 0.

Our ﬁnal results concern the distribution function F (x) = P(X ≤ x) and

tail distribution ¯F (x) = P(X > x).

Theorem 7. The function F satisﬁes, for x > 0, the diﬀerential equation:

F (x) + F ′(x) + 2xF ′′(x) = F (x − 1).

For 0 ≤ x ≤ 1, its value is:

F (x) =r 2e1−γ

π

sin √2x,

(6)

(7)

where γ is Euler’s constant. As x tends to inﬁnity, the tail distribution satisﬁes:

¯F (x) = x−x(log x)−2x(e/2)x+o(x).

(8)

7

Note that the equation (6), with the initial conditions (7), suﬃces to deter-
mine F . Indeed, working inductively on the intervals [n, n + 1], it can be seen as
an inhomogeneous ordinary linear diﬀerential equation with initial conditions
given by diﬀerentiability at n.

Moreover, we can deduce from that equation the singularity proﬁle of F :
since F is not diﬀerentiable at 0, F ′′
is not diﬀerentiable at 1 due to the
term F (x − 1). In the same way, F has a singularity at every integer point n,
where it is exactly 2n times continuously diﬀerentiable.
Finally, since F is twice diﬀerentiable for x > 0, the distribution X admits

a density function f = F ′, which shares similar properties.

1

0

F0(x)

1

x

1

0

F (x)

1

x

Figure 3: Left: a plot of the function F0(x) = p2e1−γ /π sin √2x. Right: a

plot of the distribution function F (x) computed from the diﬀerential equation
(6). The function F (x) is equal to F0(x) until x = 1 and then deviates from it.

Proof. We prove these results using the Laplace transform of F , which is given
by LF (z) = eK(−z)/z. From (5), we get:

−2z2LF

′(z) = (e−z − 3 + z)LF (z),

which translates into (6) whenever F is twice diﬀerentiable. We now put the
Laplace transform into the form1 , valid for z 6∈ R−:
2z exp(cid:18)Z ∞
2z + O(cid:18) e−z
z7/2(cid:19)

√e1−γ
z3/2 e− 1
√e1−γ
z3/2 e− 1

LF (z) =

dy(cid:19)

e−y
2y2

=

z

as |z| tends to inﬁnity in any direction. The main term transforms back into (7)
(see [1, 29.3.78]). The inverse transform of the error term is supported for
x ≥ 1 (since it is O(e−z) as z tends to inﬁnity) and is twice diﬀerentiable (since,
multiplied by z2, it is integrable on iR). This proves (6) and (7).

Getting the asymptotics for large x is trickier. We use a saddle point ap-
proximation, widely used in statistics to estimate tail densities and distributions
[6, 12]. General saddle point asymptotics are described in detail in [9, Chap-
ter VIII]. We compute the tail distribution using the formula, valid for c > 0:

¯F (x) =

e−xz+K(z)

2πiZ c+i∞
1This comes from the fact thatR 1
be derived by integrating by parts twice to get −R ∞

e−y/y2dy = γ, which can itself
e−y log ydy. That integral is also linked
to the exponential integral function, in which the constant γ famously plays a role (see for
instance [1, Chapter 5]).

− 1 + y)/y2dy +R ∞

(e−y

c−i∞

0

1

dz.

z

1

0

8

Write ξ(z) = K(z)− log z. We choose c to be the real point where the integrand
is smallest (the saddle point), given by:

ξ′(c) =

ec − 1 − 3c

2c2

= x.

This entails:

c = log x + 2 log log x + log 2 + o(1).

Moreover, ξ(c) and all its derivatives are asymptotic to ec(cid:14)2c2 ∼ x.

Let d = x−a with 1/3 < a < 1/2 and let ¯F0(x) and ¯F1(x) be:

1

2πiZ c+id
¯F0(x) =
¯F1(x) = ¯F (x) − ¯F0(x).

c−id

e−xz+ξ(z)dz;

We prove below that all the weight of the integral is concentrated in ¯F0(x) and
that we have the saddle point approximation:

¯F (x) ∼ ¯F0(x) ∼

e−xc+ξ(c)
√2πx

.

(9)

This evaluates to (8) (the denominator is subsumed into the error term).

To show that the approximation (9) is valid, we check that the conditions

detailed in [9, Theorem VIII.3] are satisﬁed.

• First, we need to check that ¯F0(x) satisﬁes (9). To do that, we do a Taylor

expansion of ξ(z) around the point c:

ξ(z) = ξ(c) + x(z − c) +

ξ′′(c)

2

(z − c)2 + O(cid:0)ξ′′′(c)(z − c)3(cid:1).

Since ξ′′′(c)d3 ∼ xd3 → 0, the error term tends in fact to zero, uniformly
for all z such that |z − c| ≤ d. This entails that ¯F0(x) is approximated by
the integral:

¯F0(x) ∼

e−xc+ξ(c)

2π

Z d

−d

e− ξ′′(c)t2

2

dt.

Since ξ′′(c)d2 ∼ xd2 → ∞, the integral can be completed to R, which gives
a Gaussian integral evaluating to (9).

• Second, we need to check that the integral ¯F1(x) is negligible. Using the

estimate (9) of ¯F0(x), we compute:

¯F1(x)

¯F0(x)(cid:12)(cid:12)(cid:12)(cid:12)

(cid:12)(cid:12)(cid:12)(cid:12)

where:

c

3/2

2π

≤r x
2π Z|t|>d(cid:12)(cid:12)eξ(c+it)−ξ(c)(cid:12)(cid:12)dt
≤r x
eρ(x)Z|t|>d(cid:12)(cid:12)(cid:12)
c + it(cid:12)(cid:12)(cid:12)
= O(cid:0)c√xeρ(x)(cid:1),
R(cid:18)Z c+it
dy(cid:19).

ey − 1
2y2

dt

ρ(x) = sup
|t|>d

c

9

This means that the ratio ¯F1(x)/ ¯F0(x) tends to zero as soon as ρ(x) tends
to −∞ suﬃciently fast (like a power of x). To show this, we set the contour
of integration to c → 1 → 1 + it → c + it, which follows the direction of
steepest descent around the endpoints and avoids the singularity at zero.
The contribution of the interval [1, 1+it] is bounded, as is the contribution
of the term 1/y2. Grouping the other two intervals together, we ﬁnd:

ρ(x) ∼ sup

1

es

2(s + it)2 −
es
es

|t|>d Z c
R(cid:18) es+it
|t|>d Z c
1 (cid:18)
≤ sup
2(s2 + t2) −
ect2
|t|>d −
∼ sup

2s2(cid:19)ds
2s2(cid:19)ds
2c2(c2 + d2) ∼ −

2c2(c2 + t2)

= −

ecd2

x1−2a
log2 x

.

This concludes the proof.

References

[1] M. Abramowitz and I. A. Stegun. Handbook of mathematical functions with formulas,
graphs, and mathematical tables, volume 55 of National Bureau of Standards Applied
Mathematics Series. For sale by the Superintendent of Documents, U.S. Government
Printing Oﬃce, Washington, D.C., 1964.

[2] A. Bacher, O. Bodini, and A. Jacquot.

Eﬃcient

nary and unary-binary trees
http://arxiv.org/abs/1401.1140.

via holonomic

equations.

random sampling of bi-
2014.

Submitted,

[3] C. Banderier and P. Flajolet. Basic analytic combinatorics of directed lattice paths.
Theoret. Comput. Sci., 281(1-2):37–80, 2002. Selected papers in honour of Maurice
Nivat.

[4] E. Barcucci, R. Pinzani, and R. Sprugnoli. The random generation of directed animals.

Theoret. Comput. Sci., 127(2):333–350, 1994.

[5] E. Barcucci, R. Pinzani, and R. Sprugnoli. The random generation of underdiagonal
walks. Discrete Math., 139(1-3):3–18, 1995. Formal power series and algebraic combi-
natorics (Montreal, PQ, 1992).

[6] H. E. Daniels. Saddlepoint approximations in statistics. Ann. Math. Statist., 25:631–650,

1954.

[7] L. Devroye. Simulating size-constrained Galton-Watson trees. SIAM J. Comput.,

41(1):1–11, 2012.

[8] P. Duchon. On the enumeration and generation of generalized Dyck words. Dis-
crete Math., 225(1-3):121–135, 2000. Formal power series and algebraic combinatorics
(Toronto, ON, 1998).

[9] P. Flajolet and R. Sedgewick. Analytic combinatorics. Cambridge University Press,

Cambridge, 2009.

[10] D. E. Knuth and A. C. Yao. The complexity of nonuniform random number generation.
In Algorithms and complexity (Proc. Sympos., Carnegie-Mellon Univ., Pittsburgh, Pa.,
1976), pages 357–428. Academic Press, New York, 1976.

[11] M. Lothaire. Applied combinatorics on words, volume 105 of Encyclopedia of Mathe-

matics and its Applications. Cambridge University Press, Cambridge, 2005.

[12] R. Lugannani and S. Rice. Saddle point approximation for the distribution of the sum

of independent random variables. Adv. in Appl. Probab., 12(2):475–490, 1980.

[13] J. Remy. Un procédé itératif de dénombrement d’arbres binaires et son application a

leur génération aléatoire. ITA, 19(2):179–195, 1985.

[14] R. P. Stanley. Enumerative combinatorics. Vol. 2, volume 62 of Cambridge Studies in

Advanced Mathematics. Cambridge University Press, Cambridge, 1999.

10

