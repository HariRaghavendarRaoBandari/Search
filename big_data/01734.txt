Freiman homomorphisms on sparse random sets

D. Conlon∗

W. T. Gowers†

6
1
0
2

 
r
a

M
5

 

Abstract

A result of Fiz Pontiveros shows that if A is a random subset of ZN where each element
is chosen independently with probability N −1/2+o(1), then with high probability every Freiman
homomorphism deﬁned on A can be extended to a Freiman homomorphism on the whole of ZN . In
this paper we improve the bound to CN −2/3(log N )1/3, which is best possible up to the constant
factor.

 
 
]

.

O
C
h
t
a
m

[
 
 

1
v
4
3
7
1
0

.

3
0
6
1
:
v
i
X
r
a

1

Introduction

A Freiman homomorphism from a subset A ⊂ ZN to ZN is a function φ : A → ZN with the property
that φ(a) + φ(b) = φ(c) + φ(d) whenever a, b, c and d are elements of A with a + b = c + d. If φ is an
aﬃne function, meaning that there exist r and s such that φ(a) = ra + s for every a ∈ A, then clearly
φ is a Freiman homomorphism. It is also easy to prove that every Freiman homomorphism from ZN
to ZN is aﬃne. From this it follows that a Freiman homomorphism deﬁned on A is aﬃne if and only
if it can be extended to a Freiman homomorphism on the whole of ZN .

Over the last ten years or so, a number of results have been proved that show that important
combinatorial and additive properties of structures such as complete graphs and ﬁnite Abelian groups
are preserved when one passes to random subsets of those structures of surprisingly low density.
We will not attempt an exhaustive summary of this area here, referring the reader instead to the
papers [2, 4, 5, 7, 10, 11] and the surveys [3, 9].
In the light of these developments, it is natural
to ask whether with high probability every Freiman homomorphism deﬁned on a random subset of
ZN must be aﬃne. It turns out to be an easy exercise to show that if the elements of A are chosen
independently with probability CN −1/3, then this is indeed the case. Recently, Fiz Pontiveros [6]
proved the signiﬁcantly harder result that this remains true if the elements of A are chosen with
probability N −1/2+o(1).

In the other direction, it is easy to see that the result is false if the elements of A are chosen with
probability N −2/3/2. Indeed, for each element a, the expected number of triples (b, c, d) ∈ A3 with
a + b = c + d and no two of a, b, c and d equal is at most N 2(N −2/3/2)3 = 1/8, from which it follows
that there is a high probability that there will be an “isolated” element a ∈ A that belongs to no
non-trivial quadruple a + b = c + d. But that implies that however we choose φ(a) we will not violate
the condition for φ to be a Freiman homomorphism.

With a little more eﬀort, one can show that even if we choose elements independently with proba-
bility c(log N )1/3N −2/3, for a suﬃciently small positive constant c, there is still a signiﬁcant probability

∗Mathematical Institute, Woodstock Road, Oxford OX2 6GG, UK. E-mail: david.conlon@maths.ox.ac.uk. Research

supported by a Royal Society University Research Fellowship.

†Department of Pure Mathematics and Mathematical Statistics, Wilberforce Road, Cambridge CB3 0WB, UK. Email:

w.t.gowers@dpmms.cam.ac.uk. Research supported by a Royal Society 2010 Anniversary Research Professorship.

1

that some of the elements of A will be isolated in this sense. Therefore, the best result that one can
hope for is a probability on the order of (log N )1/3N −2/3. We shall obtain a bound of this form.

Theorem 1.1 There exists a positive constant C such that if A is a random subset of ZN where each
element is chosen independently with probability C(log N )1/3N −2/3, then, with high probability, every
Freiman homomorphism from A to ZN is aﬃne.

It is also possible to show by similar methods that if the elements of A are chosen with probability
CN −2/3, then, with high probability, for every Freiman homomorphism φ deﬁned on A there is an aﬃne
function that agrees with φ on most of A. We have not shown this in detail, because the additional
factor of (log N )1/3 that is needed for our main result to be true also simpliﬁes other aspects of the
proof.

Theorem 1.1 is somewhat unexpected because the bound obtained by Fiz Pontiveros is a natural
boundary for his method and could lead one to think that his result is best possible. His proof is based
on the following idea. If φ is a Freiman homomorphism deﬁned on A, then one can deﬁne a function
ψ on A − A by taking ψ(a − b) to be φ(a) − φ(b). This is well-deﬁned because if a − b = c − d, then
φ(a) − φ(b) = φ(c) − φ(d). Fiz Pontiveros proves that φ is an aﬃne function by noting that A − A
is, with high probability, the whole of ZN and then proving that ψ is an additive function: that is,
ψ(x + y) = ψ(x) + ψ(y) for every x and y. This implies that ψ is linear and hence that φ is aﬃne.

However, the diﬀerence set A − A trivially ceases to be the whole of ZN once p goes below N −1/2,
which is why N −1/2 is as far as Fiz Pontiveros’s argument will go. Indeed, one can say more. For any
non-zero x, the expected number of pairs (a, b) ∈ A2 such that a − b = x is p2N , so if p is substantially
less than N −1/2, as it will be for us, then this expectation is substantially less than 1. Moreover, even
when x is an element of A − A, this will almost always happen in just one way, so it seems as though
it ought to be very hard for the values of φ on one part of A to inﬂuence the values it takes on other
parts. However, all is not quite lost, because if p = C(log N )1/3N −2/3, then for each a ∈ ZN , and
in particular for each a ∈ A, the expected number of triples (b, c, d) ∈ A3 such that a + b = c + d
and no two of a, b, c and d are equal is roughly C 3 log N . Therefore, a typical element of A will feel
the inﬂuence from the rest of the set. Nevertheless, it is quite surprising that one can obtain a global
result when the average number of such triples is so small.

The proof of Theorem 1.1 has three parts. To begin, we prove a transference principle similar
to that used in [4] to prove a number of analogues of combinatorial theorems in sparse random sets.
One of the main tools we used there was the ﬁnite-dimensional Hahn–Banach separation theorem.
In this paper, we shall also use the Hahn–Banach theorem, but this time it is the complex version
of the theorem that will be useful to us, and the way we use it will be diﬀerent. We then use this
complex-valued transference principle to prove that any Freiman homomorphism from A to ZN agrees
on most of A with an aﬃne function. In [4], our results were usually straightforward corollaries of the
transference principle. Here, a number of additional ideas are needed to make the argument work.
Finally, we conclude with a short argument showing that any function which is aﬃne on most of A is
actually aﬃne on all of A. Since our proof does not depend in a serious way on the structure of ZN ,
we shall prove the following more general result.

Theorem 1.2 There exists a positive constant C such that if G is an Abelian group of order n and U
is a random subset of G where each element is chosen independently with probability C(log n)1/3n−2/3,

2

then, with high probability, every Freiman homomorphism from U to a ﬁnitely generated Abelian group
H can be extended to a Freiman homomorphism deﬁned on all of G.

The condition that H is ﬁnitely generated is not important, since we can always restrict to the
subgroup generated by the image of U ; it is there to allow us to take expectations over the characters
of H. Note that a Freiman homomorphism deﬁned on all of G is simply an aﬃne homomorphism: that
is, a map of the form g 7→ φ(g) + h for some group homomorphism φ and some h ∈ H. Thus, the result
is saying that all Freiman homomorphisms deﬁned on U are restrictions of aﬃne homomorphisms.

2 Consequences of the complex ﬁnite-dimensional Hahn–Banach the-

orem

The version of the Hahn–Banach theorem that we shall rely on is the following. Recall that, given a
norm k.k on a vector space X, the dual norm k.k∗ of k.k is a norm on the collection of linear functionals
φ acting on X, given by

kφk∗ = sup{|φ(x)| : kxk ≤ 1}.

Theorem 2.1 Let k.k be a norm on Cn for some positive integer n and let φ be a linear functional
deﬁned on a subspace X of Cn. Then φ can be extended to a linear functional ψ on Cn with kψk∗ =
kφk∗.

In particular, this theorem has the following corollary. Recall that a subset of Cn is absolutely

convex if it is convex and closed under multiplication by scalars of modulus 1.

Corollary 2.2 Let K and L be two closed bounded absolutely convex subsets of Cn and suppose that
0 belongs to the interior of K + L. Let v ∈ Cn be a vector that does not belong to K + L. Then there
exists a linear functional ψ such that ψ(v) > 1 and |ψ(w)| ≤ 1 for every w ∈ K ∪ L.

Proof. Deﬁne a norm k.k on Cn by kvk = inf{|λ| + |µ| : v ∈ λK + µL}. The absolute convexity of K
and L guarantees that this is a norm. Then kvk > 1, since otherwise for every ǫ > 0 we would be able
to ﬁnd x ∈ K and y ∈ L and complex scalars λ and µ with |λ| + |µ| ≤ 1 + ǫ such that v = λx + µy.
By the compactness of K and L and the fact that both are closed under multiplication by scalars of
modulus at most 1, it would then follow that v ∈ K + L.

Since kvk > 1, the linear functional φ deﬁned on the 1-dimensional subspace generated by v given
by φ(λv) = λkvk has dual norm 1, and φ(v) = kvk > 1. By Theorem 2.1, we can extend φ to a linear
functional ψ deﬁned on all of Cn such that kψk∗ ≤ 1. From this last property, we see that if w ∈ K
then |ψ(w)| ≤ kwk ≤ 1, and similarly if w ∈ L. This proves the lemma.
✷

The main result of this section is the following further corollary. We will use the fact that every
linear functional on a Hilbert space is of the form h · , φi for some φ, where the inner product of two
functions f, g : X → C is given by hf, gi = Exf (x)g(x). By saying that a function is a measure on a
ﬁnite set X, we mean that it is a non-negative function from X to R.

Corollary 2.3 Let µ and ν be measures on a ﬁnite set X and let k.k be a norm on CX. Suppose that
|hµ − ν, |φ|i| ≤ ǫ for every function φ such that kφk∗ ≤ η−1. Let f be a function such that |f | ≤ µ.
Then there exists a function g such that 0 ≤ |g| ≤ (1 − ǫ)−1ν and kf − gk ≤ η.

3

Proof. Suppose that we cannot ﬁnd such a g. Then f /∈ K + L, where K = {g : 0 ≤ |g| ≤ (1 − ǫ)−1ν}
and L = {h : khk ≤ η}. Since both K and L are closed, bounded, and absolutely convex, it follows
from Corollary 2.2 that there exists φ such that hf, φi > 1, |hg, φi| ≤ (1 − ǫ) whenever 0 ≤ |g| ≤ ν,
and |hh, φi| ≤ 1 whenever khk ≤ η. The third condition tells us that kφk∗ ≤ η−1. The second tells us
that hν, |φ|i ≤ 1 − ǫ, since the function g that maximizes |hg, φi| subject to the constraint that |g| ≤ ν
is the function g(x) = ν(x)eiarg(φ(x)), and for that g we have hg, φi = hν, |φ|i. From these facts and
our hypothesis we deduce that

1 < hf, φi ≤ h|f |, |φ|i ≤ hµ, |φ|i ≤ ǫ + hν, |φ|i ≤ 1,

a contradiction.

✷

3 A norm to which the Hahn–Banach argument will be applied

Let G be an Abelian group of order n and let Γ be the set of all non-degenerate additive quadruples
in G. That is, Γ is the set of all quadruples (x, y, z, w) such that x + y = z + w and neither x nor y is
equal to z or w. For every function f we deﬁne a quantity M (f ) to be E(x,y,z,w)∈Γf (x)f (y)f (z)f (w).
Before we continue, we make a quick remark. It is important to consider non-degenerate additive
quadruples only, since in a random set of density n−2/3, the non-degenerate additive quadruples
are swamped by the degenerate ones.
Indeed, the number of non-degenerate additive quadruples
is approximately n3−8/3 = n1/3, whereas the number of degenerate additive quadruples is around
(n1/3)2 = n2/3.
(The density at which there are roughly equal numbers of degenerate and non-
degenerate additive quadruples is n1/2, which is another reason for the natural-seeming barrier there.)
At ﬁrst this appears to be a serious problem, because the quantity M (f ) that we have deﬁned is
not the fourth power of a norm. However, it turns out not to matter, because the norm we use is
constructed in a diﬀerent way from the U 2 norm.

Let U be a random subset of G with characteristic measure µ. (The characteristic measure of a
set is its characteristic function divided by its density. Thus, µ is zero outside U , constant inside U ,
and has average value 1.) We shall show that, with high probability, for every function f from G to
C such that |f | ≤ µ there exists a function g with the following three properties:

1. kgk∞ ≤ 1;

2. M (g) ≈ M (f );

3. hg, τ i ≈ hf, τ i for every character τ : G → C.

The approach we use to obtain this transference result is closely related to the approach we used
in [4], though in that paper we used the real Hahn–Banach theorem. We begin by deﬁning a norm
k.k with the property that if kf − gk is small, then conclusions 2 and 3 above hold. For this, we begin
with a simple observation. Write M (f, g, h, k) for the quantity E(x,y,z,w)∈Γf (x)g(y)h(z)k(w). (Thus,
M (f ) can be thought of as shorthand for M (f, f, f, f ).) Then M is additive in all four variables, so

M (f ) − M (g) = M (f − g, f, f, f ) + M (g, f − g, f, f ) + M (g, g, f − g, f ) + M (g, g, g, f − g).

Each of the four expressions on the right-hand side can be regarded as the inner product of f − g with
another function. For example, M (g, g, f − g, f ) = hh, f − gi, where h(z) = E(x,y,z,w)∈Γg(x)g(y)f (w).

4

This motivates the following deﬁnitions. First, for any x ∈ ZN , let us deﬁne Γx to be the set of triples
(y, z, w) such that (x, y, z, w) ∈ Γ. These triples satisfy the equation z + w − y = x, but they also
satisfy the non-degeneracy condition.

Now deﬁne a basic anti-uniform function to be any function from G to C of the form

u(x) = E

(y,z,w)∈Γxh1(y)h2(z)h3(w),

where each hi either satisﬁes khik∞ ≤ 1 or |hi(v)| ≤ µ(v) for every v. Then each of the four terms on
the right-hand side of the equation above is the inner product of f − g with some basic anti-uniform
function (with f − g either on the left or on the right). Therefore, if all such inner products are
small, then M (f ) ≈ M (g). If h1 = h2 = h3 = τ for some character τ , then u = τ , since for every
(y, z, w) ∈ Γx we have ¯τ (y)τ (z)τ (w) = τ (x). Therefore, all characters are basic anti-uniform functions
and we also obtain the third condition.

We now deﬁne a norm k.k by setting kf k to be the maximum of |hf, ui| over all basic anti-uniform

functions u. From the discussion above, the following lemma follows easily.

Lemma 3.1 Let G be a ﬁnite Abelian group, let f and g be functions from G to C, and let k.k be the
norm just deﬁned. Then |M (f ) − M (g)| ≤ 4kf − gk.

Proof. As commented above, M (f ) − M (g) can be written as a sum of four terms, each of which is
an inner product of f − g with a basic anti-uniform function.
✷

We now want to apply Corollary 2.3. To do that, we need an expression for the dual norm of the
norm k.k we have just deﬁned. The following lemma is a standard fact, which can be proved easily
with the help of the Hahn–Banach theorem.

Lemma 3.2 Let X be a ﬁnite set and let k.k be a norm on CX deﬁned by a formula of the form
kf k = max{|hf, ψi| : ψ ∈ Ψ}. Then the dual norm k.k∗ is given by the formula

n

kφk∗ = inf{

Xi=1

|ai| : φ =

n

Xi=1

aiψi, ψi ∈ Ψ}.

The fact that CX is ﬁnite-dimensional implies also that this inﬁmum is attained. So the condition
in Corollary 2.3 that kφk∗ ≤ η−1 implies that φ can be written as a linear combination of basic
anti-uniform functions with the absolute values of the coeﬃcients summing to at most η−1.

We want to apply Corollary 2.3 with µ being the characteristic measure of a sparse random set U
and with ν being the constant function 1. Therefore, we need to establish that |hµ − 1, |φ|i| is small
whenever φ is of the form just described. Before we start on this, we must ﬁnd a way to deal with the
fact that we are looking at |φ|, which cannot be described as easily as φ. This we do with the help of
the following lemma, which is a special case of the Stone–Weierstrass theorem.

Lemma 3.3 For every pair of real numbers C, ǫ > 0 there exists a polynomial P in z and z that
uniformly approximates the function |z| to within ǫ on the disc {z : |z| ≤ C}.

From this we obtain a further reduction of what we hope to prove.

5

Corollary 3.4 For every ǫ > 0 and every real number C there exist δ > 0 and a positive integer k
with the following property. Let µ be a measure on G with Eµ = 1 and let k.k be the norm deﬁned
earlier on CG. Suppose that |hµ − 1, ξi| ≤ δ for every ξ that can be written as a product of at most
k basic anti-uniform functions. Suppose also that kuk∞ ≤ 2 for every basic anti-uniform function.
Then |hµ − 1, |φ|i| ≤ ǫ for every function φ such that kφk∗ ≤ C.

a linear combination Pn

Proof. Let P be a polynomial in z and z that approximates |z| to within ǫ/3 on the closed disc of
radius 2C. Then kP ◦ φ − |φ|k∞ ≤ ǫ/3 for every function φ : G → C with kφk∞ ≤ 2C. By assumption,
kuk∞ ≤ 2 for every basic anti-uniform function u, so, by Lemma 3.2, kφk∞ ≤ 2C whenever kφk∗ ≤ C.
By Lemma 3.2 again, and also the remark following it, if kφk∗ ≤ C then we can express φ as
i=1 aiψi, where the ψi are basic anti-uniform functions. Since the pointwise
complex conjugate of a basic anti-uniform function is also a basic anti-uniform function, it follows that
P ◦ φ is a linear combination of products of at most k basic anti-uniform functions, where k is the
degree of P and the sum of the absolute values of the coeﬃcients in the linear combination is bounded
above by a constant M that depends on P and C only. (A bound that works is Q(C), where Q is the
polynomial obtained from P by replacing each coeﬃcient by its absolute value.)

If we set δ = ǫ/3M , then we obtain the upper bound |hµ − 1, P ◦ φi| ≤ ǫ/3 for every φ with
kφk∗ ≤ C. Since kP ◦ φ − |φ|k∞ ≤ ǫ/3 and kµk1 = k1k1 = 1, it follows that |hµ − 1, |φ|i| ≤ ǫ, as
claimed.
✷

The main task ahead of us, therefore, is to prove that under suitable circumstances we have the
hypothesis that |hµ − 1, ξi| ≤ δ for every product ξ of at most k basic anti-uniform functions. For this
we shall need some probabilistic lemmas, proved in the next section, followed by an argument similar
to one in [4] that established a result of this type. However, the argument in this paper is substantially
simpler, because the factor of (log n)1/3 in our probability allows us to prove that certain functions
are uniformly bounded rather than bounded almost everywhere. (We stress that we do not introduce
the logarithmic factor merely to simplify the proof: for this problem it gives the correct bound up to
a constant factor.)

4 Some probabilistic lemmas

We begin with the standard Chernoﬀ bound.

Lemma 4.1 Let X be a set of size n, let 0 < δ ≤ 1, let p ∈ [0, 1] and let U be a random subset of X
where each element is chosen independently with probability p. Then

P(cid:2)(cid:12)(cid:12)|U | − pn(cid:12)(cid:12) > δpn(cid:3) ≤ 2 exp(−δ2pn/3).

Amongst other things, this lemma allows us to ignore the diﬀerence between the characteristic measure
µ of U , deﬁned by µ(x) = |X|/|U | if x ∈ U and 0 otherwise, and its associated measure, deﬁned by
µ′(x) = p−1 if x ∈ U and 0 otherwise. For example, in the next section, we will actually prove that
with high probability |hµ′ − 1, ξi| ≤ δ for every product ξ of at most k basic anti-uniform functions
built relative to µ′, but the result for the characteristic measure is an immediate corollary.

Lemma 4.2 Let U1 and U2 be two random subsets of an Abelian group G of size n, each with elements
chosen independently with probability p. Then the probability that there exists an element of G that
can be written in four ways as u1 + u2 with u1 ∈ U1 and u2 ∈ U2 is at most n5p8.

6

Proof. Fix x ∈ G and for each u let E(u) be the event that u ∈ U1 and x − u ∈ U2. Then the
events E(u) are independent and each holds with probability p2, so the expected number of quadruples
(u1, u2, u3, u4) with distinct elements such that E(u1), E(u2), E(u3) and E(u4) all hold is at most n4p8.
Therefore, the probability that x can be written in four ways as the sum of an element of U1 and an
element of U2 is at most n4p8, so the probability that some x can be written in four ways is at most
n5p8, as claimed.
✷

We shall apply this result with p = Cn−2/3(log n)1/3, and the main consequence we shall need is
that the probability tends to zero. (If we had replaced the number of ways by three, then the bound
obtained would have been n4p6, which is greater than 1 for this value of p.) For the next lemma, we
recall that the convolution of two functions f, g : G → C is given by f ∗ g(x) = Ey+z=xf (y)g(z).

Lemma 4.3 For every 0 < ǫ ≤ 1, there exists a constant C with the following property. Let G be an
Abelian group of order n and let U1, U2 and U3 be independent random subsets of G with each element
chosen (for each Ui) independently with probability p = Cn−2/3(log n)1/3. For each i, let µi = p−1χUi,
where χUi is the characteristic function of Ui, and let µ−
i (x) = µi(−x). Then, with probability 1− o(1),
every value of the function µ1 ∗ µ2 ∗ µ−

3 lies between 1 − ǫ and 1 + ǫ.

Proof. Let x ∈ G. Then µ1 ∗ µ2 ∗ µ−
3 (x) is equal to p−3 times the number of ways of writing x
as u1 + u2 − u3 with ui ∈ Ui for each i. By Lemma 4.2, there is a probability of 1 − o(1) that the
maximum value of χU1 ∗ χU2 is at most 3. For convenience, write η for ǫ/4. Then, by Lemma 4.1,
there is a probability of 1 − o(1) that both U1 and U2 have sizes between (1 − η)pn and (1 + η)pn. Let
us ﬁx U1 and U2 with these properties and consider our random choice of U3.

can represent as a sum of independent random variables Xu, where Xu = χU1 ∗ χU2(x + u) with

The number of ways of writing x as u1 + u2 − u3 is equal to Pu∈U3 χU1 ∗ χU2(x + u). This we
probability p and 0 with probability 1 − p. The expectation of Pu Xu is n−1|U1||U2|E|U3|, which lies
Pu var(Xu) ≤ 3(1 + η)2p3n2 ≤ 5p3n2. Therefore, by Bernstein’s inequality,

between (1 − η)2p3n2 and (1 + η)2p3n2. From this and the fact that each Xu is bounded above by 3,

P(cid:2)(cid:12)(cid:12)Xu

Xu − EXu

Xu(cid:12)(cid:12) > ηp3n2(cid:3) ≤ 2 exp(−η2p6n4/2(5p3n2 + ηp3n2)) ≤ 2 exp(−η2p3n2/12).

But p3n2 = C 3 log n, so if we set C = 4/η2/3 then this upper bound is at most exp(−5 log n) = o(n−1).

We are more or less done, but we need to renormalize. Note that

Eu1+u2−u3=xµ1(u1)µ2(u2)µ3(u3) = n−2p−3Xu

Xu,

so we have shown that with probability 1 − o(1), every value of µ1 ∗ µ2 ∗ µ−
3 lies between (1 − η)2 − η
and (1 + η)2 + η. Since η ≤ 1, these values lie between 1 − 4η and 1 + 4η, which proves the result. ✷

5 Basic anti-uniform functions are approximately contained in the

convex hull of a small set

We now return to our task of proving that with high probability hµ − 1, ξi is small whenever ξ is a
product of not too many basic anti-uniform functions. A diﬃculty with doing this is that the deﬁnition

7

of a basic anti-uniform function depends on the measure µ, but this turns out to be less of a problem
than it looks: it will be enough to prove the result when the random measure µ and all the measures
used to deﬁne the diﬀerent basic anti-uniform functions are independent. We shall do this ﬁrst and
then give a standard argument that shows why it is enough.

As for the result when all the measures are independent, the technique here, as in [4], is to prove
that there is a set F of bounded functions that is not too large such that every product ξ of basic
anti-uniform functions can be approximated by a convex combination ω of functions in F. In [4] we
had to give a somewhat complicated deﬁnition of “can be approximated by”, but here it is simply a
uniform approximation. If F is small enough and if for every bounded function g the inner product
hµ − 1, gi is small with high probability, then a union bound will tell us that with high probability
hµ − 1, φi is small for every φ ∈ F and hence for every φ in the convex hull of F.

The proof is slightly complicated by the fact that our basic anti-uniform functions are convolutions
of two kinds of functions: functions that are bounded above by 1 and functions that are bounded above
by the characteristic measure of a sparse random set. Let us consider ﬁrst the functions of the latter
kind. For these our argument is based on the following very simple observation. Suppose that f is
a function deﬁned on a ﬁnite Abelian group and θ ∈ [0, 1]. Then we deﬁne the θ-random restriction
Rθf of f to be a random function g where for each x we have g(x) = f (x)/θ with probability θ and
g(x) = 0 with probability 1 − θ, where all these events are independent. It is important that Rθf is
not a ﬁxed function but a random one. We shall adopt as a notational convention that if we have
functions Rθf1, . . . , Rθfk then all the random values Rθfi(x) are independent. That is, the random
restrictions of the diﬀerent fi are made independently. We adopt this convention even if some of the fi
are equal. For example, Rθf ∗ Rθf denotes the convolution of a random restriction of f with another,
independently chosen, random restriction of f .

We shall want to take averages over random functions. To avoid confusion with averages of the

form Exf (x) we shall write EΣ for the average over the functions themselves.

The simple observation has two parts. The ﬁrst part is that many quantities deﬁned in terms of
random restrictions average to the corresponding quantities for the original functions. The underlying
reason for this is that for each x we have EΣRθf (x) = f (x). That is, EΣRθf = f . From this it follows
that if f, g and h are functions deﬁned on G, then EΣRθf ∗ Rθg ∗ Rθh = f ∗ g ∗ h. (Here we are using
independence, so that expectations of products are products of expectations.) We even have that

EΣ

k

Yi=1

Rθfi ∗ Rθgi ∗ Rθhi =

k

Yi=1

fi ∗ gi ∗ hi

for any functions f1, . . . , fk, g1, . . . , gk, h1, . . . , hk.

This implies that a product of basic anti-uniform functions is a convex combination of products
of functions built like basic anti-uniform functions but out of random restrictions instead. Since the
random restrictions have smaller support, there are fewer of them – or rather, they can be approximated
by a smaller net – which gives us the small set we are looking for.

Unfortunately, when we have 0 ≤ f ≤ 1 rather than 0 ≤ f ≤ µ, the number of random restrictions
is too large for our argument to work. However, in this case (which we would expect in advance to be
easier) there is something else we can do. We ﬁrst choose three independent random sets A, B, C ⊂ G
of size qn. Given a function f with 0 ≤ |f | ≤ 1, we then deﬁne RAf as follows. We choose a random
u ∈ G and we then set RAf (x) = q−1f (x) if x ∈ A + u and 0 otherwise. We make similar deﬁnitions

8

for RBf and RCf . We have that EΣRAf = f , where here A is ﬁxed and EΣ is the average over
the diﬀerent RAf corresponding to diﬀerent choices of u, and similarly for B and C. With the same
convention that diﬀerent random restrictions are chosen independently, we also have that

EΣ

k

Yi=1

RAfi ∗ RBgi ∗ RChi =

k

Yi=1

fi ∗ gi ∗ hi

for any functions f1, . . . , fk, g1, . . . , gk, h1, . . . , hk. More generally, let us take Rf to be Rθf if 0 ≤ f ≤ µ
and RAf , RBf or RCf if 0 ≤ f ≤ 1, depending on whether f appears ﬁrst, second or third in the
convolution. Then we have the identity

EΣ

k

Yi=1

Rfi ∗ Rgi ∗ Rhi =

k

Yi=1

fi ∗ gi ∗ hi

regardless of which kinds of functions the fi and gi are.

The reason this observation does not instantly prove what we want is that in order to prove that
hµ − 1, φi is small for every φ ∈ F we shall need the functions in F to be bounded. This is almost
always true when we take convolutions of random restrictions, but not quite always. So we need to
prove that the functions that are not bounded form a suﬃciently small proportion of the functions
in F that we can remove them from the convex combination above and still have an approximate
equality, where the approximation is in the uniform norm. This we shall do with the help of the
following deﬁnition and lemma.

Deﬁnition 5.1 Let G be an Abelian group of order n, let q ∈ [0, 1] and let W1, W2, W3 be subsets of
G. Then the triple (W1, W2, W3) is (ǫ, q)-good if it has the following properties:

1. Each Wi has size (1 + o(1))qn.

2. Let V1, V2, V3 be independent random subsets of G, where each element of each set is chosen with
probability q. Let ωi = q−1χWi and νi = q−1χVi for each i. Then, with probability 1 − o(1), all
eight convolutions β1 ∗ β2 ∗ β−
3 where each βi is either ωi or νi have the property that every value
they take lies between 1 − ǫ and 1 + ǫ.

If V1, V2, V3 satisfy the conclusion of condition 2, we shall say that the triple (V1, V2, V3) complements
the triple (W1, W2, W3).

Lemma 5.2 For every 0 < ǫ ≤ 1 there exists a constant D with the following property. Let G be an
Abelian group of order n and let W1, W2 and W3 be independent random subsets of G with elements
chosen with probability q, where q = Dn−2/3(log n)1/3. Then the triple (W1, W2, W3) is (ǫ, q)-good with
probability at least 1 − o(1).

Proof. Let D be the constant given by Lemma 4.3 (where it is called C), let (V1, V2, V3) be chosen
according to the same distribution as (W1, W2, W3) and let β1, β2 and β3 be one of the eight choices
as in the deﬁnition above. Then, by Lemma 4.3, the probability that the values of β1 ∗ β2 ∗ β−
3 all lie
between 1 − ǫ and 1 + ǫ is 1 − o(1). Therefore, the probability is 1 − o(1) that this is true for all eight
possible choices of β1, β2, β3.
✷

9

Now let us deﬁne a set of bounded functions Ψ1 and prove that every product of at most k basic
anti-uniform functions can be approximated by a convex combination of functions in Ψ1. We will then
ﬁnd a fairly small subset Ψ ⊂ Ψ1 with the same property.

Let q be as in Lemma 5.2 and let (W1, W2, W3) be a good triple. Let p = Cn−2/3(log n)1/3 = Cq/D
and let U1, U2, U3 be independent sets where each element is chosen independently with probability p.
Let µi = p−1χUi for each i.

Given any function f : G → C, write supp(f ) for the support of f and deﬁne σ(f ) to be the function
that takes the value q−1 on supp(f ) and 0 elsewhere. This is a kind of “normalized support” of f . Given
a function h, let h∗ be the function given by h∗(x) = h(−x). In particular, supp(h∗) = − supp(h). We

shall now let Ψ1 consist of all functions of the form Qk

i=1 fi ∗ gi ∗ h∗

i with the following properties:

• For each i, supp(fi) is contained in either U1 or a translate of W1, supp(gi) is contained in either

U2 or a translate of W2, and supp(hi) is contained in either U3 or a translate of W3.

• For each i, kfik∞, kgik∞ and khik∞ are all at most q−1.

• For each i, all of supp(fi), supp(gi) and supp(hi) have size at most 2qn.

• (cid:13)(cid:13)(cid:13)Qk

i=1 σ(fi) ∗ σ(gi) ∗ σ(h∗

≤ 3/2.

i )(cid:13)(cid:13)(cid:13)∞

We also need to change slightly the notion of a basic anti-uniform function. We now deﬁne it to
3 such that for each i we either have 0 ≤ |ui(x)| ≤ µi(x) for every x or we

be a convolution u1 ∗ u2 ∗ u∗
have 0 ≤ |ui(x)| ≤ 1 for every x. (The earlier deﬁnition had U1 = U2 = U3.)

Corollary 5.3 Suppose that (W1, W2, W3) is (ǫ, q)-good, with q = Dn−2/3(log n)1/3 and ǫ = 1/4k,
and let U1, U2, U3 and Ψ1 be as deﬁned above. Then, with probability 1 − o(1), every product of at
most k basic anti-uniform functions can be approximated up to η in the uniform norm by a convex
combination of functions in Ψ1.

Proof. Since (W1, W2, W3) is a good triple, the probability that a random triple (V1, V2, V3) comple-
ments (W1, W2, W3) is 1−o(1), when the elements of each Vi are chosen independently with probability
q. But we can choose the triple (V1, V2, V3) by ﬁrst choosing the triple (U1, U2, U3) with elements cho-
sen independently with probability p and then letting each Vi be a random subset of Ui with elements
chosen independently with probability q/p = D/C. Therefore, with probability 1 − o(1) the triple
(U1, U2, U3) is such that with probability 1 − o(1) a random triple of subsets (V1, V2, V3) chosen in
this way complements the triple (W1, W2, W3). In particular, this also implies that, with probability
1 − o(1), all eight convolutions β1 ∗ β2 ∗ β−
3 k∞ ≤ 2.
Now let us ﬁx (U1, U2, U3) such that this is the case and let µi = p−1χUi for i = 1, 2, 3. Let
Qk
i=1 fi ∗ gi ∗ h∗
i be a product of basic anti-uniform functions, where each fi either satisﬁes 0 ≤ fi ≤ 1
If 0 ≤ fi ≤ 1, then let the random
or 0 ≤ fi ≤ µ1, and similarly for gi and hi with µ2 and µ3.
restriction Rfi be deﬁned as follows. We choose u uniformly at random from G and then set Rfi(x)
to be q−1fi(x) if x ∈ W1 + u and 0 otherwise. If 0 ≤ fi ≤ µ1, then let Rfi(x) = (p/q)fi(x) with
probability q/p and 0 otherwise, with the choices being independent. Deﬁne the random restrictions
Rgi(x) and Rhi(x) in the obvious corresponding ways.

3 , where each βi is either ωi or µi, satisfy kβ1 ∗ β2 ∗ β−

10

As remarked earlier, we then have that

k

Yi=1

fi ∗ gi ∗ h∗

i = EΣ

k

Yi=1

Rfi ∗ Rgi ∗ Rh∗
i .

This does not yet ﬁnish the proof, since the functions Qk

i do not necessarily belong
to Ψ1. However, because (W1, W2, W3) is a good triple, we see that with probability 1 − o(1) we have
kσ(Rfi) ∗ σ(Rgi) ∗ σ(Rh∗

i )k∞ ≤ 1 + ǫ for every i, which, since (1 + ǫ)k ≤ 3/2, implies that F ∈ Ψ1.

i=1 Rfi ∗ Rgi ∗ Rh∗

Let Σ1 be the subset of the probability space Σ for which the random function F = Qk
i belongs to Ψ1 and let Σ2 = Σ \ Σ1. We know that kRfi ∗ Rgi ∗ Rh∗

i=1 Rfi ∗Rgi ∗
3 k∞,
i k∞ ≤ 2(p/q)3 = 2(C/D)3. Therefore, we always

i k∞ ≤ (p/q)3kβ1 ∗ β2 ∗ β−

Rh∗
where each βi is equal to µi or ωi, so kRfi ∗ Rgi ∗ Rh∗
have the bound kF k∞ ≤ (2C/D)3k.

By the law of total probability, we have

k

Yi=1

fi ∗ gi ∗ h∗

i = P[F ∈ Ψ1] EΣ1F + P[F /∈ Ψ1] EΣ2F.

The ﬁrst term is a convex combination of functions in Ψ1 and the second has ℓ∞ norm o(1)(2C/D)3k =
o(1). This proves the result.
✷

It remains to show that Ψ1 has a subset Ψ that is not too large, such that every convex combination
of functions in Ψ1 can be uniformly approximated by a convex combination of functions in Ψ. This
we do in a crude way. Given δ > 0, let ∆ be a δ-net of the unit disc in C that includes 0 and has size
i ∈ Ψ1 such that every value of every

i=1 fi ∗ gi ∗ h∗

at most 16/δ2 and let Ψ consist of all functions Qk

fi, gi and hi is of the form q−1z for some z ∈ ∆.

Now let Qk

i=1 fi ∗ gi ∗ h∗
i| ≤ δσ(fi), |gi − g′

q∆ with |fi − f ′
the triangle inequality that

i ∈ Ψ1. For each i we can choose functions f ′

i taking values in
i| ≤ δσ(hi). By telescoping, it follows from

i and h′

i, g′

i| ≤ δσ(gi) and |hi − h′

kfi ∗ gi ∗ h∗

i − f ′

i ∗ g′

i ∗ h′∗

i k∞ ≤ 3δkσ(fi) ∗ σ(gi) ∗ σ(h∗

i )k∞

and, more generally, that

(cid:13)(cid:13)(cid:13)Yi

fi ∗ gi ∗ h∗

i −Yi

f ′
i ∗ g′

i ∗ h′∗

i (cid:13)(cid:13)(cid:13)∞

≤ 3kδ(cid:13)(cid:13)(cid:13)Yi

We are now ready to prove the main result of this section.

σ(fi) ∗ σ(gi) ∗ σ(h∗

≤ 9kδ/2.

i )(cid:13)(cid:13)(cid:13)∞

Lemma 5.4 For every ǫ > 0 and every positive integer k there exist constants C and D with the
following property. Let p = Cn−2/3(log n)1/3 and let q = Dp/C = Dn−2/3(log n)1/3. Let U be a random
set where each element is chosen independently with probability p. Let µ = p−1χ(U ). Let U1, U2, U3
be further random sets chosen independently in the same way and for each i let µi = p−1χ(Ui). Then,
with probability 1 − o(1), |hµ − 1, ξi| ≤ ǫ for every product ξ of at most k basic anti-uniform functions
(as deﬁned just before Corollary 5.3).

Proof. By Corollary 5.3, with probability 1 − o(1) we can express each ξ as a convex combination
of functions in Ψ1 plus an error term that is uniformly bounded by ǫ/4. And then, by the remarks

11

above, if we set δ = ǫ/18k, then we can express every convex combination of functions in Ψ1 by a
convex combination of functions in Ψ plus an error term that is again uniformly bounded by ǫ/4.
Thus, ξ = ξ1 + ξ2, where ξ1 is a convex combination of functions in Ψ and kξ2k∞ ≤ ǫ/2.

Since

|hµ − 1, ξi| ≤ |hµ − 1, ξ1i| + |hµ − 1, ξ2i| ≤ |hµ − 1, ξ1i| + p−1|U |ǫ/2n,

and since |U | ≤ 3pn/2 with probability 1 − o(1), it is enough to prove that with probability 1 − o(1),
|hµ − 1, ψi| ≤ ǫ/4 for every ψ ∈ Ψ. For this we can use a union bound. That is, we need to obtain
upper bounds for the number of functions in Ψ and for the probability that |hµ − 1, ψi| > ǫ/4 for any
individual ψ ∈ Ψ.

For any given set A of size at most 2qn, the number of functions supported in A and taking values
in q−1∆ is |∆|2qn. Since we are taking δ to be ǫ/18k, this is at most (104k2/ǫ2)2qn. The number of

possible supports for each function involved in a product of convolutions in Ψ is at most n + (cid:0)2pn
2qn(cid:1),

which is at most (4C/D)2qn. Therefore, the number of functions in Ψ is at most (105k2C/ǫ2D)6kqn.
Since each ψ ∈ Ψ has ℓ∞ norm at most 2, the probability that |hµ − 1, ψi| > ǫ/4 is, by Bernstein’s
inequality, at most 2 exp(−ǫ2n2/32(4p−1n + 1
160 ǫ2pn), since hµ − 1, ψi is an average
of n random variables, each of mean zero, second moment at most 4p−1, and maximum at most 2p−1.
160 ǫ2pn) = o(1). Taking logs, we

We are therefore done provided that (105k2C/ǫ2D)6kqn exp(− 1

6 p−1ǫn)) ≤ 2 exp(− 1

require

1
160

ǫ2pn − 6kqn log(105k2C/ǫ2D)

to tend to inﬁnity, for which it is enough if C/D > 103kǫ−2 log(105k2C/ǫ2D).
constant given by Lemma 5.2, then we are done.

If we let D be the
✷

We are not quite done, since we have assumed that our basic anti-uniform functions were built
from functions supported on random sets that were independent of U . To recover the statement for
basic anti-uniform functions built from functions supported on U itself, we think of U as being the
union of t independent random sets U1, . . . , Ut, each chosen with probability 1
t Cn−2/3(log n)1/3, with
Ui having associated measure µi. With high probability, these sets are all disjoint, so µ = Eiµi and
any function f with 0 ≤ |f | ≤ µ can be written as an expectation Eifi where 0 ≤ |fi| ≤ µi for each i.
In particular, any expression of the form hµ− 1, ξi can be rewritten as the expectation over expressions
of the form hµi − 1, ξj1,...,j3ki, where the indices j1, . . . , j3k indicate which of the sets U1, . . . , Ut the
basic anti-uniform function ξj1,...,j3k is built over.

Since i, j1, . . . , j3k all vary over 1, 2, . . . , t, the probability that any two of them are equal is at most

(cid:0)3k+1
2 (cid:1)/t. If they are all diﬀerent, Lemma 5.4 applied with C/t and ǫ/2 implies that |hµi−1, ξj1,...,j3ki| ≤
ǫ/2, while in general, using that kµa ∗ µb ∗ µ−
bound |hµi − 1, ξj1,...,j3ki| ≤ 2k+2. Therefore,

c k∞ ≤ 2 with high probability for all a, b, c, we have the

|hµ − 1, ξi| = |Ei,j1,...,j3khµi − 1, ξj1,...,j3ki|

≤

+ 2k+1(cid:0)3k+1
2 (cid:1)t

ǫ
2

≤ ǫ,

for an appropriate t. This completes the proof of our transference principle. In the next section, we
will show how to apply it.

12

6 Freiman homomorphisms are aﬃne almost everywhere

In this section, we shall use the main result of the previous section to prove that if G is an Abelian
group of order n and U is a random subset of G chosen with probability C(log n)1/3n−2/3, then,
with high probability, for every locally compact Abelian group H and every Freiman homomorphism
φ : U → H there is a Freiman homomorphism ψ : G → H such that ψ(u) = φ(u) for at least 99.99%
of the elements u ∈ U . Then in the next section we shall get from 99.99% to 100%.

Let φ : U → H be a Freiman homomorphism then. To apply our transference principle, we need
a function from U to C, and the obvious way of producing such a function is to compose φ with a
character, except that we shall normalize this function by multiplying it by the characteristic measure
µ of U . Accordingly, if χ is a character on H, let us deﬁne fχ to be the function µ(χ ◦ φ). Note that
χ ◦ φ is a Freiman homomorphism from U to the unit circle.

Let us now ﬁx χ and write f for fχ. Let η > 0 be a constant to be chosen later. By the transference
principle, we can ﬁnd a function g : G → C such that kgk∞ ≤ 1, |M (g)−M (f )| ≤ η, and |hg−f, τ i| ≤ η
for every character τ : G → C.

We shall now show that M (f ) ≈ 1, which implies that M (g) ≈ 1, which implies that g is ap-
proximately equal to a character τ , which implies that hf, τ i ≈ 1. This will show that k ˆfχk12 ≈ 1
for every character χ : H → C, which (as later calculations will reveal) eﬀectively allows us to prove
that φ coincides with a homomorphism of order 6 on almost all of U . But since 3U = G with high
probability, a homomorphism of order 6 on almost all of U gives us a homomorphism of order 2 on
almost all of G.

In the rest of this section we shall give the details. To avoid a lot of repetition, let us establish once
and for all that G is a ﬁnite Abelian group of order n, η > 0 is a small positive constant, U is a random
subset of G chosen with probability C(log n)1/3n−2/3, and µ is the characteristic measure of U . In
addition, we shall adopt the following convention. When we make a statement that involves U , it is
to be understood that that statement is valid with probability 1 − o(1). Moreover, if that statement
involves a universal quantiﬁer (either explicitly, or via the word “let”), it is to be understood that the
“with probability 1 − o(1)” comes before the quantiﬁer. For instance, if we write, “Let A be such that
P (A). Then Q(A, U ),” that is shorthand for, “With probability 1 − o(1), Q(A, U ) for every A such
that P (A).”

We begin with a simple probabilistic lemma. Though it has a much easier proof, we note here that

it follows as a corollary of the fact that hµ − 1, ξi is small for all basic anti-uniform functions ξ.

Lemma 6.1 M (µ) ≥ 1 − η.

Recall that for each character τ : G → C and any function f : G → C, the Fourier transform is
ˆf (τ )τ (x).

given by ˆf (τ ) = hf, τ i = Exf (x)τ (x). We also have the Fourier inversion formula, f (x) = Pτ
In keeping with these normalisations, we write kf kp = (Ex|f (x)|p)1/p, while k ˆf kp = (Pτ | ˆf (τ )|p)1/p.
This allows us to state Parseval’s formula kf k2 = k ˆf k2 and a number of related identities in a clean
fashion.

Lemma 6.2 Let H be a locally compact Abelian group, let φ : U → H be a Freiman homomorphism,
let χ : H → C be a character, and let f = µ(χ ◦ φ). Then k ˆf k12

12 ≥ 1 − 36η.

13

Proof. As mentioned above, there exists a function g : G → C such that kgk∞ ≤ 1, M (g) ≥ M (f )−η,
and hf, τ i ≥ hg, τ i − η for every character τ : G → C. But

M (f ) = E

(x,y,z,w)∈Γµ(x)µ(y)µ(z)µ(w)χ(φ(x) + φ(y) − φ(z) − φ(w)) = M (µ),

since φ is a Freiman homomorphism. Therefore, by Lemma 6.1, M (f ) ≥ 1 − η.
M (g) ≥ 1 − 2η.

It follows that

Now the sum of g(x)g(y)g(z)g(w) over degenerate additive quadruples x + y = z + w (that is, ones
U 2 ≥ 1 − 2η.
∞ ≥ 1 − 2η and therefore that

where x = z and y = w or x = w and y = z) is a non-negative real number. Therefore, kgk4
Therefore, kˆgk4
kˆgk∞ ≥ 1 − 2η.

4 ≥ 1 − 2η. Since kˆgk2 = kgk2 ≤ 1, it follows that kˆgk2

Since hf, τ i ≥ hg, τ i − η for every character τ : G → C, it follows that k ˆf k∞ ≥ 1 − 3η and therefore

✷

that k ˆf k12

12 ≥ 1 − 36η, as claimed.

The proof of the above lemma is the only place where we need to use the transference result of the

previous section. (However, the lemma is crucial to our main argument.)

Let us now regard H and φ as ﬁxed (though it is important that the statement we are proving
about U is one that with high probability holds for all H and φ). We shall now convert this statement
about ℓ12 norms of Fourier transforms into a statement about Freiman homomorphisms of order 6.
To begin with, we obtain near homomorphisms. The rough meaning of the next statement is that for
almost every additive 12-tuple (x1, . . . , x12) in U , we also have φ(x1)+· · ·+φ(x6) = φ(x7)+· · ·+φ(x12).

Lemma 6.3 Let Γ be the set of all (x1, . . . , x12) ∈ G12 such that x1 + · · · + x6 = x7 + · · · + x12 and
let Φ be the set of all (x1, . . . , x12) ∈ Γ such that φ(x1) + · · · + φ(x6) = φ(x7) + · · · + φ(x12). Then

E

(x1,...,x12)∈Γ µ(x1) . . . µ(x12)1(x1,...,x12)∈Φ ≥ 1 − 36η.

Proof. Let us write fχ for the function µ(χ ◦ φ). (Previously we just wrote f , but now we need to
consider all such functions.) Then, by Lemma 6.2, we know that k ˆfχk12
12 ≥ 1 − 36η for every character
χ, and therefore that Eχk ˆfχk12

12 ≥ 1 − 36η. Note that

k ˆfχk12

12 = Xτ

| ˆf (τ )|12 = h ˆf 6, ˆf 6i = hf ∗ · · · ∗ f, f ∗ · · · ∗ f i = E

(x1,...,x12)∈Γf (x1) . . . f (x6)f (x7) . . . f (x12)

and, therefore, Eχk ˆfχk12

12 is equal to

EχE

(x1,...,x12)∈Γ µ(x1) . . . µ(x12)χ(φ(x1) + · · · + φ(x6) − φ(x7) − · · · − φ(x12)).

The expectation over χ is 1 if (x1, . . . , x12) ∈ Φ and 0 otherwise, so we have precisely the expectation
on the left-hand side of the inequality we are trying to prove.
✷

The rough idea of what we want to do next is to deﬁne a function ψ : 3U → H by taking ψ(u) to
be the most popular value of φ(x1) + φ(x2) + φ(x3) when x1 + x2 + x3 = u. Lemma 6.3 implies that
most of the time one value is predominant and that the function ψ thus deﬁned has the property that
u1 + u2 = u3 + u4 almost always implies that ψ(u1) + ψ(u2) = ψ(u3) + ψ(u4). This in turn implies
that ψ agrees almost everywhere with an aﬃne homomorphism.

However, arguments of the above kind can get quite messy, so for the sake of tidiness we shall
instead postpone for as long as we can the moment where we have to use an averaging argument to

14

commit ourselves to a particular function. The price we pay for this is that we must consider functions
whose values are probability distributions on H rather than single elements of H. However, this is a
very natural thing to do: instead of deﬁning ψ(u) to be the most popular value of φ(x1)+φ(x2)+φ(x3)
such that x1 + x2 + x3 = u, we deﬁne it to be something like the probability distribution where the
probability that ψ(u) = h is the probability that φ(x1)+ φ(x2)+ φ(x3) = h given that x1 + x2 + x3 = u.
This is not quite accurate, because we need to take account of the fact that µ ∗ µ ∗ µ is not quite
constant, so here is the precise deﬁnition.

Deﬁnition 6.4 Let φ : U → H and let π(H) be the set of all non-negative real-valued ﬁnitely supported
functions on H. Then, for each x ∈ G, let ψ(x) ∈ π(H) be the function deﬁned by the formula

ψ(x)(h) = E{µ(x1)µ(x2)µ(x3) : x1 + x2 + x3 = x, φ(x1) + φ(x2) + φ(x3) = h}.

Typically, ψ(x)(h) will be almost 1 for one h ∈ H and the sum over h will be asymptotically equal to
1. In other words, it will be concentrated at one h, so we can think of ψ as like a function from G to
H but slightly fuzzy.

We also need to be able to make sense of expressions such as ψ(x) + ψ(y). That is easy enough: we
simply convolve ψ(x) with ψ(y). To avoid confusion, we shall write ψ(x)∗ψ(y), which we deﬁne formally
as follows. Note that the normalization is diﬀerent from that used earlier: it is more appropriate for
convolutions of probability distributions.

Deﬁnition 6.5 Let p, q ∈ π(H). The convolution p∗q of p and q is deﬁned by the formula (p∗q)(h) =

Ph1+h2=h p(h1)q(h2).

If ψ(x) is concentrated at h1 and ψ(y) is concentrated at h2, then ψ(x) ∗ ψ(y) is concentrated (but
not quite as strongly) at h1 + h2. In this situation, convolution can be thought of as a fuzzy version
of addition.

We would also like a fuzzy version of subtraction, so we deﬁne p−(h) to be p(−h). Then the fuzzy

analogue of ψ(x) − ψ(y) is ψ(x) ∗ ψ−(y).

Finally, we need a fuzzy version of equality: there are no circumstances under which we can
reasonably expect two expressions such as ψ(x1) ∗ ψ(x2) and ψ(x3) ∗ ψ(x4) to be exactly equal, but
we can certainly expect them to be roughly equal. To measure this, we deﬁne an inner product in an
obvious way. Again, this is deﬁned with a diﬀerent normalization from earlier.

Deﬁnition 6.6 Let p and q be two non-negative ﬁnitely supported functions on H. Then their inner

product hp, qi is deﬁned to be Ph∈H p(h)q(h).

If p and q both sum to 1 (or approximately 1), then we regard p and q as close if hp, qi is close to 1.
This is a stronger statement than merely that p and q are similar functions: it implies also that p and
q are both fairly concentrated at a single value. However, that is exactly what we want to show, so
this notion of closeness is useful.

The next lemma is just a reformulation of Lemma 6.3.

Lemma 6.7 Ez1+z2=z3+z4hψ(z1) ∗ ψ(z2), ψ(z3) ∗ ψ(z4)i ≥ 1 − 36η.

15

Proof. The inner product expands to

Xh1+h2=h3+h4

ψ(z1)(h1)ψ(z2)(h2)ψ(z3)(h3)ψ(z4)(h4).

But ψ(zi)(hi) can be written as

E{µ(x3i−2)µ(x3i−1)µ(x3i) : x3i−2 + x3i−1 + x3i = zi, φ(x3i−2) + φ(x3i−1) + φ(x3i) = hi}.

Therefore, taking the expectation of the inner product over all additive quadruples z1 + z2 = z3 + z4,
we obtain

E{µ(x1) . . . µ(x12) : x1 + · · · + x6 = x7 + · · · + x12, φ(x1) + · · · + φ(x6) = φ(x7) + · · · + φ(x12)}

which is another way of writing E(x1,...,x12)∈Γ µ(x1) . . . µ(x12)1(x1,...,x12)∈Φ. Thus, the result follows
from Lemma 6.3.
✷

Corollary 6.8 Ez1−z2=z3−z4hψ(z1) ∗ ψ−(z2), ψ(z3) ∗ ψ−(z4)i ≥ 1 − 36η.

Proof. The inner product expands to

which equals

which equals

Xh1+h2=h3+h4

ψ(z1)(h1)ψ(z2)(−h2)ψ(z3)(h3)ψ(z4)(−h4)

Xh1−h2=h3−h4

Xh1+h4=h3+h2

ψ(z1)(h1)ψ(z2)(h2)ψ(z3)(h3)ψ(z4)(h4)

ψ(z1)(h1)ψ(z2)(h2)ψ(z3)(h3)ψ(z4)(h4)

which equals hψ(z1) ∗ ψ(z4), ψ(z2) ∗ ψ(z3)i. We are taking the expectation of this quantity over
quadruples (z1, z2, z3, z4) such that z1 + z4 = z2 + z3, so the result follows from Lemma 6.7.
✷

We are about to deﬁne θ : G → π(H) as the convolution of ψ with ψ−

−, where ψ−

−(x)(h) is deﬁned

to be ψ(−x)(−h). However, we must ﬁrst say what “convolution” means here.

Deﬁnition 6.9 Let φ, ψ : G → π(H). The convolution φ ∗ ψ : G → π(H) is deﬁned by the formula

(φ ∗ ψ)(x) = Ex1+x2=xφ(x1) ∗ ψ(x2).

In that case, φ ∗ φ−

Let ζ : G → H be a Freiman homomorphism and let φ : G → π(H) be deﬁned by φ(x)(h) = 1
−(x)(h) = 1 if for every x1 − x2 = x we have
if h = ζ(x) and 0 otherwise.
ζ(x1) − ζ(x2) = h and 0 otherwise.
− is essentially the well-deﬁned function
from G − G to H that is induced by the fact that ζ is a Freiman homomorphism. Lemma 6.7 can be
thought of as saying that ψ is an approximate homomorphism. We therefore expect θ = ψ ∗ ψ−
− to
be “approximately well-deﬁned”. We shall show that for every x the function θ(x) is concentrated at
some value γ(x) ∈ H, and that γ is a group homomorphism.

In other words, φ ∗ φ−

First, we need a lemma that can be thought of as a kind of triangle inequality, with 1 − hp, qi being
the “distance” between p and q. This distance is similar to the Ruzsa distance between two sets: in
particular, a function need not be close to itself.

16

Lemma 6.10 Let p, q and r be elements of π(H), each of which sums to at most 1 + β, where β ≤ 1.
Then

1 − hp, ri ≤ 1 − hp, qi + 1 − hq, ri + 3β.

Proof. For every h ∈ H we have the inequality (1 + β − p(h))(1 + β − r(h)) ≥ 0, since p and r take
values in [0, 1 + β]. It follows that p(h)r(h) ≥ (1 + β)(p(h) + r(h)) − (1 + β)2. Therefore, since q also
takes values in [0, 1 + β],

1 − hp, ri = 1 −Xh

p(h)r(h)

q(h)p(h)r(h)

≤ 1 − (1 + β)−1Xh
≤ 1 −Xh
= 1 − hp, qi − hq, ri + (1 + β)Xh

q(h)(p(h) + r(h) − (1 + β))

q(h)

≤ 1 − hp, qi + 1 − hq, ri + 3β,

as claimed.

✷

Let us write d(p, q) for 1 − hp, qi. Then Lemma 6.10 tells us that d(p, r) ≤ d(p, q) + d(q, r) + β.
Note that d(p, q) can be negative, but it cannot be smaller than −2β − β2. The fact that it can be
negative turns out not to matter.

Now we need an estimate that can be used to give us a β to use in the previous lemma.

Lemma 6.11 kµ ∗ µ ∗ µ − 1k∞ ≤ η.

It will suﬃce to show that for any ﬁxed x, the number of distinct ways S of writing x as a
Proof.
sum of three elements in U satisﬁes |S − ES| ≤ ηp3n2 with probability 1 − o(1/n). A straightforward
application of Janson’s inequality (see [1]) gives the required estimate for the probability that S <
ES − ηp3n2. We will therefore focus on estimating the probability that S > ES + ηp3n2.

We will use the method described in Section 2.3.4 of [8]. Let S′ be the random variable counting
the maximum number of disjoint three element sets each of which sum to x. We claim that S ≤ S′ +28
with probability 1 − o(1/n). To prove the claim, let Si be the collection of i element subsets of U
giving rise to a triple summing to x. Form a graph J whose vertices are the elements of S3, where two
elements are joined if and only if they intersect. Then, with probability 1−o(1/n), it is straightforward
to verify that the maximum degree of J is at most 4 and the largest induced matching has size at
most 3. Note that S′ is the order of the largest independent set in J. Since at most 24 vertices are
joined to a maximal induced matching and the remaining set is independent, we have

S′ ≥ |J| − 24 = |S3| − 24.

Since it is also easy to verify that |S2| ≤ 3 with probability 1 − o(1/n) and S1 ≤ 1 (unless G has
characteristic 3 and x = 0), the claim follows.

17

The required conclusion now follows from the inequality

P[S′ ≥ ES + λ] ≤ exp(cid:18)

−t2

2(ES + t/3)(cid:19) ,

which is Lemma 2 of [8].

✷

Remark. It is possible to prove the above lemma in a slightly more elementary way, by deducing it
from Lemma 4.3. To do this, one must split µ into several independent parts and use the fact that
most of the terms that arise involve diﬀerent parts. (We used a similar idea at the end of the previous
section.)

There is a simple way of measuring the well-deﬁnedness of θ: we look at how small the distances

d(θ(x), θ(x)) are.

Lemma 6.12 For every x ∈ G, d(θ(x), θ(x)) ≤ 75η.

Proof. Fix x ∈ G. We need to show that

Ez1−z2=z3−z4=xhψ(z1) ∗ ψ−(z2), ψ(z3) ∗ ψ−(z4)i ≥ 1 − 75η.

From Corollary 6.8, we know both that

Ew1−w2=w3−w4(1 − hψ(w1) ∗ ψ−(w2), ψ(w3) ∗ ψ−(w4)i) ≤ 36η

and that

Ew1−w2=w3−w4(1 − hψ(w1 + x) ∗ ψ−(w2 + x), ψ(w3) ∗ ψ−(w4)i) ≤ 36η.

Now Ph∈H ψ(x)(h) = µ ∗ µ ∗ µ(x), which is at most 1 + η, by Lemma 6.11. It follows from Lemma

6.10 that

Ew1,w2(1 − hψ(w1) ∗ ψ−(w2), ψ(w1 + x) ∗ ψ−(w2 + x)i) ≤ 75η.

But

hψ(w1) ∗ ψ−(w2), ψ(w1 + x) ∗ ψ−(w2 + x)i = hψ(w1 + x) ∗ ψ−(w1), ψ(w2 + x) ∗ ψ−(w2)i.

Therefore,

Ew1,w2hψ(w1 + x) ∗ ψ−(w1), ψ(w2 + x) ∗ ψ−(w2)i ≥ 1 − 75η,

which is (a slightly rewritten version of) what we needed to show.

✷

Corollary 6.13 For every x, there exists h such that θ(x)(h) ≥ 1 − 77η.

Proof. We know that Ph θ(x)(h)2 ≥ 1 − 75η. Also, since Ph ψ(y)(h) ≤ 1 + η for every y,
Ph θ(x)(h) = Ex1−x2=xPh1,h2 ψ(x1)(h1)ψ(x2)(−h2) is at most (1+η)2. It follows that maxh θ(x)(h) ≥

(1 − 75η)(1 + η)−2 ≥ 1 − 77η, as claimed.

✷

Corollary 6.14 θ(0)(0) ≥ 1 − 77η.

18

Proof. For every h,

θ(0)(h) = Ex Xh1−h2=h

ψ(x)(h1)ψ(x)(h2).

Let h′ and h′′ be such that ψ(x)(h′) is the largest value over all h of ψ(x)(h) and ψ(x)(h′′) is the
second largest. Then, if h 6= 0,

Xh1−h2=h

ψ(x)(h1)ψ(x)(h2) ≤ 2ψ(x)(h′) Xh16=h′

ψ(x)(h1) + ψ(x)(h′′) Xh16=h′

ψ(x)(h1) ≤

3(1 + η)2

4

,

where we used that ψ(x)(h′)Ph16=h′ ψ(x)(h1) is bounded by an expression of the form x((1 + η) − x) ≤

(1 + η)2/4. Therefore, if h 6= 0, θ(0)(h) ≤ 3(1 + η)2/4. Since this is less than 1 − 77η for η suﬃciently
small, the only way that Corollary 6.13 can be true is if θ(0)(0) ≥ 1 − 77η.
✷

Lemma 6.15 Let β, γ ≥ 0 and let p, q ∈ π(H) with Ph p(h) and Ph q(h) at most 1 + β. Suppose

that d(p, q) ≤ γ. Then there exists h such that p(h)q(h) ≥ (1 − β − γ)2.

Proof. We know that

Xh

p(h)q(h) ≤ (max

h

p(h)1/2q(h)1/2)Xh

p(h)1/2q(h)1/2.

If the result is false, then maxh p(h)1/2q(h)1/2 is less than 1 − β − γ, and by the Cauchy–Schwarz
inequality and the assumptions on p and q, the inner sum is at most 1 + β. It follows that hp, qi <
(1 − β − γ)(1 + β) ≤ 1 − γ, and therefore that d(p, q) > γ, a contradiction.
✷

The next lemma tells us that inner products are “approximately Lipschitz” functions of their

arguments.

Lemma 6.16 Let 0 ≤ β ≤ 1/5 and let p, q, r ∈ π(H) be such that Ph p(h), Ph q(h) and Ph r(h) are

all at most 1 + β. Then |hp, ri − hq, ri| ≤ 5d(p, q) + 10β.

Proof. For any element p ∈ π(H) and any s ∈ [1, ∞), write kpks for (cid:0)Ph∈H p(h)s(cid:1)1/s and kpk∞ for

maxh p(h). Then

|hp, ri − hq, ri| = |hp − q, ri|

≤ kp − qk1krk∞
≤ (1 + β)kp − qk1.

Let us write γ for d(p, q). By Lemma 6.15, there exists h such that p(h)q(h) ≥ (1−β−γ)2, which implies

that p(h)+q(h) ≥ 2(1−β −γ), which is at least 2−2β −2γ. Therefore, Ph′6=h(p(h′)+q(h′)) ≤ 4β +2γ.

Also, |p(h) − q(h)| is at most 1 + β − (1 − β − γ)2/(1 + β) ≤ 4β + 2γ. Therefore, kp − qk1 ≤ 8β + 4γ.
Since β ≤ 1/5, this gives us the desired estimate.
✷

We would also like to know that convolutions are approximately Lipschitz.

19

Corollary 6.17 Let 0 ≤ β ≤ 1/2 and let p, q, r, s ∈ π(H) be such that kpk1, kqk1, krk1, ksk1 ≤ 1 + β.
Then

d(p ∗ r, q ∗ s) ≤ (1 + β)2(d(p, q) + d(r, s)) + 8β2.

Proof. We shall use the fact that f ∗ g−(0) = hf, gi for any two functions f, g ∈ π(H). That implies
that

hp ∗ r, q ∗ si = hp ∗ q−, s ∗ r−i

≥ hp, qihr, si.

Since ((1 + β)2 − hp, qi)((1 + β)2 − hr, si) ≥ 0,

hp, qihr, si ≥ (1 + β)2(hp, qi + hr, si) − (1 + β)4.

The result follows after a quick calculation.

✷

The next lemma tells us that θ is close to a group homomorphism. Here and in what follows, we

write δa for the function taking value 1 at a and 0 everywhere else.

Lemma 6.18 For every x1, x2 ∈ G, d(θ(x1 + x2), θ(x1) ∗ θ(x2)) ≤ 1100η.

Proof. By deﬁnition,

θ(x1 + x2) = Exψ(x + x1 + x2) ∗ ψ−(x).

We would like to begin by “adding and subtracting ψ(x + x1)”. More precisely, we would like to
approximate θ(x1 + x2) by

Exψ(x + x1 + x2) ∗ ψ−(x + x1) ∗ ψ(x + x1) ∗ ψ−(x).

Lemma 6.12 tells us that d(θ(x1 + x2), θ(x1 + x2)) ≤ 75η. Since the distance is a bilinear function (in
the sense that it commutes with expectations), this implies that

Ex,yd(ψ(x + x1 + x2) ∗ ψ−(x), ψ(y + x1 + x2) ∗ ψ−(y)) ≤ 75η.

(1)

We are trying to estimate the distance

d(Exψ(x + x1 + x2) ∗ ψ−(x), Eyψ(y + x1 + x2) ∗ ψ−(y + x1) ∗ ψ(y + x1) ∗ ψ−(y)).

(2)

By the bilinearity of d, it equals

Ex,yd(ψ(x + x1 + x2) ∗ ψ−(x), ψ(y + x1 + x2) ∗ ψ−(y + x1) ∗ ψ(y + x1) ∗ ψ−(y)),

which equals

Ex,yd(ψ(x + x1 + x2) ∗ ψ−(x) ∗ ψ−(y + x1 + x2) ∗ ψ(y), ψ−(y + x1) ∗ ψ(y + x1)).

By Lemma 6.16, this is at most the sum of

Ex,yd(ψ(x + x1 + x2) ∗ ψ−(x) ∗ ψ−(y + x1 + x2) ∗ ψ(y), δ0),

20

and

where β = (1 + η)4 − 1. The ﬁrst of these terms is equal to

5Eyd(ψ−(y + x1) ∗ ψ(y + x1), δ0) + 10β,

Ex,yd(ψ(x + x1 + x2) ∗ ψ−(x), ψ(y + x1 + x2) ∗ ψ−(y)),

which, as we have already remarked, is at most 75η. We also have that

Eyd(ψ−(y + x1) ∗ ψ(y + x1), δ0) = d(Eyψ−(y + x1) ∗ ψ(y + x1), δ0) = d(θ(0), δ0),

which, by Corollary 6.14, is at most 77η. Therefore, the distance (2) is at most 75η+385η+10β < 700η.

We shall now further approximate

Exψ(x + x1 + x2) ∗ ψ−(x + x1) ∗ ψ(x + x1) ∗ ψ−(x)

by

θ(x2) ∗ θ(x1) = Eu,vψ(u + x1 + x2) ∗ ψ−(u + x1) ∗ ψ(v + x1) ∗ ψ−(v).

By Corollary 6.17 with β = 2η + η2, and using the bilinearity of d, the distance between them is at
most

(1 + β)2Ex,ud(ψ(x + x1 + x2) ∗ ψ−(x + x1), ψ(u + x1 + x2) ∗ ψ−(u + x1))

+(1 + β)2Ex,vd(ψ(x + x1) ∗ ψ−(x), ψ(v + x1) ∗ ψ−(v)) + 8β2.

But this equals (1 + β)2(d(θ(x1 + x2), θ(x1 + x2)) + d(θ(x1), θ(x1))) + 8β2, which, by Lemma 6.12, is
at most (1 + β)2.150η + 8β2. Since (1 + β)2 = (1 + η)8 ≤ 2, this is at most 400η.
✷

Now let us put together what we have proved so far.

Corollary 6.19 There exists a group homomorphism γ : G → H such that d(θ(x), δγ(x)) ≤ 160η for
every x ∈ G.

Proof. Corollary 6.13 is the statement that there exists a function γ : G → H with the property
stated. It remains to show that γ is a group homomorphism.

Let β = (1 + η)2 − 1. Then, by Corollary 6.17,

d(θ(x1) ∗ θ(x2), δγ(x1) ∗ δγ(x2)) ≤ (1 + β)2(cid:0)d(θ(x1), δγ(x1)) + d(θ(x2), δγ(x2))(cid:1) + 8β2,

which is at most (1 + β)2.320η + 8β2 ≤ 800η.

By Corollary 6.13, Lemma 6.18, Lemma 6.16 (twice) and this calculation,

d(δγ(x1+x2), δγ(x1) ∗ δγ(x2)) ≤ d(θ(x1 + x2), δγ(x1) ∗ δγ(x2)) + 5d(θ(x1 + x2), δγ(x1+x2)) + 10β

≤ d(θ(x1 + x2), δγ(x1) ∗ δγ(x2)) + 800η + 10β
≤ d(θ(x1 + x2), θ(x1) ∗ θ(x2)) + 5d(θ(x1) ∗ θ(x2), δγ(x1) ∗ δγ(x2)) + 800η + 20β
≤ 1100η + 4000η + 800η + 20β ≤ 6000η.

But δγ(x1) ∗ δγ(x2) = δγ(x1)+γ(x2), so if η < 1/6000, the only way this estimate can be true is if
γ(x1 + x2) = γ(x1) + γ(x2).
✷

It remains to relate the homomorphism γ to the original function φ : U → H. This we do with a

standard averaging argument.

21

Theorem 6.20 There exists an aﬃne homomorphism α : G → H such that φ(x) = α(x) for all but
160η|U | elements x ∈ U .

Proof. First, let us write an expression for θ(x). It is given by

θ(x)(h) = Ex1+x2+x3−x4−x5−x6=xµ(x1) . . . µ(x6)1φ(x1)+φ(x2)+φ(x3)−φ(x4)−φ(x5)−φ(x6)=h.

Therefore, we have just shown that

Ex1+x2+x3−x4−x5−x6=xµ(x1) . . . µ(x6)1φ(x1)+φ(x2)+φ(x3)−φ(x4)−φ(x5)−φ(x6)=γ(x)

is at least 1 − 160η.

Taking the expectation over x, we deduce that

Ex1,...,x6µ(x1) . . . µ(x6)1φ(x1)+φ(x2)+φ(x3)−φ(x4)−φ(x5)−φ(x6)=γ(x1+x2+x3−x4−x5−x6)

is also at least 1 − 160η. Therefore (since µ is a probability measure on G), there exist x2, . . . , x6 such
that, writing z = x2 + x3 − x4 − x5 − x6 and h = φ(x2) + φ(x3) − φ(x4) − φ(x5) − φ(x6), we have

Ex1µ(x1)1φ(x1)=γ(x1+z)−h ≥ 1 − 160η.

That is, φ(x) = γ(x) + γ(z) − h for all but 160η|U | elements of U . Thus, we may take α(x) =
γ(x) + γ(z) − h.
✷

7 Freiman homomorphisms that are aﬃne almost everywhere are

aﬃne everywhere

The ﬁnal step in the argument is to prove that if U is a random set where every element is chosen inde-
pendently with probability Cn−2/3(log n)1/3, then with high probability every Freiman homomorphism
deﬁned on U that is aﬃne on at least 99.99% of U is in fact aﬃne on all of U .

Deﬁnition 7.1 Let U be a subset of an Abelian group G. An aﬃne homomorphism φ : U → H
from U to an Abelian group H is a function of the form φ(u) = a + ψ(u), where ψ : U → H is the
restriction to U of a group homomorphism. The set U has the (1 − η)-extension property if every
Freiman homomorphism from U to an Abelian group H that coincides with an aﬃne homomorphism
φ on a subset V ⊂ U of size at least (1 − η)|U | is in fact equal to φ.

Deﬁnition 7.2 Let U be a subset of a ﬁnite Abelian group G, let W ⊂ U and let V = U \ W . Then
W is additively isolated in U if (V + V − V ) ∩ W = ∅. Let η > 0. The set U is (1 − η)-additively
connected if no subset of U of size at most η|U | is additively isolated in U .

The deﬁnitions we have given are not standard, but they are the ones that we shall need for our

argument. Let us prove a simple lemma that illustrates their usefulness.

Lemma 7.3 Let G be a ﬁnite Abelian group and let η > 0. Then every (1 − η)-additively connected
subset U of G has the (1 − η)-extension property.

22

Proof. Let φ be a Freiman homomorphism deﬁned on U , let V0 be a subset of U of size at least (1 −
η)|U | and suppose that the restriction of φ to V0 is also the restriction to V0 of an aﬃne homomorphism
ψ : G → H. Let V be the set of all points u ∈ U such that φ(u) = ψ(u).

If V is not the whole of U , then we have an easy contradiction, since |V | ≥ (1 − η)|U |, from
which it follows by hypothesis that its complement W is not additively isolated in U . Therefore, we
can ﬁnd v1, v2, v3 ∈ V such that v1 + v2 − v3 = w ∈ W . Since φ is a Freiman homomorphism, it
follows that φ(w) = φ(v1) + φ(v2) − φ(v3), which equals ψ(v1) + ψ(v2) − ψ(v3), and since ψ is an aﬃne
homomorphism, this is equal to ψ(w).
✷

The converse of this statement is not quite true, because it is also possible for W + W − W to

intersect V . We leave it as an exercise to ﬁnd a counterexample.

Our strategy, then, is to prove that if G is a ﬁnite Abelian group of order n, then a binomial
random subset U ⊂ G where each element is chosen independently with probability Cn−2/3(log n)1/3
is (1−η)-additively connected with high probability for some absolute constant η > 0. In what follows,
we will work in a slightly diﬀerent probabilistic model, proving that random subsets U of G with ﬁxed
size C(n log n)1/3 are (1 − η)-additively connected with high probability for some appropriate η > 0.
However, this easily implies that the same holds in the binomial model.

We begin with a preparatory lemma.

Lemma 7.4 Let G be a ﬁnite Abelian group of order n, let K be a subset of G of size k and let A be
a random subset of G of size m. Then, if km ≤ n, P[|A + K| < km/4] ≤ e−m/32, and if n ≤ km ≤ 2n,
P[|A + K| < n/2] ≤ e−m/800.

Proof. Let x be any element of G. The probability that x ∈ A + K is 1 − (1 − k/n)m ≥ 1 − e−km/n.
Therefore, the expectation of |A + K| is at least n(1 − e−km/n). If we alter a single element of A, then
the change to |A + K| is at most k. It follows by Azuma’s inequality that

P[|A + K| < E|A + K| − tk] ≤ e−t2/2m.

Now e−x ≤ 1 − x + x2/2 for every x ≥ 0, so if km ≤ n, then n(1 − e−km/n) ≥ n(km/n − k2m2/2n2) ≥
nkm/2n = km/2. Therefore, P[|A + K| < km/4] ≤ e−(m/4)2/2m, which establishes the ﬁrst bound. If
km ≥ n, then n(1 − e−km/n) ≥ n(1 − 1/e) > 3n/5, so P[|A + K| < n/2] ≤ e−(n/10k)2/2m ≤ e−(m/20)2/2m,
which establishes the second.
✷

1(B′), A′

2(B′) and A′

Now let X be the set {1, 2, . . . , t} for a t to be chosen later (which will be of the form C(n log n)1/3).
Let k ≤ ηt for some η > 0 also to be chosen later (which will be an absolute constant). For each B′ ⊂ X
3(B′) be three sets of equal size that partition X \ B′, with the
of size k, let A′
exception of at most two elements, with these sets chosen arbitrarily. Now let φ be a random function
from X to G. It is easy to show that for suﬃciently large n the probability that the restrictions of
φ to the sets B′, A′
3(B′) are all injections is at least 1/2. If we condition on this
event, then the images B, A1, A2, A3 of those four sets are independent random subsets of G of the
appropriate cardinalities. If we condition further on φ being an injection (so now we ask for the images
to be disjoint), which again is true with probability at least 1/2, then their union U is a random set
of size t and B is a random subset of U of size k.

1(B′), A′

2(B′) and A′

For each B′ ⊂ X, let P (B′) be the probability that A1 + A2 − A3 is disjoint from B, given that the

restrictions of φ to the sets B′, A′

1(B′), A′

2(B′) and A′

3(B′) are all injections. If P|B′|≤ηt P (B′) = p,

23

then the probability that there exists B′ ⊂ X of size at most ηt such that A1 + A2 − A3 is disjoint from
B is at most p. If we now condition on φ being an injection, this probability goes up to at most 2p.
Therefore, with probability at least 1 − 2p, no subset of U of size at most η|U | is additively isolated
in U . In other words, with probability at least 1 − 2p, U is (1 − η)-additively connected.

We shall therefore concentrate our attention on estimating P (B′).

Lemma 7.5 Let G be a ﬁnite Abelian group of order n, let B be a ﬁxed subset of G of size k, and
let A1, A2 and A3 be random subsets of G of size s = C(n log n)1/3. Let t = k + 3s and suppose that
k ≤ t/105. Then there exists an absolute constant C > 0 such that the probability that A1 + A2 − A3

and B are disjoint is at most (2n)−2(cid:0)t

.

k(cid:1)−1

Proof. Observe ﬁrst that A1 + A2 − A3 and B are disjoint if and only if A1 + A2 − B and A3 are
disjoint. Next, note that by Lemma 7.4 and the fact that ks ≤ n (we are assuming throughout that
n is suﬃciently large), we have that |A1 − B| ≥ ks/4 with probability at least 1 − e−s/32.

Let K = A1 − B. The rest of the proof splits into two cases. If |K|s ≤ n, then Lemma 7.4 implies
that |A2 + K| ≥ |K|s/4 ≥ ks2/16 with probability at least 1 − e−s/32. If this event happens, then
the probability that A1 + A2 − B is disjoint from A3 is at most (1 − ks2/16n)s ≤ exp(−ks3/16n) =
n−C 3k/16. Since k ≤ t/105, standard estimates for binomial coeﬃcients give us, with room to spare,

that (cid:0)t

k(cid:1) ≤ (et/k)k ≤ et/4000 ≤ es/1000. Also, when C = 4, n−C 3k/16 is much less than (cid:0)n

these estimates easily suﬃce to show that

k(cid:1)−1. Together,

e−s/32 + n−C 3k/16 ≤ (2n)−2(cid:18)t

k(cid:19)−1

.

If |K|s > n, then let L be a subset of K such that n ≤ |L|s ≤ 2n. The second part of Lemma
7.4 implies that P[|A2 + L| < n/2] ≤ e−s/800. If |A2 + L| ≥ n/2, then the probability that A2 + L is
when k = t/105, by the estimates
, so we
✷

disjoint from A3 is at most 2−s, which is much smaller than (cid:0)t
in the previous paragraph. Moreover, by the same estimates, e−s/800 is much less than (cid:0)t

are again done in this case provided C is suﬃciently large.

k(cid:1)−1

k(cid:1)−1

Combining Lemma 7.5 with the preceding remarks, we obtain the main result of this section.

Lemma 7.6 Let G be a ﬁnite Abelian group of order n and let U be a random subset of G of size
C(n log n)1/3. Then there exists an absolute constant C > 0 such that the probability that U is (1 −
10−5)-additively connected is at least 1 − 1/n.

Since this was what we needed to complete the proof of our main theorem, we are now done.

8 Concluding remarks

Ultimately, one might hope to prove a more precise result still. Deﬁne the Freiman dimension of a
subset A of an Abelian group to be one less than the dimension of the vector space of all Freiman
homomorphisms from A to R. For example, ZN has Freiman dimension 0, since every Freiman
homomorphism from ZN to R is constant, and an arithmetic progression P ⊂ Z has Freiman dimension
1, since a Freiman homomorphism from P to R is determined by the values it takes at the ﬁrst two

24

points. If A is a subset of ZN such that every Freiman homomorphism from A to an Abelian group H
extends to a Freiman homomorphism deﬁned on all of ZN , then A has Freiman dimension 0, since if
H = R, then the extension, and therefore the original homomorphism, must be constant. Therefore,
Theorem 1.2 implies that if a random subset A of ZN is chosen with probability C(log N )1/3N −2/3,
then it has Freiman dimension 0. It would be interesting to understand how the Freiman dimension of
the random set A decreases as the probability moves from CN −2/3 to C(log N )1/3N −2/3. For example,
it might be the case that a hitting time result holds. That is, if we build up our random set one element
at a time, it may be that the Freiman dimension drops to 0 at precisely the same moment when all
elements are contained in an additive quadruple.

References

[1] N. Alon and J. H. Spencer, The Probabilistic Method, 3rd edition, John Wiley & Sons, Inc.,

Hoboken, NJ, 2008.

[2] J. Balogh, R. Morris and W. Samotij, Independent sets in hypergraphs, J. Amer. Math. Soc. 28

(2015), 669–709.

[3] D. Conlon, Combinatorial theorems relative to a random set, in Proceedings of the International

Congress of Mathematicians 2014, Vol. 4, 303–328, Kyung Moon Sa, Seoul, 2014.

[4] D. Conlon and W. T. Gowers, Combinatorial theorems in sparse random sets, submitted,

arXiv:1011.4310 [math.CO].

[5] D. Conlon, W. T. Gowers, W. Samotij and M. Schacht, On the K LR conjecture in random graphs,

Israel J. Math. 203 (2014), 535–580.

[6] G. Fiz Pontiveros, Freiman homomorphisms of random subsets of ZN , Combin. Probab. Comput.

22 (2013), 592–611.

[7] E. Friedgut, V. R¨odl and M. Schacht, Ramsey properties of random discrete structures, Random

Structures Algorithms 37 (2010), 407–436.

[8] S. Janson and A. Ruci´nski, The infamous upper tail, Random Structures Algorithms 20 (2002),

317–342.

[9] V. R¨odl and M. Schacht, Extremal results in random graphs, in Erd˝os Centennial, 535–583, Bolyai

Soc. Math. Stud., Vol. 25, J´anos Bolyai Math. Soc., Budapest, 2013.

[10] D. Saxton and A. Thomason, Hypergraph containers, Invent. Math. 201 (2015), 925–992.

[11] M. Schacht, Extremal results for random discrete structures, preprint.

25

