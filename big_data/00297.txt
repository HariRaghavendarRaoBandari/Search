6
1
0
2

 

b
e
F
7
2

 

 
 
]

O
C

.
t
a
t
s
[
 
 

1
v
7
9
2
0
0

.

3
0
6
1
:
v
i
X
r
a

Bayesian Quantile Regression for Ordinal

Longitudinal Data

Rahim Alhamzawi∗

Abstract. Since the pioneering work by Koenker and Bassett (1978), quantile
regression models and its applications have become increasingly popular and im-
portant for research in many areas. In this paper, a random eﬀects ordinal quantile
regression model is proposed for analysis of longitudinal data with ordinal out-
come of interest. An eﬃcient Gibbs sampling algorithm was derived for ﬁtting the
model to the data based on a location-scale mixture representation of the skewed
double exponential distribution. The proposed approach is illustrated using sim-
ulated data and a real data example. This is the ﬁrst work to discuss quantile
regression for analysis of longitudinal data with ordinal outcome.

Keywords: Bayesian inference, Cut-points, Longitudinal data, Ordinal regression,
Quantile regression .

1 Introduction

The mean value has long been used as a measure of location of the center of a distribu-
tion. However, in many applications, there are occasions when analysts are interested
to observe and analyze diﬀerent points of the distribution. The distribution function
F of a random variable can be characterized by inﬁnite number of points spanning its
support. These points are called quantiles. Thus, quantiles are points taken at regular
intervals from F . The θth quantile of a data distribution, θ ∈ (0, 1), is interpreted as
the value such that there is 100(1 − θ)% of mass on its right side and 100θ% of mass
on its left side. In particular, for a continuous random variable Y , the 100θ% quantile
of F is the value y which solves F (y) = θ (we assume that this value is unique), where
F (y) = P (Y ≤ y). Thus, the population lower quartile, median and upper quartile are
the solutions to the equations F (y) = 1
4 , respectively. Com-
pared to mean value, quantiles are useful measures because they are less susceptible to
skewed distributions and outliers. This fact form the building block of quantile regres-
sion which unlike its standard mean regression counterpart, lies in its ﬂexibility and
ability in providing a more complete investigation of the entire conditional distribution
of the response variable distribution given its predictors. To this end, quantile regression
has become increasingly popular since the pioneering research of Koenker and Bassett
(1978).

2 and F (y) = 3

4 , F (y) = 1

After its introduction, quantile regression has attracted considerable attention in
recent literature. It has been applied in a wide range of ﬁelds such as agriculture
(Kostov and Davidova, 2013), body mass index (Bottai et al., 2014), microarray study

Statistics Department, College of Administration and Economics, Al-Qadisiyah University, Al Di-

waniyah, Iraq

March 2, 2016

2

Quantile Regression

(Wang and He, 2007), ﬁnancial portfolio (Mezali and Beasley, 2013), economics (Hendricks and Koenker,
1992), ecology (Cade and Noon, 2003), climate change (Reich, 2012), survival analysis
(Koenker and Geling, 2001) and so on. A comprehensive account of other recent appli-
cations of quantile regression can be found in Yu et al. (2003) and Koenker (2005).

Longitudinal data is encountered in a wide variety of applications, including eco-
nomics, ﬁnance, medicine, psychology and sociology. It is repeatedly measured from
independent subjects over time and correlation arises between measures from the same
subject. Since the pioneering work by Laird and Ware (1982), the mixed models with
random eﬀects have become common and active models to deal with longitudinal
data. A number of books and a vast number of research papers published in this
area have been motivated by Laird and Ware’s mixed models. The majority of these
books and research papers focuses on standard mean regression. See for example,
Wolﬁnger and O’connell (1993), Verbeke and Lesaﬀre (1996), Hedges and Vevea (1998),
Tao et al. (1999), McCulloch and Neuhaus (2001), Hedeker and Gibbons (2006) and
Baayen et al. (2008), among others. In contrast, limited research papers have been
conducted on quantile regression for longitudinal data. For example, Koenker (2004)
proposed the l1 regularization quantile regression model, Lipsitz et al. (1997) studied
quantile regression for longitudinal data in diﬀerent contexts and developed resampling
approaches for inference. Geraci and Bottai (2007) suggested a Bayesian quantile re-
gression method for longitudinal data using the skewed Laplace distribution (SLD) for
the errors, Reich et al. (2010) proposed a ﬂexible Bayesian quantile regression method
for dependent and independent data using an inﬁnite mixture of normals for the errors,
Yuan and Yin (2010) studied quantile regression for longitudinal data with nonignor-
able intermittent missing data and Alhamzawi and Yu (2014) proposed a method for
regularization in mixed quantile regression models.

Longitudinal data with ordinal responses routinely appear in many applications,
including economics, psychology and sociology. Existing approaches in classical mean
regression are typically designed to deal with such data. At present time, the most
common method in classical mean regression for modelling such data employs the cu-
mulative logit model. There exists a large literature on the analysis of longitudinal data
with ordinal responses, and we refer to Fitzmaurice et al. (2012) for an overview. In
contrast, quantile regression approaches for estimating the parameters of ordinal longi-
tudinal data have not been proposed, yet. The goal of this paper is to ﬁll this gap by
introducing an ordinal random eﬀects quantile regression model that is appropriate for
such data.

In Section 2, we present a random eﬀects ordinal quantile regression model for analy-
sis of longitudinal data with ordinal outcome by using a data augmentation method. We
also discuss prior elicitation. In Section 3, we outline the Bayesian estimation method
via Gibbs sampler. In Section 4, we carry out simulation scenarios to investigate the per-
formance of the proposed method, and in Section 5, we illustrate our proposed method
using a real dataset. We conclude the paper with a brief discussion in Section 6. An
appendix contains the Gibbs sampler details.

March 2, 2016

Rahim Alhamzawi

2 Methods

2.1 Quantile Regression

3

Given training data {(xi, yi), i = 1,··· , N}, with covariate vector xi ∈ Rp and outcome
of interest yi ∈ R. The θth quantile regression model for the response yi given the
covariate vector xi takes the form of

Qyi(θ|xi) = x′

iβ,

(1)

where Qyi(θ|xi) = F −1
yi (θ|xi) is the inverse Cumulative Distribution Function (CDF)
and β is the unknown quantile coeﬃcients vector. This is what makes the quantile esti-
mators can be considered nonparametric maximum likelihood estimators (Wasserman,
2006).

Unlike the standard mean regression, the error term does not appear in (1) because
all the random variation in the conditional distributions is accounted for by variation
in the θth quantile, θ ∈ (0, 1). Consequently, quantile regression does not require any
assumption about the distribution of the errors and, unlike standard mean regression,
is more robust to outliers and non-normal errors, oﬀering greater statistical eﬃciency
if the data have outliers or is non-normal. It belongs to a robust model family, which
can provide a more complete picture of the predictor eﬀects at diﬀerent quantile levels
of the response variable rather than focusing solely on the center of the distribution
(Yu et al., 2003). One attractive feature of quantile regression is that the linear quantile
regression model (Koenker and Bassett, 1978) can be used to estimate the parameters of
the nonlinear model because the quantile regression estimators are equivariant to linear
or nonlinear monotonic transformations of the response variable, i.e., Qlog10 yi(θ|xi) =
log10 Qyi(θ|xi). In general, this is a very important property since it tells us that quantile
regression provides consistent back transformation and easy in interpretation in the case
of transformations such as the logarithm and the square root.

The quantile estimators have the same interpretation as those of a standard mean re-
gression model except for the indexed quantile levels where each is estimated (Cade et al.,
2008). For example, if the slope is -0.78 for the response variable y given the predictor
x in the 95th quantile would indicate that the 95th quantile of the response variable
decreased by 0.78 for each 1 unit increase in x. The unknown quantity β is estimated
by

NXi=1

min
β

ρθ(yi − x′

iβ),

(2)

where ρθ(t) = tθ − tI(t < 0) is the check loss function (CLF) at a quantile θ, 0 < θ < 1,
and I(.) is the indicator function. By contrast, standard mean regression method based
on the quadratic loss t2. Koenker and Bassett (1978) observed that the CLF (2) is
closely related to the skewed Laplace distribution (SLD) and consequently the unknown
quantity β can be estimated through exploiting this link. This observation opens new

March 2, 2016

4

Quantile Regression

avenues when dealing with quantile regression and its applications. The density function
of a SLD is

f (ε|θ) = θ(1 − θ) expn − ρθ(ε)o,

−∞ < ε < ∞.

(3)

Minimizing the CLF (2) is equivalent to maximizing the likelihood function of εi =
yi − x′
iβ by assuming εi from a SLD. By utilizing the link between the CLF (2) and
the SLD, Yu and Moyeed (2001) proposed a Bayesian framework for quantile regression
using the SLD for the error distribution and show the propriety of the conditional distri-
bution of β under an improper prior distribution. Unfortunately, the joint posterior dis-
tribution under this framework does not have a known tractable form and consequently
Yu and Moyeed (2001) update the unknown quntity β from its posterior using the
Metropolis-Hastings (M-H) algorithm. In this context, Kozumi and Kobayashi (2011)
proposes a simple and eﬃcient Gibbs sampling algorithm for updating β by motivating
the SLD as a member of the scale mixture of normals. If εi ∼ N((1−2θ)vi, 2vi), then the
SLD for εi arises when vi has an exponential distribution with rate parameter θ(1 − θ).
Under this formulation, Yue and Rue (2011) presented a Bayesian framework for struc-
tured additive quantile regression models, Luo et al. (2012) developed Bayesian quantile
regression for longitudinal data and Alhamzawi and Yu (2014) presented Bayesian Lasso
mixed quantile regression.

2.2 Modeling Ordinal Longitudinal Data

Let y = {yij}(i = 1,··· , N ; j = 1,··· , ni), where yij denote the response for the ith
subject measured at the jth time. Then, the θth quantile regression model for ordinal
longitudinal data can be formulated in terms of an ordinal latent variable lij as follows:

Qlij|αi (θ|xij, αi) = αi + x′

ij β

(4)

where Qlij |αi(θ|xij , αi) is the inverse CDF of the unobserved latent response lij condi-
tional on a location-shift random eﬀect αi, αi ∼N(0, φ), and xij is a vector of predictors.
The observed ordinal response yij is assumed to be related to the unobserved response
lij by

yij =


if
1
if
c
C if

δ0 < lij ≤ δ1;
δc−1 < lij ≤ δc,
δC−1 < lij < δC ;

c = 2,··· , C − 1;

where δ0,··· , δC are cut-points whose coordinates satisfy −∞ = δ0 < δ1 < ··· <
δC−1 < δC = +∞. Here, δc−1 and δc are respectively deﬁnes the lower and upper
bounds of the interval corresponding to observed outcome c.

Assuming that the error εij of the unobserved response lij has a SLD as in (3),

we have εij = (1 − 2θ)vij +p2vij ǫij (Kozumi and Kobayashi, 2011). Here, the latent
variable vij follows an exponential distribution with rate parameter θ(1 − θ), and ǫij
follows the standard normal distribution. Then, the CDF for the c category of the
observed response yij is:

P(cid:0)yij ≤ c|lij, δc(cid:1)

= P(cid:0)lij ≤ δc|β, αi, vij(cid:1),

March 2, 2016

Rahim Alhamzawi

5

= P(cid:0)αi + x′
= P(cid:16)ǫij ≤
= Φ(cid:16) δc − αi − x′

ijβ + (1 − 2θ)vij +p2vijǫij ≤ δc(cid:1),
δc − αi − x′

(cid:17),

ijβ − (1 − 2θ)vij
p2vij
(cid:17),

ijβ − (1 − 2θ)vij
p2vij

as follows:

where Φ is the standard normal CDF. Using Φ, we can calculate P(cid:0)yij = c|lij, δc−1, δc(cid:1)
P(cid:0)yij = c|lij , δc−1, δc(cid:1)

= P(cid:0)δc−1 < lij ≤ δc|β, αi, vij(cid:1),
= Φ(cid:16) δc − αi − x′
ij β − (1 − 2θ)vij
p2vij

(cid:17) − Φ(cid:16) δc−1 − αi − x′

ij β − (1 − 2θ)vij
p2vij

(cid:17).

2.3 Priors

Prior distribution selection is an essential step in any Bayesian inference; however, in
the Bayesian paradigm it is particularly crucial as issues can arise when default prior
distributions are used without caution (Kinney and Dunson, 2007). For the ﬁxed eﬀects
β, a typical choice is to assign a zero mean normal prior distribution on each βk, k =
1, 2,··· , p, which leads to the ridge estimator. However, this prior performs poorly if
there are big diﬀerences in the size of ﬁxed eﬀects (Griﬃn et al., 2010). An generalization
of the ridge prior is a Laplace prior, which is equivalent to the Lasso model (Tibshirani,
1996; Bae and Mallick, 2004). This prior has received considerable attention in the
recent literature (for example see, Bae and Mallick (2004); Park and Casella (2008);
Hans (2009); Li et al. (2010); Griﬃn et al. (2010)). In this paper, we assign a Laplace
prior on each βk takes the form of

P (β|λ) =

pYk=1

λ
2

e−λ|βk|,

λ ≥ 0.

According to Andrews and Mallows (1974), the prior (5) can be written as

pYk=1

λ
2

e−λ|βk| =

Z ∞

0

pYk=1

N(βk; 0, sk)Exp(sk; λ2/2)dsk.

(5)

(6)

From (6), it can be seen that we assign a zero-mean normal prior distribution with
unknown variance for each βk. We specify an exponential prior distributions with rate
parameter λ2/2 for the variances assuming they are independent. Then, we put a gamma
prior on λ2 with shape parameter a1 and rate parameter a2. Since αi ∼N(0, φ), this
motivates us to consider an inverse gamma prior on φ with shape parameter b1 and
scale parameter b2.

Following Montesinos-L´opez et al. (2015) and Sorensen et al. (1995), we consider an

order statistics from U (δ0, δC) distribution, for the C − 1 unknown cut-points:

P (δ) = (C − 1)!(cid:16)

1

δmax − δmin(cid:17)C−1

I(δ ∈ T ),

(7)

March 2, 2016

6

Quantile Regression

where δ = (δ0, δ1,··· , δC) and T = {(δmin, δ1,··· , δmax)|δmin < δ1 < ··· < δC−1 <
δmax}. Because lij ∼N(αi + x′
ijβ + (1 − 2θ)vij, 2vij ) and we observe yij = c if δc−1 <
lij < δc, the posterior distribution of all the parameters and latent variables is given by

P (β, α, l, δ, v, s, λ2, φ|y) ∝ P (y|l, δ)P (l|β, α, v)P (δ)P (v)

× P (β|s)P (s|λ2)P (λ2)P (α|φ)P (φ),

(8)

), v = (v11,··· , vNnN

), l = (l11,··· , lNnN

), α = (α1,··· , αN )

where, y = (y11,··· , yNnN
and s = (s1,··· , sp).

The full conditional distributions for β, α, l, δ, v, s, λ2 and φ are summarized below

and details of all derivations are provided in Appendix A.

3 Gibbs Sampler

Using the data augmentation procedure as in Albert and Chib (1993), a Gibbs sampling
method for the ordinal quantile regression model with longitudinal data is constructed
by updating β, α, l, δ, v, s, λ2, and φ from their full conditional distributions. From (8),
we can construct a tractable algorithm for eﬃcient posterior computation that works
as follows:

1. Sample vij (i = 1,··· , N, j = 1,··· , ni) from the generalized inverse Gaussian

distribution GIG(ν, ̺1, ̺2), where ̺2

1 = (lij − x′

ijβ − αi)2/2 and ̺2

2 = 1/2.

2. Sample βk(k = 1, 2,··· , p) from N(µβk , σ2

βk

) where

σ2

βk = (cid:16) NXi=1

niXj=1

and

x2
ijk
2vij

µβk = σ2
βk

NXi=1

niXj=1

,

1

+

sk(cid:17)−1
(cid:16)lijk −Pp

h=1,h6=k xijhβh − αi − (1 − 2θ)vij(cid:17)xijk

.

2vij

1 = β2

k and ̺2

k=1 sk/2 + a2.

3. Sample sk, (k = 1, 2,··· , p) from GIG(0.5, ̺1, ̺2), where ̺2
4. Sample λ2 from Gamma distribution with shape parameter p + a1 and rate pa-
rameter Pp
5. Sample αi(i = 1,··· , N ) from N(µαi , σ2
φ(cid:17)−1

αi = (cid:16) niXj=1

αi ), where

2 = λ2.

1
2vij

σ2

,

1

+

and

µαi = σ2
αi

(cid:16)lij − x´ij β − ξvij(cid:17)

2vij

.

niXj=1

March 2, 2016

Rahim Alhamzawi

7

i=1

6. Sample φ from inverse Gamma distribution with shape parameter N

α2
2 + b2.
i

scale parameter PN
7. Sample lij(i = 1,··· , N, j = 1,··· , ni) from truncated normal (TN) distribution
TN(δc−1,δc)(cid:16)αi + x′
8. Sample δc from a uniform distribution on the interval (cid:2) min{min(lij|yij = c +
1), δc+1, δmax}, max{max(lij|yij = c), δc−1, δmin}(cid:3).

ij β + (1 − 2θ)vij , 2vij(cid:17).

2 + b1 and

The details of the proposed Gibbs sampler algorithm and fully conditional posterior
distributions are given in Appendix A.

4 Simulation Studies

We carry out a Monte Carlo simulation studies to assess the performance of the pro-
posed method. We compared the proposed Bayesian quantile regression method for
ordinal longitudinal data, referred to as “BQOL”, with Bayesian Quantile Regression
for Ordinal Models (BQROR) reported by Rahman (2016). The results of Bayesian
logistic ordinal regression (BLOR) for longitudinal data and the maximum likelihood
logistic ordinal regression (MLE) were also reported. Models were assessed based on
the relative average bias and the estimated relative eﬃciency. Suppose that we are in-
terested in the estimation of a vector of parameters ψ´ = (ψ1, ψ2,··· , ψm). Then, the
relative average bias of ψh(h = 1, 2,··· , m) is given by
ˆψr
h − ψh
| ψh|

MXr=1

1
M

,

dbias( ˆψh) =

and the estimated relative eﬃciency

ceﬀ model( ˆψh) =

model( ˆψh)
S2
BQOL( ˆψh)
S2

,

where M denotes the number of replications, ˆψr
replication, ψh is the true value, S2( ˆψh) = 1

M PM

h is the parameter estimate for the rth
ˆψr
r=1( ˆψr
h.

h − ¯ψh)2 and ¯ψh = 1

r=1

M PM

4.1 Simulation 1

Here, we follow the same simulation strategy introduced by Montesinos-L´opez et al.
(2015). Speciﬁcally, we simulated data from the following liability:

lij = β1x1ij + β2x2ij + β3x3ij + εij ,

(i = 1,··· , 40; j = 1,··· , ni)

where x1ij and x2ij were sampled independently from a uniform distribution on the
interval [−0.1, 0.1], (β1, β2, β3) = (−5,−10, 15) and εij were sampled independently

March 2, 2016

8

Quantile Regression

Table 1: Estimated relative bias and relative eﬃciency for the simulated data 1. The
proposed model (BQOL) is compared with three other models: the Bayesian quantile

regression for ordinal models (BQROR), Bayesian logistic ordinal regression (BLOR) for

longitudinal data and the maximum likelihood logistic ordinal regression (MLE)

ni Parameter

5

10

20

β1
β2
β3
δ1
δ2
δ3
δ4

β1
β2
β3
δ1
δ2
δ3
δ4

β1
β2
β3
δ1
δ2
δ3
δ4

BQOLθ=0.5
bias
eﬀ
-0.051
-0.002
0.019
-0.012
0.003
0.003
0.012

1.000
1.000
1.000
1.000
1.000
1.000
1.000

-0.058
0.022
0.020
-0.002
-0.001
-0.003
-0.001

-0.011
-0.010
0.004
-0.005
0.003
0.000
0.003

1.000
1.000
1.000
1.000
1.000
1.000
1.000

1.000
1.000
1.000
1.000
1.000
1.000
1.000

eﬀ

BQRORθ=0.5
bias
-0.079
0.082
0.169
-0.011
-0.010
-0.024
-0.011

1.103
1.113
1.350
1.091
1.014
1.213
1.203

-0.099
0.132
0.026
0.009
0.004
0.038
0.035

-0.032
0.077
0.042
-0.016
-0.017
-0.029
-0.036

1.128
1.059
1.056
1.007
0.999
1.006
1.014

1.117
1.019
1.107
1.008
1.015
1.073
1.088

BLOR
bias
0.082
0.093
0.110
-0.036
-0.009
-0.001
0.013

-0.165
-0.033
-0.055
-0.001
-0.003
0.002
0.000

-0.030
-0.162
0.029
-0.001
0.014
-0.002
0.002

eﬀ

1.012
1.034
1.131
1.113
1.013
0.944
1.147

1.211
1.067
1.029
1.004
0.998
1.003
0.998

1.071
1.131
1.224
0.999
1.007
0.996
0.999

MLE

bias
-0.068
-0.134
0.167
-0.031
-0.016
0.002
0.016

-0.119
-0.100
-0.032
-0.002
0.002
-0.003
0.006

-0.107
-0.116
0.108
-0.003
-0.004
-0.016
-0.006

eﬀ

1.009
1.071
1.025
1.004
1.037
1.056
1.007

1.018
1.009
1.035
1.021
1.048
1.025
1.008

1.051
1.119
1.103
0.999
1.028
1.008
1.034

from a logistic distribution with location parameter µ = 0 and scale parameter s = 1.
Three values of ni were considered, ni = 5, 10, and 20. The cut-points used were δ1 =
−0.8416, δ2 = −0.2533, δ3 = 0.2533 and δ4 = 0.8416. Then the outcome yij was sampled
according to:

yij =




1
2
3
4
5

if
if
if
if
if

−∞ < lij ≤ −0.8416,
−0.8416 < lij ≤ −0.2533,
−0.2533 < lij ≤ 0.2533,
0.2533 < lij ≤ 0.8416,
0.8416 < lij < ∞.

For each choice of ni (ni = 5, 10, and 20), we generated 200 data sets. We ran the
proposed Gibbs sampler algorithm for 20,000 iterations, after a burn-in period of 2000
iterations.

In Table 1, we present the simulation results of Simulation study 1 for β1, β2, β3, δ1,

March 2, 2016

Rahim Alhamzawi

9

δ2, δ3 and δ4, including the estimated relative bias and the estimated relative eﬃciency.
In general, it can be seen that the absolute bias obtained by the proposed model (BQOL)
when θ = 0.5 is much smaller than its competing models. In most cases, BQOL was
better than the other methods in terms of bias and the relative eﬃciency. The results
suggest that our method performs well compare to other approaches. We see that the
Bayesian quantile regression approach for ordinal data (BQROR) performs poorly com-
pared to the other methods because it ignores the nature of the longitudinal data. We
also see that as ni increases, the Bayesian logistic ordinal regression (BLOR) for longi-
tudinal data yields low bias and more eﬃciency. In Table 2, we present the simulation
results of Simulation study 1 for Bayesian quantile regression methods when θ = 0.25
and 0.75. Again, in most cases, BQOL was better than BQROR in terms of bias and
the relative eﬃciency.

March 2, 2016

10

Quantile Regression

Table 2: Estimated relative bias and relative eﬃciency of the Bayesian quantile regression

methods for the simulated data 1 when θ = 0.25 and 0.75.

θ = 0.25

θ = 0.75

ni Parameter

5

10

20

β1
β2
β3
δ1
δ2
δ3
δ4

β1
β2
β3
δ1
δ2
δ3
δ4

β1
β2
β3
δ1
δ2
δ3
δ4

BQOL
eﬀ

1.000
1.000
1.000
1.000
1.000
1.000
1.000

1.000
1.000
1.000
1.000
1.000
1.000
1.000

1.000
1.000
1.000
1.000
1.000
1.000
1.000

bias
0.128
-0.057
0.016
0.035
0.018
0.013
0.020

-0.132
-0.049
-0.003
-0.016
-0.009
-0.008
0.019

-0.026
-0.156
0.037
-0.014
-0.007
0.000
0.008

eﬀ

BQROR
bias
0.194
-0.058
0.018
-0.030
-0.039
-0.021
-0.025

1.738
2.014
1.374
1.238
1.098
1.043
1.051

0.137
0.064
0.002
0.037
0.040
0.033
0.036

-0.037
0.210
-0.044
0.064
0.005
0.030
0.070

1.035
1.836
1.005
1.016
1.142
1.115
1.003

1.731
1.079
1.117
1.008
1.116
1.138
1.129

BQOL
bias
-0.174
-0.070
0.083
-0.003
0.005
0.010
0.022

-0.182
-0.054
0.011
-0.008
-0.008
-0.007
-0.018

0.013
-0.177
0.013
-0.012
-0.009
-0.008
-0.006

eﬀ

1.000
1.000
1.000
1.000
1.000
1.000
1.000

1.000
1.000
1.000
1.000
1.000
1.000
1.000

1.000
1.000
1.000
1.000
1.000
1.000
1.000

BQROR
bias
-0.191
0.091
0.066
-0.014
-0.059
-0.040
-0.027

-0.183
-0.074
0.083
0.020
0.031
0.004
0.028

0.018
0.235
0.018
-0.009
0.016
0.016
0.010

eﬀ

1.223
2.031
1.319
1.011
1.015
1.056
1.037

1.159
1.037
1.215
1.117
1.027
1.006
1.014

1.005
1.371
1.009
1.004
1.032
1.098
1.007

4.2 Simulation 2

The setup for this simulation study is the same as Simulation 1, except we sampled the
latent variable lij as follows:

lij = αi + β1x1ij + β2x2ij + β3x3ij + εij,

αi ∼ N(0, 1).

This allows us to examine the performance of the proposed model in the case of random
eﬀects. In this simulation study, we only consider the performance of the Bayesian
methods for longitudinal data with ordinal outcome (BQOL and BLOR). In Table 3,
we present the estimates of the parameters β1, β2, β3, δ1, δ2, δ3 and δ4, when θ = 0.5 and
0.25. From Table 3 we can see that, our approach tends to give less biased parameter
estimates for β1, β2, β3, δ1, δ2, δ3 and δ4 compared to BLOR. The convergence of the
proposed Gibbs sampling algorithm in this simulation study was monitored using the
multivariate potential scale reduction factor (MPSRF) reported by Brooks and Gelman
(1998).

March 2, 2016

Rahim Alhamzawi

11

Table 3: The parameter estimations for the simulated data 2 when θ = 0.50 and 0.25.

ni Parameter Mean
-5.169
-10.028
15.259
-0.862
-0.249
0.251
0.849

BQOLθ=0.50
SD
0.738
0.771
0.688
0.061
0.066
0.063
0.073

5

β1
β2
β3
δ1
δ2
δ3
δ4

10

20

β1
β2
β3
δ1
δ2
δ3
δ4

β1
β2
β3
δ1
δ2
δ3
δ4

-5.132
-10.239
15.024
-0.848
-0.258
0.258
0.848

-4.992
-10.039
15.040
-0.856
-0.263
0.249
0.842

0.935
0.722
0.776
0.064
0.061
0.073
0.059

0.739
0.812
0.699
0.066
0.085
0.081
0.076

BQOLθ=0.25
SD
1.003
1.035
0.935
0.083
0.064
0.079
0.083

Mean
-5.310
-9.838
15.392
-0.842
-0.237
0.261
0.857

-5.116
-10.117
15.317
-0.842
-0.244
0.246
0.845

-5.162
-10.337
14.893
-0.853
-0.257
0.249
0.853

0.998
1.028
0.993
0.083
0.089
0.076
0.037

0.893
0.926
0.794
0.081
0.063
0.066
0.087

BLOR

Mean
-5.661
-9.682
14.273
-0.871
-0.231
0.261
0.881

-5.842
-9.773
15.235
-0.863
-0.255
0.259
0.868

-5.337
-10.241
14.753
-0.863
-0.247
0.261
0.857

SD
1.069
1.036
1.053
0.088
0.071
0.069
0.093

1.014
0.998
1.037
0.087
0.073
0.079
0.081

0.982
1.013
1.045
0.079
0.066
0.071
0.081

March 2, 2016

12

Quantile Regression

q = 0.5

F
R
S
P
M

F
R
S
P
M

6

5

4

3

2

1

7

6

5

4

3

2

1

5000

10000

Iterations

q = 0.25

15000

20000

5000

10000

Iterations

15000

20000

Figure 1: MPSRF for longitudinal ordinal quantile regression in Simulation 2.

From Figure (1), it can be observed that the MPSRF becomes stable and very close
to 1 after about the ﬁrst 5000 iterations for each quantile level under consideration.
Hence, the convergence to the posterior distribution was quick and the mixing was
good.

5 Longitudinal Data Example

In this section, we consider a data set from the National Institute of Mental Health
Schizophrenia Collaborative (NIMHSC) study previously analysed by (Gibbons and Hedeker,
1994). The objective of this study is to assess treatment-related changes in illness sever-
ity over time. Speciﬁcally, we studied item 79 (imps79o; severity of illness) of the inpa-
tient multidimensional psychiatric scale. This item was measured on a seven point scale

March 2, 2016

Rahim Alhamzawi

13

Table 4: Seven point scale for the NIMHSC study

normal
borderline mentally ill

1
2
3 mildly ill
4 moderately ill
5 markedly ill
6
7

severly ill
among the most extremely ill

as in Table 4:

Hedeker and Gibbons (1994) recorded the seven point scale into four: (1) not ill or
borderline, (2) mildly or moderately, (3) markedly ill, (4) severely or most extremely
ill. Patients were randomized to receive one of four medications, either placebo or one
of three diﬀerent anti-psychotic drugs. This study consists of three predictors: TxDrug
a dummy coded drug eﬀect variable (0=Placebo, 1=Drug), the square root of the week
(SqrtWeek), and the interaction between TxDrug and SqrtWeek (TxSWeek). At the θth
ordinal quantile regression, we considered

Qimps79oij (θ|·) = αi + β0 + β1TxDrugij + β2SqrtWeekij + β3TxSWeekij

March 2, 2016

14

Quantile Regression

Table 5: The parameter estimations for the NIMHSC study when θ = 0.50 and 0.25.

BQOLθ=0.50

BQOLθ=0.25

Parameter

β0
β1
β2
β3
δ1
δ2
δ3

Mean
5.663
-0.073
-0.746
-1.206
2.751
4.173
5.889

%95 CI

(5.037, 6.1192)
(-0.523, 0.419)
(-1.351, -0.1337)
(-1.663, -0.881)
(2.538, 2.879)
(3.894, 4.337)
(5.103, 6.709)

Mean
3.527
-0.048
-0.643
-1.104
2.865
3.984
5.765

%95 CI

(2.442, 4.735)
(-0.661, 0.783)
(-0.897, -0.437)
(-1.437, -0.789)
(2.479, 3.125)
(3.716, 4.118)
(5.042, 6.327)

BLOR
Mean
6.021
-0.227
-1.247
-0.883
1.997
3.764
5.443

%95 CI

(5.571, 7.421)
(-0.991, 0.771)
(-1.562, -0.661)
(-1.641, -0.291)
(1.087, 3.114)
(3.221, 4.261)
(4.793, 6.431)

Table 5 lists parameter estimations obtained using the Bayesian methods (BQOL
and BLOR). The methods are assessed based on 95% credible intervals and the de-
viance information criterion (DIC; Spiegelhalter et al., 2002). Clearly, it can be seen
that the credible intervals (95% CI) obtained using the BQOL when θ = 0.50 are
generally shorter than the credible intervals obtained using the BLOR, suggesting an
eﬃciency gain and stable estimation from the posterior distributions. In addition, DIC
was computed for our model when θ = 0.50 and θ = 0.25 as well as for BLOR and
the numbers were 3311.32, 3615.48 and 3417.39, respectively. Hence, under θ = 0.50,
model comparison using DIC indicates that quantile ordinal models can give a better
model ﬁt compared to the Bayesian logistic ordinal regression (BLOR) for longitudinal
data. This shows that the model uesd for the errors in (3) is a working model with arti-
cial assumptions, employed on the outcome variable to achieve the equivalence between
maximising SLD and the minimising proplem in (2).

6 Conclusion

Since Bayesian quantile methods for estimating ordinal models with longitudinal data
have not been proposed, yet. This paper ﬁlls this gap and presents a random eﬀects
ordinal quantile regression model for analysis of longitudinal data with ordinal outcome
of interest. An eﬃcient Gibbs sampling algorithm was derived for ﬁtting the model to the
data based on a location-scale mixture representation of the skewed double exponential
distribution. The proposed approach is illustrated using simulated data and a real data
example. Results show that the proposed approach performs well. One of the most
desirable features of the proposed method is its model robustness in the sense that
makes very minimal assumptions on the form of the error term distribution and thus is
able to accommodate non-normal errors and outliers, which are popular in many real
world applications.

March 2, 2016

Rahim Alhamzawi

15

Appendix A: Gibbs Sampler Details

The full conditional distribution of each vij , denoted by P (vij|lij , β, αi) is proportional
to P (lij|vij , β, αi)P (vij ). Thus, we have
P (vij|lij , β, αi) ∝ v−1/2

1

ij

expn −
expn −
expn −
expn −
expn −

1

1

2(cid:16) lij − x′
2(cid:16) (lij − x′
2h (lij − x′
2h (lij − x′
2h̺2

1v−1

1

1

ijβ − αi)2
2
ijβ − αi)2
2
2vijio,
ij + ̺2

− ζvijo
(cid:17)2
ijβ − αi − ξvij
p2vij
ij − 2ξvij (lij − x′
ij β − αi)2 + ξ2v2
2vij
+ 2ζ(cid:17)vijio
ij +(cid:16) ξ2
2(cid:17)vijio
ij +(cid:16) 1

v−1

v−1

2

ij

ij

∝ v−1/2
∝ v−1/2
∝ v−1/2
∝ v−1/2

ij

ij

ij β − αi)

+ 2ζvij(cid:17)o

where ξ = 1− 2θ and ζ = θ(1− θ). Thus, the full conditional distribution of each vij is a
generalized inverse Gaussian distribution GIG (ν, ̺1, ̺2), where ̺2
ij β − αi)2/2
and ̺2
2 = 1/2. Recall that if x ∼ GIG (0.5, ̺1, ̺2) then the pdf of x is given by
(Barndorﬀ-Nielsen and Shephard, 2001)

1 = (lij − x′

f (x|ν, ̺1, ̺2) =

(̺2/̺1)ν
2Kν(̺1̺2)

xν−1 exp(cid:26)−

1
2

(x−1̺2

1 + x̺2

2)(cid:27) ,

where x > 0, −∞ < ν < ∞, ̺1, ̺2 ≥ 0 and Kν(.) is so called “modiﬁed Bessel function
of the third kind ”.

The full conditional distribution of each βk, denoted by P (βk|l, β−k, α, v, sk) is pro-
portional to P (l|β, α, v, sk)P (βk|sk), where β−k is the vector β excluding the element
βk. Thus, we have

P (βk|l, β−k, α, v, sk) ∝ P (l|β, α, v, sk)P (βk|sk)

1

1
2

∝ expn −
∝ expn −

niXj=1
NXi=1
2h(cid:16) NXi=1
niXj=1
where xij = (xij1,··· , xijp) and ˜lijk = lijk −Pp
niXj=1

NXi=1

σ−2
βk

=

x2
ijk
2vij

conditional distribution for βk is normal with mean µβk and variance σ2
βk

, where

h=1,h6=k xijhβh − αi − ξvij. Then the full

(lij − x′

ijβ − αi − ξvij )2

2vij

x2
ijk
2vij

+

1
sk

)β2

k − 2

NXi=1

o expn −
niXj=1

˜lijkxijk

2vij

β2
k

2sko
βkio,

+

1
sk

,

March 2, 2016

16

Quantile Regression

and

µβk = σ2
k

NXi=1

niXj=1

˜lijkxijk

2vij

.

The full conditional distribution of each sk, denoted by P (sk|βk) is
sko

P (sk|βk) ∝ P (βk|sk)P (sk)
2sko expn −
expn −
k + λ2sk(cid:17)o
2(cid:16)β2
expn −

√2πsk

∝ s

ks−1

λ2
2

− 1
k

β2
k

∝

1

1

2

Thus, the full conditional distribution of sk is a GIG(0.5, ̺1, ̺2), where ̺2
2 = λ2.
̺2

1 = β2

k and

The full conditional distribution of λ2, denoted by P (λ2|s) is

P (λ2|s) = P (s|λ2)P (λ2)
expn −

pYk=1

sko(λ2)
∝
∝ (λ2)p+a1−1 expn − λ2(cid:16) pXk=1

λ2
2

λ2
2

a1−1

exp{−a2λ2}
sk/2 + a2(cid:17)o

(9)

(10)

(11)

That is, the full conditional distribution of λ2 is a Gamma distribution.

The full conditional distribution of each αi, denoted by P (αi|l, β, v, φ) is propor-

tional to P (l|αi, β, v)P (αi|φ). Thus, we have

P (αi|l, β, v, φ) ∝ P (l|αi, β, v)P (αi|φ)

∝ expn −
∝ expn −

1
2

niXj=1
2h(cid:16) niXj=1

1

1
2vij

(lij − x′

2vij

ij β − αi − ξvij )2
niXj=1

i − 2

)α2

1
φ

+

o expn −
αiio,

ηij
2vij

α2
i

2φo

where ηij = lij − x´ij β − ξvij . Then the full conditional distribution for αi is normal
with mean µαi and variance σ2

αi , where

niXj=1

1
2vij

+

1
φ

,

σ−2
αi =

and

µαi = σ2
αi

niXj=1

ηij
2vij

.

March 2, 2016

Rahim Alhamzawi

17

The full conditional distribution of φ, denoted by P (φ|α), is proportional to P (α|φ)P (φ).
Thus, we have

P (φ|α) ∝ P (α|φ)P (φ),

1

∝ (cid:16) NYi=1
∝ φ− N

√2πφ(cid:17) expn − PN
φ(cid:16)PN
2 −b1−1 expn −

1

i=1 α2
i
2φ

i=1 α2
i
2

b2

φo

oφ−b1−1 expn −
+ b2(cid:17)o

That is, the full conditional distribution of φ is a inverse Gamma distribution.

The full conditional distribution of each lij, denoted by P (lij|β, δ, αi, vij ) is propor-

tional to P (yij|lij, δ) P (lij|β, αi, vij ). Thus, we have

P (lij|β, δ, αi, vij ) ∝ P (yij|lij, δ)P (lij|β, αi, vij)
∝ 1{δc−1 < lij ≤ δc}N(lij; x′

ijβ + αi + ξvij, 2vij )

That is, the full conditional distribution of lij is a truncated normal distribution.

At last, the full conditional posterior distribution of δc, denoted by P (δc|y, l) is

proportional to p(y|l, δ)P (δ). Thus, we have

P (δc|y, l) ∝ p(y|l, δ)P (δ)
CXc=1

niYj=1

NYi=1

∝

1(yij = c)1(δc−1 < lij < δc)1(δ ∈ T )

(12)

(13)

Following Montesinos-L´opez et al. (2015) and Sorensen et al. (1995), the full conditional
distribution of δc is

P (δc|y, l) =

1

min(cid:16)lij|yij = c + 1(cid:17) − max(cid:16)lij|yij = c(cid:17) 1(δ ∈ T )

That is, the full conditional distribution of δc is a uniform distribution.

References

Albert, J. H. and Chib, S. (1993). “Bayesian analysis of binary and polychotomous
response data.” Journal of the American statistical Association, 88(422): 669–679. 6

Alhamzawi, R. and Yu, K. (2014). “Bayesian Lasso-mixed quantile regression.” Journal

of Statistical Computation and Simulation, 84(4): 868–880. 2, 4

Andrews, D. F. and Mallows, C. L. (1974). “Scale mixtures of normal distributions.”

Journal of the Royal Statistical Society. Series B (Methodological), 99–102. 5

Baayen, R. H., Davidson, D. J., and Bates, D. M. (2008). “Mixed-eﬀects modeling with
crossed random eﬀects for subjects and items.” Journal of memory and language,
59(4): 390–412. 2

March 2, 2016

18

Quantile Regression

Bae, K. and Mallick, B. K. (2004). “Gene selection using a two-level hierarchical

Bayesian model.” Bioinformatics, 20(18): 3423–3430. 5

Barndorﬀ-Nielsen, O. E. and Shephard, N. (2001). “Non-Gaussian Ornstein–Uhlenbeck-
based models and some of their uses in ﬁnancial economics.” Journal of the Royal
Statistical Society: Series B (Statistical Methodology), 63(2): 167–241. 15

Bottai, M., Frongillo, E. A., Sui, X., O’Neill, J. R., McKeown, R. E., Burns, T. L., Liese,
A. D., Blair, S. N., and Pate, R. R. (2014). “Use of quantile regression to investigate
the longitudinal association between physical activity and body mass index.” Obesity,
22(5): E149–E156. 1

Brooks, S. P. and Gelman, A. (1998). “General methods for monitoring convergence of
iterative simulations.” Journal of computational and graphical statistics, 7(4): 434–
455. 10

Cade, B. S. and Noon, B. R. (2003). “A gentle introduction to quantile regression for

ecologists.” Frontiers in Ecology and the Environment , 1(8): 412–420. 2

Cade, B. S., Terrell, J. W., and Porath, M. T. (2008). “Estimating ﬁsh body condition
with quantile regression.” North American Journal of Fisheries Management , 28(2):
349–359. 3

Fitzmaurice, G. M., Laird, N. M., and Ware, J. H. (2012). Applied longitudinal analysis,

volume 998. John Wiley & Sons. 2

Geraci, M. and Bottai, M. (2007). “Quantile regression for longitudinal data using the

asymmetric Laplace distribution.” Biostatistics, 8(1): 140–154. 2

Gibbons, R. D. and Hedeker, D. (1994). “Application of random-eﬀects probit regression

models.” Journal of consulting and clinical psychology, 62(2): 285. 12

Griﬃn, J. E., Brown, P. J., et al. (2010). “Inference with normal-gamma prior distri-

butions in regression problems.” Bayesian Analysis, 5(1): 171–188. 5

Hans, C. (2009). “Bayesian lasso regression.” Biometrika, 96(4): 835–845. 5

Hedeker, D. and Gibbons, R. D. (1994). “A random-eﬀects ordinal regression model for

multilevel analysis.” Biometrics, 933–944. 13

— (2006). Longitudinal data analysis, volume 451. John Wiley & Sons. 2

Hedges, L. V. and Vevea, J. L. (1998). “Fixed and random-eﬀects models in meta-

analysis.” Psychological methods, 3(4): 486. 2

Hendricks, W. and Koenker, R. (1992). “Hierarchical spline models for conditional quan-
tiles and the demand for electricity.” Journal of the American statistical Association,
87(417): 58–68. 2

Kinney, S. K. and Dunson, D. B. (2007). “Fixed and random eﬀects selection in linear

and logistic models.” Biometrics, 63(3): 690–698. 5

Koenker, R. (2004). “Quantile regression for longitudinal data.” Journal of Multivariate

March 2, 2016

Rahim Alhamzawi

Analysis, 91(1): 74–89. 2

19

— (2005). Quantile regression. 38. Cambridge university press. 2

Koenker, R. and Bassett, G. (1978). “Regression quantiles.” Econometrica: Journal of

the Econometric Society, 33–50. 1, 3

Koenker, R. and Geling, O. (2001). “Reappraising medﬂy longevity: a quantile re-
gression survival analysis.” Journal of the American Statistical Association, 96(454):
458–468. 2

Kostov, P. and Davidova, S. (2013). “A quantile regression analysis of the eﬀect of
farmers attitudes and perceptions on market participation.” Journal of Agricultural
Economics, 64(1): 112–132. 1

Kozumi, H. and Kobayashi, G. (2011). “Gibbs sampling methods for Bayesian quantile
regression.” Journal of statistical computation and simulation, 81(11): 1565–1578. 4

Laird, N. M. and Ware, J. H. (1982). “Random-eﬀects models for longitudinal data.”

Biometrics, 963–974. 2

Li, Q., Xi, R., and Lin, N. (2010). “Bayesian regularized quantile regression.” Bayesian

Analysis, 5(3): 533–556. 5

Lipsitz, S. R., Fitzmaurice, G. M., Molenberghs, G., and Zhao, L. P. (1997). “Quantile
Regression Methods for Longitudinal Data with Drop-outs: Application to CD4 Cell
Counts of Patients Infected with the Human Immunodeﬁciency Virus.” Journal of
the Royal Statistical Society: Series C (Applied Statistics), 46(4): 463–476. 2

Luo, Y., Lian, H., and Tian, M. (2012). “Bayesian quantile regression for longitudinal
data models.” Journal of Statistical Computation and Simulation, 82(11): 1635–1649.
4

McCulloch, C. E. and Neuhaus, J. M. (2001). Generalized linear mixed models. Wiley

Online Library. 2

Mezali, H. and Beasley, J. E. (2013). “Quantile regression for index tracking and en-
hanced indexation.” Journal of the Operational Research Society, 64(11): 1676–1692.
2

Montesinos-L´opez, O. A., Montesinos-L´opez, A., Crossa, J., Burgue˜no, J., and Eskridge,
K. (2015). “Genomic-enabled prediction of ordinal data with Bayesian logistic ordinal
regression.” G3: Genes— Genomes— Genetics, 5(10): 2113–2126. 5, 7, 17

Park, T. and Casella, G. (2008). “The Bayesian lasso.” Journal of the American

Statistical Association, 103(482): 681–686. 5

Rahman, M. A. (2016). “Bayesian Quantile Regression for Ordinal Models.” Bayesian

Analysis, 11(1): 1–24. 7

Reich, B. J. (2012). “Spatiotemporal quantile regression for detecting distributional
changes in environmental processes.” Journal of the Royal Statistical Society: Series
C (Applied Statistics), 61(4): 535–553. 2

March 2, 2016

20

Quantile Regression

Reich, B. J., Bondell, H. D., and Wang, H. J. (2010). “Flexible Bayesian quantile

regression for independent and clustered data.” Biostatistics, 11(2): 337–352. 2

Sorensen, D., Andersen, S., Gianola, D., and Korsgaard, I. (1995). “Bayesian inference
in threshold models using Gibbs sampling.” Genetics Selection Evolution, 27(3):
229–249. 5, 17

Spiegelhalter, D. J., Best, N. G., Carlin, B. P., and Van Der Linde, A. (2002). “Bayesian
measures of model complexity and ﬁt.” Journal of the Royal Statistical Society: Series
B (Statistical Methodology), 64(4): 583–639. 14

Tao, H., Palta, M., Yandell, B. S., and Newton, M. A. (1999). “An estimation method

for the semiparametric mixed eﬀects model.” Biometrics, 55(1): 102–110. 2

Tibshirani, R. (1996). “Regression shrinkage and selection via the lasso.” Journal of

the Royal Statistical Society. Series B (Methodological), 267–288. 5

Verbeke, G. and Lesaﬀre, E. (1996). “A linear mixed-eﬀects model with heterogeneity
in the random-eﬀects population.” Journal of the American Statistical Association,
91(433): 217–221. 2

Wang, H. and He, X. (2007). “Detecting diﬀerential expressions in Gene Chip microar-
ray studies: a quantile approach.” Journal of the American Statistical Association,
102(477): 104–112. 2

Wasserman, L. (2006). All of nonparametric statistics. Springer Science & Business

Media. 3

Wolﬁnger, R. and O’connell, M. (1993). “Generalized linear mixed models a pseudo-
likelihood approach.” Journal of statistical Computation and Simulation, 48(3-4):
233–243. 2

Yu, K., Lu, Z., and Stander, J. (2003). “Quantile regression: applications and current
research areas.” Journal of the Royal Statistical Society: Series D (The Statistician),
52(3): 331–350. 2, 3

Yu, K. and Moyeed, R. A. (2001). “Bayesian quantile regression.” Statistics & Proba-

bility Letters, 54(4): 437–447. 4

Yuan, Y. and Yin, G. (2010). “Bayesian quantile regression for longitudinal studies

with nonignorable missing data.” Biometrics, 66(1): 105–114. 2

Yue, Y. R. and Rue, H. (2011). “Bayesian inference for additive mixed quantile regres-

sion models.” Computational Statistics & Data Analysis, 55(1): 84–96. 4

March 2, 2016

