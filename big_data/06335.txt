6
1
0
2

 
r
a

M
 
1
2

 
 
]

.

M
B
o
i
b
-
q
[
 
 

1
v
5
3
3
6
0

.

3
0
6
1
:
v
i
X
r
a

ASYMPTOTICS OF STOCHASTIC PROTEIN ASSEMBLY

MODELS

MARIE DOUMIC, SARAH EUG`ENE, AND PHILIPPE ROBERT

Abstract. Self-assembly of proteins is a biological phenomenon which gives
rise to spontaneous formation of amyloid ﬁbrils or polymers. The starting
point of this phase, called nucleation exhibits an important variability among
replicated experiments. To analyse the stochastic nature of this phenomenon,
one of the simplest models considers two populations of chemical components:
monomers and polymerised monomers.
Initially there are only monomers.
There are two reactions for the polymerization of a monomer: either two
monomers collide to combine into two polymerised monomers or a monomer
is polymerised after the encounter of a polymerised monomer. It turns out
that this simple model does not explain completely the variability observed in
the experiments. This paper investigates extensions of this model to take into
account other mechanisms of the polymerization process that may have impact
an impact on ﬂuctuations. The ﬁrst variant consists in introducing a prelim-
inary conformation step to take into account the biological fact that, before
being polymerised, a monomer has two states, regular or misfolded. Only mis-
folded monomers can be polymerised so that the ﬂuctuations of the number of
misfolded monomers can be also a source of variability of the number of poly-
merised monomers. The second variant, based on numerical considerations,
represents the reaction rate α of spontaneous formation of a polymer as of the
order of N−ν , for some large scaling variable N representing the reaction vol-
ume and ν some positive constant. Asymptotic results involving diﬀerent time
scales are obtained for the corresponding Markov processes. First and second
order results for the starting instant of nucleation are derived from these limit
theorems. The proofs of the results rely on a study of a stochastic averaging
principle for a model related to an Ehrenfest urn model, and also on a scaling
analysis of a population model.

Contents

Introduction

1.
2. Stochastic Models with Misfolding Phenomena
3. Models with Scaled Reaction Rates
References

1. Introduction

1
6
15
18

Self-assembly of proteins is an important biological phenomenon, on the one
hand associated with human diseases such as Alzheimer’s, Parkinson’s, Hunting-
ton’s diseases and still many others, and on the other hand involved in industrial
processes, see McManus et al. [20] and Ow and Dustan [22]. The initial step of
the chain reactions giving rise to amyloid ﬁbrils consists in the spontaneous forma-
tion of a so-called nucleus, that is, the simplest possible polymer able to ignite the

Date: March 22, 2016.

1

2

MARIE DOUMIC, SARAH EUG`ENE, AND PHILIPPE ROBERT

reaction. This early phase is called nucleation, and is still far from being under-
stood. As underlined by previous studies Szavits-Nossan et al. [28], the nucleation
step is intrinsically stochastic, leading to an important variability among replicated
experiments, not only in small volumes but even in relatively large ones, see Xue
et al. [29]. The question of building convenient stochastic models, able to render
out the heterogeneity observed, and even to predict it, has recently raised much
interest in the biological and biophysical community, see Szavits-Nossan et al. [28],
Yvinec et al. [30], Pigolotti et al. [24] and Eden et al. [9].

We start with a simple stochastic model, proposed and studied in Eug`ene et
al. [10] for which we consider extensions to get a deeper understanding on the in-
tricate inﬂuence of each reaction considered. In Eug`ene et al. [10], rigorous asymp-
totics of the simple model were proved, and it was ﬁtted to the experimental data
published in Xue et al [29]. It was shown that the predicted variability was much
smaller by the model than what was experimentally obtained. One of the conclu-
sions of this work is that other mechanisms had to be taken into account to explain
the variability observed in the experiments. We thus propose here two ways to
complement the basic model. Let us ﬁrst recall its deﬁnition.

1.1. The Basic Model. One of the simplest models to describe the nucleation
process considers two populations of chemical components: (regular) monomers
and polymerised monomers.
Initially there are only monomers. There are two
reactions for the polymerization of a monomer: either two monomers collide to
combine into two polymerised monomers or a monomer is polymerised after the
encounter of a polymerised monomer. The chemical reactions associated with the
basic model can then be described as follows:

(1)

X1 + X1

X1 + X2

α−→ 2X2,
β−→ 2X2.

1 (t), X N

2 (t)), where X N

These reactions can be represented by the sample paths of a Markov process
(X N
2 (t)] is the number of regular [resp. poly-
merised] monomers at time t ≥ 0. The scaling variable N which will be used should
be thought of as the reaction volume. In particular X N
2 (t)/N is the concentration
of polymerised monomers at time t. If MN is the initial number of monomers, it is
assumed that the following regime

1 (t) [resp. X N

(2)

lim

N→+∞

MN
N

= m

holds for some m > 0. The quantity MN /N is in fact the initial concentration of
monomers.

2 (t)) are given by, for x = (x1, x2) ∈ N2,

The transition rates of (X N

(3)

x (cid:55)→

(cid:40)

1 (t), X N
x+(−2, 2)
x+(−1, 1)

at rate

α(x1/N )2
βx1/N × x2/N.

The second coordinate x2 is in fact the polymerized mass which explains the jumps
of size 2 in the reactions. Note that the conservation of mass implies that the
quantity X N
2 (t) is constant and equal to MN , the total number of initial
monomers.

1 (t)+X N

(cid:19)

= (x2(t))

lim

(cid:18) X N
˙x2(t) = α(cid:0)m − x2(t)(cid:1)2

N→+∞

2 (N t)
N

(4)

(5)

ASYMPTOTICS OF STOCHASTIC PROTEIN ASSEMBLY MODELS

3

— The ﬁrst reaction of (1) converts two monomers into two polymerised
monomers.
In our model, due to thermal noise in particular, these re-
actions will occur in a stochastic way. Following the principles of the law
of mass action, the encounter of two chemical species occurs at a rate pro-
portional to the product of the concentrations of each species. Therefore
two given monomers disappear to produce two polymerised monomers at a
rate α(x1/N )2.

— The second reaction can be seen as an auto-catalytic process. Here, given
a monomer at the contact of a polymerised monomer, the monomer is
converted into a polymerised monomer at a rate β. Again, by the law of
mass action, regular monomers disappear at the rate β(x1/N )(x2/N ).

See Eug`ene et al. [10], Szavits-Nossan et al. [28] and Xue et al. [29] for a gen-
eral presentation of these phenomena in a biological context. For more discussion
and results on stochastic models associated to chemical reactions, see for example
Anderson and Kurtz [1] and Higham [13] and references therein.

This simple, intuitive model of polymerisation has the advantage of having only
two parameters to determine. It can be analyzed mathematically by standard tools
of probability theory, see Eug`ene et al. [10]. It has been shown that if X N
2 (t) is the
number of polymerised monomers at time t, then the polymerisation process can
be described via the following convergence in distribution

holds, where (x2(t)) is the non-trivial solution of the following simple ordinary
diﬀerential equation

+ β(cid:0)m − x2(t)(cid:1)x2(t)

converging to m has t goes to inﬁnity.

By using these simple mathematical results and the data from experiments with
17 diﬀerent concentrations of monomers (the value of m) and 12 experiments for
each concentration, Table I of Eug`ene et al. [10] shows that, in this setting, the
estimation of β is reasonably robust. This is unfortunately not the case for the
numerical estimation of α which is varying from 1.68·10−2 to 9.57·10−8. An addi-
tional diﬃculty with this simple model comes from the small values of α obtained.
Indeed, for the experiments, the value of the volume N is in the order of 1015,
some of the estimated values of α in 10−8 are therefore, numerically, of the order
N . The asymptotic results are obtained when N gets large and α ﬁxed.
of 1/
For this reason, one may suspect a problem of convergence speed in Relation (4)
when these parameters are used. It turns out that our simulations conﬁrm that the
asymptotic regime (4) does not seem to represent accurately the system when α is
too small.

√

The purpose of the present paper is to reﬁne this basic model in two diﬀerent

ways.

(1) The model can be improved by introducing a key feature of the poly-
merisation process: the misfolding of monomers. Experiments show that
monomers can be polymerised only if their 3-D structure has been modi-
ﬁed by some events. Such monomers are called misfolded monomers, see
Dobson [7, 8], Knowles et al. [17]. It turns out that, at a given time, only

4

MARIE DOUMIC, SARAH EUG`ENE, AND PHILIPPE ROBERT

a small fraction of monomers are misfolded which may also explain that
the polymerisation process starts very slowly. In biological cells, this phe-
nomenon of misfolding is reversible, dedicated proteins may “correct” the
misfolded monomers. A misfolded monomer can be turned into a “regular”
monomer and vice-versa. See Bozaykut et al. [4] and Lanneau et al. [19]
for example. Section 3 is devoted to the mathematical analysis of these
models.

(2) Another approach is to keep the basic model but with the parameter α
being of the order of 1/N ν for some positive ν to take into account that,
in practice, the values of this parameter can be very small. Note that this
is only a numerical observation, the value of α has no reason to depend on
the volume. This model is analyzed in Section 3.

The rest of the section is devoted to a brief sketch of the mathematical aspects of
these two classes of models. As it will be seen, the models are more challenging from
a mathematical point of view, the model with misfolded monomers in particular.

1.2. Models with Misfolding Phenomena. The chemical reactions associated
with this simple model are as follows:

X1 + X1

X1 + X2

α−→ 2X2,
β−→ 2X2.

X1,

X0

γ−→←−
∗

γ

0 (t) denotes the number of regular monomers, X N

At time t ≥ 0, X N
of misfolded monomers. As before the last coordinate X N
mass. As a Markov process, (X N (t)) = (X N
1 (t), X N
transitions, for an element x = (x0, x1, x2) ∈ N3,

0 (t), X N

1 (t) the number
2 (t) is the polymerized
2 (t)) has the following

(cid:40)
x+(1,−1, 0) at rate γ∗ x1
x+(−1, 1, 0)
γ x0,

(6)

x (cid:55)→

(cid:40)

x (cid:55)→

x+(0,−2, 2) α (x1/N )2
x+(0,−1, 1) β x1/N × x2/N.

It is important to note that the transition between state “0”, regular monomer, and
state “1”, misfolded monomer, is spontaneous. Consequently, as it can be seen, the
corresponding transition rates do not depend on the volume N but simply on the
numbers of components and not on their concentrations. An important consequence
of this observation is that the system exhibits a two time scales behavior that we
will investigate.

An informal description of the asymptotic behavior of (X N
2 (t)). The ﬁrst
two coordinates can be seen as an Ehrenfest process with two urns 0 and 1 where
each particle in urn 0 (resp. 1) goes to urn 1 (resp. 0) at rate γ (resp. γ∗). See
Bingham [3] and Karlin and McGregor [16] for example. Particles in urn 1 can also
go to the urn 2 corresponding to the polymerized mass but this phenomenon occurs
at a much slower rate so that, locally, it does not change the orders of magnitude
in N of X N
2 .
2 ∼x2N , there is a total of (m−x2)N particles in the urns 0 or 1. The
When X N
components (X N
1 (t)) are both of the order of N and are moving on a fast
time scale, proportional to N . The transition rates of the process (X N
2 (t)) are
slower, bounded with respect to N . Because of the fast transition rates of the ﬁrst
two coordinates, the Ehrenfest urn process should reach quickly an equilibrium

0 (t), X N

ASYMPTOTICS OF STOCHASTIC PROTEIN ASSEMBLY MODELS

5

for which X N
r = γ/(γ+γ∗), in particular

0 has a binomial distribution with parameter (m − x2)N and r with

X N
0
N

∼ (1 − r)(m − x2) and

X N
1
N

∼ r(m − x2).

This suggests that,

a) to see an evolution of X N

2 of the order of N , one has to be on the linear

time scale t (cid:55)→ N t: transition rates of the process X N
2 (N t) ∼ x2(t)N , in view of transition rates of (X N

b) if X N

2 are O(1)),
2 (t)) of Relation (6),

then (x2(t)) should satisfy the following ordinary diﬀerential equation

˙x2(t) = αr2(m − x2(t))2 + βr(m − x2(t))x2(t).

(7)

We recognize the limit equation (5) of the simple model, where α, β are respectively
replaced by αr2 and βr. This result is also true when considering the second
order ﬂuctuations of the number of polymers, see Theorem 2. The proof of the
convergence of the process of the concentration of polymerized monomers to the
solution of the ODE (5) use standard arguments of convergence of a sequence of
stochastic processes, see the supplementary material of Eug`ene et al. [10]. The
proof of the corresponding result with misfolding phenomena for the ODE (7) is,
as we shall see, more delicate to handle.

Stochastic Averaging Phenomenon. To summarize these observations, the co-
ordinates (X N
2 (t)) is a “slow” process
when the scaling parameter N goes to inﬁnity. This suggests a stochastic averaging
principle (SAP) in a fully coupled context.

1 (t)) form a “fast” process and (X N

0 (t), X N

(1) The stochastic evolution of (X N

2 (N t)) is driven by the invariant distribution

of an “instantaneous” associated Ehrenfest process.

(2) The parameters of the Ehrenfest process depend on the macroscopic vari-

able (X N

2 (N t)).

see Papanicolaou et al. [23] and Chapter 8 of Freidlin and Wentzell [11] for example,
see also Kurtz [18].

A stochastic averaging principle is indeed proved as well as a corresponding cen-
tral limit theorem (CLT). In our cases there are some diﬀerences with the “classical”
framework of stochastic averaging principles. The state space of the fast process
depends on the scaling parameter N , and is not in particular a “ﬁxed” process
(with varying parameters) as it is usually the case. See Hunt and Kurtz [14] or Sun
et al. [27] for example. A law of large numbers with respect to N for the invariant
distribution of the fast process is driving the evolution of the slow process. The
approach used in the paper relies on the use of occupation measures on a continuous
state space instead of a discrete space, this leads to some technical complications as
it will be seen. Concerning central limit theorems in a SAP context, there are few
references available for jump processes. The methods presented in Kang et al. [15]
or in Sun et al. [27] do not seem to be helpful in our case. Instead, an ad-hoc esti-
mation, Proposition 4, gives the main ingredient to derive a central limit theorem,
see Section 2.

1.3. Models with Scaled Reaction Rates. Again, X N
2 (t)) is the
number of regular (resp. polymerised) monomers at time t ≥ 0. The transition
rates of the Markov process (X N (t))=(X N
2 (t)) associated to these models

1 (t) (resp. X N

1 (t), X N

6

MARIE DOUMIC, SARAH EUG`ENE, AND PHILIPPE ROBERT

are the same, except that the parameter α is replaced by α/N ν with 0 < ν. For
x = (x1, x2) ∈ N2, the rates are given by

(8)

x (cid:55)→

x+(−2, 2)
x+(−1, 1)

at rate

α/N ν (x1/N )2
β x1/N × x2/N.

(cid:40)

Convergence (4) shows that the polymerisation occurs on the linear time scale
t (cid:55)→ N t for the basic model. It will be shown that the phenomenon does not start
on this time scale. A slightly more rapid time scale is necessary for this purpose,
it is shown that it is on the time scale t (cid:55)→ N log N·t for 0 < ν ≤ 1 and t (cid:55)→ N νt
when ν>1. See Section 3.

2. Stochastic Models with Misfolding Phenomena

The following notations will be used throughout the paper. For ξ ≥ 0, Nξ(dt)
denotes a Poisson process with parameter ξ and (N i
ξ (dt)) an i.i.d. sequence of such
processes. All the Poisson processes are deﬁned on a probability space (Ω,F, P). If
f is a real valued function on R+, f (t−) denotes its limit on the left of t≥0 when
it exists. Finally, m∗ denotes an upper bound for the sequence (MN /N ) which
converges to m > 0 by Relation (2).

Recall that, at time t ≥ 0 , (X N (t))=(X N

0 (t) is the
number of monomers, X N
2 (t) is
the polymerized mass. It is not diﬃcult to see that these processes can be seen as
the solution of the following stochastic diﬀerential equations,

1 (t) is the number of misfolded monomers and X N

2 (t)) where X N

0 (t), X N

1 (t), X N

X N

1 (t−)(cid:88)

0 (t−)(cid:88)
γ∗ (dt)− X N
N i
(cid:88)
i=1
i=1
1 −1)(t−)/2
1 (t−)(X N
X N

(9)

dX N

0 (t) =

dX N

2 (t) = 2



N i
γ(dt),

N i
α/N 2(dt)+

2 (t−)(cid:88)

1 (t−)X N
X N

N i
β/N 2 (dt),

i=1
0 (t)+X N
1 (t)+X N

2 (t) and initial

with the relation of conservation of mass MN =X N
condition X N (0)=(MN , 0, 0).

Equation (9) gives in particular that

(10) X N

2 (t) = X N

2 (0) +

α
N 2

X N

1 (s)(X N

i=1

(cid:90) t

0

(cid:90) t
1 (s)−1) ds

+

β
N 2

0

(cid:10)M N

(cid:11) (t) = 2

(cid:90) t

where (M N

2 (t)) is a martingale whose previsible increasing process is given by

(11)

X N
For i = 0, 1, 2 and t ≥ 0, denote

2

0

α
N 2

1 (s)(X N

1 (s)−1) ds +

β
N 2

X N

1 (s)X N

2 (s) ds

(cid:90) t

0

X N

1 (s)X N

2 (s) ds + M N

2 (t),

X

N
i (t) =

X N

i (N t)
N

,

N
the main goal of this section is to prove that the process (X
2 (t)) is converging in
distribution to the solution (x2(t)) of a non-trivial ordinary diﬀerential equation.
It will show in particular that the polymerization process is occurring on the linear
time scale t (cid:55)→ N t.

ASYMPTOTICS OF STOCHASTIC PROTEIN ASSEMBLY MODELS

7

2.1. Random Measures Associated to Occupation Times. Deﬁne µN the
random measure on R3

(cid:17)

X

N
0 (N u), X

N
1 (N u), u

du.

(cid:90)

+ by
(cid:104)µN , g(cid:105) =

(cid:16)

g

R+

(cid:90)

Proposition 1. The sequence (µN ) is tight. Any limiting point µ∞ of this sequence
is such that

(12)

(cid:104)µ∞, g(cid:105) =

g (x, y, u) πu(dx, dy) du,

R3

+

for any continuous function g on [0, m∗]2 × [0, T ], where for each u ≥ 0, πu is a
random Radon measure on R2
+.

N
0 (t) and X

Proof. Since X
restricted to the set R2
of Dawson [5] gives directly that the sequence (µN ) of random measure on R3
tight.

N
1 (t) are bounded, for any T > 0, the measure µN
+ × [0, T ] has a compact support. Lemma 3.2.8 page 44
+ is

Let (µNk ) be a convergent subsequence with limit µ∞. By using Skorohod’s
representation theorem, one can assume that there exists a negligible measurable
set A of the probability space such that, outside this subset, the convergence of the
sequence (µNk ) of Radon measures towards µ∞, that is
k→+∞(cid:104)µNk , g(cid:105) = (cid:104)µ∞, g(cid:105) for all g ∈ C([0, m
∗

]2 × [0, T ]),

lim

holds.
Let h ∈ C([0, m∗]2) and f ∈ C([0, T ], denoting h ⊗ f (x, y, u) = h(x, y)f (u), for
(x, y) ∈ [0, m∗]2 and u ∈ [0, T ], then, as a limit of the sequence (µNk ), the Radon
measure

f (cid:55)→ (cid:104)µN , h ⊗ f(cid:105)

is absolutely continuous with respect to Lebesgue’s measure. Consequently, for any
h ∈ C([0, m∗]2), there exists some function (˜πu(h), 0 ≤ u ≤ T ) such that

(cid:90) T

(cid:104)µ∞, h ⊗ f(cid:105) =

˜πu(h)f (u) du.

0

By the diﬀerentiation theorem, see Theorem 7.10 in Rudin [26], the function (˜πu(h))
can be represented as

(cid:10)µ∞, h ⊗ 1{[u−ε/2,u+ε/2]}(cid:11) ,

u ∈ [0, T ],

˜πu(h) = lim sup

ε→0

1
ε

consequently, the mapping (ω, u) (cid:55)→ ˜πu(h)(ω) is F ⊗ B([0, T ])-measurable.
Let S be a countable dense subset of C([0, m∗]2), then there exists a subset E0
of [0, T ] negligible for the Lebesgue measure such that, for all u ∈ [0, T ] \ E0 and
φ1, φ2 ∈ S,

(1) ˜πu(p1φ1 + p2φ2) = p1 ˜πu(φ1) + p2 ˜πu(φ2), ∀p1, p2 ∈ Q,
(2) ˜πu(φ1) ≤ ˜πu(φ2) if φ1 ≤ φ2,
(3) ˜πu(1) = 1.

With the same method as in Section II.88 of Rogers and Williams [25], for any
u ∈ [0, T ]\ E0 , one gets the existence of a Radon measure πu on [0, m∗]2 such that

8

MARIE DOUMIC, SARAH EUG`ENE, AND PHILIPPE ROBERT

˜πu(h) = πu(h) for any h ∈ S. By density of S, the mapping (ω, u) (cid:55)→ πu(h)(ω) is
also F ⊗ B([0, T ])-measurable and the relation

(cid:90) T

(cid:104)µ∞, h ⊗ f(cid:105) =

πu(h)f (u) du.

0

holds for all h ∈ C([0, m∗]2) and f ∈ C([0, T ]. The proposition is therefore proved.(cid:3)

Representation (12) is related to Lemma 1.4 of Kurtz [18]. Our proof relies
on classical arguments of measure theory, a functional version of Carath´eodory’s
extension theorem in particular which is described in Section II.88 of Rogers and
Williams [25]. In Kurtz [18], a more sophisticated result, see Morando [21], on the
extension of bi-measures is the key ingredient. The notion of bi-measure goes back
to Kingman, see Dellacherie and Meyer [6] for example. It should be mentioned
that Lemma 1.4 of Kurtz [18] gives also additional measurability properties of the
family (πu) which are of no use in our case.

Proposition 2. If µ∞ is a limiting point of (µN ) with the representation (12) then,
for any C1-function f on R2

+, almost surely

(cid:90) t

(cid:90)

(cid:18) ∂

(cid:19)

(13)

0

R2

+

∗

y − γx)

(γ

f (x, y) − ∂
∂y

∂x

f (x, y)

πu(dx, dy) du = 0,

∀t ≥ 0,

in particular, almost surely,

(cid:90) t

(cid:90)

(14)

0

R2

+

∗

y − γx)2 πu(dx, dy) du = 0,

(γ

∀t ≥ 0.

Relation (14) just says that almost surely and for almost all u, the measure πu

is degenerated on R2

+ and carried by the subset{(x, γx/γ∗) : 0 ≤ x ≤ m}.
Proof. for (i, j) ∈ Z2, one denotes by ∆ij the discrete diﬀerential operator

ij (f )(x, y) = f (x + i/N, y + j/N ) − f (x, y),
∆N

(x, y) ∈ [0, m
∗

]2.

After some trite calculations, the stochastic diﬀerential equations (9) give the rela-
tion

(15)

f

N

X

(t/N )

= f

X N

0 (s)∆N−1,1(f )

N

X

(s/N )

ds

(cid:16)

(cid:17)

(cid:90) t

(0)

+ γ

0

(cid:16)

(cid:17)
(cid:90) t

+ α

0

N

X

(cid:16)
∗(cid:90) t
(cid:90) t

+ γ

X N

1,−1(f )

0

X N

1 (s)∆N
1 (s) − 1)
1 (s)(X N
2N 2
X N
1 (s)
N

X N
2 (s)
N

0

+ β

(cid:17)

(cid:16)

(cid:17)

N

X

(s/N )

ds

(cid:16)

N

X

(cid:16)

(cid:17)

ds

(cid:17)

∆N

0,−2(f )

(s/N )

∆N

0,−1(f )

N

X

(s/N )

ds + M N

f (t),

ASYMPTOTICS OF STOCHASTIC PROTEIN ASSEMBLY MODELS

9

where (X
gale. Its previsible increasing process is given by

0 (N t)/N , X N

1 (N t)/N ) and (M N

(t)) = (X N

f (t)) is the associated martin-

N

(cid:10)M N

f

(16)

(cid:90) t

0

(cid:11) (t) = γ
(cid:90) t

+ γ

+ α

0

X N

X N

N

X

(s/N )

0 (s)∆N−1,1(f )2(cid:16)
∗(cid:90) t
1,−1(f )2(cid:16)
1 (s) − 1)
(cid:90) t
1 (s)(X N
2N 2

(cid:17)
0,−2(f )2(cid:16)

X1(s)∆N

∆N

X

N

0

+ β

0

X N
1 (s)
N

X N
2 (s)
N

∆N

(s/N )

X

ds

N

ds

(s/N )

(cid:17)
(cid:17)
0,−1(f )2(cid:16)
(cid:19)

(x, y)

+ o(1/N ),

(cid:17)

(s/N )

ds

N

X

ds.

Note that, for i, j ∈ Z

∆N

i,j(f )(x, y) =

(cid:18)

1
N

i

∂f
∂x

(x, y) + j

∂f
∂y

by changing the time variable in N t in Equation (15) and by dividing by N one
gets the relation

(17)

1
N

(cid:16)

(cid:16)

f

N

X

=

N

(t)

(0)

(cid:17) − f
(cid:16)
(cid:17)(cid:17)
(cid:90) t
(cid:104)
X
(cid:90) t
1 (s) − γX
(cid:16)
(cid:90) t

N
1 (s)

X

X

X

γ

∗

N

0

0

− α
N
− β
N

X

0

(cid:105)(cid:20) ∂f
N
0 (s)
∂x
1 (s) − 1/N
(cid:16)

N

(cid:21)(cid:16)
(cid:16)
(cid:17)

X

− ∂f
∂y

(cid:17) ∂f

∂y

(cid:17)

(cid:17)

N

X

(s)

ds

N

(s)

ds

N
1 (s)X

N
2 (s)

∂f
∂y

N

X

(s)

ds +

M N

f (N t)
N

+ o(1/N ),

N

(t) = (X

N
0 (t), X

with (X
(M N

f (N t)/N ) in the above expression is ((cid:104)M N

N
1 (t)). The previsible increasing process of the martingale
f (cid:105)(N t)/N 2). By using Equation (16)
N
and the fact that (X
i (t)) is bounded for i = 0 and 1, it is not diﬃcult to show
that its expected value converges to 0 as N gets large and, by Doob’s Inequality,
that the martingale converges in distribution to 0. With similar arguments, from
Equation (17), one gets therefore the following convergence in distribution

(cid:18)(cid:90) t

(cid:104)

(18)

lim

N→+∞

0

∗

X

N

1 (s) − γX

γ

N
0 (s)

(cid:105)(cid:20) ∂f

∂x

− ∂f
∂y

(cid:21)(cid:16)

(cid:17)

(cid:19)

N

X

(s)

ds

= 0.

For t ≥ 0,

(cid:90) t

(cid:104)

0

∗

X

N

1 (s) − γX

γ

(cid:105)(cid:20) ∂f
(cid:90)

∂x

N
0 (s)

=

(cid:21)(cid:16)

X

− ∂f
∂y
y − γx]
∗

[γ

N

(s)

(cid:20) ∂f

∂x

(cid:17)

ds

− ∂f
∂y

(cid:21)

(x, y) 1{s≤t} µN (dx, dy, ds),

10

MARIE DOUMIC, SARAH EUG`ENE, AND PHILIPPE ROBERT

and this last term converges in distribution to

(cid:90)

∗

y − γx]

[γ

(cid:20) ∂f

∂x

=

(cid:21)

− ∂f
∂y

(cid:90) t

(cid:90)

0

R2

+

(cid:18) ∂

(x, y) 1{u≤t} µ∞(dx, dy, du)

∗

y − γx)

(γ

f (x, y) − ∂
∂y

∂x

(cid:19)

f (x, y)

πs(dx, dy) ds.

This convergence in distribution also holds for any ﬁnite marginals of this process.
The convergence of processes (18) gives therefore the desired identity (13) in dis-
tribution. The last assertion of the proposition is proved by taking the function
f (x, y) = γ∗y2 − γx2.
(cid:3)

2.2. A Stochastic Averaging Principle. Relation (10) gives the following inte-
gral equation for (X

N
2 (t)),

(cid:90) t

0

(cid:17)

ds

(cid:16)

X

N

(cid:90) t
1 (s)−1/N

+ β

X

0

N
1 (s)X

N
2 (s) ds +

M N

2 (N t)
N

,

(19) X

N
2 (t)) = X

N
2 (0) + α

X

N
1 (s)

(cid:18)(cid:90) t

(cid:19)

(cid:18)(cid:90) t

The expected value of the previsible increasing process of the martingale converges
M N
2 (N t)N ) is vanishing as N gets large by Equation (11). Doob’s Inequality shows
that the martingale converges in distribution to 0. The criteria of the modulus of
N
continuity, see Billingsley [2], gives therefore that the sequence of processes (X
2 (t))
is tight. It can therefore be assumed, for some subsequence (Nk), that the following
convergence holds,

(cid:16)

(cid:16)

(cid:17)(cid:17)

lim

k→+∞

µNk ,

X

Nk
2 (t)

= (µ∞, (x2(t)))

for a random measure µ∞ as in Proposition 1 and some continuous stochastic
process (x2(t)). The rest of the section is devoted to the identiﬁcation of (x2(t)).
Proposition 3. For any continuous function g on [0, m∗]2, the relation

g(x, y)µ∞(dx, dy) du

dist.
=

g ((m−x2(u))(1−r, r)) du

0

holds, with r = γ/(γ + γ∗).

0

One concludes that the measure πu(dx, dy) of Proposition 1 is simply the Dirac
measure at [m−x2(u)](1−r, r). This is the rigorous description of the fact described
at the beginning of this section that if the fraction of polymerized mass is x2(u)
then the fraction of regular [resp. misfolded] monomers is (1− r)(m− x2(u)) [resp.
r(m − x2(u))].

Proof. The criteria of the modulus of continuity shows that the sequence of pro-
cesses

(cid:18)(cid:90) t

(cid:16)

g

0

(cid:17)

(cid:19)

X

Nk
0 (u), X

Nk
1 (u)

du

(cid:19)

ASYMPTOTICS OF STOCHASTIC PROTEIN ASSEMBLY MODELS

11

is tight. By convergence in distribution of (µNk ), one has, for t ≥ 0,
(cid:19)

Nk
0 (u), X

Nk
1 (u)

(cid:90) t

(cid:90) t

lim

k→+∞

(cid:18)

(cid:16)

(cid:17)

g

X

(cid:90) t

0

(20)

du

g(x, y)πu(dx, dy) du =

g

x,

0

0

γ
γ∗ x

πu(dx, dy) du

by Proposition 2. The same convergence in distribution also holds for ﬁnite marginals.
One has to identify the ﬁrst marginal of (πu). If f is a continuous function on [0, m∗],
by conservation of mass, one has the relation

(cid:17)

(cid:19)

(cid:18)(cid:90) t

du

=

f

0

(cid:18) MNk

Nk

(cid:19)

(cid:19)

− X

Nk
2 (u)

du

.

X

Nk
0 (u) + X

Nk
1 (u)

Relation (20) and the convergence properties of the right hand side of this identity
give the following identity of processes

(cid:18)(cid:90) t

(cid:16)

f

0

(cid:18)(cid:90) t

(cid:19)

(cid:18)(cid:90) t

(cid:19)
f (m − x2(u)) du

f (x/r) πu(dx, dy) du

=

0

0

The proposition is proved.

.

(cid:3)

Theorem 1. Under the scaling condition (2) and if the initial state of the solu-
tion (X N (t)) of the SDE (9) is X N (0) = (MN , 0, 0) then, for the convergence in
distribution,

(cid:18) X N

(cid:19)

(cid:18)

2 (N t)
N

= (x2(t))

def.
=

1 − e−βrmt

1 + (β/αr − 1)e−βrmt m

,

(cid:19)

lim

N→+∞

(21)
with r = γ/(γ + γ∗).

(cid:90) t

(cid:90) t

Proof. By using Relation (19), Proposition 1 and the above proposition, one gets
that any limiting point (x2(t)) of (X N
2 (N t)/N ) satisﬁes necessarily the following
integral equation (integral form of the equation (7))

(22)

x2(t) = αr2

(m − x2(s))2 ds + βr

(m − x2(s))x2(s) ds.

0

0

By uniqueness of the solution of this equation, one gets the convergence in distri-
bution of the sequence of processes (X N
2 (N t)/N ). Its explicit expression is easily
(cid:3)
obtained.

The following corollary gives the asymptotics of the ﬁrst instant when a fraction
δ ∈ (0, 1) of monomers has been polymerized. This is a key quantity that can be
measured with experiments.

Corollary 1. [Asymptotics of Lag Time] Under the conditions of Theorem 1, if
for δ ∈ (0, 1),
(23)

T N (δ) = inf{t ≥ 0 : X N

then, for the convergence in distribution

(24)

lim

N→+∞

T N (δ)

N

= tδ

def.
=

1

rmβ

2 (t)/MN ≥ δ},
(cid:18)

log

1 +

δβ

αr(1 − δ)

(cid:19)

.

12

MARIE DOUMIC, SARAH EUG`ENE, AND PHILIPPE ROBERT

2.3. Central Limit Theorem. From Proposition 2, it has been proved that if
f : [0, m∗]2 is a C1-function then, for the convergence in distribution

(cid:18)(cid:90) t

(cid:18) ∂

lim

N→+∞

0

∗

y−γx)

(γ

f (x, y)− ∂
∂y

∂x

f (x, y)

µN (dx, dy, ds)

= (0),

(cid:19)

with the above notations, The following proposition is an extension of this result.
This is the key ingredient to prove the central limit result of this section.
Proposition 4. If g : [0, m∗]2 × R+ is a C1-function then, for the convergence in
distribution,

(cid:18)(cid:90) t

(cid:18) ∂

lim

N→+∞

0

∗

y−γx)

(γ

g(x, y, u)− ∂
∂y

∂x

g(x, y, u)

N µN (dx, dy, du)

= (0).

(cid:19)

Proof. We follow the same lines as in the proof of Proposition 2. The analogue of
Relation (17) is

(cid:19)

(cid:19) √

(cid:16)

(cid:16)

g
√

X

N

(cid:90) t

N

0

(t), t

∗

(γ

(25)

1√
N

=

g(x, y, s)

µN (dx, dy, ds)

(cid:17) − g
(cid:90) t

y−γx)

X

(cid:16)
(cid:18) ∂
(cid:90) t

N
1 (s)

X

∂x

0

1√
N

+

X

− α√
N
− β√
N

0

(cid:32)(cid:42)

(cid:17)(cid:17)

N

(0), 0

(cid:19)

N

(cid:17)

(cid:17)

X

(s)

ds

N

X

(cid:16)
(cid:90) t

g(x, y, s)− ∂
∂y
1 (s) − 1/N
(cid:16)

N
1 (s)X

N
2 (s)

∂f
∂y

N

(cid:16)

(cid:17) ∂f
(cid:16)

∂y

N

X

(cid:17)

X

(s), s

∂f
∂z

0

(cid:43)(cid:33)

√

E(cid:0)(cid:10)M N

(cid:11) (N t)(cid:1)

(s)

ds

ds +

M N

g (N t)√

N

√
+ o(1/

N ),

It is not diﬃcult to check with the analogue of Relation (16) for the previsible
increasing process of the martingale (M N

N ) that, for t ≥ 0,

g (N t)/

E

lim

N→+∞

M N

g (N t)√

N

= lim

N→+∞

g
N

= 0.

Consequently, by Doob’s Inequality, the martingale of Relation (25) vanishes when
N gets large. The desired convergence of the proposition is then easily derived. (cid:3)

Theorem 2 (Central Limit Theorem). Under Condition (2) and if (x2(t)) is the
function deﬁned by Relation (21) then, for the convergence in distribution,

lim

N→+∞

= (U (t)),

(cid:19)

(cid:18) X N
2 (N t) − N x2(t)
(cid:112)

√

N

where (U (t)) is the solution of the stochastic diﬀerential equation

(26)

and (B(t)) is a standard Brownian motion and

dU (t) =

σ(t) dB(t) + h(t)U (t) dt,

(cid:40)
σ(t) = 2αr2(m−x2(t))2+βr(m−x2(t))x2(t)
h(t) = r(β − 2αr)(m − x2(t)) − βrx2(t).

ASYMPTOTICS OF STOCHASTIC PROTEIN ASSEMBLY MODELS

13

The corresponding result of Eug`ene et al. [10] when there is no misfolding phe-
nomenon shows that the functions σ and h are similar if α and β are respectively
replaced by αr2 and βr.

Proof. Denote

U N (t) =

(cid:90) t

√

2 (N t) − N x2(t)
X N
(cid:90) t

N

By combining Equation (19),

(cid:16)

X

(cid:17)
2 (t)) − x2(t)

N

.

√

N

=

√

N

√

(cid:90) t
(cid:16)
(cid:29)
(cid:28) M N
(cid:18)(cid:28) M N

2√
N

2√
N

X

N
2 (t)) = α

X

N
1 (s)2 ds + β

X

N
1 (s)X

N
2 (s) ds +

M N

2 (N t)
N

+ O(1/N )

(m − x2(s))x2(s) ds,

0
and Relation (22),

x2(t) = αr2

(27)

one gets

(cid:90) t

(cid:16)

0

U N (t) = α

N

X

+ β

X

N
1 (s)X

0

0

0

(m − x2(s))2 ds + βr

(cid:90) t
(cid:90) t
1 (s)2 − r2(m − x2(s))2(cid:17)

(cid:17)
2 (s) − r(m − x2(s))x2(s)
(cid:90) t
(cid:90) t

N

N

ds

N
Concerning the martingale term, Relation (11) gives, for t ≥ 0,

0

M N

2 (N t)√

ds +

√
+ O(1/

N ).

N
1 (s)2 ds + β

N
1 (s)X

N
2 (s) ds + O(1/N ).

X

0

(N t) = 2α

X

0

(cid:29)

(cid:19)

(cid:18)

(cid:90) t

With the same method as in the proof of Theorem 1, one gets the following con-
vergence in distribution

lim

N→+∞

(N t)

=

2αr2

(m−x2(s))2 ds+βr

x2(s)(m−x2(s)) ds

0

0

(cid:90) t

(cid:19)

by Relation (27).

Note also that, for s ≥ 0,
√

(cid:17)
2 (s) − r(m − x2(s))x2(s)

N
1 (s)X

(cid:16)

X

N

N

and

(28)

√

N

(cid:16)

X

(29) U N (t) =

= U N (s)X

(cid:17)

= −

N

1 (s) − r(m − x2(s)
(cid:90) t
(cid:90) t

U N (s)

(cid:16)

0

(β − αr)X

N

N

X

√

(cid:16)

(cid:16)

x2(s)

1 (s) − r(m − x2(s))

N
1 (s) +
√
N
γ + γ∗

(cid:17)
(cid:17) − rU N (t).
(cid:17)
1 (s) − αr2(m − x2(s)) − βrx2(s)

0 (s) − γ

N
1 (s)

γX

ds

X

∗

N

N

The above relation for (U N (t)) can then be rewritten as

− 1

γ + γ∗

(γ

0

∗

y−γx) [α(y+r(m−x2(s)))+βx2(s)]

√

N µN (dx, dy, ds)
√
+ O(1/

2 (N t)√

M N

+

N ).

N

14

MARIE DOUMIC, SARAH EUG`ENE, AND PHILIPPE ROBERT

The convergence in distribution of the martingale, Proposition 4 and the criterion
of the modulus of continuity give easily the tightness of the sequence (U N (t)). Let
(U (t)) be a limit of some subsequence (U Nk (t)).

A close look at Relation (29) shows that the theorem will be proved, with stan-

dard arguments, if the following convergence in distribution is proved
U (s)(m − x2(s)) ds

U Nk (s)X

Nk
1 (s) ds

lim

=

r

(cid:18)(cid:90) t

k→+∞

0

(cid:19)

(cid:18)

(cid:90) t

0

For k ≥ 0,

(cid:90) t

0

(cid:19)

.

(cid:19)

the process associated to the last term of the second part of this identity converges
in distribution to 0. By Relation (28), the ﬁrst term can be written as

U Nk (s)X

(cid:90) t

=

0

(cid:90) t

(cid:16)

0

U N (s)

0

N

Nk

X

ds+

(cid:90) t

1 (s) − rU (s)(m − x2(s)) ds
(cid:17)
(cid:16)
1 (s)−r(m−x2(s))
(cid:16)
0 (s) − γX
(cid:17)
(cid:19)
2 (s) − x2(s)

(cid:17)(cid:18) √
(cid:90) t
(cid:16)
(cid:18) MNk

2 (s) − x2(s)
(cid:90) t

Nk
γ + γ∗

= −r

− x − y − x2(s)

X

X

Nk

Nk

∗

γ

Nk

0

− 1

γ + γ∗

0

Nk

−

X

r(m−x2(s))(cid:0)U N (s)−U (s)(cid:1) ds,

(cid:17)

(cid:112)

Nk
1 (s)

+ rU Nk (t)

ds

U Nk (s) ds

(γx − γ

∗

y)

NkµNk (dx, dy, ds).

the ﬁrst term of the right hand side converges in distribution to 0 due to Theorem 1
and the same property also holds for the second term by Proposition 4. The theorem
(cid:3)
is proved.

As a consequence, one gets the following central limit theorem for the lag time.

The notations of Corollary 1 and Theorems 1 and 2 are used.
Corollary 2. Under the scaling regime (2), for δ ∈ (0, 1), the convergence in
distribution

(30)

lim

N→+∞

T N (δ) − N tδ

√

N

δη − U (tδ)

=

rm2(1 − δ)(β + αr(1 − δ))

holds, where the variables T N (δ) and tδ are deﬁned by (23) and (24) and (U (t))
by (26), and r = γ/(γ + γ∗).
Proof. For z ∈ R note that, since (X N

2 (t)) is a non-decreasing process,

(cid:26) T N (δ) − N tδ

√

N

(cid:27)

≥ z

=(cid:8)X N
(cid:40)

=

with sN = N tδ + z

√

(cid:9)

2 (sN ) < δMN
2 (sN ) − N x2(sN /N )

N

X

√

N

(cid:41)

,

δMN − N x2(sN /N )

√

N

<

N . From Theorem 2 one gets the convergence in distribution

X

lim

N→+∞

N

2 (sN ) − N x2(sN /N )

√

N

= U (tδ)

ASYMPTOTICS OF STOCHASTIC PROTEIN ASSEMBLY MODELS

15

and the expansion of (x2(t)) at tδ gives

δMN − N x2(sN /N )

√

N

lim

N→+∞

= δη − zrm2(1 − δ)(β + αr(1 − δ)).

This completes the proof of the corollary.

(cid:3)

Equation (30) shows that the variance of the lag time is inversely proportional to
γ/γ∗, a low misfolding rate will thus increase the variability of the polymerisation
process.

3. Models with Scaled Reaction Rates

For t ≥ 0, X N

1 (t) is the number of monomers at time t and X N

of polymerized monomers. The initial condition is X N
Because of the relation of conservation of mass, one has MN = X N

1 (0) = MN and X N

1 (t) + X N

2 (t).

It is not diﬃcult to see that the process (X N

2 (t)) can be represented as the

solution of the following stochastic diﬀerential equations,

2 (t) is the number
2 (0) = 0.

(31)

dX N

2 (t) = 2

N i
α/N ν+2(dt)+

N i
β/N 2 (dt).

1 −1)(s−)/2(cid:88)

X N

1 (X N

(cid:90) t

i=1

(cid:90) t

2 (s−))(cid:88)

1 (s−)X N
X N

(cid:90) t

0

i=1

(cid:90) t

By integrating this equation, one gets the relation

(32) X N

2 (t) =

α

N 2+ν

0

X N

1 (s)(X N

1 (s)−1) ds+

β
N 2

X N

1 (s)X N

2 (s) ds+M N (t),

where (M N (t)) is a martingale whose previsible increasing process is given by

(cid:104)M(cid:105)N (t) = 2

α

1 (s)−1) ds +

β
N 2

X N

1 (s)(X N

0

N 2+ν

(33)
The following proposition shows that, on the time scale t (cid:55)→ N t, the polymerised
mass is for this model in the order of N 1−ν.
Proposition 5. Under the scaling condition (2), for the convergence in distribu-
tion, the relation

2 (s) ds.

0

X N

1 (s)X N

(cid:18) X N

(cid:19)

(cid:18) αm

β

(cid:0)eβmt − 1(cid:1)(cid:19)

2 (N t)
N 1−ν

=

lim

N→+∞

holds.

Proof. The proof is standard by using the identities (32) and (33), and the relation
(cid:3)
X N

1 (t)+X N
The following lemma introduces a branching process which will be helpful to

2 (t)=MN . See Eug`ene et al. [10] for example.

estimate the order of magnitude in N of the lag time

T N (δ) = inf{t ≥ 0 : X N

2 (t)/MN ≥ δ},

for 0 < δ < 1.

Lemma 1. For a, b > 0, let (W N

a,b(t)) be a pure birth process with birth rate

x
in state x ∈ N, with W (0) = 0 and 0 < ν ≤ 1. If

a
N ν +

b
N

= inf(cid:8)t > 0 : W N

a,b(t) ≥ δN(cid:9) ,

def.

τ N
a,b(δ)

16

MARIE DOUMIC, SARAH EUG`ENE, AND PHILIPPE ROBERT

then the sequence (τ N

a,b(δ)/(N log N )) converges in distribution to ν/b.

As it can be seen (W N

a,b(t)) is a branching process with immigration. Immigration
rate is a/N ν and the reproduction rate is given by b/N . See Harris [12] for example.
Proof. Let, for x ∈ N, EN
a/N ν + xb/N , assuming that the random variables EN
then clearly

x denotes an exponential random variable with parameter
x , x ≥ 0 are independent,

(cid:98)δN(cid:99)(cid:88)

a,b(δ) dist=
τ N

EN
x .

hence after some simple estimations

x=0

E(τ N
a,b(δ))
N log N

=

ν
b

.

lim

N→+∞

(cid:32)

(cid:33)

≤ +∞(cid:88)

x=0

τ N
a,b(δ)
N

1

(aN 1−ν + xb)2 .

(cid:3)

In the same way, one checks that the sequence (Var(τ N

a,b(δ)/N )) is bounded

(34)

Var

The convergence in distribution follows , by using Chebishev’s Inequality.

Figure 1. In blue, 20 simulations of (W¯a,¯b/MN ) and in green, 20
simulations of (X N

2 /MN ) on the time scale t (cid:55)→ N log N t.

Let 0 < δ < 1 and ﬁx some κ < 1 < κ, one can assume that N is suﬃciently
large so that κ≤MN /(mN )≤κ holds. Recall that T N (δ) is the ﬁrst time that the
fraction of the number of polymerised monomers X N
2 (t)/MN is greater than δ. The
transition rates of (X N

2 (t)) are given by

(35)

x (cid:55)→

x+2 at rate
x+1

α/N ν [(MN − x)/N ]2
β x/N × (MN − x)/N.

(cid:40)

012345600.10.20.30.40.5M=106,m=1,α=1,β=0.1,ν=0.7XN2(NlogNt)/MNW¯a,¯b(NlogNt)/MNASYMPTOTICS OF STOCHASTIC PROTEIN ASSEMBLY MODELS

17

By comparing the transition rates, we see that, for x < δMN one has

(cid:40)
α/N ν ((MN − x)/N )2 ≥ α/N ν (κm)2(1 − δ)2,
β x/N × (MN − x)/N ≥ βκm(1 − δ).

One can therefore construct a coupling such that, on the event {T N (δ) > t}, the
2 (t)≥Wa,b(t) holds with a=ακm2(1−δ)2 and b=βκm(1−δ). One obtains
relation X N
a,b(δm)≥stT N (δ), where ≥st denotes the stochastic order: if U and V
the relation τ N
are two real valued random variables

U ≥st V if P(V ≥ x) ≤ P(U ≥ x)

∀x ∈ R.
2 (t)≤2W¯a,¯b(t), with ¯a=α(κm)2 and ¯b=βκm, one has τ N

¯a,¯b(δm/2)≤stT N (δ).

Since X N
One gets therefore

(36)

¯a,¯b(δm/2) ≤st T N (δ) ≤st τ N
τ N

a,b(δm).

Since the constants κ and κ can be chosen arbitrarily close to 1, the following
proposition has therefore been proved.
Proposition 6 (Order of Magnitude of Lag Time). For δ > 0 and 0<ν≤1,

(cid:19)

(cid:18) ν

P

lim

N→+∞

≤ T N (δ)
N log N

≤

ν

βm(1 − δ)

βm

= 1.

Remark. It is very likely that, to reach the state δN , only the second reaction has
a real impact as soon as the variable X N
2 is not 0. If true, simple calculations, as in
the proof of the above lemma, would then give that the variable T N (δ)/(N log N )
is converging in distribution to ν/(βm) as N get large. Note that the limit in this
asymptotic result does not depend on δ which suggests a sharp transition for the
polymerisation process.

The birth process (W¯a,¯b(t)) seems to be close to (X N

2 (t)) during the initiation
of the polymerisation, as the simulations of Figure 1. This suggests that, for δ
small, the variables τ N
¯a,¯b(δm) and T N (δ) are very close. We conclude this part by
considering the case ν > 1.

A Very Slow Nucleation Step. Now we assume that ν > 1, in this regime, the
ﬁrst reaction, the nucleation step, is then signiﬁcantly slowed.

Proposition 7. For any ε > 0 and 0 < δ < 1, there exist 0 < K1 < K2 such that

P

lim inf
N→+∞

K1 ≤ T N (δ)
N ν

≤ K2

≥ 1 − ε.

(cid:18)

(cid:98)δN(cid:99)(cid:88)

x=0

(cid:19)

(cid:98)δN(cid:99)(cid:88)

x=1

Proof. By using Relation (36), it is enough to derive a corresponding limit theorem
for τ N
x) be a sequence of i.i.d. exponential
random variables with parameter 1, then

a,b(δ)/N ν for some a>0 and b>0. Let (E1

(37)

τ N
a,b(δ)
N ν =

E1
x

a + xbN ν−1 =

E1
0
a

+

E1
x

a + xbN ν−1 .

The expected value of the last term of the right hand side of the above relation
is bounded by K log(N )/N ν−1 for some constant K>0. Consequently, this term
becomes negligible in distribution for N large. One gets that the variable τ N
a,b(δ)/N ν
converges in distribution to an exponential random variable. The proposition is
(cid:3)
proved.

18

MARIE DOUMIC, SARAH EUG`ENE, AND PHILIPPE ROBERT

As we have seen in the proof, the only term that matters in the series in Rela-
tion (37) is the ﬁrst one: the time to reach one polymerised monomer. It charac-
terises the order of magnitude of the lag time. This variable has been analysed in
Szavits-Nossan et al. [28] and Yvinec et al. [30].

Acknowledgments. We thank W.F. Xue (University of Kent) for inspiring
discussions. M. Doumic and S. Eug`ene’s research was supported by ERC Starting
Grant SKIPPERAD No. 306321.

References

[1] David F. Anderson and Thomas G. Kurtz, Continuous time Markov chain models for chemi-
cal reaction networks, Design and Analysis of Biomolecular Circuits (Heinz Koeppl, Gianluca
Setti, Mario di Bernardo, and Douglas Densmore, eds.), Springer New York, 2011, pp. 3–42.
[2] P. Billingsley, Convergence of probability measures, second ed., Wiley Series in Probability
and Statistics: Probability and Statistics, John Wiley & Sons Inc., New York, 1999, A Wiley-
Interscience Publication.

[3] N. H. Bingham, Fluctuation theory for the Ehrenfest urn, Advances in Applied Probability

23 (1991), no. 3, 598–611.

[4] Perinur Bozaykut, Nesrin Kartal Ozer, and Betul Karademir, Regulation of protein turnover

by heat shock proteins, Free Radic Biol Med. 77 (2014), 195–209.

[5] Donald A. Dawson, Measure-valued Markov processes, ´Ecole d’´Et´e de Probabilit´es de Saint-

Flour XXI—1991, Lecture Notes in Math., vol. 1541, Springer, Berlin, 1993, pp. 1–260.

[6] Claude Dellacherie and Paul-Andr´e Meyer, Probabilities and potential, North-Holland Mathe-
matics Studies, vol. 29, North-Holland Publishing Co., Amsterdam-New York; North-Holland
Publishing Co., Amsterdam-New York, 1978.

[7] Christopher M. Dobson, Protein folding and misfolding, Nature 426 (2003), 884–890.
[8] ChristopherM. Dobson, The generic nature of protein folding and misfolding, Protein Mis-
folding, Aggregation, and Conformational Diseases (VladimirN. Uversky and AnthonyL.
Fink, eds.), Protein Reviews, vol. 4, Springer US, 2006, pp. 21–41 (English).

[9] Kym Eden, Ryan Morris, Jay Gillam, Cait E. MacPhee, and Rosalind J. Allen, Competition
between primary nucleation and autocatalysis in amyloid ﬁbril self-assembly, Biophysical
Journal 108 (2015), no. 3, 632 – 643.

[10] Sarah Eug`ene, Wei-Feng Xue, Philippe Robert, and Marie Doumic, Insights into the vari-
ability of nucleated amyloid polymerization by a minimalistic model of stochastic protein
assembly, Submitted to Journal of Chemical Physics, September 2015.

[11] M. I. Freidlin and A. D. Wentzell, Random perturbations of dynamical systems, second ed.,
Springer-Verlag, New York, 1998, Translated from the 1979 Russian original by Joseph Sz¨ucs.
[12] Theodore E. Harris, The theory of branching processes, Dover Phoenix Editions, Dover Pub-

lications, Inc., Mineola, NY, 2002, Corrected reprint of the 1963 original.

[13] Desmond J. Higham, Modeling and simulating chemical reactions, SIAM Review 50 (2008),

no. 2, 347–368.

[14] P.J. Hunt and T.G Kurtz, Large loss networks, Stochastic Processes and their Applications

53 (1994), 363–378.

[15] Hye-Won Kang, Thomas G. Kurtz, and Lea Popovic, Central limit theorems and diﬀusion
approximations for multiscale Markov chain models, The Annals of Applied Probability 24
(2014), no. 2, 721–759.

[16] Samuel Karlin and James McGregor, Ehrenfest urn models, Journal of Applied Probability

2 (1965), 352–376.

[17] Tuomas P. J. Knowles, Michele Vendruscolo, and Christopher M. Dobson, The amyloid state
and its association with protein misfolding diseases, Nature Reviews Molecular Cell Biology
15 (2014), 384–396.

[18] T.G. Kurtz, Averaging for martingale problems and stochastic approximation, Applied Sto-
chastic Analysis, US-French Workshop, Lecture notes in Control and Information sciences,
vol. 177, Springer Verlag, 1992, pp. 186–209.

[19] David Lanneau, Guillaume Wettstein, Philippe Bonniaud, and Carmen Garrido, Heat shock
proteins: cell protection through protein triage, ScientiﬁcWorldJournal 10 (2010), 1543–1552.

ASYMPTOTICS OF STOCHASTIC PROTEIN ASSEMBLY MODELS

19

[20] Jennifer J. McManus, Patrick Charbonneau, Emanuela Zaccarelli, and Neer Asherie, The

physics of protein self-assembly, preprint, February 2016.

[21] Philippe Morando, Mesures al´eatoires, S´eminaire de Probabilit´es de Strasbourg III (1969),

190–229.

[22] Sian-Yang Ow and Dave E. Dunstan, A brief overview of amyloids and alzheimer’s disease,

Protein Science 23 (2014), no. 10, 1315–1331.

[23] G. C. Papanicolaou, D. Stroock, and S. R. S. Varadhan, Martingale approach to some limit
theorems, Papers from the Duke Turbulence Conference (Duke Univ., Durham, N.C., 1976),
Paper No. 6, Duke Univ., Durham, N.C., 1977, pp. ii+120 pp. Duke Univ. Math. Ser., Vol.
III.
[24] Simone Pigolotti, Ludvig Lizana, Daniel Otzen, and Kim Sneppen, Quality control system
response to stochastic growth of amyloid ﬁbrils, {FEBS} Letters 587 (2013), no. 9, 1405 –
1410.

[25] L. C. G. Rogers and David Williams, Diﬀusions, Markov processes, and martingales. Vol. 1:

Foundations, second ed., John Wiley & Sons Ltd., Chichester, 1994.

[26] Walter Rudin, Real and complex analysis, third ed., McGraw-Hill Book Co., New York, 1987.
[27] Wen Sun, Mathieu Feuillet, and Philippe Robert, Analysis of large unreliable stochastic

networks, Annals of Applied Probability (2015), To Appear.

[28] Juraj Szavits-Nossan, Kym Eden, Ryan J. Morris, Cait E. MacPhee, Martin R. Evans, and
Rosalind J. Allen, Inherent variability in the kinetics of autocatalytic protein self-assembly,
Physical Review Letters 113 (2014), 098101.

[29] W-F Xue, S W Homans, and S E Radford, Systematic analysis of nucleation-dependent
polymerization reveals new insights into the mechanism of amyloid self-assembly, PNAS 105
(2008), 8926–8931.

[30] Romain Yvinec, Samuel Bernard, Erwan Hingant, and Laurent Pujo-Menjouet, First passage
times in homogeneous nucleation: Dependence on the total number of particles, The Journal
of Chemical Physics 144 (2016), no. 3, 034106.

E-mail address: Marie.Doumic@inria.fr
URL: https://team.inria.fr/mamba/marie-doumic/

E-mail address: Sarah.Eugene@inria.fr

E-mail address: Philippe.Robert@inria.fr
URL: http://team.inria.fr/rap/robert

(M. Doumic, S. Eug`ene, Ph. Robert) INRIA Paris, 2 rue Simone Iff, F-75012 Paris,

France

(M. Doumic, S. Eug`ene) Sorbonne Universit´es, UPMC Universit´e Pierre et Marie

Curie, UMR 7598, Laboratoire Jacques-Louis Lions, F-75005, Paris, France

