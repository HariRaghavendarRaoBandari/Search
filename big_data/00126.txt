6
1
0
2

 
r
a

M
1

 

 
 
]
T
S
h
t
a
m

.

[
 
 

1
v
6
2
1
0
0

.

3
0
6
1
:
v
i
X
r
a

Information Measures, Experiments,

Multi-category Hypothesis Tests, and Surrogate Losses

John C. Duchi1,2

Khashayar Khosravi2

Feng Ruan1

Departments of 1Statistics and 2Electrical Engineering, Stanford University

{jduchi,khosravi,fengruan}@stanford.edu

Abstract

We provide a unifying view of statistical information measures, multi-class classiﬁcation
problems, multi-way Bayesian hypothesis testing, and loss functions, elaborating equivalence
results between all of these objects.
In particular, we consider a particular generalization of
f -divergences to multiple distributions, and we show that there is a constructive equivalence
between f -divergences, statistical information (in the sense of uncertainty as elaborated by
DeGroot), and loss functions for multi-category classiﬁcation. We also study an extension of
our results to multi-class classiﬁcation problems in which we must both infer a discriminant
function γ and a data representation (or, in the setting of a hypothesis testing problem, an
experimental design), represented by a quantizer q from a family of possible quantizers Q.
There, we give a complete characterization of the equivalence between loss functions, meaning
that optimizing either of two losses yields the same optimal discriminant and quantizer q. A main
consequence of our results is to describe those convex loss functions that are Fisher consistent
for jointly choosing a data representation and minimizing the (weighted) probability of error in
multi-category classiﬁcation and hypothesis testing problems.

1

Introduction

Consider the following multiclass classiﬁcation problem: a decision maker receives a pair of random
variables (X, Y ) ∈ X × {1, . . . , k}, where Y is unobserved, and wishes to assign the variable X to
one of the k classes {1, 2, . . . , k} so as to minimize the probability of a misclassiﬁcation, that is,
predicting some bY 6= Y . Formally, we represent the decision maker via a discriminant function
γ : X → Rk, where each component γy(x), y = 1, . . . , k, represents the margin (or a score or
perceived likelihood) the decision maker assigns to class y for datum x. The goal is then to
minimize the expected loss, or Ψ-risk,

RΨ(γ) := E[ΨY (γ(X))],

(1)

where Ψy : Rk → R measures the loss of decision γ(X) ∈ Rk when the true label of X is y
and the expectation (1) is taken jointly over (X, Y ). When the loss Ψ is the 0-1 loss, that is,
Ψy(γ(x)) = 1{γy(x) ≤ γi(x) for some i 6= y}, the formulation (1) measures the misclassiﬁcation
probability P(argmaxy γy(X) 6= Y ). More broadly, we may consider the classical k-way Bayesian
experiment: given a random variable X ∈ X drawn according to one of the k hypotheses

H1 : X ∼ P1, H2 : X ∼ P2,

. . . Hk : X ∼ Pk

with prior probabilities π1, π2, . . . , πk, we wish to make a decision minimizing the expected loss

E[ΨY (γ(X))], or (in a pointwise sense) the posteriorPy P(Y = y | X = x)Ψy(γ(x)).

In many applications, making decisions based on a raw vector X is undesirable—the vector X
may be extremely high-dimensional, carry useless information impinging on statistical eﬃciency,
or we may need to store or communicate the sample using limited memory or bandwidth. If all

1

we wish to do is to classify a person as being taller or shorter than 160 centimeters, it makes little
sense to track his or her blood type and eye color. With the increase in the number and variety of
measurements we collect, such careful design choices are—in our estimation—yet more important
for maintaining statistical power, interpretability, accountability, eﬃcient downstream use, and
mitigating false discovery [3, 12]. This desire to give “better” representations of data X has led to
a rich body of work in statistics, machine learning, and engineering, highlighting the importance of
careful measurement, experimental design, and data representation strategies [29, 9, 10, 27, 33, 24].
To allow better ﬁdelity to real-world considerations, one thus frequently expands this classical
formulation to include a preprocessing stage in which the vector X is mapped into a vector Z via
a (data-dependent) mapping q : X → Z. A number of situations suggest such an approach. In
most practical classiﬁcation scenarios [30], one includes an equivalent “feature selection” stage to
reduce the dimension of X or increase its interpretability. As a second motivation, consider the
decentralized detection problem [34] in communication applications in engineering, where data are
collected through remote sensors and communicated through limited bandwidth or stored using
limited memory. In this case, the central decision maker can infer the initial distribution Pi only
after communication of the transformed vector Z = q(X), and one wishes to choose a quantizer
q from a family Q of acceptable (low complexity) quantizers. In fuller abstraction, we may treat
the problem as a Bayesian experimental design problem, where the mapping q : X → Z may be
stochastic and is chosen from a family Q of possible experiments (observation channels). In each
of the preceding examples, the desire to incorporate a quantizer q into the testing classiﬁcation
procedure poses a more complicated problem, as it is now required to simultaneously ﬁnd both a
data representation q and decision rule γ. The goal, paralleling that for the risk (1), thus becomes
joint minimization of the quantized Ψ-risk

RΨ,π(γ | q) := E [ΨY (γ(q(X)))]

(2)

over a prespeciﬁed family Q of quantizers q : X → Z, where γ : Z → Rk.
Frequently—for example, in the zero-one error case—the loss function Ψ is non-convex (and even
discontinuous), so that its population or empirical minimization is intractable. It is thus common
to replace the loss with a convex surrogate and minimize this surrogate instead. We call such a
surrogate Fisher consistent if its minimization yields a Bayes optimal discriminant γ for the original
loss Ψ (for any P distribution on (X, Y )), and for the classical binary and multiclass classiﬁcation
problems, several researchers have characterized conditions when solutions using convex surrogate
losses yield Fisher consistency [22, 36, 21, 2, 32]. Nguyen et al. [24] substantially extend these
results in the binary case to the problem of joint selection of the discriminant function γ and
quantizer q : X → Z when q ∈ Q, for any Q. In particular, Nguyen et al. exhibit a correspondence
between binary margin-based loss functions and f -divergences—measures of the similarity between
two probability distributions originally developed in information theory and statistics [1, 8, 35]—to
give a general characterization of loss equivalence through classes of divergences. An interesting
consequence of their results is that, in spite of positive results [36, 21, 2] for Fisher consistency in
binary classiﬁcation problems, essentially only the hinge loss is consistent for the 0-1 loss.

Outline and informal discussion of our contributions

In the present paper, we build on these prior results on Fisher consistency to provide a unifying
framework that relates statistical information measures, loss functions, and uncertainty functions
in the context of multi-category classiﬁcation. To begin, we present a generalization of Ali and

2

Silvey’s and Csisz´ar’s f -divergences that applies to multiple distributions, enumerating showing
analogues of their positivity properties, data-processing inequalities, and discrete approximation
(Section 2). We begin our main contributions in Section 3, where we establish a correspondence
between loss functions Ψ, concave measures of uncertainty on discrete distributions as deﬁned by
DeGroot [9], and multi-way f -divergences. In particular, letting π ∈ Rk
+ satisfying 1T π = 1 be
a prior distribution on the class labels Y , eπ(X) be the vector of posterior probabilites of label Y
conditional on the observation X, and U : Rk
deﬁnes the information associated with the experiment X as

+ → R = R ∪ {−∞} be a concave function, DeGroot

I(X, π; U ) := U (π) − E[U (eπ(X))].

(3)

1 , . . . , Ψ(2)

We show that there is an explicit mapping from concave uncertainty functions U to (potentially
multiple) loss functions Ψ, and conversely that each loss function induces a concave uncertainty U
and statistical information (3). The mapping U 7→ Ψ is one-to-many, while the mapping Ψ 7→ U
is many-to-one, but we show that there is always at least one explicitly constructable convex loss
Ψ = {Ψ1, . . . , Ψk} generating U . We also show how these uncertainty functions U have natural
connections to classiﬁcation calibration.
In Section 4 we present our main results on consistency of joint selection of quantizer (data
representation/experiment) q and discriminant function γ. We give a complete characteriza-
tion of the situations in which two multi-category loss functions Ψ(1) = {Ψ(1)
k } and
Ψ(2) = {Ψ(2)
k } always yield equivalent optimal quantizers and discriminant functions via
minimization of the quantized risk (2). In particular, we show that loss functions are equivalent
in this way if and only if their associated uncertainty functions U1 and U2—as constructed in
Section 3—satisfy U1(π) = aU2(π) + bT π + c for some a > 0, b ∈ Rk, and c ∈ R. We give a
similar characterization that reposes on the generalized f -divergences associated with each loss
function (again, as constructed in Section 3). Measures of statistical information and divergence
have been central to the design of communication and quantization schemes in the signal pro-
cessing literature [34, 26, 20, 17, 24], and one interpretation of our results is a characterization
of those divergence measures that—when optimized for—yield optimal detection and quantization
procedures. More broadly, we give necessary and suﬃcient conditions for the Fisher-consistency of
diﬀerent loss functions for joint selection of data representation (i.e. the experimental design) and
classiﬁcation scheme, and we provide a result showing when empirical minimization of a surrogate
risk yields a consistent risk-minimization procedure.

1 , . . . , Ψ(1)

A number of researchers have studied the connections between divergence measures and risk
for binary and multi-category experiments, which point to the results we present.
Indeed, in
the 1950s Blackwell [6] shows that if a quantizer q1 induces class-conditional distributions with
larger divergence than those induced by q2, then there are prior probabilities such that q1 allows
tests with lower probability of error than q2. Liese and Vajda [19] give a broad treatment of
f -divergences, using their representation as the diﬀerence between prior and posterior risk in a
binary experiment [25] to derive a number of their properties; see also the paper [28]. Garc´ıa-
Garc´ıa and Williamson [13] show how multi-distribution f -divergences [14] arise naturally in the
context of multi-category classiﬁcation problems as the gap between prior and posterior risk in
classiﬁcation, as in the work of Liese and Vajda. In the binary case, these results point the way
towards the characterization of Fisher consistency for quantization and binary classiﬁcation Nguyen
et al. [24] realize. We pursue this line of research to draw the connections between Fisher consistency,
information measures, multi-category classiﬁcation, surrogate losses, and divergences.

3

Notation We let 0 and 1 denote the all-zeros and all-ones vectors, respectively. For a vector or
collection of objects {t1, . . . , tm}, the notation t1:m = {t1, . . . , tm}. The set indicator function I{·}
is +∞ if its argument is false, 0 otherwise, while 1{·} is 1 if its argument is true, 0 otherwise.
For vectors v, u ∈ Rk, we let v ⊙ u = [viui]k
i=1 ∈ Rk be their Hadamard (pointwise) product. We
let ∆k = {v ∈ Rk
+ : 1T v = 1} denote the probability simplex in Rk. For any m ∈ N, we set
[m] = {1, . . . , m}. For a set A ⊂ Rk, we let aﬀ A = {Pm
i=1 λixi : λT 1 = 1, xi ∈ A, m ∈ N} denote
the aﬃne hull of A, and rel int A denotes the interior of A relative to aﬀ A. We let R = R ∪ {+∞}
and R = R ∪ {−∞} be the upward and downward extended real numbers. For f : Rk → R, we let
epi f = {(x, t) : f (x) ≤ t} denote the epigraph of f . We say a convex function f is closed if epi f
is a closed set, though we abuse notation and say that a concave function f is closed if epi(−f ) is
closed. For a convex function f : Rk → R, we say that f is strictly convex at a point t ∈ Rk if for
all λ ∈ (0, 1) and t1, t2 6= t such that t = λt1 + (1 − λ)t2 we have f (t) < λf (t1) + (1 − λ)f (t2). We
deﬁne the (Fenchel) conjugate of a function f : Rk → R by
t∈Rk(cid:8)sT t − f (t)(cid:9) .

For any function f , the conjugate f ∗ is a closed convex function [16, Chapter X]. For measures ν
and µ, we let dν/dµ denote the Radon-Nikodym derivative of ν with respect to µ. For random

f ∗(s) = sup

(4)

variables Xn, we say Xn

Lp→ X∞ if E[|Xn − X∞|p] → 0.

2 Multi-distribution f -divergences

Divergence measures for probability distributions have signiﬁcant statistical, decision-, and information-
theoretic applications [1, 8, 18, 26, 17], including in optimal testing, minimax rates of convergence,
and the design of communication and encoding schemes. Central to this work is the f -divergence,
introduced by Ali and Silvey [1] and Csisz´ar [8], and deﬁned as follows. Given a pair of distributions
P, Q deﬁned on a common set X , a closed convex function f : [0,∞) → R satisfying f (1) = 0, and
any measure µ satisfying P ≪ µ and Q ≪ µ, the f -divergence between P and Q is

Df (P||Q) :=ZX

q(x)(cid:19) q(x)dµ(x) =Z f(cid:18) dP
f(cid:18) p(x)

dQ(cid:19) dQ.

dµ and q = dQ

Here p = dP
dµ denote the densities of P and Q, respectively, and the value uf (t/u) is
deﬁned appropriately for t = 0 and u = 0 (e.g. [19]). A number of classical divergence measures
arise out of the f -divergence; taking variously f (t) = t log t, f (t) = 1
2|t − 1|
yields (respectively) the KL-divergence, squared Hellinger distance, and total variation distance.
Central to our study of multi-way hypothesis testing and classiﬁcation is an understanding of
relationships between multiple distributions simultaneously. Thus, we use the following generaliza-
tion [14, 13] of the classical f -divergence to multiple distributions.

2 (√t − 1)2, and f (t) = 1

Deﬁnition 2.1. Let P1, . . . , Pk be probability distributions on a common σ-algebra F over a set X .
Let f : Rk−1
+ → R be a closed convex function satisfying f (1) = 0. Let µ be any σ-ﬁnite measure
such that Pi ≪ µ for all i, and let pi = dPi/dµ. The f -divergence between P1, . . . , Pk−1 and Pk is

Df (P1, . . . , Pk−1||Pk) :=Z f(cid:18) p1(x)

pk(x)

, . . . ,

pk−1(x)

pk(x) (cid:19) pk(x)dµ(x).

(5)

(6)

4

We have not speciﬁed the value of the integrand in Def. 2.1 when pk(x) = 0. In this case, the

function ef : Rk

+ → R deﬁned, for an arbitrary t′ ∈ rel int dom f , by
if u > 0
if u = 0

sf (t′ − t + t/s)

ef (t, u) =

uf (t/u)
lim
s→0
+∞

otherwise

(7)

is a closed convex function whose value is indepenedent of t′; this ef is the closure of the perspective

function of f (see Hiriart-Urruty and Lemar´echal [15, Proposition IV.2.2.2]). Any time we consider
a perspective function (u, t) 7→ uf (t/u) we treat it as its closure (7) without comment.
We now enumerate a few properties of multi-way f -divergences, showing how they are natural
generalizations of classical binary f -divergences. We focus on basic properties that will be useful for
our further results on Bayes risk, classiﬁcation, and hypothesis testing. Speciﬁcally, we show that
generalized f -divergences parallel the binary divergence (6): they are well-deﬁned, have continuity
properties with respect to discrete approximations, and satisfy data-processing inequalities. These
results are essentially known (we somewhat more carefully address measurability concerns) and we
use them as deﬁnitional building blocks, so we defer all proofs to Appendix D.

As our ﬁrst step, we note that Deﬁnition 2.1 gives a well-deﬁned quantity, independent of the

base measure µ. (See Appendix D.1 for a proof.)

Lemma 2.1. In expression (6), the value of the divergence does not depend on the choice of the
dominating measure µ. Moreover,

Df (P1, . . . , Pk−1||Pk) ≥ 0,

and the inequality is strict if f is strictly convex at 1 and the Pi are not all identical.

We now consider approximation of the f -divergence. Given a partition P of X , meaning a ﬁnite
or countable collection of disjoint measurable sets A ∈ P satisfying ∪{A | A ∈ P} = X , we deﬁne
the partitioned f -divergence as

Df (P1, . . . , Pk−1||Pk | P) = XA∈P

f(cid:18) P1(A)

Pk(A)

, . . . ,

Pk−1(A)

Pk(A) (cid:19) Pk(A).

Equivalently, given a quantizer q, meaning a measurable mapping q : X → N (any countable image
space Im q yields equivalent deﬁnition), we deﬁne the quantized f -divergence as

Df (P1, . . . , Pk−1||Pk | q) = XA∈q−1(N)

f(cid:18) P1(A)

Pk(A)

, . . . ,

Pk−1(A)

Pk(A) (cid:19) Pk(A).

As in the binary case [35, 19], we have the following approximability result, that is, that quantizers
give arbitrarily good approximations to generalized f -divergences (see Appendix D.2).

Proposition 1 (Approximation). Let f be a closed convex function with f (1) = 0. Then

Df (P1, . . . , Pk−1||Pk) = sup

P

Df (P1, . . . , Pk−1||Pk | P) = sup

q

Df (P1, . . . , Pk−1||Pk | q) ,

(8)

where the ﬁrst supremum is over ﬁnite measurable partitions of X and the second is over quantizers
of X with ﬁnite range.

5

An important property of f -divergences is that they satisfy data processing inequalities (see,
for example, Csisz´ar [8], Gy¨orﬁ and Nemetz [14], Cover and Thomas [7], or Liese and Vajda [19])
which state that processing or transforming an observation X drawn from one of the distributions
P1, . . . , Pk, decreases the divergence between them. That is, transforming X cannot yield more
“information.” Recall that Q is a Markov kernel from a set X to Z if Q(· | x) is a probability
distribution on Z for each x ∈ X , and for each measurable A ⊂ Z, the mapping x 7→ Q(A | x) is
measurable. We have the following general data processing inequality, whose proof we include in
Appendix D.3 (see also Garc´ıa-Garc´ıa and Williamson [13, Theorem 4]).

Proposition 2. Let f be a closed convex function with f (1) = 0. Let Q be a Markov kernel from

X to Z and deﬁne the marginals QP (A) :=RX Q(A | x)dP (x). Then

Df(cid:0)QP1, . . . , QPk−1||QPk(cid:1) ≤ Df (P1, . . . , Pk−1||Pk) .

This proposition immediately yields the intuitive result that quantization reduces information: for
any quantizer q the indicator Q(A | x) = 1{q(x) ∈ A} deﬁnes a Markov kernel, yielding
Corollary 1. Let f be closed convex, satisfy f (1) = 0, and q be a quantizer of X . Then

Df (P1, . . . , Pk−1||Pk | q) ≤ Df (P1, . . . , Pk−1||Pk) .

We also see that if q1 and q2 are quantizers of X , and q1 induces a ﬁner partition of X than q2,
meaning that for x, x′ ∈ X the equality q1(x) = q1(x′) implies q2(x) = q2(x′), we have

Df (P1, . . . , Pk−1||Pk | q1) ≤ Df (P1, . . . , Pk−1||Pk | q2) .

In the sequel, we show how the ordering of quantizers by divergence (and information content)—as
related to the quantized risk (2)—is essential to our understanding of consistency.

3 Risks, information measures, and f -divergences

Having established the basic properties of generalized f -divergences, showing that they essentially
satisfy the same properties as the binary case (cf. [19]), we turn to a more detailed look at their
relationships with multi-way hypothesis tests, multi-class classiﬁcation, uncertainty measures and
statistical informations relating multiple distributions. We build a set of correspondences between
these ideas that parallels those available for binary experiments and classiﬁcation problems (see,
for example, Liese and Vajda [19], Nguyen et al. [24], and Reid and Williamson [28]).

We begin by recalling the probabilistic model for classiﬁcation and Bayesian hypothesis testing
problems described in the introduction. We have a prior distribution π ∈ ∆k = {p ∈ Rk
+ : 1T p = 1}
and probability distributions P1, . . . , Pk deﬁned on a set X . The coordinate Y ∈ [k] = {1, . . . , k}
is drawn according to a multinomial with probabilities π, and conditional on Y = y, we draw
X ∼ Py. Following DeGroot [9], we refer to this as an experiment. Associated with any experiment
(equivalently, a multi-category classiﬁcation problem) is a family of information measures DeGroot

deﬁnes as follows. Leteπ be the posterior distribution on Y given the observation X = x,

.

eπi(x) =

Pk

πidPi(x)
j=1 πjdPj(x)

6

Given any closed concave function U : Rk
+ → R, which we refer to as an uncertainty function, the
information associated with the experiment is the reduction of uncertainty from prior to posterior
(recall equation (3)), that is,

I(X, π; U ) = U (π) − E[U (eπ(X))].
The expectation is taken over X drawn marginally according toPk

i=1 πiPi. That I(X, π; U ) ≥ 0 is
immediate by concavity; DeGroot [9, Theorem 2.1] shows that I(X, π; U ) ≥ 0 for all distributions
P1, . . . , Pk and priors π if and only if U is concave on ∆k.
In this section we develop equivalence results between classiﬁcation risk, loss functions, general-
ized f -divergences, and uncertainty measures. More concretely, consider a vector Ψ = {Ψ1, . . . , Ψk}
of loss functions with Ψi : Rk → R, and recall the risk (1), deﬁned as RΨ(γ) = E[ΨY (γ(X))], where
γ ∈ Γ, the set of measurable functions γ : X → Rk. We show in Section 3.1 that each such loss
Ψ induces a concave uncertainty measure U : ∆k → R, and conversely, each uncertainty function
U is induced by (potentially many) convex loss functions Ψ. In Section 3.2, we illustrate Fisher
consistency (see [36, 32]) properties that uncertainty functions U directly imply about the convex
losses Ψ that induce them. Finally, we connect these results in Section 3.3 with our generalized
f -divergences. We show for any loss Ψ there exists an uncertainty function UΨ such that the fol-
lowing holds: for any π ∈ ∆k, there exists a convex function fΨ,π : Rk−1
+ → R with f (1) = 0 such
that the gap between the prior Bayes Ψ-risk—the best expected loss attainable without observing
X—and the posterior Bayes risk inf γ∈Γ RΨ(γ) is

inf
α∈Rk

kXi=1

πiΨi(α) − inf

γ∈Γ

RΨ(γ) = UΨ(π) − E[UΨ(eπ(X))] = DfΨ,π (P1, . . . , Pk−1||Pk) .

Conversely, given any closed convex f : Rk−1
Ψ = {Ψ1, . . . , Ψk}, an associated uncertainty function UΨ, and a prior π ∈ ∆k satisfying

+ → R with f (1) = 0, there exist convex losses

Df (P1, . . . , Pk−1||Pk) = UΨ(π) − E[UΨ(eπ(X))] = inf

α∈Rk

3.1 Uncertainty functions and losses

kXi=1

πiΨi(α) − inf

γ∈Γ

RΨ(γ).

We now construct a natural bidirectional mapping between losses and uncertainty functions. We
begin by showing how any vector of loss functions for multi-category classiﬁcation induces a concave
uncertainty function, giving a few examples to illustrate our constructions. Following DeGroot [9,
Eq. (2.14)], we note that the function

UΨ(π) = inf

α∈Rk(cid:26) kXi=1

πiΨi(α) − I{π ∈ ∆k}(cid:27)

(9)

is a closed concave function, as it is the inﬁmum of linear functionals of π restricted to π ∈ ∆k. It
uncertainty is non-negative, and by the construction (9) any loss function Ψ gives rise to a closed

is thus an uncertainty function. Thus, the gap UΨ(π) − E[UΨ(eπ(X))] between prior and posterior

7

concave uncertainty UΨ. The following two examples with zero-one loss are illustrative.
Example 1 (Zero-one loss): Consider the zero one loss Ψzo deﬁned for y ∈ [k] by

y (α) = 1{αy ≤ αj for some j 6= i} =(1

0

Ψzo

if there is j 6= y such that αj ≥ αy
otherwise, i.e. αy > maxj6=y αj.

Then we have

UΨzo(π) = inf

α ( kXi=1

πi1{αi ≤ αj for some j 6= i}) = 1 − max

j

πj.

This uncertainty function is concave, bounded on ∆k, and satisﬁes UΨzo(ei) = 0 for each standard
basis vector ei. ♣

In some scenarios, we allow diﬀerent costs for classi-
Example 2 (Cost-weighted classiﬁcation):
fying certain classes y as others; for example, it may be more costly to misclassify a benign tumor
as cancerous than to misclassify a cancerous tumor as benign. In this case, we assume a matrix
y,i=1 ∈ Rk×k
C = [cyi]k
+ , where cyi ≥ 0 is the cost for classifying an observation of class y as class i
(i.e. as X having been drawn from Pi instead of Py in the experiment). We assume that cyy = 0
for each y and deﬁne

Ψcw

y (α) = max

i {cyi | αi = max

j

αj},

(10)

the maximal loss for those indices of α ∈ Rk attaining maxj αj. Let C = [c1 ··· ck] be the column
representation of C. If cT
l π, then by choosing any α such that αy > αj for all j 6= y,
we have

y π = minl cT

UΨcw (π) = inf

πy max

i {cyi | αi = max

j

= min

l

πT cl.

α 
kXy=1

αj}

The uncertainy UΨcw is concave, bounded on ∆k, continuous, and satisﬁes UΨcw(ei) = 0 for any
standard basis vector ei. We recover Example 1 by taking C = 11T − Ik×k. ♣

The forward mapping (9) from loss function Ψ to uncertainty measures Uπ is straightforward,
though it is many-to-one. Using convex duality and conjugacy arguments (recall the deﬁnition (4)
of the conjugate function), we can show a converse: given any (closed concave) uncertainty function
U deﬁned on ∆k, there exists a loss function Ψ such that U has the form (9).

Proposition 3. For any closed concave uncertainty function U : ∆k → R, the loss functions

Ψi : Rk → R, Ψi(α) = −αi + (−U )∗(α),

(11)

for i ∈ {1, . . . , k}, are closed, convex, and satisfy the equality (9).
Proof Using standard Fenchel conjugacy relationships [16, Chapter X], we have

U (π) = inf

α∈Rk(cid:8)−πT α + (−U )∗(α)(cid:9) where (−U )∗(α) := sup

π∈∆k(cid:8)αT π + U (π)(cid:9) .

8

Deﬁning Ψi(α) = −αi + (−U )∗(α) for i = 1, . . . , k, we can write

U (π) = inf

α∈Rk(cid:8)−πT α + (−U )∗(α)(cid:9) = inf

α∈Rk(cid:8)−πT α + πT 1 · (−U )∗(α)(cid:9) = inf

α∈Rk( kXi=1

πiΨi(α)).

This is our desired inﬁmal relationship.

Proposition 3 shows that associated with every concave utility deﬁned on the simplex, there is
at least one convex loss function Ψ generating the utility via the inﬁmal representation (9), and
there is thus a mapping from loss functions to uncertainty functions and from uncertainty functions
to losses. The mapping from uncertainty functions U to loss functions generating U as in (9) may
be one-to-many; we may begin with a non-convex loss Ψ′ in the deﬁnition (9), then construct a
convex Ψ via Proposition 3 satisfying UΨ = UΨ′.

3.2 Surrogate risk consistency and uncertainty functions

The construction (11) of loss functions is a somewhat privileged construction, as it often yields
desirable properties of the convex loss function itself, especially as related to the non-convex zero-
one loss. Indeed, it is often the case that the convex loss Ψ so generated is Fisher consistent; to
make this explicit, we recall the following deﬁnition [36, 32].
Deﬁnition 3.1. Let Ψ = {Ψ1, . . . , Ψk} be a vector of loss functions with Ψi : Rk → R. Then Ψ is
classiﬁcation calibrated for the zero-one loss if for any π ∈ ∆k and any i∗ such that πi∗ < maxj πj,
we have

πiΨi(α)) < inf
Given a cost matrix C = [c1 ··· ck] ∈ Rk×k
is classiﬁcation calibrated for the cost matrix C if for any π ∈ ∆k and any i∗ such that cT
minj cT

as in the cost-weighted loss of Example 2, we say Ψ
i∗ π >

α∈Rk( kXi=1

α∈Rk( kXi=1

πiΨi(α) : αi∗ ≥ max

αj) .

(12)

j π, we have

inf

j

+

α∈Rk( kXi=1

inf

πiΨi(α)) < inf

α∈Rk( kXi=1

πiΨi(α) : αi∗ ≥ max

j

αj) .

(13)

Indeed, let R(γ) be the zero-one risk (Ex. 1) or the cost-weighted risk (Ex. 2).

Tewari and Bartlett [32, Theorem 2] and Zhang [36, Theorem 3] show the importance of Deﬁ-
nition 3.1.
If
inf α Ψi(α) > −∞ for all i, then Ψ is classiﬁcation calibrated if and only if for any sequence of
functions γn : X → Rk we have the Fisher consistency guarantee that
RΨ(γ) implies R(γn) → inf

RΨ(γn) → inf

R(γ).

γ∈Γ

γ∈Γ

That is, classiﬁcation calibration is equivalent to surrogate risk or Fisher consistency of the losses
Ψ, and minimization of RΨ implies minimization of the true risk R.

We now show how—under minor restrictions on the uncertainty function U —the construc-

tion (11) yields losses that are classiﬁcation calibrated. We ﬁrst deﬁne the restrictions.

9

Deﬁnition 3.2. A convex function f : Rk → R is (λ, κ,k·k)-uniformly convex for some κ ≥ 2 over
C ⊂ Rk if it is closed and for all t ∈ [0, 1] and x1, x2 ∈ C we have

f (tx1 + (1 − t)x2) ≤ tf (x1) + (1 − t)f (x2) −

λ
2

t(1 − t)kx1 − x2kκ(cid:2)(1 − t)κ−1 + tκ−1(cid:3) .

We say, without qualiﬁcation, that a function f is uniformly convex on a set C if dom f ⊃ C and
there exist some λ > 0, norm k·k, and constant κ < ∞ such that Deﬁnition 3.2 holds, and that say
f is uniformly concave if −f is uniformly convex. Deﬁnition 3.2 is an extension of the usual notion
of strong convexity, which holds when κ = 2, and is essentially a slightly quantiﬁed notion of strict
convexity.1

With this deﬁnition, we have the following two propositions.

Proposition 4. Assume that U is closed concave, symmetric, and ﬁnite on ∆k with dom U = ∆k,
and let Ψi have deﬁnition (11). Additionally assume either that (a) U is strictly concave, and the
i=1 πiΨi(α) is attained for all π ∈ ∆k, or (b) U is uniformly concave. Then Ψ is

inﬁmum inf αPk

classiﬁcation calibrated.

Even when U is not strictly convex, we can give classiﬁcation calibration results. Indeed, recall
Example 1, which showed that for the zero-one-loss, we have UΨ(π) = 1 − maxj πj.
Proposition 5. Let U (π) = 1 − maxj πj. The loss (11) deﬁned by Ψi(α) = −αi + (−U )∗(α) is
classiﬁcation calibrated. Moreover, we have for any π ∈ ∆k and α ∈ Rk that
πiΨzo

πiΨzo

1

πiΨi(α) − inf

α

πiΨi(α) ≥

k(cid:18) kXi=1

i (α) − inf

α

kXi=1

i (α)(cid:19).

kXi=1

kXi=1

These two propositions, whose proofs we provide in Appendix A, show that uncertainty functions
very naturally give rise to classiﬁcation calibrated loss functions; we collect several examples of
these results in Section 3.4.

3.3 Divergences, risk, and uncertainty functions

In this section, we show that f -divergences as given in Deﬁnition 2.1 have a precise corresondence
with uncertainty functions and losses; Garc´ıa-Garc´ıa and Williamson [13] also establish a corre-
spondence between f -divergences and inﬁmal losses, though we present it here to give a complete
picture. We begin as in equation (9) with a concave uncertainty function U and corresponding loss
Ψ satisfying U (π) = inf α∈RkPk
i=1 πiΨi(α); by Proposition 3 it is no loss of generality to assume
this correspondence. Let µ be any measure such that Pi ≪ µ for each i, pi = dPi/dµ, and Γ be the
collection of measurable functions γ : X → Rk. The posterior Bayes risk for the loss Ψ is
γ∈ΓZX
kXi=1
α∈Rk( kXi=1
=ZX

πjpj(x)(cid:19)dµ(x) = E[UΨ(eπ(X))],

1Strict convexity requires that f (tx1 + (1 − t)x2) < tf (x1) + (1 − t)f (x2) for t ∈ (0, 1) and x1 6= x2.

If C is
compact, then letting diam(C) be the diamater of C, we may take λ = ǫ/ diam(C)κ, for some ǫ arbitrarily close to 0;
then Def. 3.2 is implied by f (tx1 + (1 − t)x2) ≤ tf (x1) + (1 − t)f (x2) − ǫt(1 − t)[(1 − t)κ−1 + tκ−1], and taking κ ↑ ∞
shows that uniform convexity is not much stronger than strict convexity for compact C.

πipi(x)

j=1 πjpj(x))(cid:18) kXj=1
Pk

πiΨi(γ(x))pi(x)dµ(x)

UΨ(π, P1:k) := inf

Ψi(α)

(14)

inf

10

is thus the gap between the prior Bayes Ψ-risk and posterior Bayes Ψ-risk. We may then write

whereeπ(x) is the posterior distribution on Y conditional on X = x. The information measure (3)

inf
α∈Rk

πiΨi(α) − inf

kXi=1
α∈Rk UΨ(π) −
=ZX

sup

γ∈Γ

RΨ(γ) = UΨ(π) − UΨ(π, P1:k) = I(X, π; UΨ)

πiΨi(α)

pi(x)

pk(x) − πkΨk(α)! pk(x)dµ(x) = DfΨ,π (P1, . . . , Pk−1||Pk) ,

k−1Xi=1

where the closed convex function fΨ,π : Rk−1

+ → R is deﬁned by

fΨ,π(t) := sup

α∈Rk UΨ(π) −

πiΨi(α)ti − πkΨk(α)!

k−1Xi=1

(15)

As fΨ,π is the supremum of aﬃne functions of its argument t, it is closed convex, and fΨ,π(1) =
UΨ(π) − UΨ(π) = 0. That is, equation (15) shows that given any loss Ψ = {Ψ1, . . . , Ψk} or
uncertainty function U , the information measure I(X, π; UΨ), gap between prior and posterior
Ψ-risk, and fΨ,π-divergence between distributions P1, . . . , Pk−1 and Pk are identical.

We can also give a converse result that shows that every f -divergence can be written as the gap
between prior and posterior risks for a convex loss function. We ﬁrst state a result that allows us
to write Df (P1:k−1||Pk) as a statistical information (3) based on a particular concave uncertainty
function U (see also [13, Theorem 3]).

Proposition 6. For any closed and convex function f such that f (1) = 0, let π = 1/k and

U (t1, . . . , tk) = −ktkf(cid:18) t1

tk

, . . . ,

tk−1

tk (cid:19) ,

where we implicitly use the closure of the perspective (cf. deﬁnition (7)). Then

where the expectation is taken according to 1

Df (P1, . . . , Pk−1||Pk) = U (1/k) − E[U (eπ(X))],

i=1 πiPi.

Proof The function U so deﬁned is concave, as it is a negative scalar multiple of the perspective
transform of the function f , which is convex [15, Section IV.2.2]. We have that U (1/k) = 0, and
we also have for t ∈ Rk

, . . . , tk−1
tk

+ that U (

t1Pk
i=1 ti

), so that

f ( t1
tk

, . . . ,

i=1 ti

kPk
i=1 Pi =Pk
) = − ktkPk

tkPk
i=1 ti

Df (P1, . . . , Pk−1||Pk) = U (1/k) −Z U  dP1(x)
kPk

Pk

i=1 Pi.

i=1 dPi(x)

where ¯P = 1

, . . . ,

dPk(x)

i=1 dPi(x)! d ¯P (x),
Pk

By combining Propositions 3 and 6 with the inﬁmal representation (9) of UΨ, we immediately

obtain the following corollary.

11

Corollary 2. Let π0 = 1/k. For any closed and convex function f such that f (1) = 0, the convex
loss Ψ deﬁned by

Ψi(α) = −αi + sup
i=1 π0

π∈∆k(cid:26)πT α − kπkf(cid:18) π1
i Ψi(α)ti − π0

πk

, . . . ,

πk−1

πk (cid:19)(cid:27)

kΨk(α)}. Additionally,

satisﬁes f (t) = supα∈Rk{UΨ(π0) −Pk−1

Df (P1:k−1||Pk) = UΨ(π0) − E[UΨ(eπ(X))] = inf

α∈Rk

kXi=1

π0
i Ψi(α) − inf

γ

E[ΨY (γ(X))],

where the expectation is taken according to Y ∼ π0 = 1/k and X ∼ Py conditional on Y = y.

Corollary 2, coupled with the information representation given by the f -divergence (15), shows
that there is a complete equivalence between f -divergences, loss functions Ψ, and uncertainty
measures U . For any f -divergence, there exists a loss function Ψ and prior π = 1/k such that
Df (P1:k−1||Pk) = UΨ(π)− UΨ(π, P1:k). Conversely, for any loss function Ψ and prior π, there exists
a multi-distribution f -divergence such that the gap UΨ(π) − UΨ(π, P1:k) = Df (P1:k−1||Pk).

3.4 Examples of uncertainty and loss correspondences

We give several examples illustrating the correspondence between (concave) uncertainty functions
and the loss construction (11), using Propositions 4 and 5 to guarantee classiﬁcation calibration.
Example 3 (0-1 loss, Example 1, continued): We use the uncertainty function U (π) = 1−maxj πj
generated by the zero-one loss to derive a convex loss function Ψ that gives the same uncertainty
function via the representation (9). Consider the conjugate

(−U )∗(α) = 1 + max(cid:26)α(1) − 1,

α(1) + α(2)

2

1
2

−

, . . . ,Pk

k

i=1 α(i)

1

k(cid:27),

−

(16)

where α(1) ≥ α(2) ≥ ··· are the entries of α ∈ Rk in sorted order (we show this equality subse-
quently). Then the convex “family-wise” loss (named for its similarity to family-wise error control
in hypothesis tests)

Ψfw
i (α) = 1 − αi + max

l∈{1,...,k}(cid:26) 1

l

lXj=1

α(j) −

1

l(cid:27)

generates the same uncertainty function UΨfw and associated f -divergence as the zero-one loss.
Moreover, Proposition 5 guarantees that Ψfw
is classiﬁcation calibrated (Def. 3.1). It appears that
i
the loss Ψfw
i

is a new convex classiﬁcation-calibrated loss function.

Let us now demonstrate the equality (16) for (−U )∗(α) = supπ∈∆k{πT α + 1 − kπk∞}. Formu-

lating the Lagrangian for the supremum with dual variables θ ∈ R, λ ∈ Rk

+, we have

which has dual objective

L(π, θ, λ) = πT α − kπk∞ − θ(1T π − 1) + λT π,
π L(π, θ, λ) =(θ

if kα + λ − θ1k1 ≤ 1

−∞ otherwise.

sup

12

As inf λ≥0 kα + λ − θ1k1 =Pk

have that the supremum in expression (16) is

j=1 [αj − θ]+ and strong duality obtains (the problems are linear), we

sup

π (cid:8)πT α − kπk∞ | πT 1 = 1, π ≥ 0(cid:9) = inf(cid:26)θ |

kXj=1

[αj − θ]+ ≤ 1(cid:27).

Without loss of generality we may assume that α1 ≥ α2 ≥ ··· by symmetry, so that over the
j=1 [αj − θ]+ is strictly decreasing. Thus, there is a
j=1 [αj − θ]+ ≤ 1 (attaining the equality), and by inspection, this

must be one of

domain θ ∈ (−∞, α1], the function θ 7→ Pk
unique smallest θ satisfying Pk
θ ∈(cid:26)α1 − 1,

α1 + α2

2

1
2

,

−

α1 + α2 + α3

3

1
3

−

, . . . ,

1T α
k −

1

k(cid:27) .

(Any θ makes some number of the terms [αj − θ]+ positive; ﬁxing the number of terms and solving
for θ gives the preceding equality.) Expression (16) follows. ♣

Now we consider the logistic loss for multiclass classiﬁcation problems; this does not directly

correspond to the zero-one loss, but it generates Shannon entropy and information.

Example 4 (Logistic loss and entropy): The multi-class logistic loss is

Ψi(α) = log(cid:18) kXj=1

eαj −αi(cid:19),

for 1 ≤ i ≤ k.

The uncertainty function (prior Bayes risk) for the logistic loss is the Shannon entropy,

U (π) = inf

α∈Rk(cid:26) kXi=1

πi log(cid:18) kXj=1

eαj −αi(cid:19)(cid:27) = −

kXi=1

πi log πi.

(17)

Moreover, the negative entropy is strongly convex over the simplex ∆k (this is Pinsker’s inequal-
ity [7, Chapter 17.3]), so Proposition 4 immediately implies the classiﬁcation calibration of the
multiclass logistic loss (cf. [36, Section 4.4]). The information measure (3) associated with the
logistic loss is the mutual information between the observation X and label Y . Indeed, we have

I(X, π; U ) = U (π) − E[U (eπ(X))] = H(Y ) −ZX

H(Y | X = x)d ¯P (x)

where H denotes the Shannon entropy, ¯P = Pk

information between X and Y . ♣

= H(Y ) − H(Y | X) = I(X; Y )
i=1 πiPi, and I(X; Y ) is the (Shannon) mutual

4 Comparison of loss functions

In Section 3, we demonstrated the correspondence between loss functions, concave measures of
uncertainty, statistical information, and f -divergences. These correspondences assume that decision

13

makers have access to the entire observation X, which is often not the case; as noted in the
introduction, it is often beneﬁcial to pre-process data to make it lower dimensional, communicate
or store it eﬃciently, or to improve statistical behavior. In such cases, it is useful to understand
correspondence between criteria used for the design of experiments, quantization methods, and
data representation, which we now explore.

4.1 A model of quantization and experimental design

Abstractly, we treat the design of an experiment or choice of data representation as a quantization
problem, where a quantizer q maps the space X to a countable space Z (we assume with no loss
of generality that Z ⊂ N). Then, for a loss Ψ and discriminant function γ : Z → Y = {1, . . . , k},
we consider the quantized risk (2), which we recall is

RΨ,π(γ | q) := E [ΨY (γ(q(X)))] .

Given a prior π ∈ ∆k on the label Y and class-conditional distributions P1, . . . , Pk (equivalently,
hypotheses Hi : Pi in the Bayesian testing setting), and collection Q of quantizers, our design
criterion is to choose the quantizer q that allows the best attainable risk. That is, we consider
the quantized Bayes Ψ-risk, deﬁned as the inﬁmum of the risk (2) over all possible discriminant
functions Γ = {γ : Z → Rk},

inf
γ∈Γ

RΨ,π(γ | q) =Xz∈Z

α∈Rk( kXi=1

inf

πiΨi(α)Pi(q−1(z))) .

(18)

Whether for computational or analytic reasons, minimizing the loss (18) is often intractable;
the zero-one loss Ψzo (Ex. 1), for example, is non-convex and discontinuous. It is thus of interest to
understand the asymptotic consquences of using a surrogate loss Ψ in place of the desired loss (say
Ψzo), including in the face of quantization or a further dimension reduction embodied by the choice
q ∈ Q. In the binary case, Nguyen et al. [24] have studied this problem, but the consequences of
using a surrogate for consistency of the resulting quantization and classiﬁcation procedure is a-priori
unclear: we do not know when using such a surrogate can be done without penalty. To that end,
we now characterize when two loss functions Ψ(1) and Ψ(2) provide equivalent criteria for choosing
quantizers (experimental designs or data representations) according to the Bayes Ψ-risk (18).

4.2 Universal Equivalence of Loss Functions

Recalling our arguments in Section 3.3 that statistical information (the gap between prior and
posterior risks) is a multi-way f -divergence between distributions P1, . . . , Pk−1 and Pk, we give a
quantized version of this construction. In analogy with the results of Section 3.3, the quantized
statistical information is

I (X, π; UΨ | q) := UΨ(π) − E[UΨ(eπ(q(X)))] = inf

α∈Rk

kXi=1

πiΨi(α) − inf

γ

RΨ,π(γ | q)

(19)

= DfΨ,π (P1, . . . , Pk−1||Pk | q) ,

where UΨ(π) = inf α∈RkPk
sion (15) and does not depend on the quantizer q, andeπ(q(X)) denotes the posterior distribution

i=1 πiΨi(α) as in (9), the convex function fΨ,π is deﬁned as in expres-

on Y ∈ [k] conditional on observing q(X).

14

Using the representation (19), we deﬁne loss functions to be equivalent if they provide the same

ordering of quantizers q under the information measure (19).
Deﬁnition 4.1. Loss functions Ψ(1) and Ψ(2) are universally equivalent for the prior π, denoted
Ψ(1) u

≡π Ψ(2), if for any distributions P1, . . . , Pk on X and quantizers q1 and q2
I (X, π; UΨ(1) | q1) ≤ I (X, π; UΨ(1) | q2)

iﬀ I (X, π; UΨ(2) | q1) ≤ I (X, π; UΨ(2) | q2) .

Deﬁnition 4.1 of equivalent losses evidently is equivalent to the ordering condition

inf
γ

RΨ(1),π(γ | q1) ≤ inf

γ

RΨ(1),π(γ | q2) iﬀ inf

γ

RΨ(2),π(γ | q1) ≤ inf

γ

RΨ(2),π(γ | q2),

(20)

for all distributions P1, . . . , Pk, on the quantized Bayes Ψ-risk (18). This deﬁnition is somewhat
stringent: losses are universally equivalent only if they induce the same quantizer ordering for all
population distributions. Whenever a quantizer q1 is ﬁner than a quantizer q2, all losses yield
I (X, π; UΨ | q2) ≤ I (X, π; UΨ | q1) by the data processing inequality (Corollary 1 of Section 2).
The stronger equivalence notion is important for nonparametric classiﬁcation settings in which the
underlying distribution on (X, Y ) is only weakly constrained and neither of a pair of quantizers
q1, q2 ∈ Q is ﬁner than the other.
Deﬁnition 4.1 and the representation (19) suggest that the uncertainty function UΨ associated
with the loss Ψ through the inﬁmal representation (9) and the f -divergence associated with Ψ via
the construction (15) are important for the equivalence of two loss functions. This is indeed the
case. First, we have the following result on universal equivalence on loss functions based on their
associated uncertainty functions.
Theorem 1. Let Ψ(1) and Ψ(2) be bounded below loss functions. Let UΨ(1) and UΨ(2) be the associ-
ated uncertainy functions as in the construction (9). Then Ψ(1) and Ψ(2) are universally equivalent
if and only if there exist a > 0, b ∈ Rk, and c ∈ R such that for all π ∈ ∆k,

UΨ(1)(π) = aUΨ(2)(π) + bT π + c.

π and f (2)
π

Secondly, we can characterize universal equivalence for a ﬁxed prior π using f -divergences.
Theorem 2. Let π ∈ ∆k and as in Theorem 1, let Ψ(1) and Ψ(2) be bounded below loss functions,
with f (1)
the associated f -divergences as in the construction (15). Then Ψ(1) and Ψ(2) are
universally equivalent for the prior π if and only if there exist exist a > 0, b ∈ Rk−1, and c ∈ R
such that
(21)

f (1)
π (t) = af (2)

π (t) + bT t + c

for all t ∈ Rk−1
+ .

We provide a proof of each of these results in Section 5.

Theorems 1 and 2 show that two loss functions Ψ(1) and Ψ(2) are equivalent, namely if and
only if their associated uncertainty measures U or f -divergences are positive scalar multiples of one
another (potentially with a linear shift). A major application of these theorems, which we touch
on in the examples in Section 4.3 to follow, is to show that certain non-convex loss functions (such
as the zero-one loss) are equivalent to convex loss functions, including variants of the hinge loss.

As a ﬁrst application of the theorems, however, we consider the Bayes consistency of empirical
risk minimization strategies for selecting a discriminant γ and quantizer q. In this case, we are
given a sample {(X1, Y1), . . . , (Xn, Yn)}, and we deﬁne the empirical risk

1
n

bRΨ,n(γ | q) :=

nXi=1

15

ΨYi(γ(q(Xi))).

Now, let Q1 ⊂ Q2 ⊂ ··· ⊂ Q be a non-decreasing collection of quantizers, indexed by sample size n,
and similarly let Γ1 ⊂ Γ2 ⊂ ··· ⊂ Γ be a non-decreasing collection of discriminant functions, where
we assume the collections satisfy the estimation and approximation error conditions

and

sup

E"
γ∈Γn,q∈Qn(cid:12)(cid:12)(cid:12)bRΨ,n(γ | q) − RΨ(γ | q)(cid:12)(cid:12)(cid:12)# ≤ ǫest

n

inf

γ∈Γn,q∈Qn

RΨ(γ | q) − inf

γ∈Γ,q∈Q

RΨ(γ | q) ≤ ǫapp
n ,

(22a)

(22b)

n → 0 and ǫapp

where ǫest
weighted misclassiﬁcation loss Ψcw (Example 2), where Ψcw
we have the following result, which is a consequence of Theorems 1 and 2.

n → 0 as n → ∞. Additionally, let R be the risk functional for the cost-
y (α) = maxi{cyi | αi = maxj αj}. Then

Theorem 3. Assume the conditions (22) hold and that γn and qn are approximate empirical Ψ-risk
minimizers, that is,

ǫopt
n

:= E(cid:2)bRΨ,n(γn | qn) −

inf

γ∈Γn,q∈Qn bRΨ,n(γ | q)(cid:3) → 0 as n → ∞.

Let R⋆(Q) = infγ∈Γ,q∈Q R(γ | q). If the loss Ψ is (i) classiﬁcation calibrated for the cost-weighted
loss Ψcw and (ii) universally equivalent to the cost-weighted loss, then

R(γn | qn) − R⋆(Q)

L1→ 0.

Theorem 3 guarantees—at least under the estimation and approximation conditions (22)—that
empirical risk minimization yields a consistent procedure for minimizing the quantized Bayes risk
whenever the loss Ψ is classiﬁcation calibrated and equivalent to the desired loss. We provide its
proof in Appendix C.

4.3 Examples of universal equivalence

In this section, we give several examples that build oﬀ of Theorems 1 and 2, showing that there
exist convex losses that allow optimal joint design of quantizers (or measurement strategies) and
discriminant functions, opening the way for potentially eﬃcient convex optimization strategies. To
that end, we give two examples of hinge-like loss functions that are universally equivalent to the
zero-one loss for all prior distributions π. We also give examples of classiﬁcation calibrated loss
functions that are not universally equivalent to the zero-one loss, although minimizing them sans
quantization yields Bayes-optimal classiﬁers.

In this example, we consider a pairwise-type multiclass hinge loss,

Example 5 (Hinge losses):
where Ψhinge

i

: Rk → R is deﬁned by
Ψhinge

i

(α) =Xj6=i

[1 + αj]+ + I(cid:8)1T α = 0(cid:9) .
We also consider the slight extension to weighted loss functions to address asymmetric losses of the
form (10) from Example 2. In this case, given the loss matrix C ∈ Rk×k
cij [1 + αj]+ + I(cid:8)1T α = 0(cid:9) .

+ , we set

kXj=1

Ψhinge

(α) =

i

16

We make the following observation, essentially due to Zhang [36, Theorem 8]. For completeness,
we include a proof in Appendix A.4.

Observation 1. Let φ : R → R be any convex function that is bounded below, diﬀerentiable on
(−∞, 0], and satisﬁes φ′(0) < 0. Then the loss Ψy(α) =Pk
i=1 cyiφ(−αi) is classiﬁcation calibrated
for the cost matrix C (Def. 3.1, Eq. (13)).
Taking C = 11T − Ik×k, we see that the hinge loss is calibrated for the zero-one loss (Ex. 1); taking
arbitrary C ∈ Rk×k
We claim that the associated uncertainty function (as deﬁned by the construction (9)) for the
weighted hinge loss with matrix C = [c1 ··· ck] is

+ , the weighted hinge loss is calibrated for the cost matrix C.

U (π) = inf

πiΨhinge

i

πT cl.

(23)

α∈Rk( kXi=1

(α)) = k min

l

for π ∈ ∆k. Deferring the derivation of this equality, we have that UΨhinge(π) = k minl πT cl =
kUΨcw (π) (recall Example 2). Theorem 1 immediately guarantees that the (weighted) hinge loss
is universally equivalent to the (weighted) 0-1 loss. Even more, as we show in Lemma C.1 in
Appendix C (recall also Proposition 5), we have the quantitative calibration guarantee

kXi=1

πiΨhinge

i

(α) − inf

α′

kXi=1

πiΨhinge

πiΨcw

i (α) − inf

α′

πiΨcw

i (α′)

kXi=1

for all π ∈ ∆k and α ∈ Rk, strengthening Observation 1.

We return to demonstrating equality (23) with C = [c1 ··· ck]. We note that

U (π) = inf

αT 1=0

πy

kXy=1

kXi=1

= inf

αT 1=0( kXi=1

πT ci [1 + αi]+) ,

i

(α′) ≥

kXi=1
cyi [1 + αi]+
kXi=1

and formulating the Lagrangian by introducing dual variable θ ∈ R, we have

L(α, θ) =

πT ci [1 + αi]+ − θ1T α.

The generalized KKT conditions [4] for this problem are given by taking subgradients of the La-
grangian. At optimum, we must have

νi ∈ ∂ [1 + αi]+ =

0
[0, 1]
1

if αi < −1
if αi = −1
if αi > −1,

and πT ci νi − θ = 0, 1T α = 0, i = 1, . . . , k.

Without loss of generality, assume that πT c1 = minj πT cj. Set α⋆ ∈ Rk and θ⋆ via

α⋆
1 = (k − 1), α⋆

i = −1 for i ≥ 2,

θ⋆ = min

j

πT cj = πT c1.

17

We have 1T α⋆ = (k − 1) − (k − 1) = 0, and setting νi = 1 for i such that πT ci = minj πT cj and
νi = minj πT cj
∈ [0, 1] otherwise, we see that πT ciνi − θ⋆ = minj πT cj − minj πT cj = 0 for all i; the
KKT conditions are satisﬁed. Thus α⋆ and θ⋆ are primal-dual optimal, yielding expression (23). ♣

πT ci

Example 6 (Max-type losses and zero-one loss): We return to Example 3 and let Ψfw be the family-
wise loss Ψfw
that the associated uncertainty

ko. We know by Example 3

2 , . . . , 1T α

α(1)+α(2)

2

i (α) = 1 − αi + maxnα(1) − 1,
α ( kXi=1

UΨfw(π) = inf

− 1
k − 1
i (α)) = 1 − max

j

πj

πiΨfw

for π ∈ ∆k, and Proposition 5 shows that Ψfw is classiﬁcation calibrated. As the uncertainty
function satisﬁes UΨfw ≡ UΨzo, we have that Ψfw and Ψzo are universally equivalent by the con-
struction (15) and Theorems 1 and 2. ♣

For our ﬁnal example, we consider the logistic loss, which is classiﬁcation calibrated but—as we

show—not universally equivalent to the zero-one loss.

Example 7 (Logistic loss, Example 4 continued):

j=1 eαj −αi)
has uncertainty function U (π) = −Pk
i=1 πi log πi by Example 4. It is clear that there are no a, b, c
such that UΨzo(π) = 1 − maxj πj = aUΨlog(π) + bT π + c for all π ∈ ∆k. Theorem 1 shows that the
logistic loss is not universally equivalent to the zero-one loss. ♣

The logistic loss Ψlog

(α) = log(Pk

i

5 Proof of the Theorems 1 and 2

We divide the proof of the theorems into two parts. The “if” part is straightforward; the “only if”
is substantially more complex, so we present it in parts.

Proof (if direction) We give the proof for Theorem 2, as that for Theorem 1 is identical. Assume
that dom f (1)
and there exist some a > 0, b ∈ Rk−1, and c ∈ R such that equation (21)
holds. By Deﬁnition 2.1 of multi-way f -divergences, for any quantizer q, we have

π = dom f (2)
π

D

f (1)
π

(P1, . . . , Pk−1||Pk | q) = aD

f (2)
π

(P1, . . . , Pk−1||Pk | q) + bT 1 + c,

asRX dPi = 1. Applying the relationship (19), we obtain

I (X, π; UΨ(1) | q) = aI (X, π; UΨ(2) | q) + bT 1 + c.

As q was arbitrary and a > 0, the universal equivalence of Ψ(1) and Ψ(2) follows immediately.

We turn to the “only if” part of the proofs of Theorems 1 and 2. A roadmap of the proof is as
follows: we ﬁrst provide a deﬁnition of what we call order equivalence of convex functions, which is
related to the equivalence of f -divergences and uncertainy functions (Def. 5.1). Then, for any two
loss functions Ψ(1) and Ψ(2) that are universally equivalent, we show that the associated uncertainty

18

functions UΨ(1) and UΨ(2), as constructed in the inﬁmal representation (9), and the functions f (1) and
f (2) generating the f -divergences via expression (15), are order equivalent (Lemmas 5.1 and 5.3).
After this, we provide a characterization of order equivalent closed convex functions (Lemma 5.4),
which is the lynchpin of our analysis. The lemma shows that for any two order equivalent closed
convex functions f1 and f2 with dom f1 = dom f2 ⊂ Rk
+, there are parameters a > 0, b ∈ Rk−1, and
c ∈ R such that f (1)(t) = af (2)(t) + bT t + c for all t ∈ dom f1 = dom f2. This proves the “only if”
part of the Theorems 1 and 2, yielding the desired result. We present the main parts of the proof
in the body of the paper, deferring a number of technical nuances to appendices.

5.1 Universal equivalence and order equivalence

By Deﬁnition 4.1 (and its equivalent variant stated (20)), universally equivalent losses Ψ(1) and
Ψ(2) induce the same ordering of quantized information measures and f -divergences. The next
deﬁnition captures this ordering in a slightly diﬀerent way.

Deﬁnition 5.1. Let f1 : Rk
arbitrary and the matrices A, B ∈ Rk×m
and B has columns b1, . . . , bm ∈ Rk
such matrices A and B we have

+

+ → R and f2 : Rk

+ → R be closed convex functions. Let m ∈ N be
satisfy A1 = B1, where A has columns a1, . . . , am ∈ Rk
+. Then f1 and f2 are order-equivalent if for all m ∈ N and all

+

mXj=1

f1(aj) ≤

mXj=1

f1(bj) if and only if

mXj=1

f2(aj) ≤

mXj=1

f2(bj).

(24)

As suggested by the above context, order equivalence has strong connections with universal
equivalence of loss functions Ψ and associated f -divergences and uncertainty functions. The next
three lemmas make this explicit; we begin by considering uncertainty functions.

Lemma 5.1. If losses Ψ(1) and Ψ(2) are lower bounded and universally equivalent, then the asso-
ciated uncertainty functions of the construction (9) are order equivalent over ∆k ⊂ Rk
+.
Proof Let U1 and U2 be the associated uncertainty functions, noting that dom U1 = dom U2 = ∆k
and B ∈ Rk×m
because inf π∈∆k mini Ui(π) > −∞. Let the matrices A = [a1 ··· am] ∈ Rk×m
satisfy ai, bi ∈ ∆k for each i = 1, . . . , m, and let v = 1
m B1 ∈ ∆k. We will show that
Pm
j=1 U1(aj) ≤ Pm
j=1 U2(bj), that is, expression (24)
holds, by constructing appropriate distributions P1:k and π, then applying the universal equivalence
of losses Ψ(1) and Ψ(2).

j=1 U1(bj) if and only if Pm

m A1 = 1

+

+

j=1 U2(aj) ≤ Pm
)1 − 1

k (1 + 1
M0

M0

v ∈ Rk

+, so that v0 ∈ ∆k. Then

Let M0 be any integer large enough that v0 = 1

deﬁne the vectorsea1 = v0, . . . ,eamM0 = v0, and let
Aext = [a1 ··· amea1 ··· eamM0] ∈ Rk×M

where M = (M0 + 1)m. These satisfy Aext1 = Bext1 = M
columns of these extended matrices.

+

and Bext = [b1 ··· bmea1 ··· eamM0] ∈ Rk×M

k 1. We let aext and bext denote the

+

,

Now, let the spaces X = [M ] × [M ] and Z = [M ]. Deﬁne quantizers q1, q2 : X → Z by

q1(i, j) = i and q2(i, j) = j. For l = 1, . . . , k, deﬁne the distributions Pl on X by
k
M

k2
M 2 · aext

Pl(i, j) =

Pl(i, j) =

il bext
jl ,

bext
jl =

k
M

k
M

aext
il

so

aext
il

MXj=1

MXj=1

19

and similarly Pi Pl(i, j) = k

Y ∈ {1, . . . , k}, and note that the posterior probability

jl . Let π = 1

M bext

k 1 be the uniform prior distribution on the label

l=1

l=1

i ∈ ∆k,

= aext

M aext
il

because Pl(q−1

Pl′ πl′Pj Pl(i, j)#k
1 ({i})) =" πlPj Pl(i, j)
eπ(q−1
1 (i)) =Pj Pl(i, j) = k
taking the expectation over X drawn according toPk
1 (i))UΨ(eπ(q−1
E[UΨ(eπ(q−1
because Pl aext
il = 1. Similarly, we have E[UΨ(eπ(q−1

=(cid:20) aext
il′ (cid:21)k
ilPl′ aext
, and similarly eπ(q−1
2 ({j})) = bext
1 (i))) =Xi,l

2 (q2(X))))] = 1

MPM

l=1 πlPl, we have

kXi,l

1 (q1(X))))] =

UΨ(aext

aext
il
M

Pl(q−1

). Recalling
the deﬁnitions (19) and (3) of the (quantized) information associated with the uncertainty U , we
immediately ﬁnd that the universal equivalence of losses Ψ(1) and Ψ(2) implies that

j

j=1 Uπ(bext

1
M

MXi=1

UΨ(aext

i

),

j ∈ ∆k. In particular,

) =

i

1

1
M

MXi=1

U1(aext

i

) ≤ U1(π) −

1
M

MXi=1

U1(bext

i

) = I (X, π; U1 | q2)

1
M

MXi=1

U2(aext

i

) ≤ U2(π) −

1
M

MXi=1

U2(bext

i

) = I (X, π; U2 | q2) .

I (X, π; U1 | q1) = U1(π) −

(for π = 1

k 1) if and only if

I (X, π; U2 | q1) = U2(π) −

Noting that aext
adding 1

i = bext
i

MPi≥m+1 U (aext

i

for each i ≥ m + 1, we rearrange the preceding equivalent statements by
) to each side to obtain that the Ui satisfy inequality (24).

We now provide a result for f -divergences similar to that for uncertainty functions. Before
stating the lemma, we give a matrix characterization of non-negative vectors with equal sums
similar to the characterization of majorization via doubly stochastic matrices (cf. Marshall et al.
[23]; see Appendix B.1 for a proof).
Lemma 5.2. Vectors a, b ∈ Rm
such that Z1 = a and Z T 1 = b.
Using Lemma 5.2, we can construct a particular discrete space X , discrete measure on X , and
quantizers to show that universal equivalence implies order equivalence for f -divergence functionals.

+ satisfy 1T a = 1T b if and only if there exists a matrix Z ∈ Rm×m

+

Lemma 5.3. If losses Ψ(1) and Ψ(2) are universally equivalent for the prior π (Def. 4.1) and
lower-bounded, the corresponding f -divergences fΨ(1),π and fΨ(2),π of construction (15) are order
equivalent.

Let fi = fΨ(i),π for shorthand. Note that dom f1 = dom f2 = Rk−1
Proof
satisfying
tion (15), because mini infα∈Rk Ψi(α) > −∞. Now, given matrices A, B ∈ R
A1 = B1 (where A = [a1 ··· am] and B = [b1 ··· bm]), we construct distributions Pi and
quantizers q1 and q2 such that for any f we have

by the construc-

(k−1)×m
+

+

Df (P1, . . . , Pk−1||Pk | q1) = C

mXj=1

f (aj) and Df (P1, . . . , Pk−1||Pk | q2) = C

f (bj),

mXj=1

20

where C > 0 is a constant. We then use Deﬁnition 4.1 of loss equivalence to show that f1 and f2
are order equivalent.

enlarge A and B into matrices Aext, Bext ∈ R
i,m+1 = M −Pm
construct these matrices, let aext
and set aext
M Aext1 = 1
1

With that in mind, take M to be any positive integer such that M > max{kA1k∞ , m}. We
respectively, adding M − m columns. To
j=1 bij, for i = 1, . . . , k−1,
il = 0 for all m + 1 < l ≤ M . The enlarged matrices Aext and Bext thus satisfy
Let the spaces X = {(i, j) | 1 ≤ i ≤ M, 1 ≤ j ≤ M} and Z = {1, 2, . . . , M}. Deﬁne quantizers
q1, q2 : X → [M ] by q1(i, j) = i and q2(i, j) = j. As Aext1 = Bext1 = M 1, Lemma 5.2 guarantees
the existence of matrices Z l = [zl

M Bext1 = 1, and their columns belong to dom f1 = dom f2 = Rk−1
+ .

i,m+1 = M −Pm

j=1 aij and bext

il = bext

(k−1)×M
+

such that

+

ij] ∈ RM ×M
j=1 ∈ RM
lj ]M

+

[aext

Z l1 =

1
M

and (Z l)T 1 =

which implies that for all l ∈ [k − 1], the matrix Z l satisﬁes Pij zl
deﬁne the probability distribution Pl on X by Pl((i, j)) = zl
the distribution deﬁned by Pk((i, j)) = M −2.
Under this quantizer design and choice of distributions Pl, we have for any prior π ∈ Rk

which the functions f1 and f2 implicitly depend) and f = f1 or f = f2 that

+ (upon

1
M

[bext

lj ]M

j=1 ∈ RM
+ ,
ij = 1. For each l ∈ [k − 1],
ij for i, j ∈ [M ]. Moreover, let Pk be

Df (P1, . . . , Pk−1||Pk | q1) =

1
M

f (aext

j

) and Df (P1, . . . , Pk−1||Pk | q2) =

MXj=1

1
M

MXj=1

f (bext

j ),

By the loss equivalence of Ψ(1) and Ψ(2) (recall Def. 4.1), we obtain that

i=1 zl

ij = aext

i=1 Pk((i, j)) = M −1, and similarly for Bext.

lj /M and PM

because PM

i=1 Pl((i, j)) =PM
MXj=1
MXj=1

f1(aext

) ≤

j

f1(bext

j

) if and only if

MXj=1

f2(aext

j

) ≤

MXj=1

f2(bext

j

).

j = bext

Note that aext
1 ≤ j ≤ m, so the preceding display is equivalent to the order equivalence (24).

j ∈ dom fi for each j > m and i = 1, 2. Moreover, aext

j = aj and bext

j = bj for

5.2 Characterization of the order equivalence of convex functions

Lemmas 5.1 and 5.3 show that order equivalence (Def. 5.1) and universal equivalence (Def. 4.1)
are strongly related. With that in mind, we now present a lemma fully characterizing the order
equivalence of closed convex functions with identical domains.
Lemma 5.4. Let f1, f2 : Ω → R be closed convex functions, where Ω ⊂ Rk
+ is a convex set. Then
f1 and f2 are order equivalent on Rk if and only if there exist a > 0, b ∈ Rk, and c ∈ R such that
for all t ∈ Ω
(25)

f1(t) = af2(t) + bT t + c.

Lemma 5.4 immediately shows that Theorems 1 and 2 hold. In the ﬁrst case, we apply Lemma 5.1,
which shows that the uncertainty functionals UΨ(1) and UΨ(2) are order equivalent on Ω = ∆k;

21

Lemma 5.4 yields Theorem 1 as desired. In the second case, Lemma 5.3 implies that the divergence
functionals fΨ(1),π and fΨ(2),π are order equivalent, thus giving Theorem 2.

The proof of Lemma 5.4 relies on several intermediate lemmas and deﬁnitions, which we turn

to presently. In brief, we prove Lemma 5.4 via the following steps:
1. We show that it is no loss of generality to assume that int Ω 6= ∅.
2. We show that Lemma 5.4 holds on any simplex with non-empty interior. Explicitly, considering
any two order equivalent functions f1 and f2, for any simplex E there exist aE, bE, and cE such
that f1(t) = aEf2(t) + bT

Et + cE, for all t ∈ E. (Lemma 5.9)

3. We show that any convex set can be covered by simplices (Lemma 5.10).

4. We show that if for each simplex E ⊂ Ω the relationship (25) holds for some aE, bE, and cE,

then there exist a, b, and c such that the relationship (25) holds on all of Ω (Lemma 5.12).

We defer technical (convex-analytic) proofs to appendices to avoid disrupting the ﬂow of the argu-
ment.

5.2.1

It is no loss of generality to assume non-empty interior in Lemma 5.12

Let H = aﬀ Ω be the aﬃne hull of Ω, where dim H = l ≥ 1. (If dim H = 0, then Ω is a single
point, and Lemma 5.4 is trivial.) We argue that if Lemma 5.4 holds for sets Ω such that int Ω 6= ∅
it holds generally; thus we temporarily assume its truth for convex Ω with int Ω 6= ∅.
Since dim H = l, we have H =(cid:8)Av + d | v ∈ Rl(cid:9) for some full column-rank matrix A ∈ Rk×l
and d ∈ Rk. As Ω has non-empty interior relative to H (e.g. [15, Theorem 2.1.3]), we have
Ω = {Av + d | v ∈ Ω0} for a convex set Ω0 ⊂ Rl with int Ω0 6= ∅. Deﬁning ef1(v) = f1(Av + d) and
ef2(v) = f2(Av + d), where efi(v) = ∞ for v 6∈ Ω0, we have that ef1 and ef2 are order equivalent on
Ω0 ⊂ Rl. By assumption, Lemma 5.4 holds for Ω0, so there exist a > 0,eb ∈ Rl,ec ∈ R such that

for v ∈ Ω0.

f1(Av + d) = ef1(v) = aef2(v) + heb, vi + c,

As A is full column rank, for all t ∈ Ω there exists a unique vt ∈ Ω0 such that t = Avt + d, and
the mapping t 7→ vt is linear, i.e., vt = Et + g for some E ∈ Rl×k and g ∈ Rl (we may take E ∈ Rl×k
to be any left-inverse of A and g = −Ed, so v = Et − Eg). We obtain that fi(t) = efi(Et + g) for
i = 1, 2, whence

f1(t) = ef1(Et + g) = aef2(Et + g) + heb, Et + gi +ec = af2(t) + hETeb, ti + heb, gi +ec

for all t ∈ Ω, which is our desired result. From this point forward, we thus assume w.l.o.g. that
int Ω 6= ∅.

5.2.2 Proof of Lemma 5.4 for simplices

As outlined above, we ﬁrst show Lemma 5.4 holds for simplices. To do this, we require the deﬁnition
of aﬃne independence.
Deﬁnition 5.2. Points x0, x1, . . . xm ∈ Rk, m ≤ k + 1, are aﬃnely independent if the vectors

are linearly independent. A set E ⊂ Rk is a simplex if E = Conv{x0, x1, . . . , xk} where x0, . . . , xk
are aﬃnely independent.

x1 − x0, x2 − x0, . . . , xm − x0,

22

We now state four technical lemmas, whose proofs we defer, that we use to prove Lemma 5.9,

Note that the simplex E = Conv{x0, x1, . . . , xk} ⊂ Rk has non-empty interior.
which states that Lemma 5.4 holds on simplices.
Lemma 5.5. Let x1, . . . , xm ∈ Rk
f1 : Rk

+, α ∈ Qm satisfy 1T α = 1, and y =Pm

+ → R are order equivalent, then

+ → R and f2 : Rk

i=1 αixi with y ∈ Rk

+. If

mXi=1

αif1(xi) ≤ f1(y) if and only if

mXi=1

αif2(xi) ≤ f2(y).

See Section B.2 for a proof of Lemma 5.5. As an immediate consequence of Lemma 5.5, we see that
if α ∈ Qn

+ satisﬁes 1T α = 1 and x1, . . . , xn ∈ Rk

+, then

f1  nXi=1

αixi! =

αif1(xi) if and only if f2  nXi=1

nXi=1

αixi! =

αif2(xi).

(26)

nXi=1

Closed convex functions equal on a dense subset of a convex set Ω are equal on Ω (e.g. [15,
Proposition IV.1.2.5]); this is useful as it means we need only prove equivalence results for convex
functions on dense subsets of their domains.

Lemma 5.6. Let f1 : Ω → R and f2 : Ω → R be closed convex functions satisfying f1(t) = f2(t)
for all t in a dense subset of Ω. Then we have f1(t) = f2(t) for t ∈ Ω.

The next lemma shows that we can make the equality (25) hold for the extreme points and

centroid of any simplex (see Section B.3 for a proof).
Lemma 5.7. Let f1, f2 : Ω → R be closed convex and let x0, x1, . . . , xk ∈ Ω ⊂ Rk be aﬃnely
independent. Then there exist a > 0, b ∈ Rk, and c such that f1(x) = af2(x) + bT x + c for
x ∈ {x0, . . . , xk, xcent}, where xcent = 1
Lastly, we characterize the linearity of convex functions over convex hulls of ﬁnite collections of
points. (See Sec. B.4 for a proof of this lemma.)
Lemma 5.8. Let f : Ω → R be convex with x1, . . . , xm ∈ Ω and xcent = 1
mPm

i=1 f (xi), then for all λ ∈ Rm

+ such that 1T λ = 1,

k+1Pk

i=1 xi. If f (xcent) =

mPm

i=0 xi.

1

f  mXi=1

λixi! =

mXi=1

λif (xi).

We now state and prove Lemma 5.4 for simplices using the preceding four lemmas, assuming

that int Ω 6= ∅.
Lemma 5.9. Let E = Conv{x0, . . . , xk} ⊂ Ω where x0, . . . , xk are aﬃnely independent. If f1 and
f2 are order equivalent, then there exist a > 0, b ∈ Rk, and c ∈ R such that

f1(t) = af2(t) + bT t + c for all t ∈ E.

23

Proof
Rk×k. Deﬁne the two convex functions g1 : Rk

Let δi = xi−x0, 1 ≤ i ≤ k, be a linearly independent basis for Rk and let D = [δ1 ··· δk] ∈
gj(y) = fj(x0 + Dy) = fj x0 +

+ → R and g2 : Rk
δiyi! = fj (1 − 1T y)x0 +

xiyi!

+ → R via

kXi=1

kXi=1

k+1Pk

Linear case: Suppose that g1(ecenter) = 1

+ | 1T y ≤ 1}, then we know that g1 and g2 are continuous,
for j = 1, 2. If we deﬁne Y = {y ∈ Rk
deﬁned, convex, and order equivalent on Y . The lemma is equivalent to the existence of a > 0,
b ∈ Rk, and c ∈ R such that g1(y) = ag2(y) + bT y + c for y ∈ Y .
vector. Further, let ecenter = 1
divide our discussion into two cases.

Let ei ∈ Rk for 1 ≤ i ≤ k be the standard basis for Rk and e0 = 0 be shorthand for the all-zeros
i=0 ei be the centroid of Y (so Y = Conv{e0, . . . , ek}). We
i=0 g1(ei). Then by order equivalence of g1 and
i=0 g2(ei). Lemma 5.8 thus implies that g1 and g2 are
i t + ci for some bi ∈ Rk and ci ∈ R for i = 1, 2.
k+1Pk
i=0 g1(ei). By the convexity of g1, we then
i=0 g1(ei), and order equivalence (Lemma 5.5) implies that g2(ecenter) <

k+1Pk
g2 (Eq. (26)) we have g2(ecenter) = 1
linear on Y = Conv{e0, . . . , ek}. That is, gi(t) = bT
The conclusion of the lemma follows by choosing a = 1, b = b1 − b2, and c = c1 − c2.
Nonlinear case: Suppose that g1(ecenter) 6= 1
have g1(ecenter) < 1
k+1Pk
1

k+1Pk
g1(y) = ag2(y) + bT y + c for y ∈ {e0, e1, . . . , ek, ecenter}.

i=0 g2(ei). Lemma 5.7 guarantees the existence of a > 0, b ∈ Rk, c ∈ R such that

k+1Pk

For shorthand, let h1(y) = g1(y) and h2(y) = ag2(y) + bT y + c, noting that h1(y) = h2(y) for
y ∈ {e0, . . . , ek, ecenter} and that h1 and h2 are order equivalent. We will show that this implies

h1(y) = h2(y) for y ∈ Y = {y ∈ Rk

+ | 1T y ≤ 1} = Conv{e0, e1, . . . , ek, ecenter},

(27)

which of course is equivalent to g1(y) = ag2(y)+bT y+c, yielding our desired result. For j = 1, 2, and
y ∈ Qk
i=0 yiei
and havePk

+ such that 1T y ≤ 1, we use y0 = 1 − 1T y for shorthand. We may thus write y =Pk

i=0 yi = 1, so [y0 y1 ··· yk] ∈ ∆k+1. We deﬁne the linear functions ϕj : R → R as

kXi=0(cid:18)yir −

1 − r

k + 1(cid:19) hj(ei) + (1 − r)hj(ecenter)

ϕj(r) = −rhj(y) +

for j = 1, 2. Then we have

ϕj(0) = hj(ecenter) −

1

k + 1

kXi=0

hj(ei) < 0.

by the non-linearity of g1 and g2. Further, by the convexity of h1 and h2 we have

ϕj(1) = −hj(y) +

kXi=0

yihj(ei) = −hj(y) +

kXi=1

yihj(ei) + (1 − 1T y)hj(e0) ≥ 0.

We claim that the order equivalence of h1 and h2 on Y = {y ∈ Rk

+ | 1T y ≤ 1} implies that

sign(ϕ1(r)) = sign(ϕ2(r)) for r ∈ Q ∩ [0, 1].

(28)

24

To see this, ﬁx any r ∈ Q ∩ (0, 1], and note that y0 = 1 − 1T y ∈ [0, 1] ∩ Q. Consider the expression

kXi=0(cid:18)yir −

1 − r

k + 1(cid:19) hj(ei) + (1 − r)hj(ecenter) ≤ rhj(y).

Dividing both sides by r > 0 and deﬁning αi = r−1(yir− 1−r
we see that

k+1 ) ∈ Q for i = 0, . . . , k and αk+1 = 1−r
r ,

ϕj(r) ≤ 0 if and only if

Moreover, we have 1T α = 1, and

kXi=0

αihj(ei) + αk+1hj(ecenter) ≤ hj(y).

αiei + αk+1ecenter =

kXi=0

kXi=0

yiei −

kXi=0

1 − r
r(k + 1)

ei +

r

1 − r

ecenter = y.

Applying Lemma 5.5 immediately yields that ϕ1(r) ≤ 0 if and only if ϕ2(r) ≤ 0 for all r ∈ (0, 1]∩ Q.
Noting that ϕ1(0) < 0 and ϕ2(0) < 0, we obtain the sign equality (28).
Using the equality (28), the linearity of ϕj then implies sign(ϕ1(r)) = sign(ϕ2(r)) for all r ∈
[0, 1], and, moreover, there exists some r⋆ ∈ (0, 1] such that ϕ1(r⋆) = ϕ2(r⋆) = 0. In particular, we
have

0 = ϕ1(r⋆) − ϕ2(r⋆) = −r⋆h1(y) + r⋆h2(y),

where we have used that h1(ei) = h2(ei) for i = 0, . . . , k and h1(ecenter) = h2(ecenter). As r⋆ > 0
and y ∈ Qk

+ was arbitrary subject to 1T y ≤ 1, we ﬁnd that

h1(y) = h2(y)

for all y ∈ Qk

+ such that 1T y ≤ 1.

The set Y ∩ Q is dense in Y and h1 and h2 are closed, so Lemma 5.6 implies that h1(y) = h2(y)
for y ∈ Y = Conv{e0, . . . , ek} = {y ∈ Rk
+ | 1T y ≤ 1}. That is, expression (27) holds, and the proof
is complete.

5.2.3 Covering sets with simplices

With Lemma 5.9 in hand, we now show that the special case for simplices is suﬃcient to show the
general Lemma 5.4. First, we show that simplices essentially cover convex sets Ω.
Lemma 5.10. Let x, y be arbitrary points in int Ω ⊂ Rk. Then, there exist x0, x1, . . . , xk ∈ Ω
such that x, y ∈ int E, where E = Conv{x0, x1, . . . , xk}. Moreover, for any points x2, . . . , xk
that make x, y, x2, . . . , xk aﬃnely independent (Def. 5.2), there exist x0, x1 ∈ Ω such that x, y ∈
int Conv{x0, x1, . . . , xk}.
Before proving Lemma 5.10, we state a technical lemma about interior points of convex sets.
Lemma 5.11 (Hiriart-Urruty and Lemar´echal [15], Lemma III.2.1.6). Let C ⊂ Rk be a convex set,
a ∈ rel int C and b ∈ cl C. Then for any λ ∈ [0, 1), we have λa + (1 − λ)b ∈ rel int C.

25

z2 = x2

Ω

y

x1

x

x0

Figure 1: The construction in Lemma 5.10.

1

Proof of Lemma 5.10
Take z2, . . . , zk ∈ Ω arbitrarily but in general position, so that the
points x, y, z2, . . . , zk and y, x, z2, . . . , zk are aﬃnely independent (Def. 5.2). Now, deﬁne zcent =
i=2 zi), so that zcent ∈ int Ω (Lemma 5.11), and choose ǫ > 0 small enough that the
points z0 = x + ǫ(x− zcent) and z1 = y + ǫ(y − zcent) are both in Ω. (This is possible as x, y ∈ int Ω;
see Figure 1.) Then we ﬁnd that x = (z0 + ǫzcent)/(1 + ǫ) and y = (z1 + ǫzcent)/(1 + ǫ), so that

k+1 (x + y +Pk

zcent =

1

k + 1  z0

1 + ǫ

+

z1

1 + ǫ

+

2ǫ

1 + ǫ

zcent +

zi! ,

kXi=2

or by rearranging, zcent = λ0(z0 + z1) + λ1Pk

1

λ0 =(cid:18)1 −

2ǫ

(k + 1)(1 + ǫ)(cid:19)−1

i=2 zi, where

(k + 1)(1 + ǫ)

and λ1 =(cid:18)1 −

2ǫ

(k + 1)(1 + ǫ)(cid:19)−1

1

k + 1

.

Noting that 2λ0 + (k − 1)λ1 = 1 and λi > 0, we obtain that zcent ∈ int Conv{z0, . . . , zk}. As the
points zi are in general position, and as

x =

1

1 + ǫ

z0 +

ǫ

1 + ǫ

zcent and y =

1

1 + ǫ

z1 +

ǫ

1 + ǫ

zcent,

we have x, y ∈ int Conv{z0, . . . , zk} by Lemma 5.11.

5.2.4 Extension from a single simplex to all of Ω

We use Lemma 5.10 to show the following lemma, which implies Lemma 5.4.

26

Lemma 5.12. In addition to the conditions of Lemma 5.4, assume that for all simplices E ⊂ int Ω
there exist aE > 0, bE ∈ Rk, and cE ∈ R such that f1(t) = aEf2(t) + bT
Et + cE for t ∈ E. Then
there exist a > 0, b ∈ Rk, and c ∈ R such that

f1(t) = af2(t) + bT t + c for t ∈ Ω.

Coupled with Lemma 5.9, Lemma 5.12 immediately yields Lemma 5.4; indeed, Lemma 5.9 shows
that for any simplex E the conditions of Lemma 5.12 holds, so that Lemma 5.4 follows, i.e.,
f1(t) = af2(t) + bT t + c for all t ∈ Ω.
For i ∈ {1, 2} deﬁne the sets
Proof

Si =(cid:8){(x, y) ∈ int Ω × int Ω | ∇fi(x) 6= ∇fi(y)}

∪ {(x, y) ∈ int Ω × int Ω | ∇fi(x) or ∇fi(y) does not exist}(cid:9) ⊂ Ω × Ω.

We divide our discussion into two cases.

Case 1. First we suppose that S1 = S2 = ∅. Then for i = 1, 2, fi are diﬀerentiable in int Ω in
this case, we have that ∇fi(x) = ∇fi(y) for all x, y ∈ int Ω. Then by continuity of the fi on int Ω,
we must have fi(t) = bT
i t + ci for i = 1, 2. The result follows by taking a = 1, b = b1 − b2 and
c = c1 − c2 and applying Lemma 5.6.
Case 2. We have that at least one of S1 and S2 is non-empty. Without loss of generality, say
S1 6= ∅. Choose a pair (x⋆, y⋆) ∈ S1 and consider the collection of sets

M = {E = Conv{x0, x1, . . . , xk} | x⋆, y⋆ ∈ int E and x0, x1, . . . xk ∈ Ω} .

We show that for any E1, E2 ∈ M, we have aE1 = aE2, bE1 = bE2 and cE1 = cE2. We know that
int E1 ∩ int E2 6= ∅, as x⋆ ∈ int E for all E ∈ M. Now, assume for the sake of contradiction that
aE1 6= aE2. For all t ∈ E1 ∩ E2 we have
f1(t) = aE1f2(t) + bT

E1t + cE1 and f1(t) = aE2f2(t) + bT

E2t + cE2.

(29)

By subtracting the preceding equations from one another after multiplying by aE2 and aE1, respec-
tively, one obtains that for t ∈ E1 ∩ E2,

f1(t) =

1

aE2 − aE1(cid:2)(aE2bE1 − aE1bE2)T t + (aE2cE1 − aE1cE2)(cid:3) .

This yields a contradiction, since we have assumed that either (i) ∇f1(x⋆) or ∇f2(y⋆) does not exist
or (ii) ∇f1(x⋆) 6= ∇f1(y⋆), while x⋆, y⋆ ∈ int E1∩ int E2 = int(E1∩ E2). Thus aE1 = aE2. To obtain
bE1 = bE2, note that int(E1 ∩ E2) 6= ∅, as x⋆, y⋆ ∈ int(E1 ∩ E2). Subtracting the equalities (29),
we ﬁnd 0 = f1(t)− f1(t) = (bE1 − bE2)T t + cE1 − cE2 for t ∈ E1 ∩ E2, which has non-empty interior.
That bE1 = bE2 immediately implies cE1 = cE2. Hence, there exist some a > 0, b ∈ Rk, and c ∈ R
such that for all sets E ∈ M, we have aE = a, bE = b, and cE = c.
We complete the proof by showing thatS{E | E ∈ M} is dense in Ω. Deﬁne Ω◦ ⊂ Ω as
Ω◦ = {t ∈ Ω | there exist z3, . . . , zk such that x⋆, y⋆, t, z3, . . . , zk are aﬃnely independent} .
The set Ω◦ forms a dense subset of Ω, as x⋆ ∈ int Ω 6= ∅. For any t ∈ Ω◦, Lemma 5.10 guarantees
the existence of E ∈ M such that t ∈ E and x⋆, y⋆ ∈ int E. We thus have Ω◦ ⊂S{E | E ∈ M}.
As f1(t) = af2(t) + bT t + c for all t ∈ Ω◦ by the previous paragraph, Lemma 5.6 allows us to extend
the equality to f1(t) = af2(t) + bT t + c for all t ∈ Ω.

27

References

[1] S. M. Ali and S. D. Silvey. A general class of coeﬃcients of divergence of one distribution from

another. Journal of the Royal Statistical Society, Series B, 28:131–142, 1966.

[2] P. L. Bartlett, M. I. Jordan, and J. McAuliﬀe. Convexity, classiﬁcation, and risk bounds.

Journal of the American Statistical Association, 101:138–156, 2006.

[3] Y. Benjamini and Y. Hochberg. Controlling the false discovery rate: a practical and powerful
approach to multiple testing. Journal of the Royal Statistical Society, Series B, 57(1):289–300,
1995.

[4] D. Bertsekas. Nonlinear Programming. Athena Scientiﬁc, 1999.

[5] P. Billingsley. Probability and Measure. Wiley, Second edition, 1986.

[6] D. Blackwell. Comparison of experiments. In Proceedings of the 2nd Berkeley Symposium on

Probability and Statistics, pages 93–102. University of California Press, 1951.

[7] T. M. Cover and J. A. Thomas. Elements of Information Theory, Second Edition. Wiley, 2006.

[8] I. Csisz´ar. Information-type measures of diﬀerence of probability distributions and indirect

observation. Studia Scientiﬁca Mathematica Hungary, 2:299–318, 1967.

[9] M. H. DeGroot. Uncertainty, information, and sequential experiments. Annals of Mathematical

Statistics, 33(2):404–419, 1962.

[10] M. H. DeGroot. Optimal Statistical Decisions. Mcgraw-Hill College, 1970.

[11] J. C. Duchi, L. Mackey, and M. I. Jordan. The asymptotics of ranking algorithms. Annals of

Statistics, 41(5):2292–2323, 2013.

[12] B. Efron. Large-Scale Inference: Empirical Bayes Methods for Estimation, Testing, and Pre-

diction. Insitute of Mathematical Statistics Monographs. Cambridge University Press, 2012.

[13] D. Garc´ıa-Garc´ıa and R. C. Williamson. Divergences and risks for multiclass experiments. In
Proceedings of the Twenty Fifth Annual Conference on Computational Learning Theory, 2012.

[14] L. Gy¨orﬁ and T. Nemetz. f -dissimilarity: A generalization of the aﬃnity of several distribu-

tions. Annals of the Institute of Statistical Mathematics, 30:105–113, 1978.

[15] J. Hiriart-Urruty and C. Lemar´echal. Convex Analysis and Minimization Algorithms I.

Springer, New York, 1993.

[16] J. Hiriart-Urruty and C. Lemar´echal. Convex Analysis and Minimization Algorithms II.

Springer, New York, 1993.

[17] T. Kailath. The divergence and bhattacharyya distance measures in signal selection. IEEE

Transactions on Communication Technology, 15(1):52–60, 1967.

[18] L. Le Cam. Asymptotic Methods in Statistical Decision Theory. Springer-Verlag, 1986.

28

[19] F. Liese and I. Vajda. On divergences and informations in statistics and information theory.

IEEE Transactions on Information Theory, 52(10):4394–4412, 2006.

[20] M. Longo, T. D. Lookabaugh, and R. M. Gray. Quantization for decentralized hypothesis
testing under communication constraints. IEEE Transactions on Information Theory, 36(2):
241–255, 1990.

[21] G. Lugosi and N. Vayatis. On the Bayes-risk consistency of regularized boosting methods.

Annals of Statistics, 32(1):30–55, 2004.

[22] S. Mannor, R. Meir, and T. Zhang. Greedy algorithms for classiﬁcation—consistency, conver-

gence rates and adaptivity. Journal of Machine Learning Research, 4:713–741, 2003.

[23] A. W. Marshall, I. Olkin, and B. C. Arnold. Inequalities: Theory of Majorization and Its

Applications. Springer, second edition, 2011.

[24] X. Nguyen, M. J. Wainwright, and M. I. Jordan. On surrogate loss functions and f -divergences.

Annals of Statistics, 37(2):876–904, 2009.

[25] F. ¨Osterreicher and I. Vajda. Statistical information and discrimination. IEEE Transactions

on Information Theory, 39(3):1036–1039, 1993.

[26] H. V. Poor and J. B. Thomas. Applications of ali-silvey distance measures in the design of
generalized quantizers for binary decision systems. IEEE Transactions on Communications,
25(9):893–900, 1977.

[27] F. Pukelsheim. Optimal Design of Experiments. Classics in Applied Mathematics. SIAM, 1993.

[28] M. Reid and R. Williamson. Information, divergence, and risk for binary experiments. Journal

of Machine Learning Research, 12:731–817, 2011.

[29] H. Robbins. Some aspects of the sequential design of experiments. Bulletin American Mathe-

matical Society, 55:527–535, 1952.

[30] R. E. Schapire and Y. Freund. Boosting: Foundations and Algorithms. MIT Press, 2012.

[31] I. Steinwart. How to compare diﬀerent loss functions. Constructive Approximation, 26:225–287,

2007.

[32] A. Tewari and P. L. Bartlett. On the consistency of multiclass classiﬁcation methods. Journal

of Machine Learning Research, 8:1007–1025, 2007.

[33] N. Tishby, F. Pereira, and W. Bialek. The information bottleneck method.

In The 37’th

Allerton Conference on Communication, Control, and Computing, 1999.

[34] J. N. Tsitsiklis. Decentralized detection.

In Advances in Signal Processing, Vol. 2, pages

297–344. JAI Press, 1993.

[35] I. Vajda. On the f -divergence and singularity of probability measures. Periodica Mathematica

Hungarica, 2(1–4):223–234, 1972.

[36] T. Zhang. Statistical analysis of some multi-category large margin classiﬁcation methods.

Journal of Machine Learning Research, 5:1225–1251, 2004.

29

f (tx1 + (1 − t)x2) ≤ tf (x1) + (1 − t)f (x2) −

λ
2

t(1 − t)kx1 − x2kκ(cid:2)(1 − t)κ−1 + tκ−1(cid:3) .

(30)

A Proofs of classiﬁcation calibration results

In this section, we prove Propositions 4 and 5. Before proving the propositions proper, we state
several technical lemmas and enumerate continuity properties of Fenchel conjugates that will prove
useful. We also collect a few important deﬁnitions related to convexity and norms here, which we
use without comment in this appendix. For a norm k·k on Rk, we recall the deﬁnition of the dual
norm k·k∗ as kyk∗ = supkxk≤1 xT y. For a convex function f : Rk → R, we let
∂f (x) = {g ∈ Rk | f (y) ≥ f (x) + gT (y − x) for all y ∈ Rk}

denote the subgradient set of f at the point x. This set is non-empty if x ∈ rel int dom f (see [15,
Chapter VI]).

A.1 Technical preliminaries

We now give technical preliminaries on convex functions. We recall Deﬁnition 3.2 of uniform
convexity, that f is (λ, κ,k·k)-uniformly convex over C ⊂ Rk if it is closed and for all t ∈ [0, 1] and
x1, x2 ∈ C we have

We state a related deﬁnition of smoothness.
Deﬁnition A.1. A function f is (L, β,k·k)-smooth if it has β-H¨older continuous gradient with
respect to the norm k·k, meaning that

k∇f (x1) − ∇f (x2)k∗ ≤ Lkx1 − x2kβ

for x1, x2 ∈ dom f.

Our ﬁrst technical lemma is an equivalence result for uniform convexity.

Lemma A.1. Let f : Ω → R, where f is closed convex and Ω is a closed convex set. Then f is
(λ, κ,k·k)-uniformly convex over Ω if and only if for x1 ∈ rel int Ω and all y,

f (x2) ≥ f (x1) + sT

1 (x2 − x1) +

λ
2 kx1 − x2kκ for s1 ∈ ∂f (x1).

(31)

If inequality (30) holds, then inequality (31) also holds for any points x1 ∈ Ω and s1 such that
∂f (x1) 6= ∅ and s1 ∈ ∂f (x1).
See Section A.5.1 for a proof of this lemma. There is also a natural duality between uniform
convexity and smoothness of a function’s Fenchel conjugate f ∗(y) = supx{yT x − f (x)}. Such
dualities are frequent in convex analysis (cf. [16, Chapter X.4]).
Lemma A.2. Let Ω ⊂ Rk be a closed convex set and f : Ω → R be (λ, κ,k·k)-uniformly convex
over Ω. Then f ∗ is (λ− 1
See Section A.5.2 for a proof of Lemma A.2. We also have two results on the properties of smooth
functions, whose proofs we provide in Sections A.5.3 and A.5.4, respectively.
Lemma A.3. Let f be (L, β,k·k) smooth. Then

κ−1 ,k·k∗)-smooth (Def. A.1) over dom f ∗ = Rk.

κ−1 ,

1

f (x2) ≤ f (x1) + ∇f (x1)T (x2 − x1) +

L
β + 1 kx1 − x2kβ+1 .

Lemma A.4. Let f be (L, β,k·k) smooth over Rk and inf x f (x) > −∞. If the sequence xn satisﬁes
limn f (xn) = infx f (x), then ∇f (xn) → 0.

30

A.2 Proof of Proposition 4

We state two intermediate lemmas before proving Proposition 4.
Lemma A.5. If U is symmetric, closed and strictly concave, then (−U )∗ is continuously diﬀeren-
tiable over Rk. Moreover, if αi ≥ αj, then p = ∇(−U )∗(α) satisﬁes pi ≥ pj.
Proof As U is strictly concave and (−U )∗(α) = supπ∈∆k{πT α+U (π)} < ∞ for all α (suprema of
closed concave functions over compact sets are attained), we have that (−U )∗ is continuously diﬀer-
entiable by standard results in convex analysis (e.g. Hiriart-Urruty and Lemar´echal [16, Theorem
X.4.1.1]), and ∇(−U )∗(α) = argmaxp∈∆k{pT α + U (p)}.
Now let α satisfy αi ≥ αj. As ∇(−U )∗(α) = argmaxp∈∆k{pT α + U (p)}, let us assume for the
sake of contradiction that pi < pj. Then letting A be the permutation matrix swapping entries i
and j, the vector p′ = Ap satisﬁes U (p′) = U (p) but U ( 1
2 U (p) = U (p) = U (p′),
and

2 (p′ +p)) > 1

2 U (p′)+ 1

αT p − αT p′ = αipi − αipj + αjpj − αjpi = (αi − αj)(pi − pj) ≤ 0.
Thus we have −αT p ≥ −αT p′, and so
αT (p + p′) + U(cid:18) 1
p′(cid:19) > αT p + U (p),

p′(cid:19) ≥ −αT p + U(cid:18) 1

p +

p +

1
2

1
2

1
2

2

2

a contradiction to the assumed optimality of p. We must have pi ≥ pj whenever αi ≥ αj.

Lemma A.6. If U is symmetric and Pk

j . If U is strictly concave, then α⋆

i=1 πiΨi(α⋆) = inf αPk

i ≥ α⋆

i > α⋆
j .

that α⋆

i=1 πiΨi(α), then πi > πj implies

Let π satisfy πi > πj as assumed in the lemma, and suppose that α⋆

Proof
of contradiction. Let A be the permutation matrix that swaps α⋆
(−U )∗(α⋆), and (−U )∗ is also symmetric, and

i and α⋆

i < α⋆

j for the sake
j . Then (−U )∗(Aα⋆) =

kXi=1

πiΨi(Aα⋆) −

kXi=1

πiΨi(α⋆) = −πT Aα⋆ + πT α⋆ = (πi − πj)(α⋆

i − α⋆

j ) < 0,

a contradiction to the optimality of α⋆.

If U is strictly concave, then Lemma A.5 implies that for α⋆ minimizingPk
π = ∇(−U )∗(α⋆). Moreover, by Lemma A.5, if if πi > πj we must have α⋆
If the inﬁmum in the deﬁnition Pk
Proof of Proposition 4
i=1 πiΨi(α) is attained, then
Lemma A.6 gives the result. Otherwise, recall that U (π) = inf α{Pk
i=1 πiΨi(α)} > −∞, and
let πi > πj. Let α(m) be any sequence such thatPk
i=1 πiΨi(α(m)) → U (π).
Using that U is uniformly concave, we have ∇(−U )∗ is H¨older continuous over Rk (recall
Lemma A.2). This implies that that π − ∇(−U )∗(α(m)) → 0 as m → ∞ (recall Lemma A.4), or

i=1 πiΨi(α), we have
i > α⋆
j .

m→∞∇(−U )∗(α(m)) = π.
lim

Now, by Lemma A.5, for any p(m) = ∇(−U )∗(α(m)), we have that α(m)
. Thus, if πi > πj, it must be the case that eventually we have α(m)
p(m)
j

i ≥ α(m)
i > α(m)

j

j

implies p(m)
i ≥
. Moreover, if

31

i − α(m)

lim inf |α(m)
πi > πj, as we have p(m)
sequence tends to the inﬁmum U (π), which implies that

| = 0, then we must have lim inf |p(m)

i − p(m)

j

j → πi − πj. We thus ﬁnd that lim inf m(α(m)

i − α(m)

j

| = 0, which would contradict that
) > 0 if the

i − p(m)

j

inf

α ( kXi=1

πiΨi(α) : αi ≤ αj) > U (π).

The loss (11) is thus classiﬁcation calibrated (Def. 3.1).

A.3 Proof of Proposition 5

Without loss of generality, we assume that πk < maxj πj, so that restricting to αk ≥ maxj αj forces
α to have larger zero-one risk than 1 − maxj πj. We present two lemmas, based on convex duality
that imply the result.
Lemma A.7. Let v ∈ Rk. Then

inf

αk≥maxj αj

vT α =(0

if vk = −Pk−1

−∞ otherwise.

i=1 vi, v\k (cid:22) 0

Proof By introducing Lagrange multipliers β ∈ Rk−1
have Lagrangian

+

for the constraints αk ≥ αj for j 6= k, we

L(α, β) =(cid:18)v +(cid:20) β

−βT 1(cid:21)(cid:19)T

α,

so

α L(α, β) =(0

inf

if vk = βT 1, v\k = −β

−∞ otherwise.

Substuting β = −v\k and noting that β (cid:23) 0 gives the result.

Thus, if we deﬁne the matrix C = 11T − Ik×k with columns cl, we ﬁnd by strong duality that
αk≥maxj αj(cid:8)−πT α + (−UΨzo)∗(α)(cid:9) =

p∈∆k

inf

inf

inf

inf

αk≥maxj αj(−πT α + sup
αk≥maxj αj(cid:26)min

q∈∆k(cid:8)pT α + qT C T p(cid:9))
l p + (p − π)T α(cid:27)
l p : π\k (cid:23) p\k, pk = πk + 1T (π\k − p\k)(cid:27)
: π\k (cid:23) p\k, pk = πk + 1T (π\k − p\k)(cid:27) ,

p∈∆k(cid:26)min
p∈∆k(cid:26)1 − max

cT

cT

pl

l

l

l

= sup
p∈∆k

= sup

= sup

where in the second to ﬁnal line we took v = p − π. The next lemma then immediately implies
Proposition 5 once we note that UΨzo(π) = 1 − maxj πj.
Lemma A.8. Let the function Gk(π) = inf αk≥maxj αj{−πT α + (−UΨzo)∗(α)}. Then

Gk(π) − (1 − max

j

πj) ≥

1
k

(max

j

πj − πk).

32

We essentially construct the optimal p ∈ ∆k vector for the supremum in the deﬁnition
Proof
of Gk. Without loss of generality, we assume that π1 = maxj πj > πk, as the result is trivial if
πk = maxj πk. For t ∈ R, deﬁne

L(t) = πk +

kXj=1

[πj − t]+ and R(t) = t.

By deﬁnining tlow = πk and thigh = π1 we have

L(tlow) ≥ πk + [π1 − πk]+ = π1 > πk = R(tlow) and L(thigh) = πk < π1 = R(thigh),

and the fact that L is strictly decreasing in [tlow, thigh] and R is strictly increasing implies that there
exists a unique root t⋆ ∈ (tlow, thigh) such that L(t⋆) = t⋆ = R(t⋆). Now, we deﬁne the vector p by

pj = min{t⋆, πj} for j ≤ k − 1, pk = t⋆.
j=1 t⋆ ∧ πj = πk +Pk−1
Then we have 1T p = t⋆ +Pk−1
have Gk(π) ≥ 1 − maxl pl = 1 − t⋆.
It remains to show that 1 − t⋆ − (1 − π1) ≥ 1
t⋆ ≤ (1 − 1
t⋆ > (1 − 1
these two constraints, we have that

j=1 ([πj − t⋆]+ + t⋆ ∧ πj) = 1, and moreover, we
k (π1 − πk); equivalently, we must show that
k πk. Suppose for the sake of contradiction that this does not hold, that is, that
k πk. We know that tlow = πk < t⋆ < π1 = thigh by assumption. With t⋆ satisfying

k )π1 + 1
k )π1 + 1

L(t⋆) = πk +

kXj=1

[πj − t⋆]+ ≤ πk +

k−1Xj=1

[π1 − t⋆]+ = πk + (k − 1)(π1 − t⋆)
πk(cid:19) =
k − 1

< πk + (k − 1)(cid:18)π1 −

k − 1

1
k

π1 −

k

π1 +

1
k

πk < t⋆,

k

the two strict inequalities by assumption on t⋆. But then we would have L(t⋆) < R(t⋆) = t⋆, a
contradiction to our choice of t⋆. Because L is decreasing, it must thus be the case that t⋆ ≤
(1 − 1

k πk, giving the result.

k )π1 + 1

A.4 Proof of Observation 1

Our proof is essentially a trivial modiﬁcation of Zhang [36, Theorem 8]. We assume without loss
of generality that φ(·) ≥ 0. Let π ∈ ∆k, and recalling that the cost matrix C = [c1 ··· ck], let

L(π, α) =

πy

kXy=1

kXi=1

cyiφ(−αi) =

kXi=1

πT ci φ(−αi),

noting that πT ci ≥ 0 for each i. Without loss of generality, we may assume that πT c1 > πT c2 =
minl πT cl. If we can show that infα L(π, α) < infα1≥maxj αj L(π, α), then the proof will be complete.
Let α(m) ∈ Rk be any sequence satisfying 1T α(m) = 0 and α(m)
such that L(π, α(m)) →
inf α1≥maxj αj L(π, α).
We ﬁrst show that it is no loss of generality to assume that α(m) converges. Suppose for the sake
1 = ∞,

of contradiction that lim supm(cid:13)(cid:13)α(m)(cid:13)(cid:13) = ∞. Then as 1T α(m) = 0, we must have lim supm α(m)

1 ≥ maxj α(m)

j

33

1

1

so that lim supm φ(−α(m)
) = ∞ because φ′(0) < 0 and φ is convex. As it must be the case
that πT c1φ(−α(m)
) remains bounded (for the convergence of L(π, α(m))), we would then have
that πT c1 = 0, which is a contradiction because πT c1 > minl πT cl ≥ 0. Thus we must have
we assume that α(m) → α⋆. Then L(π, α⋆) = inf α1≥max αj L(π, α) by continuity of φ.
we can always improve the value L(π, α⋆). We consider three cases, noting in each that α⋆
1T α⋆ = 0.

lim supm(cid:13)(cid:13)α(m)(cid:13)(cid:13) < ∞, and so there is a subsequence of α(m) converging; without loss of generality,

2 (or increasing the latter slightly),
1 ≥ 0 as

We show that by swapping the value of α⋆

1 with the value α⋆

1. Let α⋆

1 = α⋆

2 πφ′(−α⋆
cT

2 ≥ 0. Then φ′(−α⋆
2 π < cT

2) < 0 because cT
cT
1 πφ(−α⋆

2) ≤ φ′(0) < 0, and additionally cT

1) = φ′(−α⋆
1 π. For suﬃcently small δ > 0, we thus have
2 πφ(−α⋆
2),

2 − δ) < cT

1 πφ(−α⋆

2 πφ(−α⋆

1) + cT

1 + δ) + cT

1 πφ′(−α⋆

1) −

whence L(π, α⋆) > L(π, α⋆ − δ(e1 − e2)).

2). Then taking α ∈ Rk such that α1 = α⋆

2, α2 = α⋆

1, and

2. Let α⋆
αi = α⋆

3. Let α⋆

1) > φ(−α⋆

2 and φ(−α⋆

1 > α⋆
i for i ≥ 3, it is clear that L(π, α) < L(π, α⋆).
2). Using that −α⋆
1 > α⋆
2) ≥ φ(−α⋆

2 and φ(−α⋆

1) ≤ φ(−α⋆

we have φ(−α⋆
the point −α⋆

1 + δ) < φ(−α⋆
2 as φ′(0) < 0. Thus we have L(π, α⋆ − δ(e1 − e2)) < L(π, α⋆).

1) and φ(−α⋆

1 < 0, we see that for suﬃciently small δ > 0
2 − δ), because φ must be non-decreasing at

A.5 Proofs of technical lemmas on smoothness

A.5.1 Proof of Lemma A.1
Let t ∈ (0, 1) and xt = tx2 + (1 − t)x1. Assume that inequality (31) holds and let x1 ∈ rel int Ω.
Then

t (x2 − xt) +

(1 − t)κ kx1 − x2kκ ,
f (x2) ≥ f (xt) + sT
where st ∈ ∂f (xt), which must exist as xt ∈ rel int Ω (see Lemma 5.11 and [15, Chapter VI]).
Similarly, we have

= f (xt) + (1 − t)sT

t (x2 − x1) +

λ

2(cid:13)(cid:13)xt − x2(cid:13)(cid:13)κ

λ
2

f (x1) ≥ f (xt) + tsT

t (x1 − x2) +

tκ kx1 − x2kκ ,

λ
2

and multiplying the preceding inequalities by t and (1 − t), respectively, we have
λ
2 kx1 − x2kκ [t(1 − t)κ + (1 − t)tκ]
t(1 − t)kx1 − x2kκ(cid:2)(1 − t)κ−1 + tκ−1(cid:3)
λ
2

tf (x2) + (1 − t)f (x1) ≥ f (xt) +
= f (xt) +

We now consider the case that x1 ∈ Ω \ rel int Ω, as the preceding display is equivalent to the
1 ∈ rel int Ω. For a ∈ [0, 1] deﬁne the

for any x1 ∈ rel int Ω.
uniform convexity condition (30). Let x1 ∈ Ω \ rel int Ω and x′
functions h(a) = tf (x2) + (1 − t)f ((1 − a)x1 + ax′
ht(a) = f (tx2 + (1 − t)((1 − a)x1 + ax′

1) and

1)) +

λ
2

t(1 − t)(cid:13)(cid:13)(1 − a)x1 + ax′

1 − x2(cid:13)(cid:13)κ(cid:2)(1 − t)κ−1 + tκ−1(cid:3) .

34

Then h and ht are closed one-dimensional convex functions, which are thus continuous [15, Chapter
I], and we have h(a) ≥ ht(a) for all a ∈ (0, 1) as (1 − a)x1 + ax′
ht(a) = ht(0)

1 ∈ rel int Ω. Thus

tf (x1) + (1 − t)f (x2) = h(0) = lim

a→0

h(a) ≥ lim

a→0

= f (tx2 + (1 − t)x1) +

λ
2

t(1 − t)kx1 − x2kκ(cid:2)(1 − t)κ−1 + tκ−1(cid:3) .

This is equivalent to the uniform convexity condition (30).

We now prove the converse. Assume the uniform convexity condition (30), which is equivalent

to

f (xt) − f (x1)

t

+

λ
2

(1 − t)kx1 − x2kκ [(1 − t)κ−1 + tκ−1] ≤ f (x2) − f (x1)

for all x1, x2 ∈ Ω and t ∈ (0, 1). Let f ′(x, d) = limt↓0
be the directional derivative of
f in direction d, recalling that if ∂f (x) 6= ∅ then f ′(x, d) = supg∈∂f (x) hg, di (see [16, Ch. VI.1]).
Then taking t ↓ 0, we have

t

f (x+td)−f (x)

f ′(x1, x2 − x1) +

λ
2 kx1 − x2kκ ≤ f (x2) − f (x1).

This implies the subgradient condition (31) because f ′(x1, x2 − x1) = supg∈∂f (x1) hg, x2 − x1i.
A.5.2 Proof of Lemma A.2

First, we note that as dom f = Ω and f is uniformly convex,
limkxk→∞ f (x)/kxk = ∞. Thus dom f ∗ = Rk; see [16, Proposition X.1.3.8].
As f is strictly convex by assumption, we have that f ∗ is diﬀerentiable [16, Theorem X.4.1.1].
Moreover, as f is closed convex, f = f ∗∗, and we have for any s ∈ Rk that x1 = ∇f ∗(s) if and
only if s ∈ ∂f (x1), meaning that f is subdiﬀerentiable on the set Im∇f ∗ = {∇f ∗(s) : s ∈ Rk},
whence Ω ⊃ Im∇f ∗. Now, let s1, s2 ∈ Rk and x1 = ∇f ∗(s1) and x2 = ∇f ∗(s2). We must then
have s1 ∈ ∂f (x1) and s2 ∈ ∂f (x2) by standard results in convex analysis [16, Corollary X.1.4.4], so
that ∂f (x1) 6= ∅ and ∂f (x2) 6= ∅.

it is 1-coercive, meaning that

Now we use the uniform convexity condition (31) of Lemma A.1 to see that

f (x2) − f (x1) ≥ hs1, x2 − x1i +
Adding these equations, we ﬁnd that

λ
2 kx1 − x2kκ and f (x1) − f (x2) ≥ hs2, x1 − x2i +

λ
2 kx1 − x2kκ .

hs1 − s2, x1 − x2i ≥ λkx1 − x2kκ ,

so

ks1 − s2k∗ kx1 − x2k ≥ λkx1 − x2kκ

by H¨older’s inequality. Dividing each side by kx1 − x2k = k∇f ∗(s1) − ∇f ∗(s2)k, we obtain kx1 − x2k ≤
λ− 1

, the desired result.

1

κ−1 ks1 − s2k

κ−1
∗

35

= f (x1) + h∇f (x1), x2 − x1i +Z 1
≤ f (x1) + h∇f (x1), x2 − x1i +Z 1
≤ f (x1) + h∇f (x1), x2 − x1i +Z 1

0

Ltβ kx1 − x2kβ+1 dt.

0 tβdt = 1

β+1 gives the result.

0 h∇f (x1 + t(x2 − x1)) − ∇f (x1), x2 − x1i dt

0 k∇f (x1 + t(x2 − x1)) − ∇f (x1)k∗ kx1 − x2k dt

A.5.3 Proof of Lemma A.3

Using Taylor’s theorem, we have

f (x2) = f (x1) +Z 1

0 h∇f (tx2 + (1 − t)x1), x2 − x1i dt

Computing the ﬁnal integral asR 1

A.5.4 Proof of Lemma A.4

Let gn = ∇f (xn) and suppose for the sake of contradiction that gn 6→ 0. Then there is a subse-
quence, which without loss of generality we take to be the full sequence, such that kgnk∗ ≥ c > 0
for all n. Fix δ > 0, which we will choose later. By Lemma A.3, deﬁning yn = xn − δgn/kgnk∗, we
have

f (yn) ≤ f (xn) − δ kgnk +

In particular, we see that if

L

β + 1

Lδβ+1 ≤ f (xn) − δ(cid:18)c −

L

β + 1

δβ(cid:19) .

δ ≤(cid:18) c

2 ·

β + 1

L (cid:19)1/β

,

then f (yn) ≤ f (xn) −

δc
2

for all n, which contradicts the fact that f (xn) → infx f (x) > −∞.

B Proofs for order equivalent and convex functions

In this appendix, we collect the proofs of our various technical results on order equivalent functions
(Deﬁnition 5.1).

B.1 Proof of Lemma 5.2
One direction of the proof is easy: if Z ∈ Rm×m
bT 1.

+

and Z1 = a while Z T 1 = b, then 1T Z1 = 1T a =

We prove the converse using induction. When m = 1, the result is immediate. We claim that
it is no loss of generality to assume that a1 ≥ a2 ≥ ··· ≥ am and b1 ≥ ··· ≥ bm; indeed, let Pa and
Pb be permutation matrices such that Paa and Pbb are in sorted (decreasing) order. Then if we

and Z1 = P T

construct eZ ∈ Rm×m
a eZ1 = P T
we argue that the result holds for a, b ∈ Rm

such that eZ1 = Paa and eZ T 1 = Pbb, we have Z = P T

a Paa = a and Z T 1 = P T

Now, suppose that the statement of the lemma is true for all vectors of dimension up to m − 1;
+ . It is no loss of generality to assume that am ≤ bm.

a eZPb satisﬁes Z ∈ Rm×m

+

b eZ1 = b.

+

36

Let zm,m = am, zi,m = 0 for 2 ≤ i ≤ m − 1, and set z1,m = bm − am ≥ 0. Additionally, we set
zm,i = 0 for 1 ≤ i ≤ m − 1. Now, let Zinner ∈ Rm−1×m−1
be the matrix deﬁned by the upper
(m − 1) × (m − 1) sub-matrix of Z, and deﬁne the vectors

+

ainner = [a1 + am − bm a2 a3 ··· am−1]T and binner = [b1 b2 ··· bm−1]T .

Then as a1 ≥ (1/m)1T a = (1/m)1T b ≥ bm, we have ainner ≥ 0 and binner ≥ 0, and moreover,
1T ainner = 1T a − bm = 1T b − bm = 1T binner. In particular, we have by the inductive hypothesis
inner1 = binner. By inspection, setting
that we may choose Zinner such that Zinner1 = ainner and Z T

Z =

 Zinner 



bm − am

0
...
0
am

,



0 ···
and Z1 = a and Z T 1 = b.

0

+

we have Z ∈ Rm×m
B.2 Proof of Lemma 5.5
For each i, let λi = [αi]+ and νi = [αi]− be the positive and negative parts of the αi, and let λi = ri
s
and −νi = qi

s where qi, ri, s ∈ N. Then we have

mXi=1

λixi = y −

A = [x1 ··· x1

mXi=1
and 1T r = s + 1T q as 1T (r − q)/s =Pm
}

{z
we have A1 = B1 and A, B ∈ Rk×1T r
mXi=1

rif1(xi) ≤ sf1(y) +

··· xm ··· xm

mXi=1

{z

rm times

r1 times

|

}

|

+

] and B = [y ··· y

x1 ··· x1

q1 times

··· xm ··· xm

],

qm times

|

{z

}

{z

}

. Thus, the deﬁnition (24) of order equivalence implies that

qif1(xi) iﬀ

rif2(xi) ≤ sf2(y) +

qif2(xi).

νixi or

mXi=1

rixi = sy +

qixi,

mXi=1

i=1 αi = 1. Deﬁning the matrices

s times

| {z }
mXi=1

|
mXi=1

By algebraic manipulations, each of these is equivalent toPm

B.3 Proof of Lemma 5.7

i=1 αifj(xi) ≤ fj(y) for j = 1, 2.

We assume that f1 and f2 are non-linear over Conv{x0, . . . , xk}, as otherwise the result is trivial.
Let the vectors g1 and g2 and matrix X ∈ Rk×k be deﬁned by

X =

1 − xT
xT

0

...

k − xT
xT

0

 , g1 =

f1(x1) − f1(x0)

...

f1(xk) − f1(x0)

 , g2 =

f2(x1) − f2(x0)

...

f2(xk) − f2(x0)

 .

37

For any a > 0, deﬁne the vector b(a) ∈ Rk so that

b(a)T (xi − x0) = f1(xi) − f1(x0) − a(f2(xi) − f2(x0)) = g1,i − ag2,i,

that is, as b(a) = X −1(g1 − ag2), which is possible as X is full rank. By choosing c(a) = f1(x0) −
af2(x0) − b(a)T x0, we then obtain that

f1(xi) = af2(xi) + b(a)T xi + c(a)

by algebraic manipulations. We now consider xcent. We have

b(a)T xcent =

1

k + 1

kXi=0

so that

b(a)T xi = b(a)T x0 +

1

k + 1

1T Xb(a) = b(a)T x0 +

1

k + 1

1T (g1 − ag2),

af2(xcent) + b(a)T xcent + c(a)

= af2(xcent) +

= af2(xcent) +

1

k + 1

1

k + 1

kXi=1
kXi=0

[f1(xi) − f1(x0) + af2(x0) − af2(xi)] + f1(x0) − af2(x0)

f1(xi) − a

1

k + 1

f2(xi).

kXi=0

Thus we may choose an a > 0 such that our desired equalities hold if and only if there exists a > 0
such that

By the assumption that f1 and f2 are non-linear, we have that (by Lemma 5.8) f1(xcent) <

i=0 f1(xi) and f2(xcent) < 1

i=0 f2(xi). Thus, setting

1

k+1Pk

f1(xcent) −

k + 1

f1(xi) = af2(xcent) − a

1

k + 1

kXi=0

f2(xi).

1

kXi=0
k+1Pk
f1(xcent) − 1
f2(xcent) − 1

a =

i=0 f1(xi)
i=0 f2(xi)

> 0

k+1Pk
k+1Pk

gives the desired result.

B.4 Proof of Lemma 5.8

Without loss of generality, we assume that λ1 = kλk∞ and that λ1 > 1/m. Then we have

f  mXi=1

λixi! ≤

λif (xi) = λ1

mXi=1

mXi=1

f (xi) +

(λi − λ1)f (xi)

(32)

= mλ1f (xcent) +

(λ1 − λi)f (xi).

Let Λ =Pm

xcent =

i=1(λ1 − λi) = mλ1 − 1 > 0. Then

1

mλ1

mXi=1

λixi +

1

mλ1

mXi=1

(λ1 − λi)xi =

1

mλ1

38

λixi +

Λ

mλ1

mXi=1

λ1 − λi

Λ

xi,

mXi=1
mXi=2
mXi=1

and we have

mλ1f (xcent) ≤ nλ1" 1
≤ f  mXi=1

f  mXi=1
λixi! + Λ

mλ1

λixi! +
mXi=2

Λ

λ1 − λi

f (xi).

Λ

mλ1

f  mXi=2

λ1 − λi

Λ

xi!#

In particular, the inequalities (32) must have been equalities, giving the result.

C Proof of Theorem 3

The proof of Theorem 3 is almost immediate from the following (somewhat technical) lemma, which
exhibits the power of calibration and universal equivalence. The lemma may be of independent
interest, especially the quantitative guarantee of its second statement.

Lemma C.1. Suppose that Ψ is classiﬁcation-calibrated and universally equivalent to the weighted
misclassiﬁcation loss Ψcw with cost matrix C = [c1 ··· ck] ∈ Rk×k
+ . There exists a continuous
concave function h : R+ → [0, maxij cij] with h(0) = 0 such that
R(γ | q) ≤ h(cid:18)RΨ(γ | q) − inf

R(γ | q) − inf

Ψ(q)(cid:19) .

γ∈Γ,q∈Q

R⋆

q∈Q

With the choice Ψy(α) = Pk

identity function h(ǫ) = (1 + 1

R(γ | q) − inf

γ∈Γ,q∈Q

i=1 cyi [1 + αi]+, then we may take h to be the truncated and scaled
k ) min{ǫ, maxij cij}, that is,

R(γ | q) ≤(cid:18)1 +

1

k(cid:19)(cid:20)RΨ(γ | q) − inf

γ∈Γ,q∈Q

RΨ(γ | q)(cid:21) .

We postpone the proof of Lemma C.1 to the end of this section, proceeding with the proof of

the theorem. By Lemma C.1, we ahve

R(γn | qn) − R⋆(Q) ≤ h (RΨ(γn | qn) − R⋆

Ψ(Q))

for some h concave, bounded, and satisfying h(0) = 0. It is thus suﬃcient to show that E[RΨ(γn |
qn) − R⋆
n minimize RΨ(γ | q) over the set Γn × Qn (or be
arbitrarily close to minimizing the Ψ-risk), we have

Ψ(Q)] → 0. Now, if we let γ⋆

n and q⋆

RΨ(γn | qn) − RΨ(γ⋆

n | q⋆

n) = RΨ(γn | qn) − bRΨ,n(γn | qn) + bRΨ,n(γn | qn) − RΨ(γ⋆
n | q⋆
n)
≤ RΨ(γn | qn) − bRΨ,n(γn | qn) + bRΨ,n(γ⋆
n | q⋆
n) − RΨ(γ⋆
n | q⋆
n)
|
≤2 supγ∈Γn,q∈Qn | bRΨ,n(γ|q)−RΨ(γ|q)|
γ∈Γn,q∈Qn bRΨ,n(γ | q).
n | q⋆
n | q⋆

+ bRΨ,n(γn | qn) −

Ψ(Q)] ≤ E [RΨ(γn | qn) − RΨ(γ⋆

n)] + RΨ(γ⋆

n) − R⋆

{z

Ψ(Q)

}

inf

Consequently, we have the expectation bound

E [RΨ(γn | qn) − R⋆

≤ 2ǫest

n + ǫopt

n + ǫapp
n ,

39

which converges to zero as desired.
Proof of Lemma C.1 With the deﬁnition R⋆(q) := infγ R(γ | q), we have

R(γ | q) − inf

γ∈Γ,q∈Q

R(γ | q) = R(γ | q) − R⋆(q) + R⋆(q) − inf

q∈Q

R⋆(q).

(33)

For the second two terms, we note that by Theorem 1, we have

and similarly for inf q R⋆(q), so that

R⋆(q) = E[UΨcw(eπ(q(X)))] = aE[UΨ(eπ(q(X)))] + bT π + c,
Ψ(q)(cid:21) ≤ a(cid:20)RΨ(γ | q) − inf
R⋆(q) = a(cid:20)R∗

Ψ(q) − inf

γ∈Γ,q∈Q

R∗

q∈Q

R⋆(q) − inf

q∈Q

Clearly t 7→ at is concave, so that it remains to bound R(γ | q) − R⋆(q) in expression (33). To that
end, deﬁne the function

RΨ(γ | q)(cid:21) .
πyΨcw(α′) ≥ ǫ

H(ǫ) = inf

π∈∆k,α

kXy=1

πyΨy(α) − inf

α′

kXy=1

πyΨy(α′) |

kXy=1

πyΨcw

y (α) − inf

α′

kXy=1

and let H ∗∗ be its Fenchel biconjugate. Then (see Zhang [36, Proposition 25 and Corollary 26],
as well as the papers [32, 31, 11, Proposition 1]) we have that H ∗∗(ǫ) > 0 for all ǫ > 0, and
deﬁning h(ǫ) = sup{δ : δ ≥ 0, H ∗∗(δ) ≤ ǫ} yields the desired concave function except that h may be
unbounded. Noting that the loss Ψ is bounded, we may replace t 7→ h(t)+at by min{maxij cij, h(t)+
at} with no loss of generality gives the ﬁrst result of the lemma.
Now we give the second result. Without loss of generality, we may assume that the vector
γ(z) ∈ Rk has a unique maximal coordinate; we may otherwise assume a deterministic rule for
breaking ties. Let y(γ(z)) = argmaxj γj(z), assumed w.l.o.g. to be unique. Consider that

¯p(z)(cid:20)cT

l eπ(z)(cid:21) ,
y(γ(z))eπ(z) − min
where ¯p(z) = Pk
second part of the lemma, it is suﬃcient to argue that for Ψy(α) =Pk
πT cl ≥(cid:20)cT

R(γ | q) − R⋆(q) =Xz
i=1 πiPi(q−1(z)) and eπ(z) = [πiPi(q−1(z))]k

πyΨy(α) − k min

πyΨy(α) − inf

πyΨy(α′) =Xy

α′ Xy

Xy

cT

l

l

i=1/¯p(z) are shorthand. To show the

i=1 cyi [1 + αi]+, we have

y(α)π − min

l

πT cl(cid:21)

(34)

for any vector π ∈ ∆k.
that cT

1 π = cT

To show inequality (34), assume without loss of generality that there exists an index l⋆ < k such
1 π for l > l⋆. (If l⋆ = k, then inequality (34)
l π; let us suppose that αl ≥ maxj αj for some

2 π = ··· = cT

l⋆ π = minl cT

l π, while cT

l π > cT

l > l⋆; without loss of generality take l = k. Then we have

is trivial.) We always have Py πyΨy(α) ≥ k minl cT
kXy=1

πyΨy(α) ≥

cyj [1 + αj]+ =

αk≥maxj αj ,1T α=0

kXj=1

kXy=1

inf

πy

40

inf

αk≥maxj αj ,1T α=0

kXl=1

cT
l π [1 + αl]+ . (35)

Writing out the Lagrangian for this problem and introducing variables λ ≥ 0 for the inequality
αk ≥ maxj αj and θ ∈ R for the equality 1T α = 0, we have

L(α, λ, θ) =

πT cl [1 + αl]+ + θ1T α + λ(cid:18)max
l⋆+1 , and αl = −1 for l > l⋆, l 6= k. We claim that these are
Set α⋆
optimal. Indeed, set θ⋆ = −(1 − ǫ)πT c1 − ǫπT ck for some ǫ ∈ (0, 1), whose value we specify later.
Taking subgradients of the Lagrangian with respect to α, we have

αj − αk(cid:19) .

l⋆+1 , αk = k−l⋆−1

1 = ··· = α⋆

l⋆ = k−l⋆−1

kXl=1

j

∂αL(α⋆, λ, θ⋆) = diag(ν)

cT
1
...
cT
k

 π + θ⋆1 + λ [Conv{e1, . . . , el⋆, ek} − ek] ,

where νi ∈ [0, 1] are arbitrary scalars satisfying νi ∈ ∂ [1 + α⋆
i ]+, i.e. ν1 = ··· = νl⋆ = νk = 1,
νl ∈ [0, 1] for l ∈ {l⋆ +1, . . . , k−1}. Notably, we have πT cl +θ⋆ = ǫπT (c1−ck) ≤ 0 for l ∈ {1, . . . , l⋆}
and πT ck + θ⋆ = (1 − ǫ)πT (ck − c1) ≥ 0. Choosing ǫ small enough that ǫπT ck + (1 − ǫ)πT c1 < πT cl
for l ∈ {l⋆ + 1, . . . , k − 1}, it is clear that we may take νl = (1−ǫ)πT c1+ǫπT ck
∈ [0, 1] for each
l 6∈ {1, . . . , l⋆, k}, and we show how to choose λ⋆ ≥ 0 so that 0 ∈ ∂αL(α⋆, λ, θ⋆). Assume without
loss of generality (by scaling of λ ≥ 0) that πT (ck − c1) = 1. Eliminating extraneous indices in ∂αL,
we see that we seek a setting of λ and a vector v ∈ ∆l⋆+1 such that
el⋆+1 − ǫ1l⋆+1 + λ(v − el⋆+1) = 0.
l⋆ǫ+(1−ǫ) [ǫ ··· ǫ (1 − ǫ)]T ∈ ∆l⋆+1, and set λ⋆ = l⋆ǫ + (1 − ǫ) ≥ 0.
Summarizing, we ﬁnd that our preceding choices of α⋆ were optimal for the problem (35), that
1 = ··· = αl⋆ = k−l⋆−1

l⋆+1 = αk, with αl = −1 for l⋆ < l < k. We thus have

This is straightforward: take v =

is, α⋆

πT cl

1

kXy=1

πyΨy(α) ≥

l⋆Xl=1

= min

l

πT cl(cid:18)1 +
πT cl(cid:18)l⋆ +

l⋆ + 1 (cid:19) + πT ck(cid:18)1 +
k − l⋆ − 1
(k − l⋆ − 1)(cid:19) +

l⋆ + 1

l⋆

l⋆ + 1 (cid:19)
k − l⋆ − 1

k

l⋆ + 1

cT
k π.

In particular, we have

kXy=1

πyΨy(α) − k min

l

πT cl ≥ min
k

l

=

πT cl(cid:18)l⋆ +
l⋆ + 1(cid:20)cT

k π − min

l

cT

l⋆

l⋆ + 1

(k − l⋆ − 1)(cid:19) +
l π(cid:21) .

k

l⋆ + 1

cT
k π − k min

l

cT
l π

Recalling that we must have had l⋆ < k, we obtain inequality (34).

D Proofs of basic properties of f -divergences

In this section, we collect the proofs of the characterizations of generalized f -divergences (Def. 2.1).

41

D.1 Proof of Lemma 2.1

Let µ1 and µ2 be dominating measures; then µ = µ1 + µ2 also dominates P1, . . . , Pk as well as µ1
and µ2. We have for ν = µ1 or ν = µ2 that

dPi/dν
dPk/dν

=

dPi/dν
dPk/dν

dν/dµ
dν/dµ

=

dPi/dµ
dPk/dµ

and

dPi
dν

dν
dµ

=

dPi
dµ

,

the latter two equalities holding µ-almost surely by deﬁnition of the Radon-Nikodym derivative.
Thus we obtain for ν = µ1 or ν = µ2 that

Z f(cid:18) dP1/dν

dPk/dν

, . . . ,

dPk−1/dν

dPk/dν (cid:19) dPk

dν

dν =Z f(cid:18) dP1/dν
=Z f(cid:18) dP1/dµ

dPk/dµ

dPk/dν

, . . . ,

, . . . ,

dPk−1/dν

dPk/dν (cid:19) dPk
dPk/dµ (cid:19) dPk

dPk−1/dµ

dµ

dν

dµ

dν
dµ

dµ

by deﬁnition of the Radon-Nikodym derivative. Moreover, we see that pi
pk
shows that the base measure µ does not aﬀect the integral.

= dPi/dµ

dPk/dµ a.s.-µ, which

To see the positivity, we may take µ = 1

i=1 Pi, in which case Jensen’s inequality implies (via

the joint-convexity of the perspective function (7)) that

kPk
Df (P1, . . . , Pk−1||Pk) = E(cid:20)f(cid:18) dP1
≥ f(cid:18) E[dP1]

E[dPk]

dPk

(X), . . . ,

dPk−1
dPk
E[dPk−1]

, . . . ,

(X)(cid:19) dPk(X)(cid:21)

E[dPk] (cid:19) E[dPk] = f (1) = 0,

where the expectation is taken under the distribution µ. Moreover, the inequality is strict for f
strictly convex at 1 as long as dPi/dPk is non-constant for some i, meaning that there exists an i
such that Pi 6= Pk.

D.2 Proof of Proposition 1

Before proving the proposition, we ﬁrst establish a more general continuity result for multi-way
f -divergences. This result is a fairly direct generalization of results of Vajda [35, Theorem 5]. Given
a sub-σ-algebra G ⊂ F, we let P G denote the restriction of the measure P , deﬁned on F, to G.
Lemma D.1. Let F1 ⊂ F2 ⊂ . . . be a sequence of sub-σ-algebras of F and let F∞ = σ(∪n≥1Fn).
Then

Df(cid:16)P F1

1 , . . . , P F1

and moreover,

k (cid:17) ≤ Df(cid:16)P F2
k−1||P F1
Df(cid:16)P Fn

, . . . , P Fn

1

lim
n→∞

1 , . . . , P F2

k−1||P F2
k (cid:17) = Df(cid:16)P F∞

k (cid:17) ≤ ··· ≤ Df(cid:16)P F∞
k (cid:17) .
k−1||P F∞

1

1

k−1||P Fn
i=1 Pi and vectors V n via the Radon-Nikodym derivatives

, . . . , P F∞

, . . . , P F∞

k (cid:17) ,
k−1||P F∞

Proof Deﬁne the measure ν = 1

kPk
k ·  dP Fn

dνFn

1

1

V n =

2

dP Fn
dνFn

,

, . . . ,

dP Fn
k−1

dνFn ! .

42

Then (1 − 1T V n)dνFn = 1
k , and V n is a martingale adapted to the ﬁltration Fn by standard
properties of conditional expectation (under the measure ν). Letting the set Ck = {v ∈ Rk−1
|
1T v ≤ 1}, we deﬁne g : Ck → R by

k dP Fn

+

g(v) = f(cid:18)

We see that g is convex (it is a perspective function), and we have

, . . . ,

Eν[g(V n)] =Z f  dP Fn
k (cid:17) .
k−1||P Fn
Because V n ∈ Ck for all n, we see that g(V n) is a submartingale. This gives the ﬁrst result of the
lemma, that is, that the sequence Df(cid:16)P Fn

Now, assume that the limit in the second statement is ﬁnite, as otherwise the result is trivial.

k ! 1 −

Df(cid:16)P Fn

dP Fn
k−1
dP Fn

, . . . , P Fn

, . . . , P Fn

dP Fn

1
k

k

v

1 − 1T v(cid:19) (1 − 1T v).
dνFn! dν =
k (cid:17) is non-decreasing in n.

k−1Xi=1
k−1||P Fn

dP Fn

1
k

1

1

1

i

Using that f (1) = 0, we have by convexity that for any v ∈ Ck,

g(v) = f(cid:18)

v

1 − 1T v(cid:19) (1 − 1T v) + f (1)1T v ≥ f(cid:0)v + 1(1T v)(cid:1) ≥ inf

v∈Ck

f (v + 1(1T v)) > −∞,

sup

the ﬁnal inequality a consequence of the fact that f is closed and hence attains its inﬁmum. In
particular, the sequence g(V n) − inf v∈Ck g(v) is a non-negative submartingale, and thus

g(v)|(cid:21) = lim

Eν(cid:20)|g(V n) − inf

Eν(cid:20)g(V n) − inf
Coupled with this integrability guarantee, Doob’s second martingale convergence theorem [5, Thm. 35.5]
thus yields the existence of a random vector V ∞ ∈ F∞ such that
g(v)(cid:21) = Eν[g(V ∞)] − inf

Eν(cid:20)g(V n) − inf

g(v)(cid:21) < ∞.

g(v) < ∞.

0 ≤ lim

v∈Ck

v∈Ck

v∈Ck

v∈Ck

n

n

n

Because infv∈Ck g(v) > −∞, we have Eν[|g(V ∞)|] < ∞, giving the lemma.

We now give the proof of Proposition 1 proper. Let the the base measure µ = 1

i=1 Pi and
dµ be the associated densities of the Pi. Deﬁne the increasing sequence of partitions P n

let pi = dPi
of X by sets Aαn for vectors α = (α1, . . . , αk−1) and B with

kPk

Aαn =(cid:26)x ∈ X |

αj − 1

2n ≤

pj(x)
pk(x)

<

αj

2n for j = 1, . . . , k − 1(cid:27)

where we let each αj range over {−n2n,−n2n + 1, . . . , n2n}, and deﬁne and B = (∪αAαn)c =
X \ ∪αAαn. Then we have

(cid:18) p1(x)

pk(x)

, . . . ,

pk−1(x)

pk(x) (cid:19) = lim

n→∞

Xα∈{−n2n,...,n2n}k−1

α
2n χAαn(x) + (n, . . . , n)χB(x),

43

where χA denotes the {0, 1}-valued characteristic function of the set A. Each term on the right-
hand-side of the previous display is Fn-measurable, where Fn denotes the sub-σ-ﬁeld generated by
the partition P n. Deﬁning F∞ = σ(∪n≥1Fn), we have
, . . . , P Fn

Df (P1, . . . , Pk−1||Pk | P n) = Df(cid:16)P Fn
Df(cid:16)P F∞

−→n↑∞

1

1

k (cid:17)
k−1||P Fn
k (cid:17) = Df (P1, . . . , Pk−1||Pk) ,
k−1||P F∞

, . . . , P F∞

where the limiting operation follows by Lemma D.1 and the ﬁnal equality because of the measura-
bility containment ( p1
pk

, . . . , pk−1
pk

) ∈ F∞.

D.3 Proof of Proposition 2

Before proving the proposition, we state an inequality that generalizes the classical log-sum in-
equality (cf. [7, Theorem 2.7.1]).

Lemma D.2. Let f : Rk
nonnegative measurable functions. Then for any ﬁnite measure µ deﬁned on X , we have

+ → R be convex. Let a : X → R+ and bi : X → R+ for 1 ≤ i ≤ k be

(cid:18)Z adµ(cid:19) f(cid:18)R b1dµ
R adµ

, . . . ,R bkdµ

R adµ(cid:19) ≤Z a(x)f(cid:18) b1(x)

a(x)

, . . . ,

bk(x)

a(x)(cid:19) dµ(x).

Proof Recall that the perspective function g(y, t) deﬁned by g(y, t) = tf (y/t) for t > 0 is jointly
convex in y and t. The measure ν = µ/µ(X ) deﬁnes a probability measure, so that for X ∼ ν,
Jensen’s inequality implies

(cid:18)Z adν(cid:19) f(cid:18)R b1dν
R adν

, . . . ,R bkdν

R adν(cid:19) ≤ Eν(cid:20)a(X)f(cid:18)b1(X)
µ(X )Z a(x)f(cid:18) b1(x)

a(X)

a(x)

=

1

, . . . ,

bk(X)

a(X)(cid:19)(cid:21)
a(x)(cid:19) dµ(x).

bk(x)

, . . . ,

Noting thatR bidν/R adν =R bidµ/R adµ gives the result.

We use this lemma and Proposition 1 to give Proposition 2. Indeed Proposition 1 implies

Df(cid:0)QP1, . . . , QPk−1||QPk(cid:1) = sup(cid:8)Df(cid:0)QP1, . . . , QPk−1||QPk | q(cid:1) : q is a quantizer of Z(cid:9) .

It is consequently no loss of generality to assume that Z is ﬁnite and Z = {1, 2, . . . , m}. Let
i=1 Pi be a dominating measure and let pi = dPi/dµ. Letting q(j | x) = Q({j} | x) and
qPi(j) = QPi({j}), we obtain

µ = Pk

=

, . . . ,

qPk (i)

mXi=1

Df(cid:0)QP1, . . . , QPk−1||QPk(cid:1) =
mXi=1(cid:18)ZX
mXi=1ZX

qPk (i)f(cid:18) qP1(i)
q(i | x)pk(x)dµ(x)(cid:19) f(cid:18)RX q(i | x)p1(x)dµ(x)
RX q(i | x)pk(x)dµ(x)
q(i | x)f(cid:18) p1(x)
pk(x) (cid:19) pk(x)dµ(x)
by Lemma D.2. Noting thatPm

pk−1(x)

pk(x)

, . . . ,

≤

44

i=1 q(i | x) = 1, we obtain our desired result.

qPk−1(i)

qPk (i) (cid:19)
, . . . ,RX q(i | x)pk−1(x)dµ(x)
RX q(i | x)pk(x)dµ(x) (cid:19)

