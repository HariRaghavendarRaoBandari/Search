6
1
0
2

 
r
a

 

M
1
1

 
 
]

G
L
.
s
c
[
 
 

1
v
7
2
6
3
0

.

3
0
6
1
:
v
i
X
r
a

Learning from Imbalanced Multiclass Sequential

Data Streams Using Dynamically Weighted

Conditional Random Fields

Roberto L. Shinmoto Torres∗1, Damith C. Ranasinghe1, Qinfeng

Shi2, and Anton van den Hengel2

1Auto-ID Lab, The School of Computer Science,The University of

Adelaide, Adelaide, SA 5005, Australia

2The Australian Centre for Visual Technologies (ACVT), The

School of Computer Science, The University of Adelaide, Adelaide,

SA 5005, Australia

March 14, 2016

Abstract

The present study introduces a method for improving the classiﬁcation
performance of imbalanced multiclass data streams from wireless body
worn sensors. Data imbalance is an inherent problem in activity recog-
nition caused by the irregular time distribution of activities, which are
sequential and dependent on previous movements. We use conditional
random ﬁelds (CRF), a graphical model for structured classiﬁcation, to
take advantage of dependencies between activities in a sequence. However,
CRFs do not consider the negative eﬀects of class imbalance during train-
ing. We propose a class-wise dynamically weighted CRF (dWCRF) where
weights are automatically determined during training by maximizing the
expected overall F-score. Our results based on three case studies from a
healthcare application using a batteryless body worn sensor, demonstrate
that our method, in general, improves overall and minority class F-score
when compared to other CRF based classiﬁers and achieves similar or
better overall and class-wise performance when compared to SVM based
classiﬁers under conditions of limited training data. We also conﬁrm the
performance of our approach using an additional battery powered body
worn sensor dataset, achieving similar results in cases of high class imbal-
ance.

1

Introduction

Developments in emerging wireless sensor technologies is enabling a multitude of
applications, particularly in healthcare practice for applications such as location

∗Corresponding author

1

tracking, medical monitoring of patients and recognition of performed activities.
The recognition of activities in older people is of particular interest as a means of
preventing injuries from events such as falls by providing an early intervention,
or identiﬁcation of function decline, as in those with Alzheimer’s or Parkinson’s
disease, to enact preventive interventions.

One of the main challenges in human activity recognition is the fact that
sensor data is usually imbalanced as data from all possible activities are not
necessarily equally distributed. This is because people naturally perform some
activities that are of longer duration than others. For instance, in the context of
patient monitoring in hospitals or nursing homes, resting activities such as lying
on bed (i.e. sleeping) or sitting on a chair or on the bed are of longer duration
than ambulating activities, where destinations, for example a rest room, are
very close. Furthermore, data is more easily collected for certain activities
than others; for instance, data from activities performed closer to the sensing
infrastructure (e.g. motion sensors on ceilings) can be more easily collected than
those activities performed farther from the sensors.

This paper presents a novel method for learning from imbalanced data us-
ing conditional random ﬁelds. We propose a class-wise cost parameter based
classiﬁer, that is able to consider the dependencies between activities. The clas-
siﬁer considers the inﬂuence of individual classes for learning from sequential
imbalanced multiclass datasets. The cost parameters (weights) are not ﬁxed
as they are dynamically adjusted during the training process; while the clas-
siﬁer seeks to optimize the model’s expected overall F -score to minimize both
false positives (false alarms) and false negatives (missed classiﬁcations). The
performance of our approach is evaluated in three case studies in the context
of recognizing activities of older people instrumented with a single body worn
batteryless sensor. The results are validated with an external dataset where
levels of imbalance were incremented.

1.1 Scope and Background

Imbalanced data can negatively aﬀect the training of machine learning algo-
rithms as the classiﬁer can be biased to prefer the majority class [1, 2]. This
can be a serious problem as minority classes are of great importance in applica-
tions such as human activity monitoring. For example, older people previously
assessed as being at risk of falling performing a short duration ambulation—as
opposed to large amounts of time spent in resting postures such as lying in
bed—are potentially at a risk of falling and injury [3]. Hence it is important to
increase the overall classiﬁcation performance and, in particular, the classiﬁer
performance in identifying minority classes such as ambulation in our example.
Another challenge arising from the nature of human activity recognition
problems is the diﬃculty of collecting and labelling large datasets from activ-
ities of daily living (ADL). This is indeed the case for applications such as
monitoring patients in acute hospitals where collecting data to learn activities
of hospitalized older people is very diﬃcult due to physical limitations resulting
from their older age and associated ailments[4, 5]. Therefore, a classiﬁer which
is highly accurate at predicting all activity classes in datasets where availability
of training data is scarce is highly desirable.

Given that human activities are sequential and a person can perform the
same activity in diﬀerent manners; we base our classiﬁer in conditional random

2

ﬁelds (CRFs) [6], a graphical model for structured classiﬁcation that captures
dependency relationships between performed activities as described by sensor
observations. We evaluate our proposed classiﬁer with three case studies from
healthy and hospitalized older people using a battery-less body worn sensor
where the data streams from the wearable sensors are irregular and sparse, noisy
and class imbalanced. We conﬁrm our ﬁndings using a publicly available dataset
for human activity recognition using battery powered body worn sensors; in this
scenario we modiﬁed the imbalance to levels similar or higher than those of our
case studies.

The study presented in this article is part of our ongoing research aimed
at recognizing activities by older people in hospital and nursing home settings
for falls prevention, as described in [7, 8, 9]. This paper presents a method for
learning from imbalanced sensor data streams, with limited training data, using
conditional random ﬁelds.

1.2 Related works

This section reviews previous methods developed for improving the classiﬁca-
tion of imbalanced data, such as data re-sampling [10, 11, 12, 13], adjusting
decision thresholds [14] or the inclusion of cost parameters or weights into the
classiﬁcation algorithm [15, 16, 17, 18, 19, 20, 21, 22]. The approach presented
in this article is based on the latter.

The main issue with re-sampling techniques [10, 11, 12] is that the removal
or introduction of data can modify the sequence structure and its meaning. This
is an issue in some real world applications that require maintaining the original
data structure. For example, modifying parts of a sentence for text classiﬁcation
can eﬀectively change the meaning of the message. Similarly, in human activity
recognition the time sequence is important to determine the ﬂow of movement
or activities and introducing data can change the sequence of activities and the
way it is analyzed, e.g. aﬀecting transition probabilities in Markov chains.

Decision threshold methods such as that of [14] achieved similar results to
re-sampling techniques and used receiver operating characteristic (ROC) curves
to decide which decision threshold produces the best performance. However,
ROC curves depend on measuring speciﬁcity which does not reﬂect the errors
in imbalanced data; this is due to speciﬁcity of the minority class being condi-
tioned to its true negative measurement which includes the true positives of the
majority class and thus leading to over optimistic results.

In the case of cost parameter methods, these require the inclusion of ﬁxed
class-wise costs into the objective function of the classiﬁer during training to
reinforce the learning of the under-represented classes. Generally, cost sensitive
learning approaches have been reported to perform better than re-sampling
techniques in some applications [1]. Some cost parameters have the form of a
cost matrix that weighs each possible misclassiﬁcation case, giving higher costs
to misclassiﬁcations of a minority class observation in comparison to majority
classes [15, 16, 17]. Costs have also been used to rescale the data. This is
done by re-weighting or re-sampling the training samples; or moving decision
thresholds according to their costs. These costs are usually user provided, e.g.
from a cost matrix; these methods are reported to work well in binary data
and only in some multiclass cases [17]. Moreover, these costs are ﬁxed during
training, but in real world applications —as is our case— costs can change for

3

various reasons[17].

The method of Huang et al. [21] introduced a ﬁxed set of weights for each
class for a binary SVM algorithm. The binary weights ratio was inversely pro-
portional to their respective class population ratio in the training data. This
achieved a marginal improvement for the minority class accuracy at the cost of
possible overall accuracy reduction. In Jiang et al. [20], weights calculated from
the misclassiﬁcation cost of each class were introduced into Bayesian network
classiﬁers.

The study of Gimpel et al. [23], focused on improving the classiﬁcation per-
formance by modifying costs according to speciﬁc performance tasks (task-wise)
such as improving recall, precision or both (as in F -score) [23] as opposed to
classiﬁcation error minimization as in previous studies. The method itself did
not consider class speciﬁc parameters and parameter calculations required an
extensive validation process as parameters were not learned in training. The in-
troduction of weights in CRF (WCRF) is not new; however, previous approaches
only considered using a ﬁxed set of weights during training for optimization [22];
however, ﬁnding an optimal set of weights [23, 20] require an extensive validation
process.

These previously mentioned methods [20, 22, 23] require empirical calcu-
lation of parameters. This process can be cumbersome and computationally
expensive. For example, in an extensive grid search for suitable weights, the
number of validation operations is of the form V M, where V is the cardinality
of the parameters’ value range and M the number of parameters.
In addi-
tion, objective function optimization based on classiﬁcation error (1-accuracy)
minimization is not suitable for imbalanced data. This is because the result-
ing measure, accuracy, is largely favoured by the dominant class and does not
provide performance information regarding the predicted minority class [24].

Other studies, such as that of Gama et al. [19] dynamically changed the cost
of the naive Bayes classiﬁer by verifying and introducing classiﬁcation errors
on each iteration; this method optimized the squared loss function as opposed
to the 0–1 loss function. However, this study was only compared to the per-
formance of a naive Bayes approach. In Pang et al. [18], dynamically learned
parameters were introduced into a binary linear proximal SVM (LPSVM) ob-
jective function where weights were proportional to the ratio of the other class
population. The study of Pletscher et al. [25] presented a method for gener-
alizing structured classiﬁers such as CRF and Structured SVM (SSVM) and
introduced a cost parameter given by the Hamming distance between predicted
output and ground truth which was dynamically calculated during training.
Although the methods in [18, 25] presented dynamically calculated cost param-
eters, the model optimization was based on classiﬁcation error minimization.
Other studies oﬀered alternative methods [26, 27]. The method of Soda [26] de-
cided between an unbalanced or a balanced classiﬁer for every observation and
measured its performance based on accuracy; while Beyan et al. [27] proposed
a hierarchical method based on clustering and outlier detection that, in general,
was not signiﬁcantly better than other methods. Moreover, both studies did
not consider multi-class problems.

The study of Dimitroﬀ et al. [28] considered a learning algorithm for binary
classiﬁcation using a maximum likelihood model (weighted maximum entropy)
to optimize the expected F -score during training where weights were calculated
autonomously. Our study extends weighted maximum entropy [28], originally

4

proposed for binary classiﬁcation problems, to structured prediction using CRF.
We use CRF in order to model the dependency between consecutive activities
described by sensor observations in the training sequences and applied in pre-
vious research [9, 29].

In summary, most real-life data is imbalanced and methods that modify the
data structure can also change the meaning of the events being studied, specially
in the case of sequential data. Similarly, the use of optimization metrics such
as accuracy are aﬀected by the majority class performance.
In the case of
cost sensitive learning methods, most studies used a ﬁxed set of weights where
obtaining an optimal set requires a large amount of validation processes.
In
other dynamically calculated weights methods, the models were optimized based
on accuracy. Our proposed method is an alternative that considers dynamically
calculated weights that optimize the overall F-score to reduce false positives and
false negatives for multi-class structured prediction using CRF.

1.3 Paper Contributions

Our approach extends existing knowledge by solving current limitations: degra-
dation of sequential data by re-sampling; learning models controlled by measures
(accuracy and speciﬁcity) biased towards the dominant class; and inclusion of
class speciﬁc parameters that are ﬁxed or require extensive validation or opti-
mization. We make the following contributions:

1. We present a novel cost sensitive learning method for imbalanced multi-
class data classiﬁcation in real time, based on weighted conditional random
ﬁelds (WCRF) where the optimization process is based on maximizing the
expected overall F -score. In this method, the cost parameters are dynami-
cally computed during training. To our knowledge, this is the ﬁrst attempt
for multiclass classiﬁer optimization based on F -score metric to learn from
imbalanced data where the cost parameters are also learned, in particular,
for graphical models such as CRF.

2. We apply our method to two scenarios; the ﬁrst considers three case stud-
ies of sequential data streams from healthy and hospitalized older people
using a batteryless body worn sensor over their clothing in clinical and
hospital settings; and we generalize our results with a second scenario
that considers a battery powered body worn sensor dataset with increased
imbalance.

3. We achieve better overall performance in comparison to other CRF based
classiﬁers and similar (p-value > 0.44) or higher performance than other
support vector machine (SVM) based methods in the context of scarce
training data, which is often the case with practical applications using
supervised methods to obtain highly accurate predictive models.

5

2 Proposed Dynamically Weighted Learning

Method

2.1 Background

Let us assume a sequence of input observations {xt}T

In this section we brieﬂy revisit CRFs, a probabilistic graphical model for struc-
tured classiﬁcation [6, 30], as background to deﬁning our method in Section 2.2.
t=1 and their corre-
sponding labels {yt}T
t=1, where yt ∈ {1··· K} and K is the number of classes to
infer. The advantage of CRF is that it constructs pairwise relationships between
adjacent hidden variables and their corresponding observations, a property from
the ﬁrst order Markov assumption. The probability distribution in CRF is given
by the conditional probability deﬁned as

(cid:32) T(cid:88)
(cid:32) T(cid:88)

φt (yt−1, yt, x; λ)

exp

φ(yt−1, yt, x; λ)

.

(cid:33)
(cid:33)

,

p(y|x, λ) =

Z(x) =

exp

1
Z

(cid:88)

(1)

(2)

y1···T

Here the potential function exp(φ(yt−1, yt, x; λ)) follows the logistic model func-
tion

where λ =(cid:0)λ1, λ2(cid:1) are the model parameters to be estimated during training

φ(yt−1, yt, x; λ) = λ1f (yt−1, yt) + λ2f (yt, x)

(3)

and f (.) are transition and emission feature functions that produce boolean
values. The term Z(x) is the partition function and normalizes the conditional
probability.

During model training, we seek to maximize the conditional log likelihood

L, deﬁned as:

T(cid:88)(cid:0)λ1f (yt−1, yt) + λ2f (yt, x)(cid:1)

L(λ) = log p(y|x),
L(λ) =

− log(Z(x)).

(4)

(5)

Since L is a convex function we apply a quasi-Newton method for estima-
tion of model parameters λ such as the L-BFGS optimization algorithm. The
partition function considers a summation over all possible values of x and y.
We calculate the value of Z(x) using the belief propagation (sum–product) al-
gorithm which recursively calculates the passing of messages over all elements
in the tree. In the case of linear chain graphical models, belief propagation pro-
yT αT ,

vides an exact solution for the calculation of Z(x), given by Z(x) =(cid:80)

where αt are the messages propagating forward in the algorithm.

2.2 Dynamically Weighted Conditional Random Fields

(dWCRF)

In this section we detail our dynamically weighted CRF (dWCRF) approach
for structured predictions. The main motivation for the implementation of a
weighted approach is to address the negative eﬀects of imbalanced data on

6

learning. In addition, classiﬁcation performance measurements such as accuracy
(1-error) is not a suitable metric as results are biased towards the majority class.
Hence, we require the minimization of false positives (F P ) or false alarms; and
false negatives (F N ) or missed classiﬁcations. Intuitively, this means increasing
both true positives (T P ) and true negatives (T N ) of all participating classes.
We use the expected F -score (or F-measure) [28], as an optimization metric for
our model as it considers F N and F P in its deﬁnition.

In this context, we introduce a cost term in our classiﬁer objective function
to give a higher cost to errors in the minority classes to reduce the eﬀects of
imbalance on the classiﬁer. We consider the weighted log-likelihood function

T(cid:88)

t=1

L(λ, w) =

wt log p(yt|xt, λ)

(6)

where wt is a scalar weight for each element of the training sequence of length
T (weight vector represented by [wt]T
t=1). In [28], Dimitroﬀ et al. demonstrated
using the Pareto optimality concept that there exists a set of weights wFβ for
which λF , the parameter that optimizes the expected Fβ-score, coincides with
weighted maximum likelihood optimization parameter λw
M L. More information
on Pareto eﬃciency can be found in [28, 31]. However, the approach followed
in [28] was for a binary Maximum Entropy classiﬁer. In this article, we extend
this previous work to multiclass classiﬁcation using dWCRF; we consider the
expected overall F β-score ( ¯F ), given by the mean expected F β-score over all
participating classes as

K(cid:88)

(cid:18) (1 + β2)Precisionk.Recallk

(cid:19)

k=1

β2 · Precisionk + Recallk

¯F =

1
K

and recall. Henceforth, for simplicity, we consider β = 1, where precision
and recall have the same inﬂuence; i.e. the harmonic mean of both precision

where β ∈ R is non-negative and balances the contributions from precision
and recall. Let us assume (cid:98)λ to be the maximizer of ¯F , and considering that
T Pk = (cid:80)

i:yi=k p(yi = k|xi, λ) and F Pk = (cid:80)

i:yi(cid:54)=k p(yi = k|xi, λ); expanding

and operating in (7), can be rewritten as

¯F (λ) =

2
K

T P1

T PK

+ ··· +

(cid:80)
k(Tk) = T . From (8), we want to show that (cid:98)λ is an element of the Pareto

where Tk are the number of elements of class k in the training sequence, i.e.

T PK + TK + F PK

T P1 + T1 + F P1

optimal set of the multicriteria optimization problem (MOP)

λ {T P1, T P2,··· , T PK}.
max

(9)

We do not consider the F P term from (8) as we are interested in maximizing
T P s and reducing F P s; moreover, increasing T P{1···K}\u (set of all T P s except

that for class u) will reduce F Pk=u. If we consider that(cid:98)λ is not Pareto eﬃcient in
(T P1((cid:98)λ),··· , T PK((cid:98)λ)); i.e. at least one of the objectives is improved by λ0
compared to that of (cid:98)λ. Since the expression in (8) increases as T Pk increases,

the MOP in (9), then there is a λ0 such that (T P1(λ0),··· , T PK(λ0)) dominates

7

(7)

(8)

(cid:21)

(cid:20)

implying that ¯F (λ0) > ¯F ((cid:98)λ); this contradicts the initial assumption that (cid:98)λ

maximizes ¯F .

We can also observe that the Pareto optimal set of (9) is contained in that

of the MOP

λ {p(y1|x1, λ), p(y2|x2, λ)··· , p(yT|xT , λ)}
max

(10)

this is because if we assume a λ that is Pareto optimal for (9) but not for
(10), then we have a λ0 that improves at least one of the objectives in (10)
without decreasing the others. This means the K -tuple (T P1(λ0),··· , T PK(λ0))
dominates (T P1(λ),··· , T PK(λ)), which contradicts the assumption that λ is

Pareto optimal for (9). Hence the ¯F optimizer(cid:98)λ is also Pareto optimal for (10)
and therefore(cid:98)λ is Pareto optimal for the MOP

λ {log p(y1|x1, λ),··· , log p(yT|xT , λ)}
max

(11)

given that log(.) is a strictly increasing function. The Pareto optimal set of
(11) can be obtained by maximizing non-negative linear combinations of its
objectives [31]. This means there is a set of weights (w1,··· , wT ) such that

(cid:99)λ ¯F = arg max

λ

(cid:32) T(cid:88)

t=1

(cid:33)

wt log p(yt|xt, λ)

= arg max

λ

(L(λ, w))

(12)

where the rightmost expression corresponds to the weighted log-likelihood as ex-
pressed in (6). Our work above expands the proof in [28] for binary classiﬁcation
to multiclass classiﬁcation.

2.3 Weights Estimation

Now we are interested in computing the set of weights w in dWCRF that max-
imizes the function ¯F . We use the previous result in (12), which indicates that
the objective functions ¯F and weighted log-likelihood have gradients equal to

zero at the optimal(cid:98)λ. We have the gradient of the function ¯F
∇λ{ ¯F ((cid:98)λ)} =

¯F ((cid:98)λ)∇λp(yt|xt,(cid:98)λ) + ··· +

¯F ((cid:98)λ)∇λp(yt|xt,(cid:98)λ)

(cid:88)

(cid:88)

∂T PK

∂T P1

t:yt=1

t:yt=K

T(cid:88)

and the gradient of the log-likelihood function:

p(yt|xt,(cid:98)λ)∇λp(yt|xt,(cid:98)λ)
where ∇λ{ ¯F ((cid:98)λ)} = ∇λL((cid:98)λ) = 0 at the optimal parameter(cid:98)λ.
(cid:18)
(cid:19)

∇λL((cid:98)λ) =
(cid:18)

wt

t=1

(cid:20) d

T P1

d

∂F (λ)
∂T Pk

= q

dT Pk

T P1 + N1 + F P1

Considering the expression in (13) we can obtain the partial derivative:

T PK

dT Pk

T PK + NK + F PK

(15)

(13)

(14)

(cid:19)(cid:21)

+ ··· +

8

where q = 2/K and given that previously we have considered F Pk to be a
function of all T P s other than k, (15) can be expressed as:

∂F (λ)
∂T Pk

= q

Nk + F Pk

(T Pk + Nk + F Pk)2 + q

−T Pj

dF Pj
dT Pk

(T Pj + Nj + F Pj)2

(16)

we consider that the derivative term in (16) are close to zero at the optimal

(λ →(cid:98)λ) and that the derivative is much smaller than its quadratic denominator

term; hence we eliminate the summation term from (16), resulting in

(cid:88)

j:1···K\k

(T Pk + Nk + F Pk)2 .

(17)

The resulting weights for optimizing the weighted maximum likelihood and

the corresponding expected overall F -score can now be deﬁned as:

Nk + F Pk

∂T Pk (cid:39) q

∂F ((cid:98)λ)
p(yi = 1|xi,(cid:98)λ)∂T P1
¯F ((cid:98)λ)
p(yi = K|xi,(cid:98)λ)∂T PK
¯F ((cid:98)λ)

···

if yi = 1

if yi = K.

(18)

wi =

(cid:40)

We also consider a parameter τ > 0 that corresponds to the number of times
L is computed during the optimization process. We use this parameter to apply
λ considerations for (17), by executing ﬁrst homogeneous weights as in linear
chain CRF. Hence the resulting weights have the form:

wi,τ =

q
wi, as in (18)

if the number interations < τ
if the number interations ≥ τ.

(19)

2.4 Real Time Inference

Usually, class inference process for CRF is performed for complete sequences of
data where methods as the forward-backwards or Viterbi algorithms are applied
to the test segment and complete sequence of labels is returned [32].
In a
previous study, we have underscored the importance of real time prediction
of activities [29] where we applied the belief propagation method to obtain the
marginal probabilities of the last received observation; we use the current sensor
observation and the information from the last inference made on the previous
observation. This is given by the form:

exp (φ (yt, x))

(cid:88)

yt−1

m(yt) =

1
Zt

where m(yt) is the marginal probability corresponding to the tth observation
xt and Zt corresponds to the normalizing term so the marginals at a given
time t sum to unity and prevents the occurrence of ﬂoating point underﬂow.
The assigned label corresponds to the activity that has the highest marginal
probability.

9



(exp (φ (yt−1, yt)) m (yt−1))

(20)

3 Experimental Studies

This section presents the experimental framework and corresponding results.
We evaluate our dWCRF method using datasets from two diﬀerent human
activity recognition approaches:
i) using battery powered body worn sensors
(BPBW); and ii) batteryless body worn sensors (BLBW).

3.1 Problem Description

Both scenarios, BPBW and BLBW, consider sequential data from the sensors;
t=1, where xt ∈ Rd, and associated with a se-
these are time series X = {xt}T
quence of activity labels Y = {yt}T
t=1, where yt ∈ Y = {1··· K}, and K is the
number of activity labels to predict. In sequential data problems, we assume
that sequences are i.i.d. from each other; that is, given the set of M training
training labeled sequences D = {(Xm, Ym)}M
m=1, variables in (Xi, Yi) are in-
dependent of those in (Xj, Yj) for i (cid:54)= j. However, dependency relationships
between variables in a sequence cannot be assumed. Hence, given a testing se-
quence T = {(X, Y )}, we are interested in predicting individual class labels ˆyt
for every individual observation xt using our trained dWCRF model.

3.2 Statistical Analysis

In this study, we determine class speciﬁc performance measurements: true pos-
itives (T P ) are the correctly predicted activity labels. False positives (F P ) are
those predicted labels that are misclassiﬁed, thus do not match with the ground
truth. False negatives (F N ) correspond to those ground truth classes that were
missed. True negatives (T N ) are those non-target (not intended) classes that
were correctly identiﬁed by the system.

In addition, we evaluate the performance of each class k using the harmonic

mean of Precision (P r) and Recall (Re):

Precisionk(P r) = T Pk/(T Pk + F Pk)
Recallk(Re) = T Pk/(T Pk + F Nk)

(cid:18) 1
performance metrics i.e. F-scoreOverall =(cid:80)

F-scorek =

2×P rk×Rek
P rk + Rek

=

(cid:19)−1

.

(21)

(22)

(23)

+

1

2×Rek

2×P rk

k F-scorek/|k|.

In the case of overall performance, we consider the average of the class-speciﬁc

Note we do not evaluate metrics depending on true negatives (T N ) such as
speciﬁcity [33, 34, 9] as speciﬁcity does not appropriately reﬂect the performance
of the minority class. This is because T N considers all activities other than
the target activity. For example T N of a minority class includes the T P of
the majority class, producing high speciﬁcity values, giving an over optimistic
measurement of performance.

We are interested in comparing the F -score results of our classiﬁer with other
classiﬁers. Therefore, we compare the signiﬁcance between two classiﬁcation
results using a two-tailed independent t-test. A p-value (p) <0.05 is considered
statistically signiﬁcant.

Evaluation of these metrics in the case of the BLBW datasets was performed
using a 10-fold cross validation procedure, where each fold considered complete

10

sequences of activities (a trial) of diﬀerent people. We considered 6 folds for
training 2 folds each for testing and validation.
In the case of the BPBW
datasets, these were evaluated using a 4-fold cross validation for each dataset,
due to the reduced number of trials per dataset; we use two folds for training
and one for testing and validation respectively.

3.3 Batteryless Body Worn Sensor Datasets (BLBW)

These datasets were obtained in the context of a larger project by our research
group directed at the ambulatory monitoring of hospitalized older patients to
prevent falls [7].

We evaluate three case studies based on motion information from trialled
healthy and hospitalized participants using the battery-less body worn sensor
[35], shown in Figure 2(a). Trial participants were requested to perform a series
of broadly scripted ADLs which included: i) Sitting on bed; ii) Sitting on chair;
iii) Lying on the bed; and iv) Walking to the bed, chair or door. These represent
the most likely activities performed in a hospital environment by older patients.
A researcher, present during the trials, annotated the labels directly into the
middleware for reference as ground truth.

We consider that posture transitions such as sit to stand and stand to sit are
integrated into the ambulation or sitting movements as data collected during
posture transitions is scarce as the movements are of short duration [9]. For
example, we consider a participant starts ambulating as soon as the body is
not in contact with the bed or chair. Ambulation, in this case, also includes
standing and any movement the participant performs while walking around the
room.

Therefore, given the limitations imposed by the physical space and movement
of our target demographics, the BLBW datasets consider four classes (K = 4)
to distinguish whether a person is in or has exited a resting posture. These
classes are: i) Sit-on-bed; ii) Sit-on-chair; iii) Lying; and iv) Ambulating; where
class Ambulating includes all other movements associated with sitting on chair,
bed or lying. Details regarding the sensor platform and the case studies are
explained below.

3.3.1 Sensor Platform

The participants wore a ﬂexible Wearable Wireless Identiﬁcation and Sensing
Platform (W2ISP) device, developed by our team [35], over a garment on top
of the sternum. The W2ISP, see Figure 2(a), and based on [36], encases a tri-
axial accelerometer (ADXL330) and a 16 bit microcontroller (MSP430F2132).
The W2ISP is part of an emerging class of batteryless sensors. In particular,
the W2ISP harvests its energy using the electromagnetic ﬁeld illuminating the
tag from RFID antennas, which also collect the W2ISP sensor data. The main
motivation for using this passive (batteryless) device compared to using other
battery powered sensors are twofold: i) the device requires no maintenance as
it is battery free, lightweight, inexpensive and easy to replace; and ii) frail older
people, especially those with conditions such as delirium or dementia, require
easy-to-use equipment [37], and our proposed sensors’ development objective is
to be inconspicuous to the user i.e. concealed in the clothes.

11

We collect tri-axial acceleration signals and the received signal strength in-
dicator (RSSI) from the sensor signals. RSSI is used as a measure of relative
distance to the antenna receiving a sensor observation, specially over a short
distance as in our case studies. Moreover, because the device is passive, sen-
sor observations are not regularly collected in time, and thus increasing the
complexity of the problem (see Figure 3).

3.3.2 Case Studies

Case Study 1 Fourteen healthy older volunteers, with average age of 74.6
± 4.9 years old, completed around ﬁve trials each, based on their ability and
level of fatigue. Participants were allocated into two diﬀerent room conﬁgura-
tions: Room1 and Room2, each constituting a dataset with 4 and 3 antennas
deployments, shown in Figure 2(b) and (c), respectively.

Case Study 2 Twenty ﬁve hospitalized patients, with average age of 84.4
± 5.3 years old, performed a short sequence of ADLs due to the frailty of the
participants. The patients were trialled in their respective rooms, constituting
dataset Room3. In this hospital room conﬁguration, see Figure 2(d), the dis-
played measurements are approximate due to diﬀerences between rooms (single
or double bed), and the bed and the chair were always next to each other.

Case Study 3 This case study investigates the performance of our method
under the conditions of reduced training data; we use one dataset, Room1 from
Case Study 1, where data sequences are extracted to simulate datasets of in-
creasingly reduced number of sensor observations.

3.3.3 Class Imbalance in Datasets

Two main sources of imbalance aﬀect our datasets. The ﬁrst is the duration of
diﬀerent activities. This is expected as, for example, lying on bed is of longer
duration than ambulating. The second source of imbalance is due to the passive
nature of the W2ISP sensor; this aﬀects the powering of the device and the reg-
ularity of sensor readings. Sensor positioning and proximity to RFID antennas,
posture of the participant (causing occlusion) can also aﬀect the powering of
the sensor; moreover, these conditions can change from person to person and
room to room.

From the room settings, we can see that Room1 intends to collect sensor
observations from the complete room, whereas Room2 and Room3 are focused
on obtaining data from speciﬁc areas around the bed and chair while saving on
hardware infrastructure. In Room3, the small dimensions of the path between
bed and chair cause ambulation time to be minimal.

An illustration of sensor observations and the resulting data imbalance is
shown in Figure 3. Data acquired from Room1, see Figure 3(a), indicates that
sensor inter-reading times when the participant is sitting on bed range from
0.2 s to 1.3 s, from 0.5 s to 4.2 s when the person is ambulating and 0.5 s to
6 s when sitting on a chair. In addition, the ﬁrst observation corresponding to
Ambulating and Sit-on-chair are received after 0.7 s and 4.5 s respectively.

In the case of Room2 and Room3, shown in Figure 3(b) and (c), sensor ob-
servations from a person lying in bed (transparent-orange background) are more

12

(a)

(a)

(b)

(c)

(d)

(e)

Figure 2: (a): Wearable sensor (W2ISP) and acceleration vector components.
(b)–(d): Physical deployments of an RFID antenna infrastructure (antennas A1,
A2, A3, A4) for collecting three datasets: (b): healthy older people (Room1);
(c): healthy older people (Room2) and (d): hospitalized older people (Room3).
(e): Front and lateral view of sensor axes for a participant standing and sit-
ting/standing with respect to vertical.
(f): Bed overview of a Room3 case,
showing antenna A3 and supporting frame.

13

Figure 3: Raw data corresponding to body tilting with respect to the vertical for
the three datasets (a) Room1, (b) Room2 and (c) Room3; where black vertical
marks represent sensor readings and classes are: Sit-on-bed (blue), Ambulating
(red), Sit-on-chair (green) and Lying (orange).

frequently collected due to the location of the antennas when compared to a per-
son sitting on bed (transparent-blue background) or ambulating (transparent-
red background).

Class imbalance of the datasets are shown in Figure 4. Datasets Room1
and Room3 show similar imbalance where there is a dominant class (Lying),
a second dominant class (Sit-on-bed with 28.9% and Sit-on-chair with 21.3%
respectively) and the minority class Ambulating has the lowest proportion in
both datasets. However, Room1, has more than double the number of sensor
observation of Room3 (see Figure 4); and the minority class (Ambulating) for
both datasets has the same number of observations. Dataset Room2 is almost
dominated by one class (Lying) and the rest of the classes have decreasing values
of participation with Ambulating the minority class (1.5%). This dataset has
almost the same amount of sensor readings as Room3; albeit Room3 having
collected data from more participants than the other datasets.

3.3.4 Feature Extraction

From the three datasets we extract features representative of activities. We use
a ﬁxed time sliding window of duration of 4 s (referred henceforth as segment)

14

Figure 4: Overview of the data imbalance in the three datasets: Healthy older
people Room1; Healthy older people Room2; and Hospitalized older people
Room3. In all datasets the majority class is Lying and minority class is Ambu-
lating. In brackets are shown the approximate number of sensor observations
per dataset.

from which we extract instantaneous sensorial data corresponding to the last
received observation and contextual information associated with observations
in the segment. Moreover, we also use inter-segment information to further
capture trend changes of the sensor signals. We selected this window method
and length as it is simple to deploy and performs as well as more complex
windowing methods for feature extraction [29]. Hence, the feature vector is
composed of three diﬀerent types of features:

Instantaneous Features These features are strictly obtained from the last
received observation corresponding to the current performed activity, shown in
Table 1, and the gender of the participant which is known.

We consider the body tilting angle α on the midsagittal plane towards the
front or back of the participant from the vertical reference [33]. The angle α is
approximated from current acceleration values α ≈ arctan
prefer sin(α) as it is proportional to α and range limited to [-1,1]. The value of
RSSI is of interest as a reference of relative proximity to a surrounding antenna.
We also consider the time diﬀerence (∆t) between sensor observations as in
previous research [9]. Also included are the body rotation angles approximated
from current acceleration readings: yaw = arctan( al
),
af
as they carry information pertinent to body rotation movements.

) and roll = arctan( al
av

; however, we

(cid:17)

(cid:16) af

av

Contextual Information Features These features, shown in Table 2, are
extracted from each segment and provide general information of what is oc-
curring during the segment duration, i.e. complementary information to the
instantaneous features in the temporal vicinity of the last received sensor ob-
servation [38].

We include the basic contextual information of the number of events per
antenna in the segment; we also include the identiﬁcation of the antenna that
registered the highest and lowest RSSI in the segment, which serve as a location
marker as a participant is more likely to occupy an area near the antenna re-
porting higher RSSI during the segment duration. Other feature is the vertical
displacement measured from acceleration readings in the vertical axis (av) in

15

Room1(≈52400)Room2(≈22600)Room3(≈23000)05010028.95.510.88.42.321.35990.759.33.71.58.5Observations(%)SitonbedSitonchairLyingAmbulatingTable 1: Instantaneous features.

Feature

Description

af
av
al
sin(α)
aID
RSSI
∆t
yaw
roll
sex

frontal acceleration
vertical acceleration
lateral acceleration
sine of body tilting angle
receiving antenna identiﬁcation
received signal strength indicator
time diﬀerence with previous observation
trunk yaw angle
trunk roll angle
participant’s gender

Table 2: Contextual information features.

Feature

Description

aSU M1..M
amaxRSSI
aminRSSI
V disp
M Ibed−chair
r[f v,f l,vl]

number of events per antenna
antenna collecting maximum received power
antenna collecting minimum received power
vertical displacement
mutual information of bed and chair areas
Pearson correlation coeﬃcient for acceleration axes

Table 3: Inter-segment features.

Feature

∆M ax[af , av, al]
∆M in[af , av, al]
∆M ed[af , av, al]
∆M axRSSI1..M
∆M inRSSI1..M
∆M edRSSI1..M

Description

Diﬀerence of acceleration maxima per axis
Diﬀerence of acceleration minima per axis
Diﬀerence of acceleration median per axis
Diﬀerence of power maxima per antenna
Diﬀerence of power minima per antenna
Diﬀerence of power median per antenna

16

the segment. The mutual Information between bed and chair areas considers
the occurrences of consecutive observations from two antennas focused towards
the chair and bed occurring in either directions as used in [29]. We also consider
the Pearson correlation coeﬃcient of all combinations of the three acceleration
components of all observations in the segment.

Inter-Segment Features These features, shown in Table 3, aim to capture
information trend variations from consecutive segments and are useful as these
variations are insensitive to noise in unﬁltered raw sensor data.

We include the diﬀerence of the maxima, minima and median of the seg-
ments’ acceleration readings in the three axes with respect to the participant:
vertical, frontal and lateral.
In addition, we are interested in the changes of
RSSI, as an indicator of position shifting, given by the diﬀerence of the seg-
ments maxima, minima and median of the RSSI readings per antenna.

3.3.5 Parameter Selection

We evaluate the performance of our dWCRF model together with linear chain
CRF [6]; a weighted CRF with ﬁxed weight values (fWCRF), given by the
inverse of the class distribution [22]; and a cost parameter based CRF such as
the softmax-margin model (C-CRF) [23] on all three datasets, we use the L2
regularized model for each classiﬁer of the form θ(cid:107)λ(cid:107)2. Regularization parameter
θ was evaluated in the range [10−4, 10−1]. Parameter τ was chosen from the
range limited by the lowest number of iterations for linear chain CRF.

In addition, we also compare with multiclass SVM for linear and radial ba-
sis function (RBF) kernels (L-SVM and R-SVM respectively) and the weighted
SVM for both classiﬁers (L-WSVM and R-WSVM) [39, 40, 41]. All classiﬁers
were trained using the extracted features described in Section 3.3.4. Selection
of hyperparameters for the SVM classiﬁers’ regularization, C, and RBF kernel,
γ, were evaluated using a grid search in the range [2−5, 25] for both param-
eters. SVM algorithms were evaluated using libSVM [42] toolbox in Matlab,
which performs a one-vs-one approach for multiclass classiﬁcation. In the case
of dWCRF, CRF, fWCRF, L-SVM and R-SVM, these are the only validated
parameters; in all cases, the best set of parameters that produced the highest
F -score was chosen.

The weight parameters for C-CRF, L-WSVM and R-WSVM, are found
through cross-validation, evaluating the validation set. We note that for fWCRF,
the weights are ﬁxed and determined solely on the class distribution; and are
not sought by any optimization method. In the case of C-CRF, the parameters
are selected to optimize F -score as in [43]; we applied an extensive grid search to
obtain the optimal parameters in the value range [0, 20]. In the cases of weighted
SVM, the algorithms require a weight per class, K = 4 in our case, requiring
a larger grid-search evaluation of the order of N 4 processes, where N is the
number of elements in the range to evaluate. Instead we use the covariance ma-
trix adaptation evolution strategy (CMA-ES) [44], a widely used evolutionary
optimization algorithm, to ﬁnd the optimal set of per-class parameters for these
classiﬁers. Given the stochastic nature of the initial parameter selection for the
iterative CMA-ES process, we require evaluating multiple starting values; in our
case, we evaluated 350 random initial points uniformly distributed in the range
[0, 20] for each classiﬁer.

17

Figure 5: Overall F -score performance of our three datasets (a): Room1, (b):
Room2 and (c): Room3 using our dWCRF, linear chain CRF, ﬁxed weighted
CRF (fWCRF), softmax margin CRF (C-CRF), linear SVM (L-SVM), RBF
kernel SVM (R-SVM) and their corresponding weighted algorithms: L-WSVM
and R-WSVM respectively. Results are shown as boxplots (averages shown as
diamonds).

Hyperparameter validation for the tested methods was performed on a clus-
ter of Intel 8 core E5 series Xeon microprocessors due to the large number of
processes to be performed.

3.3.6 Results

First, we demonstrate the overall results corresponding to the datasets from
Case Study 1 (Room1 and Room2) and Case Study 2 (Room3). These were
obtained by averaging all participating classes’ individual F -score are shown in
Figure 5. Maximum performance variations between methods’ average F -score
is about 7%. For Room1, variation of our dWCRF with the best performing
classiﬁer, R-WSVM, is 4.6% (85.4% and 90% respectively). For Room2, the
maximum F -score variation is ≈ 8% where the diﬀerence between our dWCRF
(81.3%) and best performing R-WSVM (83.8%) is 2.5%. In Room3, the maxi-
mum F -score variation is ≈ 10%, where dWCRF is the best performing classiﬁer
(59.0%). In addition, overall dWCRF results are not statistically signiﬁcantly
diﬀerent to those of all other algorithms; p-values for Room1 are p > 0.72, for
Room2 are p > 0.67 and for Room3 are p > 0.53. Therefore, dWCRF performs
as well as other classiﬁers; particularly in Room3 where dWCRF mean F -score
was higher than other classiﬁers.

18

Figure 6: F-score performance of all classes and datasets. Results are shown as
boxplots (averages shown as diamonds). Classiﬁers tested are: 1: dWCRF, 2:
CRF, 3: fWCRF, 4: C-CRF, 5: L-SVM, 6: R-SVM, 7: L-WSVM, 8: R-WSVM.

19

Room1Room2Room3Sit-on-bed(a)(b)(c)Sit-on-chair(d)(e)(f)Lying-on-bed(g)(h)(i)Ambulation(j)(k)(l)1In terms of individual classes from the datasets corresponding to Case Study 1
and Case Study 2, we observe diﬀering behaviours. For Room1, see Figure 6(left
column), SVM classiﬁers achieve statistically signiﬁcantly better results than
those of dWCRF (p ≤ 0.015). In particular, for the minority class (Ambulat-
ing), the diﬀerence in performance is ≈ 10% in comparison to R-WSVM (see
Figure 6(j)). For the rest of activities the diﬀerences are < 5%. In comparison
to other CRF based algorithms, dWCRF has, in general, higher results in terms
of mean F -score with exception of class Sitting-on-chair, with diﬀerence of 2%
(p > 0.1).

The results for Room2, shown in Figure 6 (middle column), demonstrate that
all results are very close and no classiﬁer is statistically signiﬁcantly diﬀerent
from dWCRF (p ≥ 0.08) with exception of Ambulation with fWCRF where
dWCRF is better with statistical signiﬁcance (p = 0.003). For the minority
class Ambulation, dWCRF mean performance is higher by 3% compared to
both L-SVM classiﬁers and 0.5% compared to R-SVM classiﬁers. However, for
the Sit-on-bed class, the R-WSVM result is higher by 7%. Similarly to Room1,
dWCRF has, in general, higher results than the other CRF based classiﬁers
(p ≥ 0.20).
The results for individual classes in Room3, shown in Figure 6 (right col-
umn), indicates that, for the minority class Sit-on-bed, dWCRF almost doubles
the performance of R-WSVM with statistical signiﬁcance (p = 0.018); and is
higher than the other classiﬁers (p ≥ 0.08). For majority class Lying-on-bed
dWCRF is statistically signiﬁcantly better than fWCRF (p = 0.009). For the
minority class Ambulation, dWCRF is lower than R-SVM (4% diﬀerence), but
is not statistically signiﬁcantly diﬀerent with the other classiﬁers (p ≥ 0.19).
Compared with the other CRF based classiﬁers dWCRF obtains better results
for all classes.

In the case of Case Study 3, we consider the performance of the system when
learning with limited data. For simplicity of dWCRF calculations, we consider
parameter τ = 1. The results from Room1 in Figure 6 (left column) indi-
cate that SVM based algorithms perform statistically signiﬁcantly better than
those of dWCRF (p ≤ 0.017). A probable reason is that Room1 contains more
than double the information than the other datasets (Section 3.3.3), providing
more than enough support vectors to perform reliable classiﬁcation. We conﬁrm
our proposition by experimenting with Room1 dataset by repeatedly reducing
one sequence of activities (or trial) from each fold in order to aﬀect each fold
evenly. This process also does not aﬀect the class distribution of the remaining
population as illustrated in Figure 7(a). Each reduced dataset is tested with
the classiﬁers dWCRF, L-SVM, L-WSVM, R-SVM and R-WSVM. The overall
performance, shown in Figure 7(b) where the x -axis displays the approximate
number of sensor readings in thousands, indicates that the diﬀerence between
classiﬁers reduces as the dataset reduces.

The results in Figure 7(b) indicate that the performance of SVM based
classiﬁers do not vary between each other; moreover, the performance declines
after the 38k population marker.
In contrast, dWCRF performance remains
almost unchanged for all population markers. The performance diﬀerence be-
tween SVM classiﬁers and dWCRF also reduces, we have that between 27k and
18k population markers, this diﬀerence is minimal, ≈ 4% and 2%, respectively.
More importantly, the diﬀerences between classes are no longer statistically sig-
niﬁcant after the ﬁrst reduction (46k) with p-values of p ≥ 0.51 for 46k, p ≥ 0.56

20

(a)

(b)

Figure 7: (a): Class distribution for diﬀerent dataset populations showing that
classes distributions remain almost unchanged during testing. (b): Results from
reducing the population of Room1 dataset to verify its eﬀect on diﬀerent clas-
siﬁer results.

for 38k, p ≥ 0.41 for 27k and p ≥ 0.44 for 18k.
Notice that sensor observation populations, for both Room2 and Room3,
are within the population segment between 27k and 18k; and in these datasets,
dWCRF results are shown to be similar or superior than all other classiﬁers.
This conﬁrms our dWCRF classiﬁer performance being not signiﬁcantly diﬀerent
than SVM based methods after reducing Room1 population levels to those of
Room2 and Room3. We also note that Room3 dataset corresponds to a real
world scenario with hospitalized patients in a hospital environment. Under
these real world conditions, we gathered much fewer observations for Room3
than Room1 dataset, although having recruited 25 patients (more than the
other two datasets) over a period of more than six months. In fact, under most
practical situations, collecting and labelling data is diﬃcult and cumbersome.
Therefore the ability of our dWCRF classiﬁer to learn from imbalanced data
when available training data is scarce is a signiﬁcant result.

Furthermore, dWCRF has an added advantage over other weighted methods
in that dWCRF does not require to search for optimal weights via validation.
This makes it a faster approach than using a grid search for optimizing the
weights or using techniques such as CMA-ES, which requires multiple train-
ing initializations while providing no guarantee to achieve optimal results; and
where the complexity of optimization increases with the number of classes.

21

3.4 Battery Powered Body Worn Sensor Dataset (BPBW)

To further validate the generalizability of our approach, we consider other
datasets that showcase sequential information; speciﬁcally human activity recog-
nition using wearable sensors. Unfortunately, few public datasets on human
activity show data imbalance and have enough data samples to modify its levels
of imbalance. We chose to use the Opportunity activity recognition dataset [45],
available in the UCI repository. In this dataset, four participants with multiple
sensors attached to their body and the environment perform multiple daily liv-
ing activities. From the multiple sensor data and features generated (243), we
only select those that are related to the trunk of the participant, i.e. sensors
located on the hip and the back of the participant. This gives us only 19 sensor
related features plus a time related feature.

These sensors are considered as these are the closest to our real scenario
(hospital). Moreover, the dataset has modes of locomotion labels: Stand, Walk,
Sit, Lie; similarly to the BLBW datasets, the selected torso-based features are
used to predict these classes. There is also a null class which we consider as
an additional class where we assume the participant is doing something other
than the four basic locomotion activity labels. We also considered observations
where readings from both sensors were present, otherwise the observation was
discarded. Finally, we subdivided the data to 5 datasets, for two main reasons:
i) Each dataset contains only one trial from each participant, i.e. we train and
test the system using data from diﬀerent participants; ii) The original set is
large (≈ 610 000 observations), which is not realistic or convenient since our
goal is to evaluate performance with cases of reduced and imbalanced data.
Furthermore, the main objective of this test is not to compare to the estab-
lished benchmarks, but to compare diﬀerent methods in situations of high data
imbalance not present in the original data.

The original low levels of imbalance are modiﬁed for all classes except the
original majority class (Stand), in order to create imbalance levels similar and
greater than to those of our study cases.
In this case, we remove readings
from the rest of classes on all sequences, i.e. data for training and testing
have been similarly reduced. Three levels of data removal are used as shown
in Figure 8(a), Op1: remove up to 9 of 10 consecutive sensor readings for each
activity; Op2: remove up to 11 of 12 consecutive sensor readings for each activity;
and Op3: remove up to 14 of 15 consecutive sensor readings for each activity.

3.4.1 Results

We test the datasets with the same methods of Case Study 3 in Section 3.3.6.
the results are shown in Figure 8(b)–(d).
In general, no method is statisti-
cally signiﬁcantly better than the rest with p ≥ 0.174 for Op1, p ≥ 0.137 for
Op2 and p ≥ 0.251 for Op3. Nonetheless, the average overall F -score for our
dWCRF is in general higher than all other methods, with the exception of L-
WSVM, which has higher overall F -score in 5 (DS3 and DS4 in Op1, DS3 in
Op2, and DS3 and DS5 in Op3) of all imbalanced datasets cases. Moreover,
for dWCRF the lowest class performance in all datasets was for the class Null;
whereas for L-WSVM lowest class performance for most datasets was for class
Lie, which is the minority class. These results suggest that despite high overall
results, dWCRF struggles with identifying undeﬁned classes as in these datasets.

22

(a)

(b)

(c)

(d)

Figure 8: (a) Class imbalance distribution over three cases. Overall performance
for ﬁve datasets, DS1. . . DS5, on imbalance case (b) Op1, (c) Op2, and (d) Op3.

Weights optimization for WSVM methods using CMA-ES required 200 initial-
ization processes each dataset (5 datasets) and imbalance case (3 cases); i.e.
3000 CMA-ES processes for each L-WSVM and R-WSVM methods. These re-
sults validate our method for sequential data with high imbalance and limited
training data in terms of performance.

3.5 Empirical Comparison of Parameter Validation

We use the BPBW datasets to illustrate the diﬀerent training times (including
parameter selection) of our proposed dWCRF and other methods. From the
datasets used in the previous section, we randomly select one dataset from each
imbalance case: DS5 from Op1, DS3 from Op2 and DS3 from OP3.

The resulting times are shown in Figure 9, where the time axis is in logarith-
mic scale, where time represents the total time taken to for evaluating the range
of validation parameters. In this case, we evaluate dWCRF with one parameter
to validate (regularization parameter θ in dWCRF1), and two parameters (θ

23

DS1DS2DS3DS4DS50.20.40.60.81F-scoredWCRFL-SVMR-SVML-WSVMR-WSVMDS1DS2DS3DS4DS500.51F-scoreDS1DS2DS3DS4DS50.20.40.60.81F-scoreFigure 9: Comparison of validation times for the tested methods: DS5 from
Op1 (red), DS3 from Op2 (blue) and DS3 from Op3 (green). Time axis is in
logarithmic scale.

and τ in dWCRF2) with cardinalities of 10 and 121 respectively. LSVM had
one parameter to validate with a cardinality of 11. RSVM had two parameters
to validate with a total combination cardinality of 121. L-WSVM and R-WSVM
added also the times of 200 CMA-ES processes with random starting points, for
each method, to validate the values of 5 weight parameters. It is clear that,
increasing or decreasing the number of CMA-ES processes has an impact on the
total time; however, a larger number of processes are necessary to obtain a closer
to optimal result as a single CMA-ES process does not guarantee an optimal
solution. We note in Figure 9 the considerable diﬀerence between methods and
number of parameters; however, the time to validate parameters in dWCRF is
lower than that of SVM methods. These results conﬁrm the advantages of our
method delivered in the model selection phase of the training process.

4 Conclusion

The present study has established that dWCRF, using a class-wise cost pa-
rameter in the objective function, improves the overall F -score of our battery-
less body worn sensor datasets when compared to other CRF based classiﬁers
and performs similar or better than other SVM based classiﬁers in conditions
where training data availability is reduced or collecting large datasets is dif-
ﬁcult. Moreover, the developed approach also improves F -score performance
metrics on minority classes. Our method was validated using a set of battery
powered body worn sensor human activity recognition datasets in conditions of
high imbalance and limited training data.

This study also presents a method to obtain a class-wise weighted classiﬁer
for optimizing the expected overall F -score from imbalanced multiclass data. In
contrast to previous approaches our method dynamically calculates class-wise
cost parameters, i.e. requires no previous knowledge of the data to assign cost
parameter weights and does not need to be evaluated in the validation stage.
In addition, our method obtained performance results comparable to other cost
functions that optimize F -score such as Softmax-Margin [23] and other SVM
based classiﬁers, but with an extensive reduction in learning time. This is be-

24

cause Softmax-Margin function and the weighted SVM methods have more than
two parameters to optimize; thus require an exponential amount of validation it-
erations in order to compare and obtain the best set of parameters. The BLBW
datasets from old people provide heterogeneous data containing variations in
age, health status, physical infrastructure and settings, which were compared
using the same features; these datasets are scarce as most real-life application
data. In contrast, most laboratory datasets are well controlled and show lit-
tle data imbalance which is not representative of real-life conditions. In terms
of future work, we are interested in testing our approach with other structured
classiﬁcation applications where available data is scarce and imbalanced; as well
as investigating the eﬀects of our approach into models of higher order.

Acknowledgment

This study was supported by the Australian Research Council (DP130104614).
This study has approval by the Human Research Ethics Committee of the Queen
Elizabeth Hospital (protocol number 2011129). We also want to thank Prof.
Renuka Visvanathan, Mr. Stephen Hoskins and Dr. Shailaja Nair for their
support in the selection and supervision of participants for the trials.

References

[1] H. He and E. A. Garcia, “Learning from imbalanced data,” IEEE Trans-
actions on Knowledge and Data Engineering, vol. 21, pp. 1263–1284, Sept
2009.

[2] N. Japkowicz and S. Stephen, “The class imbalance problem: A systematic

study,” Intelligent Data Analysis, vol. 6, no. 5, p. 429, 2002.

[3] K. Rapp, C. Becker, I. D. Cameron, H. H. K¨onig, and G. B¨uchele, “Epi-
demiology of falls in residential aged care: analysis of more than 70,000
falls from residents of bavarian nursing homes,” Journal of the American
Medical Directors Association, vol. 13, no. 2, pp. 187.e1–187.e6, 2012.

[4] S. Chernbumroong, S. Cang, A. Atkins, and H. Yu, “Elderly activities
recognition and classiﬁcation for applications in assisted living,” Expert
Systems with Applications, vol. 40, no. 5, pp. 1662–1674, 2013.

[5] D. C. Ranasinghe, R. L. Shinmoto Torres, and A. Wickramasinghe, “Auto-
mated activity recognition and monitoring of elderly using wireless sensors:
Research challenges,” in Fifth IEEE International Workshop on Advances
in Sensors and Interfaces, pp. 224–227, 2013.

[6] J. D. Laﬀerty, A. McCallum, and F. C. N. Pereira, “Conditional random
ﬁelds: Probabilistic models for segmenting and labeling sequence data,”
in Proceedings of the 18th International Conference on Machine Learning,
(USA), pp. 282–289, Morgan Kaufmann Publishers Inc., 2001.

[7] R. Visvanathan, D. C. Ranasinghe, R. L. Shinmoto Torres, and K. Hill,
“Framework for preventing falls in acute hospitals using passive sensor en-
abled radio frequency identiﬁcation technology,” in 2012 Annual Interna-

25

tional Conference of the IEEE Engineering in Medicine and Biology Society
(EMBC), pp. 5858–5862, 2012.

[8] D. C. Ranasinghe, R. L. Shinmoto Torres, K. Hill, and R. Visvanathan,
“Low cost and batteryless sensor-enabled radio frequency identiﬁcation tag
based approaches to identify patient bed entry and exit posture transi-
tions,” Gait & Posture, vol. 39, no. 1, pp. 118 – 123, 2014.

[9] R. L. Shinmoto Torres, D. C. Ranasinghe, Q. Shi, and A. P. Sample, “Sen-
sor enabled wearable rﬁd technology for mitigating the risk of falls near
beds,” in Seventh IEEE International Conference on RFID, pp. 191–198,
2013.

[10] G. E. A. P. A. Batista, R. C. Prati, and M. C. Monard, “A study of the
behavior of several methods for balancing machine learning training data,”
SIGKDD Explorations Newsletter, vol. 6, no. 1, pp. 20–29, 2004.

[11] M. A. Tahir, J. Kittler, and F. Yan, “Inverse random under sampling for
class imbalance problem and its application to multi-label classiﬁcation,”
Pattern Recognition, vol. 45, no. 10, pp. 3738–3750, 2012.

[12] B. Das, N. C. Krishnan, and D. J. Cook, “Handling imbalanced and over-
lapping classes in smart environments prompting dataset,” in Data Mining
for Service (K. Yada, ed.), vol. 3 of Studies in Big Data, pp. 199–219,
Springer, 2014.

[13] J.-H. Xue and P. Hall, “Why does rebalancing class-unbalanced data im-
prove auc for linear discriminant analysis?,” IEEE Transactions on Pattern
Analysis and Machine Intelligence, vol. 37, pp. 1109–1112, May 2015.

[14] M. A. Maloof, “Learning when data sets are imbalanced and when costs
are unequal and unknown,” in ICML-2003 Workshop on Learning from
Imbalanced Data Sets II, vol. 2, pp. 2–1, 2003.

[15] P. Domingos, “Metacost: a general method for making classiﬁers cost-
sensitive,” in Fifth ACM SIGKDD International Conference on Knowledge
Discovery and Data Mining, (USA), pp. 155–164, ACM, 1999.

[16] X.-Y. Liu and Z.-H. Zhou, “The inﬂuence of class imbalance on cost-
sensitive learning: an empirical study,” in Sixth International Conference
on Data Mining., pp. 970–974, Dec 2006.

[17] Z.-H. Zhou and X.-Y. Liu, “On multi-class cost-sensitive learning,” Com-

putational Intelligence, vol. 26, no. 3, pp. 232–257, 2010.

[18] S. Pang, L. Zhu, G. Chen, A. Sarrafzadeh, T. Ban, and D. Inoue, “Dy-
namic class imbalance learning for incremental LPSVM,” Neural Networks,
vol. 44, no. 0, pp. 87 – 100, 2013.

[19] J. Gama, “Iterative bayes,” Theoretical Computer Science, vol. 292, no. 2,

pp. 417 – 430, 2003. Theoretical Aspects of Discovery Science.

[20] L. Jiang, C. Li, and S. Wang, “Cost-sensitive bayesian network classiﬁers,”

Pattern Recognition Letters, vol. 45, no. 0, pp. 211–216, 2014.

26

[21] Y.-M. Huang and S. xin Du, “Weighted support vector machine for classi-
ﬁcation with uneven training class sizes,” in Proceedings of 2005 Interna-
tional Conference on Machine Learning and Cybernetics., vol. 7, pp. 4365–
4369, Aug 2005.

[22] G. de Lannoy, D. Francois, J. Delbeke, and M. Verleysen, “Weighted con-
ditional random ﬁelds for supervised interpatient heartbeat classiﬁcation,”
IEEE Transactions on Biomedical Engineering, vol. 59, no. 1, pp. 241–247,
2012.

[23] K. Gimpel and N. A. Smith, “Softmax-margin crfs: Training log-linear
models with cost functions,” in Human Language Technologies: The 2010
Annual Conference of the North American Chapter of the Association for
Computational Linguistics, (USA), pp. 733–736, Association for Computa-
tional Linguistics, 2010.

[24] N. V. Chawla, “Data mining for imbalanced datasets: An overview,”
in Data Mining and Knowledge Discovery Handbook (O. Maimon and
L. Rokach, eds.), pp. 853–867, Springer, 2005.

[25] P. Pletscher, C. S. Ong, and J. M. Buhmann, “Entropy and margin maxi-
mization for structured output learning,” in Machine Learning and Knowl-
edge Discovery in Databases (J. L. Balczar, F. Bonchi, A. Gionis, and
M. Sebag, eds.), vol. 6323 of Lecture Notes in Computer Science, pp. 83–
98, Springer, 2010.

[26] P. Soda, “A multi-objective optimisation approach for class imbalance

learning,” Pattern Recognition, vol. 44, no. 8, pp. 1801 – 1810, 2011.

[27] C. Beyan and R. Fisher, “Classifying imbalanced data sets using similar-
ity based hierarchical decomposition,” Pattern Recognition, vol. 48, no. 5,
pp. 1653 – 1672, 2015.

[28] G. Dimitroﬀ, G. Georgiev, L. Tolo¸si, and B. Popov, “Eﬃcient f mea-
sure maximization via weighted maximum likelihood,” Machine Learning,
vol. 98, no. 3, pp. 435–454, 2015.

[29] R. L. Shinmoto Torres, D. C. Ranasinghe, and Q. Shi, “Evaluation of
wearable sensor tag data segmentation approaches for real time activity
classiﬁcation in elderly,” in Mobile and Ubiquitous Systems: Computing,
Networking, and Services (I. Stojmenovic, Z. Cheng, and S. Guo, eds.),
vol. 131 of Lecture Notes of the Institute for Computer Sciences, Social
Informatics and Telecommunications Engineering, pp. 384–395, Springer,
2014.

[30] C. Sutton and A. McCallum, “An introduction to conditional random ﬁelds
for relational learning,” in Introduction to Statistical Relational Learning
(L. Getoor and B. Taskar, eds.), pp. 93–127, The MIT Press, 2006.

[31] M. Ehrgott, Multicriteria Optimization. USA: Springer, 2005.

[32] C. Sutton and A. McCallum, “An introduction to conditional random
ﬁelds,” Foundations and Trends in Machine Learning, vol. 4, no. 4, pp. 267–
373, 2012.

27

[33] B. Najaﬁ, K. Aminian, A. Paraschiv-Ionescu, F. Loew, C. Bula, and
P. Robert, “Ambulatory system for human motion analysis using a kine-
matic sensor: monitoring of daily physical activity in the elderly,” IEEE
Transactions on Biomedical Engineering, vol. 50, no. 6, pp. 711–723, 2003.
[34] A. Godfrey, A. K. Bourke, G. M. ´Olaighin, P. van de Ven, and J. Nelson,
“Activity classiﬁcation using a single chest mounted tri-axial accelerome-
ter,” Medical Engineering & Physics, vol. 33, no. 9, pp. 1127–1135, 2011.

[35] T. Kaufmann, D. C. Ranasinghe, M. Zhou, and C. Fumeaux, “Wearable
quarter-wave microstrip antenna for passive UHF RFID applications,” In-
ternational Journal of Antennas and Propagation, vol. 2013, 2013.

[36] A. P. Sample, D. J. Yeager, P. S. Powledge, A. V. Mamishev, and J. R.
Smith, “Design of an rﬁd-based battery-free programmable sensing plat-
form,” IEEE Transactions on Instrumentation and Measurement, vol. 57,
no. 11, pp. 2608–2615, 2008.

[37] P. Topo, “Technology studies to meet the needs of people with dementia
and their caregivers: A literature review,” Journal of Applied Gerontology,
vol. 28, no. 1, pp. 5–37, 2009.

[38] N. C. Krishnan and D. J. Cook, “Activity recognition on streaming sensor

data,” Pervasive and Mobile Computing, vol. 10, pp. 138–154, 2014.

[39] C. Cortes and V. Vapnik, “Support-vector networks,” Machine Learning,

vol. 20, no. 3, pp. 273–297, 1995.

[40] B. E. Boser, I. M. Guyon, and V. N. Vapnik, “A training algorithm for
optimal margin classiﬁers,” in Proceedings of the Fifth Annual Workshop
on Computational Learning Theory, (USA), pp. 144–152, ACM, 1992.

[41] J. H. Friedman, “Another approach to polychotomous classiﬁcation,” tech.

rep., Department of Statistics, Stanford University, 1996.

[42] C.-C. Chang and C.-J. Lin, “LIBSVM: A library for support vector ma-
chines,” ACM Transactions on Intelligent Systems and Technology, vol. 2,
pp. 27:1–27:27, 2011. Software available at http://www.csie.ntu.edu.
tw/~cjlin/libsvm.

[43] K. Gimpel and N. A. Smith, “Softmax-margin training for structured log-
linear models,” Tech. Rep. CMU-LTI-10-008, Carnegie Mellon University,
2010.

[44] N. Hansen, “The CMA evolution strategy: A comparing review,” in To-
wards a New Evolutionary Computation (J. A. Lozano, P. Larra˜naga,
I. Inza, and E. Bengoetxea, eds.), vol. 192 of Studies in Fuzziness and
Soft Computing, pp. 75–102, Springer, 2006.

[45] D. Roggen, A. Calatroni, M. Rossi, T. Holleczek, K. F¨orster, G. Tr¨oster,
P. Lukowicz, D. Bannach, G. Pirkl, A. Ferscha, J. Doppler, C. Holzmann,
M. Kurz, G. Holl, R. Chavarriaga, H. Sagha, H. Bayati, M. Creatura,
and J. d. R. Mill´an, “Collecting complex activity data sets in highly rich
networked sensor environments,” in Seventh International Conference on
Networked Sensing Systems, pp. 233–240, 2010.

28

