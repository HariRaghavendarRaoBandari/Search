Minimization of Büchi Automata

using Fair Simulation

Bachelorthesis
Daniel Tischner
March 4, 2016

Supervisor: Prof. Dr. Andreas Podelski
Advisor:

Matthias Heizmann

6
1
0
2

 
r
a

M
3

 

 
 
]
L
F
.
s
c
[
 
 

1
v
7
0
1
1
0

.

3
0
6
1
:
v
i
X
r
a

Contents
1 Introduction

2 Simulation

. . . . . . . . . . . . . . . . . . . . . . . . . .
2.1 Preliminaries
2.2 Types of simulation . . . . . . . . . . . . . . . . . . . . . . .
2.3 Parity game . . . . . . . . . . . . . . . . . . . . . . . . . . .
Strategy . . . . . . . . . . . . . . . . . . . . . . . . .
2.4 Parity game graph . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . .

2.4.1 Correlation to parity games

2.3.1

3 Computing a simulation relation

3.1 Terminology . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.2 Enhanced version of Jurdzińskis algorithm . . . . . . . . . .
3.2.1 Complexity . . . . . . . . . . . . . . . . . . . . . . .
3.2.2 Correctness
. . . . . . . . . . . . . . . . . . . . . . .
3.3 Simulation from progress measure . . . . . . . . . . . . . . .
Illustration . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.4
3.4.1 Examples
. . . . . . . . . . . . . . . . . . . . . . . .

4 Minimization using fair simulation

4.1 Language preservation . . . . . . . . . . . . . . . . . . . . .
4.2 Modiﬁng the game graph . . . . . . . . . . . . . . . . . . . .
4.3 Merge states . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.4 Remove redundant transitions . . . . . . . . . . . . . . . . .
4.5 Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.5.1 Complexity . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . .

4.6 Examples

5 Optimization

6 Experimental results

6.1 Random automata . . . . . . . . . . . . . . . . . . . . . . .
6.2 Program analysis automata . . . . . . . . . . . . . . . . . .
6.3 Complemented automata . . . . . . . . . . . . . . . . . . . .
6.4 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . .

7 Conclusion

References

2

6

9
9
11
12
15
17
19

22
22
24
26
28
32
32
34

39
40
43
44
46
47
49
50

52

58
59
61
63
64

64

66

Declaration

I hereby declare, that I am the sole author and composer of my The-
sis and that no other sources or learning aids, other than those listed,
have been used. Furthermore, I declare that I have acknowledged
the work of others by providing detailed references of said work. I
hereby also declare, that my Thesis has not been prepared for another
examination or assignment, either wholly or excerpts thereof.

Place, Date

Signature

3

Zusammenfassung

Wir präsentieren einen Algorithmus, der die Größe von Büchi Auto-
maten mit Hilfe von fair simulation reduziert. Seine Zeitkomplexität
ist O(|Q|4 · |∆|2), die Platzkomplexität ist O(|Q| · |∆|).

Simulation ist ein häuﬁg genutzter Ansatz zur Minimierung von ω-
Automaten, wie Büchi Automaten. Direct simulation, delayed simula-
tion und fair simulation sind verschiedene Simulationstypen. Wie wir
zeigen werden, ist Minimierung basierend auf direct oder delayed sim-
ulation konzeptionell einfach. Wohingegen der Algorithmus basierend
auf fair simulation komplexer ist. Allerdings erlaubt fair simulation
eine stärkere Minimierung des Automaten.

Des Weiteren erläutern wir die Theorie hinter dem Algorithmus,
umfassen in der Praxis nützliche Optimierungen, zeigen Versuch-
sergebnisse auf und vergleichen unsere Technik mit anderen Min-
imierungsstrategien.

4

Abstract

We present an algorithm, which reduces the size of Büchi automata
using fair simulation. Its time complexity is O(|Q|4 · |∆|2), the space
complexity is O(|Q| · |∆|).

Simulation is a common approach for minimizing ω-automata such
as Büchi automata. Direct simulation, delayed simulation and fair
simulation are diﬀerent types of simulation. As we will show, mini-
mization based on direct or delayed simulation is conceptually sim-
ple. Whereas the algorithm based on fair simulation is more com-
plex. However, fair simulation allows a stronger minimization of the
automaton.

Further, we illustrate the theory behind the algorithm, cover opti-
mizations useful in practice, give experimental results and compare
our technique to other minimization strategies.

5

Section 1

1 Introduction
Many applications heavily make use of automata, as shown in [7, 10, 15].
Büchi automata, alongside LTL, are commonly used for model checking.
Eﬃciently reducing the size of automata without changing their language
greatly improves the capabilities of such applications, since the amount of
states and transitions often form a bottleneck.

Fig. 1: Automaton where there is no mutually delayed simulation but three
pairs of states that fairly simulate each other, {(qri, qli)|i ∈ N}. The
algorithm presented in this thesis (see Section 4) checks whether
merging those states changes the language. Since it does not, the
merges are accepted. The state qa gets removed because cccacω is no
accepting word.

The term minimizing an automaton can be used in diﬀerent ways. For
ω-automata, ﬁnding a language-equivalent automaton with minimal size is
NP-hard. This was proven in [13]. Instead, in the context of this thesis,
it is deﬁned as the search for any language-equivalent automaton with less
states and transitions.

A common approach for minimization consists of ﬁnding pairs of states that
can be merged without changing the language of the automaton. They
are called merge-equivalent. But how can those eﬃciently be found for ω-
automata such as Büchi automata?

6

Section 2

Fig. 2: This automaton, which accepts the language L(A) = {w ∈ Σω|w =
(b∗a)ω}, cannot be minimized without changing the language, al-
though the two states fairly simulate each other.

Many existing solutions are based on simulation. Moreover, as seen in
[6], they use direct simulation or delayed simulation. Simulation provides
pairs of states, they are called simulation-equivalent. For direct and de-
layed simulation such pairs are always also merge-equivalent, as shown in
[6]. Unfortunately, these types of simulation are not always practicable.
For delayed simulation, they quickly run out of space for big automata. For
direct simulation, they just remove few states.

In this work, we present an algorithm ﬁrst introduced in [7] which reduces
the size of Büchi automata using fair simulation.
Its time complexity is
O(|Q|4 ·|∆|2), the space complexity is O(|Q|·|∆|). The state pairs provided
by fair simulation are a superset of the pairs provided by direct or delayed
simulation. Therefore, a technique based on fair simulation can remove more
states than based direct or delayed simulation (compare to Fig. 1). How-
ever, in contrast to the other types, merging two fair-simulation equivalent
states is not always possible without changing the language of the automa-
ton (see Fig. 2). We present a method which checks if merging two states
changes the language with acceptable overhead.

Moreover, the presented algorithm extends techniques of [6] by also re-
moving some transitions redundant for the language of the automaton, as
seen in Fig. 3. This approach eﬀectively eliminates entire parts of an au-
tomaton which become unreachable after the edge removal.

Besides presenting the algorithm, another focus of this work is to illustrate
the theory behind it and to cover optimizations useful in practice. Further
we give experimental results as the algorithm runs in the context of the UL-
TIMATE Project [11], which is a program analysis framework. Additionally
we compare our method to other minimization techniques.

7

Section 2

Fig. 3: An example automaton, taken from [7], where there is no mutually
delayed simulation, but two safely mergeable, fairly simulating pairs
of states, (q1, q4) and (q8, q9). Further, the algorithm presented in
this thesis (see Section 4) removes the transition (q1, a, q3), which
turns out to be redundant for the language of the automaton. States
q3 and q5 become unreachable and are also removed.

8

Section 2

2 Simulation
This section presents diﬀerent types of simulation based on relations, focus-
ing on fair simulation. It ﬁrst demonstrates how to obtain simulation rela-
tions on Büchi automata in general. As an introduction to the minimization
algorithm, parity games and parity game graphs are then explained in more
detail.

2.1 Preliminaries
Deﬁnition 1. A Büchi automaton A is a tuple hΣ, Q, Q0, ∆, Fi, where Σ
is a ﬁnite set called the alphabet, Q is a ﬁnite set of states, Q0 ⊆ Q is the
set of initial states, ∆ ⊆ Q × Σ × Q is the transition relation and F ⊆ Q is
the set of ﬁnal states.

We deﬁne succ(v) for the set of successors {v0 ∈ V |∃a ∈ Σ∃(v, a, v0) ∈ ∆}
and pred(v) analogue for the set of predecessors of a given state v.
Given a Büchi automaton A, Aq refers to the Büchi automaton
hΣ, Q,{q}, ∆, Fi which is the automaton A with only q as initial state.

Deﬁnition 2. A run of a Büchi automaton A is a sequence
π = q0a1q1a2q2a3q3 . . . of arbitrary states alternating with arbitrary letters
such that ∀i : (qi, ai+1, qi+1) ∈ ∆. The run forms the path q0
a3→
q3 . . . in A and the corresponding ω-word is w = a1a2a3 . . ..

a2→ q2

a1→ q1

We write q ∈ π or a ∈ π if the state or letter occurs at least once in the
sequence π.

The automaton A accepts an ω-word w = a1a2a3 . . . iﬀ for at least one

corresponding run π the following holds:

q0 ∈ Q0,∀i : (qi, ai+1, qi+1) ∈ ∆ and |{i : qi ∈ F}| = ∞,

i.e. π starts at an initial state and visits ﬁnite states inﬁnitely often.

Deﬁnition 3. The accepted ω-language of a Büchi automaton A is
L(A) = {w ∈ Σω|A accepts w}.

For the sake of simplicity, the presented algorithm requires A to have no

9

2.1 Preliminaries

dead ends.

Section 2

Deﬁnition 4. A dead end is a state of an automaton A that has no outgoing
transitions, i.e. v dead end ⇔ v ∈ Q ∧ succ(v) = ∅.

Fig. 4: Solid lines represent the run π1 = q1aq2a . . ., dashed lines the run
π2 = q1aq3bq4aq3 . . .. They form the accepting ω-words w1 = aaω and
w2 = a(ba)ω. The dotted transition indicates the run π3 = q1aq3bq5.
This run does not build an accepting word because w3 = ab does
not visit ﬁnal states inﬁnitely often. The accepted ω-language of the
automaton is L(A) = {w1, w2}. And q5 is a dead end since it has no
successors.

However, Section 5 shows how automata with dead ends are handled.
Fig. 4 shows an automaton and its language, and illustrates several runs
with their corresponding words and a dead state.

10

2.2 Types of simulation

2.2 Types of simulation
Deﬁnition 5.

Section 2

1. Given a Büchi automaton A, fair simulation is deﬁned as a relation

(cid:22)f ⊆ Q × Q where

q (cid:22)f q0 iﬀ (∀w = a1a2 . . .∃π = qa1q1a2 . . . ⇒ ∃π0 = q0a1q0

∧(cid:16)∀w = a1a2 . . . ∈ L(Aq) ⇒ w ∈ L(Aq0)(cid:17)

.

1a2 . . .)

I.e.
for all words that have a corresponding run starting at q, there
must also be a corresponding run to the same word starting at q0. And,
for all accepting words whose runs start at q, there must also exist an
accepting run starting at q0 that corresponds to the same word.

2. Let π = q0a1q1a2q2a3q3 . . . and π0 = q0

0a1q0
runs to w starting at q = q0 and q0 = q0
a relation (cid:22)de ⊆ Q × Q where

2a3q0

1a2q0
3 . . . be corresponding
0. Then delayed simulation is

q (cid:22)de q0 iﬀ q (cid:22)f q0 ∧ ∀i : qi ∈ F ⇒ ∃j ≥ i : q0

j ∈ F.

Every time π visits an accepting state qi, π0 must also visit at least one
accepting state q0

j at some point after to cover that event.

3. Direct simulation is deﬁned analogously,

q (cid:22)di q0 iﬀ q (cid:22)f q0 ∧ ∀i : qi ∈ F ⇒ q0

i ∈ F.

That is, every time π visits an accepting state qi, π0 must also visit an
accepting state q0

i at the same time.

We say q0 ?-simulates q if the relation q (cid:22)? q0, where ? ∈ {f, de, di}, holds.
Note that q (cid:22)di q0 ⇒ q (cid:22)de q0 ⇒ q (cid:22)f q0, but not vice versa which follows
directly from the deﬁnition.
Again taking a look at Fig. 1 reveals that ql1 fairly simulates qr1 (qr1 (cid:22)f
ql1) and vice versa. The run starting at the state qr1 is πr1 = qr1cqr2cqr3bqbc . . .,
which corresponds to the word w = ccbc . . .. The run πr1 is accepting, but
there is also an accepting run starting at ql1 corresponding to the same
word, namely πl1 = ql1cql2cql3bqbc . . .. Since there are no other accepting
runs starting at qr1 it follows that qr1 (cid:22)f ql1.

11

2.3 Parity game

Section 2

It holds that qr1 delayedly and directly simulates ql1. Regardless of whether
πl1 visits qa or qb, everytime it visits an accepting state πr1 does also. This
is because qb is the only accepting state on run πl1.

But ql1 does not directly simulate qr1. Since ql1, ql2, ql3 are not accepting

states, πl1 cannot visit accepting states the same time πr1 does.

ql1 also not delayedly simulates qr1 because the corresponding word w =
ccac . . . of the run πr1 = qr1cqr2cqr3aqac . . . can only be matched by the run
πl1 = ql1cql2cql3aqac . . .. Further, πr1 visits three accepting states before en-
tering the loop whereas πl1 not visits an accepting state for coverage.

Last we point out why qr1 does not fairly simulate qr2. The run πr2 =
qr2cqr3bqbc . . . corresponds to the word w = cbc . . ., but no run πr1 corre-
sponding to the same word starting from qr1 exists.

For minimizing automata pairs of states that simulate each other, i.e. q
and q0 if q (cid:22)? q0 ∧ q0 (cid:22)? q are of interest. As seen later, for ? ∈ {di, de}
it is always possible to merge such a pair without changing the language of
the automaton. For fair simulation this is not always be the case. As the
algorithm in question aims to reduce as many states as safely possible, the
correctness of any such potential merge must be veriﬁed before it is applied.

A naive implementation, for determining whether a pair of states q and
q0 simulates each other, consists of iterating over all possible words start-
ing at q and q0. Then creating all corresponding runs for such words and
compute wether Deﬁnition 5 holds.

We present a more eﬃcient implementation, Algorithm 1. The concept

of this algorithm is based on parity games.

2.3 Parity game
A parity game GA(q, q0), where q and q0 are arbitrary states of the Büchi au-
tomaton A, is played by two players, Spoiler (or Antagonist) and Duplicator
(or Protagonist). Each player has one token, initially placed at states q and
q0, for Spoiler and Duplicator respectively. The players move their token
alongside the automaton A using transitions. Both tokens can be moved to
the same state without interfering each other.
i Spoiler’s token is at state qi and Duplicator’s at q0
follows:

The game is played in rounds, assuming that at the beginning of round
i, a round is played as

12

2.3 Parity game

Section 2

1. Spoiler chooses a transition (qi, a, qi+1) ∈ ∆ and moves his token to

qi+1.

2. Duplicator must now respond to Spoiler’s choice, choose an a-transition

(q0
i, a, q0

i+1) ∈ ∆ and move his token to q0

i+1.

If q0
i does not have such an outgoing a-transition, Duplicator can not respond.
The game halts and Spoiler wins the game. Note that Spoiler can always
choose an outgoing transition, as we assume A having no dead ends (compare
to Deﬁnition 4).
two inﬁnite runs π = qa1q1a2q2a3q3 . . . and π0 = q0a1q0
game history is deﬁned as the tuple (π, π0).

If Duplicator can always respond to Spoilers choices, the game produces
3 . . .. The

2a3q0

1a2q0

We connsider three types of parity games. All of them diﬀer in the win-
ning conditions for Duplicator.
Deﬁnition 6.

1. In the direct simulation game Gdi

winning for Duplicator iﬀ ∀i : qi ∈ F ⇒ q0

i ∈ F.

A(q, q0) the game history (π, π0) is

2. In the delayed simulation game Gde

winning for Duplicator iﬀ ∀i : qi ∈ F ⇒ ∃j > i : q0

A (q, q0) the game history (π, π0) is

j ∈ F.

3. In the fair simulation game Gf

ning for Duplicator iﬀ |{j|q0

A(q, q0) the game history (π, π0) is win-

j ∈ F}| = ∞ ⇒ |{i|qi ∈ F}| < ∞.

Note that there are similarities between this deﬁnition and the deﬁnition of
simulation (Deﬁnition 5).

Fig. 5 shows two copies of the same automata. They represent a parity game
with the token of Spoiler initially standing on q3 and the token of Duplicator
on q1. Spoiler has two possibilites in the ﬁrst round, he can choose the b-
transition (q3, b, q4) or the a-transition (q3, a, q5). A wise decision would be
to choose the a-transition, we assume he decides for this way. The token of
Spoiler now is placed at q5 and Duplicator must also choose an a-transition
or he looses. Duplicator decides for (q1, a, q2) and moves his token to q2.
The second round starts and Spoiler has again the option to choose any
transition he likes. However, there is only one transition and he chooses

13

2.3 Parity game

Section 2

Fig. 5: A parity game with Spoiler starting at q3 and Duplicator at q1. The
dashed and dotted lines represent the two possible runs Spoiler can
create and possible responses of Duplicator.

(q5, a, q5). Duplicator must react and also choose an a-transition but q2 has
no outgoing transitions. The game holds and Spoiler wins since Duplicator
can not match his transition.

Now assuming Spoiler takes the b-transition in the ﬁrst round and moves
to q4 instead of q5. If Duplicator takes the transition (q1, b, q2) he would lose
again in the next round so he chooses (q1, b, q3). The only possibility for
Spoiler is to take (q4, b, q4) and Duplicator also moves to q4. Both players
now repeatedly take the transition (q4, b, q4) and the game creates the game
history (π, π0) where π = q3bq4b . . . and π0 = q1bq3bq4b . . .. The game history
determines the winner, for fair and delayed simulation the game history is
winning for Duplicator, for direct simulation Spoiler wins since he visits an
accepting state in the ﬁrst round while Duplicator visits q3 in this round.

Observe that as soon as, in the beginning of the same round, Duplicator’s
token is placed at the same state Spoiler’s token is at, he can directly copy
every move of Spoiler by simply following him. If that is the case Spoiler
cannot win the game anymore.

While assuming both players give their best Spoiler would not choose the
transition (q3, b, q4) and Duplicator would not choose (q1, b, q2).

14

2.3 Parity game

Section 2

2.3.1 Strategy
Informally a stategy for Duplicator determines at each round of the game
which transition Duplicator should choose based on the history of previous
rounds. Such a strategy is called a winning strategy if, no matter how Spoiler
plays, Duplicator always wins. While assuming that Duplicator always gives
his best to win this corresponds to using the best strategy. Formally strategy
and winning strategy are deﬁned the way as seen in [6].

0a1q1q0

Deﬁnition 7. Let si = q0q0
i−1aiqi be an interleaving
sequence such that π0 = q0a1q1a2 . . . ai−1qi−1aiqi is a run for Spoiler and
0a1q0
π = q0
A(q, q0) is a partial function f : Q × (Q ×
Σ × Q)∗

1a2 . . . ai−1q0
7→ Q where

A strategy for Duplicator in G?

i−1 is a run for Duplicator.

1a2 . . . ai−1qi−1q0

f(q) = q0 ∧ (∀si : i > 0 ⇒ (q0

i−1, ai, f(si)) ∈ ∆).

Observe that the existance of a strategy implies that it is possible for Dupli-
cator to play the game in such way that it does not halt. It also means that
if there does not exist a strategy for Duplicator then Spoiler always wins the
game since he can make moves Duplicator cannot respond to.

In the example of Fig. 5 there does not exist a strategy for Duplicator.
Since if Spoiler chooses the a-transition (q3, a, q5) and then (q5, a, q5) Dupli-
cator, meanwhile at q2, has no possibility to ﬁnd an outgoing a-transition.
The corresponding sequence up to this point is s2 = q3q1aq5q2aq5.

Assuming the transition (q3, a, q5) does not exist, Spoiler must choose the
b-transition (q3, b, q4), then there exist two diﬀerent strategies. The ﬁrst
strategy f1 chooses (q1, b, q2) for Duplicator, f1(q3q1bq4) = q2 and the second
strategy f2 chooses (q1, b, q3), f2(q3q1bq4) = q3.

A(q, q0) is a winning strategy
Deﬁnition 8. A strategy f for Duplicator in G?
iﬀ for all runs of Spoiler π there exists a run of Duplicator π0, received by
using the strategy for each move, such that the game history (π, π0) is winning
for Duplicator (Deﬁnition 6).
∀π = q0a1q1a2 . . .∃π0 : (π, π0) winning for Duplicator, where run π0 =
q0
0a1q0

1a2 . . . is the run received by q0

i+1 = f(q0q0

1a2 . . . qi+1).

0a1q1q0

Having a winning strategy means that, for ﬁxed starting positions, no matter

15

2.3 Parity game

Section 2

how Spoiler plays the strategy will always create a winning game history for
Duplicator. When using such a strategy for given starting positions it is not
possible for Spoiler to win the game.

In Fig. 5, when again assuming (q3, a, q5) does not exist, there is a winning
strategy for fair and delayed simulation games. Strategy f2, which chooses
(q1, b, q3) instead of (q1, b, q2) is a winning strategy. In complete f2 is deﬁned
as follows:

f2(q3)
f2(q3q1bq4)
f2(q3q1bq4q3bq4)
f2(q3q1bq4q3bq4q4bq4)
...

= q1
= q3
= q4
= q4

The following lemma shows the connection between parity games and sim-
ulation relations.
Lemma 1. Given a Büchi automaton A where q and q0 are states of A,
q (cid:22)? q0 iﬀ there exists a winning strategy for Duplicator in G?
? ∈ {di, de, f}.
Proof. The winning strategy creates game histories (π, π0) for every run π
Spoiler can build. Since the strategy is a winning strategy every run π0 that
follows the strategy creates a game history that is winning for Duplicator.
Given the deﬁnition of such a game history (Deﬁnition 6) it follows directly
that q (cid:22)? q0.
Assuming q (cid:22)? q0 there must exist a game history (π, π0) that is winning
for Duplicator for every possible run π Spoiler can create. All possible runs
π of Spoiler together with the corresponding runs π0 of Duplicator deﬁne a
winning strategy and the proof is complete.

A(q, q0) where

Given two states q and q0, ﬁnding out if q (cid:22)? q0 is equivalent to ﬁnding a
winning strategy for Duplicator in the game G?

A(q, q0).

16

2.4 Parity game graph

Section 2

2.4 Parity game graph
Obviously the diﬃculty is to ﬁnd a winning strategy or to proof that there
does not exist one. By using parity game graphs the problem can be solved
algorithmic.
Deﬁnition 9. Let A = hΣ, Q, Q0, ∆, Fi be a Büchi automaton to which we
0, ∆0, F 0i is a Büchi automa-
refer as Spoiler’s automaton and A0 = hΣ, Q0, Q0
ton to which we refer as Duplicator’s automaton. A parity game graph on
A,A0 = hV ?0 , V ?1 , E?, p?i where ? ∈ {di, de, f}.
two Büchi automata is a tuple G?
V ? is the set of vertices and V ? = V ?0 ∪ V ?1 , E? ⊆ V ? × V ? is the set of
edges (note that labels for the edges are not needed) and p? : V ? → N is a
function that maps a priority to each vertex.

The elements are deﬁned as follows:
1. For fair simulation (? = f):

move from Spoiler

{z

{z

|

1 = {v(q,q0)|q ∈ Q ∧ q0 ∈ Q0}
V f
0 = {v(q,q0,a)|q ∈ Q ∧ q0 ∈ Q0 ∧ ∃˜q ∈ pred(q) : (˜q, a, q) ∈ ∆}
V f
}
Ef = {(v(q,q0), v(˜q,q0,a))|∃(q, a, ˜q) ∈ ∆}
|
}
∪{(v(q,q0,a), v(q,˜q))|∃(q0, a, ˜q) ∈ ∆0}
if v = v(q,q0) ∧ q0 ∈ F 0
if v = v(q,q0) ∧ q ∈ F ∧ q0 /∈ F 0
otherwise

pf : V f → {0, 1, 2}, pf(v) =

move from Duplicator



0
1
2

2. For direct simulation (? = di):

V di1 = V f
1
V di0 = V f
0
Edi = Ef \ ({(v(q,q0), v(˜q,q0,a))|q ∈ F ∧ q0 /∈ F 0}
∪{(v(q,q0,a), v(q,˜q))|q ∈ F ∧ ˜q /∈ F 0})
pdi : V di → {0}, pdi(v) = 0

3. For delayed simulation (? = de):

V de1 = {v(b,q,q0)|q ∈ Q ∧ q0 ∈ Q0 ∧ b ∈ {0, 1} ∧ (q0 ∈ F 0 → b = 0)}
V de0 = {v(b,q,q0,a)|q ∈ Q ∧ q0 ∈ Q0 ∧ b ∈ {0, 1} ∧ ∃˜q ∈ pred(q) :

(˜q, a, q) ∈ ∆}

17

2.4 Parity game graph

Section 2

Ede = {v(b,q,q0),v(b,˜q,q0,a)|(q, a, ˜q) ∈ ∆ ∧ ˜q /∈ F}
∪{v(b,q,q0),v(1,˜q,q0,a)|(q, a, ˜q) ∈ ∆ ∧ ˜q ∈ F}
∪{v(b,q,q0,a), v(b,q,˜q)|(q0, a, ˜q ∈ ∆0 ∧ ˜q /∈ F 0)}
∪{v(b,q,q0,a), v(0,q,˜q)|(q0, a, ˜q ∈ ∆0 ∧ ˜q ∈ F 0)}
pde : V de → {0, 1, 2}, pde(v) =

if v = v(b,q,q0) ∈ V de1
if v ∈ V de0

b

2

The bit b encodes whether Spoiler has visited a ﬁnal state without
Duplicator visiting one since then, 1 indicates this and 0 the opposite
case.

For the remainder of this thesis (q, q0) abbreviates the vertex v(q,q0) and
(q, q0, a) the vertex v(q,q0,a).

Fig. 6: The automaton A from Fig. 2 and its parity game graph for fair
1 and the
simulation Gf
box shaped in V f
0 . The vertices with a solid border have a priority
p of 0, the dashed have priority 2 and the dotted vertex v(q0,q1) has
priority 1.

A,A. The elliptical shaped vertices are in V f

From now the focus is on fair simulation parity game graphs but the same
can be applied similiar to other simulations.

18

2.4 Parity game graph

Section 2

First note that a parity game graph is build using two automata A and A0.
In order to compute simulation relations it is enough to use A = A0 and sim-
A,A. But Section 4 needs the possibility to build
ply write Gf
a game graph on two diﬀerent automata. This allows letting Spoiler play on
a diﬀerent automaton than Duplicator which makes computing simulation
relations between two diﬀerent automaton possible.

A instead of Gf

A parity game graph represents all possible positions and moves of a parity
game in one graph. For each position of the parity game, the states Spoiler
and Duplicator stand on, there is a vertex in the graph. Possible moves of
the players are represented by edges between the vertices.

1 or v0 = (q, q0, a) ∈ V f

More precisely a vertex v1 = (q, q0) ∈ V f

0 encodes
the position where Spoiler’s token is placed at q and Duplicator’s at q0.
For such a vertex v1 it is now Spoiler’s time to make a move and choose a
transition, he may choose an a-transition (q, a, ˜q) ∈ ∆ which is encoded by
the vertex v0 = (˜q, q0, a) ∈ V f
0 that stands for the position where Duplicator
also needs to choose an a-transition. Let that transition be (q0, a, ¯q) ∈ ∆0
which then leads to the vertex (˜q, ¯q) ∈ V f
in the game graph. The game
1
graph has edges between vertices for every possible move. For example the
edge (v(q,q0), v(˜q,q0,a)) does exist if it is possible for Spoiler to move from the
state q to ˜q by using the letter a, i.e. (q, a, ˜q) ∈ ∆. And (v(q,q0,a), v(q,˜q)) exists
if Duplicator can move from q0 to ˜q by using a, i.e. (q0, a, ˜q) ∈ ∆0.

Fig. 6 illustrates the fair simulation game graph Gf

A,A obtained by using
the automaton A (from Fig. 2) for Spoiler and also for Duplicator. When
creating a game graph, the transition (q0, a, q0) from A produces the edges
(v(q0,q0), v(q0,q0,a)), (v(q0,q1), v(q0,q1,a)) and (v(q0,q0,a), v(q0,q0)) in Gf
A,A. The vertex
v(q1,q0,a) does not exist since it would require q1 to have an incoming transition
labeled with a.

2.4.1 Correlation to parity games
A(q, q0) can be played on the corresponding parity game
A parity game Gf
graph by starting at the vertex (q, q0) ∈ V1. The two players, with Spoiler
starting, now alternately move the same token over the game graph repre-
senting the original game.

The priorities encode the simulation conditions. Priority 0, for fair simu-
lation, represents the situation where Duplicator visits a ﬁnal state. Anal-
ogously, priority 1 stands for the position where Spoiler visits a ﬁnal state
and Duplicator does not. Priority 2 is a neutral situation in which both
players do not visit a ﬁnal state.

Fig. 6 demonstrates the deﬁnition of priority for fair simulation. The

19

2.4 Parity game graph

Section 2

vertex v(q1,q1) has a priority of 2 since q1 is no ﬁnal state, all vertices in
V0 also have priority 2. However, the vertex v(q0,q1) has priority 1 because
Spoiler’s state q0 is ﬁnal while Duplicator’s state q1 is not.

Deﬁnition 6 describes that Duplicator wins a parity game if he does not
allow Spoiler to visit ﬁnal states inﬁnitely often, while not doing the same.
When Duplicator lost, then he visited vertices with priority 1 inﬁnitely often
by not also visiting priority 0 that many. So in general Duplicator prefers
to visit vertices with priority 0 and Spoiler prefers priority 1 since those pri-
orities bring the players closer to their victory. Although this sounds like a
good strategy for Duplicator, if he dully moves to a vertex v with priority 0,
this could lead him into a trap. For example a loop of vertices with priority
1 behind v or similar.

The following two deﬁnitions clarify the connection between parity games
and game graphs by introducing an isomorphism σ.
Deﬁnition 10. Given the Büchi automata A, A0 and the game graph Gf
let P be the set of all paths in Gf
all runs in A0.

A,A0,
A,A0, R the set of all runs in A and R0 of
Then we deﬁne the path-transformation σ : P ∼−→ (R × R0). Which is,
1) → . . ., given by σ() = (π, π0).

0,a1) → v(q1,q0
0a1q0
1 . . ..

0) → v(q1,q0
for a path  = v(q0,q0
Where π = q0a1q1 . . . and π0 = q0
Lemma 2. The path-transformation σ is an isomorphism between paths in
game graphs and game histories in parity games.
Proof. σ is a morphism by deﬁnition. We deﬁne σ−1 : (R×R0) ∼−→ P given by
σ−1((π, π0)) =  where π, π0 and  are deﬁned the same as in Deﬁnition 10.
It follows that σ ◦ σ−1 = idR×R and σ−1 ◦ σ = idP. Thus σ is bijective, an
ismorphism and σ−1 is the inverse of σ.

Given the isomorphism σ, we deﬁne when a path is winning for Duplicator.
Deﬁnition 11. A path  in a game graph Gf
A,A0 is winning for Duplicator
iﬀ the game history σ() is winning for Duplicator.

For simplicity v ∈  means the path visits a vertex v. With the aid of vertex
priorities, the following lemma enhances Deﬁnition 11.

20

2.4 Parity game graph

Section 3

Lemma 3. The path  is winning for Spoiler iﬀ min{n : |{v|v ∈ ∧pf(v) =
n}| = ∞} is odd, i.e. the smallest priority that occurs inﬁnite times in the
path.
Proof. Spoiler only wins if he visits ﬁnal states inﬁnitely times while Du-
plicator does not. This case is reﬂected by a path that visits vertices with
priority 1 inﬁnitely times while not visiting priority 0 inﬁnitely often. In all
other cases Duplicator wins the game. Since 1 is the only odd priority, the
lemma holds.

A,A0 only.

Using the path-transformation σ and Lemma 3, a winning strategy can be
obtained on a parity game graph Gf

Let us deepen that by again taking a look on Fig. 6. When playing a
A, starting at (q1, q1), Spoiler may move
parity game on the game graph Gf
to (q1, q1, b) or (q0, q1, a). Assuming he decided for (q1, q1, b), Duplicator can
only choose (q1, q1) and it is Spoiler’s turn, again on the same spot. He may
choose this edge everytime which produces the path  = v(q1,q1) → v(q1,q1,b) →
v(q1,q1) → . . .. The smallest priority that occurs inﬁnite times on  is 2, even
both vertices have that priority, which is not odd. Because of that  is
winning for Duplicator but Spoiler may choose the transition to (q0, q1, a)
and so on.

In this example, it is not possible for Spoiler to win the play since there
is no possibility to visit priority 1 inﬁnite times no matter where the start-
ing position is or how Duplicator plays. For this reason every strategy for
Duplicator is a winning strategy in this game.

The correlation between game graphs and parity games leads to the next
observation. With Lemma 1, σ and Lemma 3, a simulation relation can
be computed on a parity game graph Gf

A,A0 only.

Referring to the example of Fig. 6, where every strategy deﬁnes a win-
ning strategy, the fair simulation relation is obtained. The relation consists
of q0 (cid:22)f q1 and q1 (cid:22)f q0. As seen before such a pair that fairly simulates
each other is a candidate for merging. However, as seen later, merging q0
and q1 will change the language of the automaton from {w ∈ Σω|w = (b∗a)ω}
to {w ∈ Σω|w = (ab)ω} so the merge attempt gets rejected.

21

Section 3

3 Computing a simulation relation
In the section before we have seen that q (cid:22)f q0 if there exists a winning
A(q, q0) (see Lemma 1). This
strategy for Duplicator in the parity game Gf
section shows how to compute if there exists a winning strategy for a pair
of states q and q0. A winning strategy is computed on the game graph only
by using the isomorphism σ (Deﬁnition 10) and Lemma 3.

With the use of Jurdzińskis algorithm, originally from [9], the simulation
relation is computed for every pair of starting states at the same time. This
is done by building paths on the game graph that reﬂect the optimal solution
for the players and extending them in every round if possible. The paths
are computed by introducing a progress measure for each vertex.

A,A0 = hV0, V1, E, pi on two Büchi automata
Given a parity game graph Gf
A and A0, in order for the algorithm to work correctly we assume that the
graph has no self loops nor dead ends (Deﬁnition 4). The ﬁrst condition
will not occur if the graph was built correctly but dead ends can develop in
practice. However, Section 5 shows how to handle these.
to an arbitrary k ∈ N, as shown in [6].

Note that Jurdzińskis algorithm also works more general on priorities up

3.1 Terminology
This section starts with some terminology. First the priority function for fair
simulation parity game graphs pf (Deﬁnition 9) is needed. For simplicity
p abbreviates pf.
Deﬁnition 12. We deﬁne n as the amount of vertices that have a priority
of 1, n = |{v : v ∈ V ∧ p(v) = 1}|.
Next µ is a function that assigns each vertex a progress measure, µ : V →
({0, 1, . . . , n} ∪ {∞}), where ∀i ∈ {0, 1, . . . , n} : i < ∞.

The algorithm uses a set of functions incri. They are used to increase the
current progress measure of a vertex based on its priority i.
Deﬁnition 13. Given the priority i of a vertex, i ∈ {0, 1, 2}, we deﬁne the

22

3.1 Terminology

Section 3

function incri : ({0, 1, . . . , n} ∪ {∞}) → ({0, 1, . . . , n} ∪ {∞}) as follows.



x + 1
x
0
∞

if i = 1 ∧ x < n
if i = 2 ∧ x 6= ∞
if i = 0 ∧ x 6= ∞
if x = ∞ ∨ (i = 1 ∧ x = n)

incri(x) =

The progress measure, together with incri, is used to count the amount of
vertices visited with priority 1 and reset the counter if a vertex with priority
0 is visted. The function incri increases a progress measure from 0 to n and
then to ∞ whenever vertices with priority 1 are visited. It resets the counter
to 0 if a vertex with priority 0 gets visited and does not change it for priority
2.
Note that, for a ﬁxed priority i, the function incri(·) is monotonically in-

creasing.

If the progress measure of a vertex is inﬁnity, there does not exist a winning
strategy for a game starting at this vertex. When the algorithm terminates
and a progress measure of a vertex is not inﬁnity, a winning strategy for a
game starting at this vertex does exist. Section 3.3 deepens this later.

Next the algorithm needs a function that selects the best neighboring
It is the progress measure of a vertex, a player would

progress measure.
choose as successor if it is his turn.
Deﬁnition 14. We deﬁne the best neighboring progress measure function
best-nghb-ms : {µ|µ : V → ({0, 1, . . . , n} ∪ {∞})} × V →
({0, 1, . . . , n} ∪ {∞}), given by

best-nghb-ms(µ, v) =

0
min ({µ(w)|w ∈ succ(v)})
max ({µ(w)|w ∈ succ(v)})

if p(v) = 0
if p(v) 6= 0 ∧ v ∈ V0
if p(v) 6= 0 ∧ v ∈ V1



If its Duplicator’s turn he will choose the neighbor with the smallest mea-
sure, analogue the greatest measure for Spoiler. If the priority of the current
vertex is 0 however, it represents a vertex that resets the progress measure
counter anyways so every choice will be optimal for both players.

A very simple although not fast implementation is to initiate every ver-
tex with progress measure 0 and run incrp(v)(best-nghb-ms(µ, v)) on each

23

3.2 Enhanced version of Jurdzińskis algorithm

Section 3

vertex until there is no progress. For all vertices v that then have a progress
measure µ(v) 6= ∞, there does exist a winning strategy in the game starting
at v. This is exactly what Algorithm 2, the original version of Jurdzińskis
algorithm does. For improving the runtime of the algorithm additional ﬁelds
are needed.

Let B and C be arrays. B stores the value of best-nghb-ms(µ, v) for each

vertex v.
Deﬁnition 15. We deﬁne the neighbor counter function nghb-cnt : {µ|µ :
V → ({0, 1, . . . , n} ∪ {∞})} × V → N,

nghb-cnt(µ, v) =



|{u : u ∈ succ(v) ∧ µ(u) =
best-nghb-ms(µ, v)}|
|{u : u ∈ succ(v) ∧ 0 =
best-nghb-ms(µ, v)}|

if p(v) 6= 0

if p(v) = 0

The function nghb-cnt counts the number of neighbors a vertex has that
represent the best choice to move at. The array C stores for each vertex v
the value of nghb-cnt(µ, v).

3.2 Enhanced version of Jurdzińskis algorithm
Let us now take a brief look at Algorithm 1, which is an optimized version
of the algorithm seen in [6], and going in deep afterwards in Section 3.4.

Lines 1-5 initialize the data structures of the algorithm, every vertex gets
the progress measure 0 which also means that every neighbor w has µ(w) = 0
thus C(v) needs to be the amount of successors.

In line 5 a working list is created that contains every vertex which has a

priority of 1.

Lines 6-22 represent the loop of the algorithm that processes the working
list. Given a vertex v from the working list its values are updated in lines
10-12.

Lines 13-22 process the predecessors of the current vertex v.

If the
progress measure of v has increased the predecessors may be added to the
working list if they choose v as optimal choice to move at.

Lines 16-17 are responsible for the predecessors in V1, they represent a
move by Spoiler and he is always interested in an increased progress measure.

24

3.2 Enhanced version of Jurdzińskis algorithm

Section 3

Algorithm 1: Eﬃcient implementation of Jurdzińskis algorithm ﬁt-
ted for use with three priorities.
1 for v ∈ V do
B(v) := 0;
2
C(v) := |{w : w ∈ succ(v)}|;
3
µ(v) := 0;
4
5 L := {v ∈ V|p(v) = 1}
6 while L 6= ∅ do
let v ∈ L;
7
L := L \ {v};
8
t := µ(v);
9
B(v) := best-nghb-ms(µ, v);
C(v) := nghb-cnt(µ, v);
µ(v) := incrp(v)(B(v));
P := {w ∈ V|w ∈ pred(v) ∧ w /∈ L};
for w ∈ P do
if p(w) 6= 0 ∧ µ(v) > B(w) then

10
11
12

if w ∈ V1 then
L := L ∪ {w};

13
14
15
16
17

18

19
20

21
22

else if
w ∈ V0 ∧ ((p(w) 6= 0 ∧ t = B(w)) ∨ (p(w) = 0 ∧ 0 = B(w)))
then

if C(w) > 1 then

C(w) := C(w) − 1;
else if C(w) = 1 then

L := L ∪ {w};

25

3.2 Enhanced version of Jurdzińskis algorithm

Section 3

Lines 18-22 are responsible for the predecessors in V0, analogously they
represent a move by Duplicator and he tries to evade the update by choosing
an alternative if possible.

3.2.1 Complexity
Algorithm 1 runs in O(|Q|3 · |∆|) time and O(|Q| · |∆|) space.
following this section analyses and proofs this claim.
Given a Büchi automaton A = hΣ, Q, Q0, ∆, Fi ﬁrst the size of the game
graph Gf

A gets analysed.

In the

Lemma 4. For a game graph Gf
n = |{v ∈ V : p(v) = 1}| it holds that

A = hV0, V1, E, pi with V = V0 × V1 where

|V |,|E| ∈ O(|Q| · |∆|)

n ∈ O(|Q|2)

Proof. Looking at Deﬁnition 9 obviously |V1| = |Q|2 since for every pair
(q, q0) exactly one vertex gets created. Every state has at least one outgoing
transition because a requirement of the algorithm is that A has no dead
ends, this follows |Q| ≤ |∆|. Furthermore |V1| = |Q|2 ≤ |Q| · |∆| thus
|V1| ∈ O(|Q| · |∆|).
Analyzing the size of V0, every state q0 and transition (q, a, ˜q) creates a
vertex v(˜q,q0,a). This implies |V0| ≤ |Q| · |∆| and the following is received:

|V | = |V0| + |V1| ≤ 2 · (|Q| · |∆|) ⇒ |V | ∈ O(|Q| · |∆|).

Likewise there is an edge (v(q,q0), v(˜q,q0,a)) from V1 to V0 for every state q0
and transition (q, a, ˜q). This are |Q| · |∆| edges. Together with the edges
from V0 to V1, which are limited by |Q| · |∆| in the same way, it holds that
|E| ∈ O(|Q| · |∆|).
Last |{v ∈ V : p(v) = 1}| ∈ O(|Q|2) is proven. Since vertices with
a priority of 1 form a subset of V1, whose size is bounded by |Q|2, also
|{v ∈ V : p(v) = 1}| ≤ |Q|2 holds.

Next the complexity of the algorithm is received.
Theorem 1. Algorithm 1 runs in O(|Q|3·|∆|) time and O(|Q|·|∆|) space.

26

3.2 Enhanced version of Jurdzińskis algorithm

Section 3

Proof. First we proof the space complexity. The algorithm needs to hold
the set of successors and predecessors of every node v, this is limited by
the amount of edges |E| of the game graph. With Lemma 4 the space
complexity follows since |E| ∈ O(|Q| · |∆|).
Next to the time complexity. The initialization in lines 1-4 needs time in
O(|E|) because it processes every outcoming edge, together this are exactly
all existing edges. The other assignments and the function succ(v) itself
need to be implemented in constant time.

The time needed for processing a vertex v in lines 6-22 depends on
the number of its successors and predecessors. Thus the time complexity is
O(|pred(v)|+|succ(v)|). Calculating the best-nghb-ms, nghb-cnt and the new
progress measure of v is proportional to the amount of successors. Assuming
all if statements in lines 13-22 are implemented in constant time calculating
which predecessors needs to be added to the working list is proportional to
the amount of predecessors obviously. Note that the containment test w /∈ L
in line 13 also needs to be implemented in constant time. However, this
easily can be realized by introducing a containment ﬂag for every vertex.
An upper bound gets formed by assuming that every vertex is in the
working list. Then, the amount of iterations is |V |, each consuming time
|pred(v)| + |succ(v)|. Together this visits every edge exactly two times. It
follows that the time complexity for iterating over each vertex is O(|E|).

The progress measure of a vertex can increase at most n + 1 times where
n is the amount of vertices with priority 1. After that its progress measure
deﬁnitely reaches ∞. The algorithm only adds a vertex to the working list if
it will increase its progress measure when processing. It directly follows that
each vertex can at most be added n+1 times to the working list. Using this
the upper bound gets extended by assuming that every vertex gets added
n + 1 times to the working list. Iterating over each vertex costs O(|E|) time
hence the time complexity for the upper bound is O(|E|·(n+1)). After that
each vertex must have reached its ﬁnal progress measure and the program
terminates.
Together with the initialization part a time complexity of O(|E|· (n + 1))
Last |E| ∈ O(|Q| · |∆|) and n ∈ O(|Q|2), according to Lemma 4. Thus

follows for the whole algorithm.
the time complexity is in O(|Q|3 · |∆|).

27

3.2 Enhanced version of Jurdzińskis algorithm

Section 3

3.2.2 Correctness
The output of the algorithm is the progress measure function µ : V →
{0, 1, . . . , n} ∪ {∞}. This function is later used to obtain the elements of
the simulation relation, Section 3.3 shows this in detail.

Before we talk of correctness of Algorithm 1, we deﬁne when the result-

ing progress measure function µ is correct.
Let M = {f|f : V → ({0, 1, 2} ∪ {∞})} be the set of all functions that
map vertices to progress measures. That are all variants of progress mea-
sure functions, note that µ is a member of the set M.
Deﬁnition 16. For all u ∈ V , liftu : M → M deﬁnes an unary operator
such that

µ(v)

liftu(µ)(v) :=

incrp(v)(best-nghb-ms(µ, v))

if u 6= v
if u = v

Given a vertex u the corresponding operator liftu(µ) creates a lifted version
of µ. For all vertices v 6= u the image liftu(µ)(v) is the same as µ(v), only
the image of u may be changed.
Deﬁnition 17. An element x ∈ X is a simultaneous ﬁxed point of a set of
functions F = {f|f : X → X} iﬀ it is a ﬁxed point for all those functions.
Formally this is ∀f ∈ F : f(x) = x.
Deﬁnition 18. A progress measure function µ : V → {0, 1, . . . , n}∪{∞} is
a correct result of Algorithm 1 iﬀ µ is the least simultaneous ﬁxed point
of all operators liftu.

To prove that the result of the algorithm µ is correct we go more aﬁeld. We
will use the original version of Jurdzińskis algorithm, from [9], and prove
that our, more eﬃcient, version yields the same result.

First we deﬁne an ordering on the set of progress measure functions.
Deﬁnition 19. Given two functions µ1, µ2 ∈ M, the progress measure func-
tion ordering v deﬁnes a partial order over the set M. It is given by µ1 v µ2
iﬀ µ1(v) ≤ µ2(v)∀v ∈ V .
Analogously (cid:60) deﬁnes an order over the set M, given by µ1 (cid:60) µ2 iﬀ
(µ1 v µ2 ∧ µ1 6= µ2).

28

3.2 Enhanced version of Jurdzińskis algorithm

Section 3

The progress measure function ordering v gives the complete lattice struc-
ture hM,vi.
Proposition 1. The operator liftu is v-monotone for all u ∈ V .
Proof. Since incrp(v), for a ﬁxed p(v), is monotonically increasing it holds
that µ v liftu(µ) for all µ ∈ M.

Lemma 5. Every lift operator liftu has at least one ﬁxed point.

∀u ∈ V ∃µ : liftu(µ) = µ

Proof. hM,vi forms a complete lattice structure and liftu : M → M is v-
monotone, see Proposition 1. Using the Knaster-Tarski theorem [17] the
existance of a ﬁxed point follows.

The next deﬁnition introduces a sequence of progress measure functions.
Each received by applying an arbitrary lift operator to the previous element
of the sequence.
Deﬁnition 20. Let fam : N → V be a family of elements in V indexed by
N. seq : N → M is a sequence deﬁned by

seq(0) = µ0

seq(n + 1) = liftfam(n+1)(seq(n))

where µ0 ∈ M : µ0(v) = 0 for all v ∈ V .

Note that a sequence seq is not necessarily an injective function.
Colorally 1. seq is a v-monotone sequence.
Proof. Directly follows from Proposition 1.

Taking a look on Algorithm 2, the assignment sequence of µ in line
3 represents a sequence which we denote by seq0
It is obtained by
algo(i − 1)) for every iteration i of the while-loop in
seq0
line 2-3.

algo(i) = liftu(seq0

algo.

29

3.2 Enhanced version of Jurdzińskis algorithm

Section 3

Algorithm 2: Original version of Jurdzińskis algorithm from [9].
1 µ : V → ({0, 1, 2} ∪ {∞}), µ(v) = 0 ∀v ∈ V;
2 while ∃u ∈ V : µ (cid:60) liftu(µ) do

µ := liftu(µ);

3

Theorem 2. After Algorithm 2 has terminated the resulting progress mea-
sure function µ is the least simultaneous ﬁxed point of all operators liftu.
Proof. First of all µ is a simultaneous ﬁxed point of all operators liftu, else
the algorithm would not have terminated.
hM,vi forms a complete lattice structure and liftu is v-monotone, see
Proposition 1. Using Lemma 5 and the Knaster-Tarski theorem [17], it
follows that the least simultaneous ﬁxed point of all operators liftu does
exist. If using an approach like Deﬁnition 20 describes, it also follows that
the ﬁrst simultaneous ﬁxed point occurring in such a sequence is the least
simultaneous ﬁxed point.

Since µ is the ﬁrst simultaneous ﬁxed point occurring in seq0

is complete.

algo, the proof

Next the connection between Algorithm 1 and Algorithm 2 is shown.
Proposition 2. Algorithm 1 creates a sequence seqalgo = N → M.
Proof. The progress measure gets initialized with 0 for all vertices in lines
1-4, this corresponds to µ0 thus seqalgo(0) = µ0. In every following iteration,
let seqalgo(n) be the current progress measure of this round and v the vertex
currently processing, line 12 corresponds to applying liftv(seqalgo(n)) and
seqalgo(n + 1) is received and this
assigning it as new progress measure.
behavior exactly matches the deﬁnition of a sequence.

Lemma 6. After applying Algorithm 1 to the game graph G?
A,A0 the re-
sulting progress measure µ is a simultaneous ﬁxed point of all operators
liftv.
Proof. Using Lemma 5 we follow with Knaster-Tarski theorem [17] the
existance of simultaneous ﬁxed points. What is left is the question if the

30

3.2 Enhanced version of Jurdzińskis algorithm

Section 3

resulting progress measure µ actually is a simultaneous ﬁxed point. In other
words, does there exist a v ∈ V such that liftv(µ) (cid:60) µ? The answer is no,
we prove by contradiction and let us refer with µ0 to liftv(µ).
Assuming ∃v ∈ V : µ0 (cid:60) µ. Only one value can change by deﬁnition,
µ0(v) 6= µ(v). Because incri(·) is monotonically increasing for a ﬁxed i,
µ0(v) must be strict greater than µ(v). µ(v) gets assigned in line 12 only,
this presupposes p(v) 6= 0. Furthermore this means a successor s of v has
increased its progress measure in a previous iteration without adding v to
the working list.

1. Assuming v ∈ V1, v would have been added to the working list in lines
16-17. (cid:18)
2. Assuming v ∈ V0, C(v) > 1 else lines 21-22 would also add v to the
working list. Let µs be the progress measure right before s updated its
value for the progress measure. C(v) > 1 thus best-nghb-ms(µs, v) =
best-nghb-ms(µ0, v) while nghb-cnt(µs, v) > nghb-cnt(µ0, v) but
nghb-cnt(µ0, v) ≥ 1, i.e. s is no optimal choice for v anymore but it has
an alternative. However, this means v has a successor with a smaller
progress measure than s and best-nghb-ms prefers this successor since

v ∈ V0. This contradicts to µ0(v) > µ(v) because then µ0(v) = µ(v). (cid:18)
It follows that liftv(µ) = µ∀v ∈ V . So µ is a simultaneous ﬁxed point of
all operators liftv.

The following theorem proofs the correctness of Algorithm 1.
Theorem 3. The output of Algorithm 1, the progress measure function
µ : V → {0, 1, . . . , n} ∪ {∞}, is a correct result of the algorithm.
Proof. For µ to be a correct result it needs to be the least simultaneous ﬁxed
point of all operators liftu, compare to Deﬁnition 18. Using Lemma 6,
µ already is a simultaneous ﬁxed point of all operators liftu.

By using Proposition 2 it is clear that Algorithm 1 uses the same
lifting process as the original version uses. Furthermore, our algorithm only
describes the order of applied lifting functions more precise than Algo-
rithm 2. In fact, the original algorithm is a more general version of our
more eﬃcient implementation and the sequence seqalgo can also be produced
by Algorithm 2. Using Theorem 2 µ must also be the least simultaneous
ﬁxed point.

31

3.3 Simulation from progress measure

Section 3

It follows that µ is a correct result of Algorithm 1.

3.3 Simulation from progress measure
Once the algorithm has ﬁnished, the elements of the simulation relation are
computed by using the progress measures.
Lemma 7. Let µ be the progress measure function received by applying Al-
gorithm 1 to the game graph G?
A,A0. It holds that there exists a winning
A,A0(q, q0) iﬀ µ(v(q,q0)) < ∞, where
strategy for Duplicator in the game G?
? ∈ {di, de, f}.
Proof. Theorem 3 states that the resulting progress measure function µ of
the algorithm is a correct result. This implies that it is the least simultaneous
ﬁxed point by deﬁnition.
Theorem 11 from [9] describes that the least simultaneous ﬁxed point
progress measure function µ forms a winning set where µ(v(q,q0)) < ∞ holds
A,A0(q, q0) with ? ∈
iﬀ there exists a winning strategy for Duplicator in G?
{di, de, f}.

Theorem 4. After applying Algorithm 1 to the game graph G?
following holds

A,A0 the

q (cid:22)? q0 ⇔ µ(v(q,q0)) < ∞ where ? ∈ {di, de, f}.

Proof. Assuming µ(v(q,q0)) < ∞, by using Lemma 7 there exists a winning
A,A0. With Lemma 1 the existance of a winning
strategy for Duplicator in G?
strategy implies q (cid:22)? q0 and vice versa.

This connects simulation to the algorithm. The elements of the simulation
relation (cid:22)f are eﬃciently computed by applying Algorithm 1 to the fair
simulation game graph Gf

A and then using Theorem 4.

3.4 Illustration
In this section we illustrate the algorithm and the technique of how a sim-
ulation relation is computed by a progress measure function. Further, we
give example automata and explain the process of creating a game graph

32

3.4 Illustration

Section 3

and applying Algorithm 1 to it.

In an iteration of the algorithm, currently processing with v from the working
list, if the progress measure of v has increased in lines 14-22, the algorithm
may reversly build paths that use v by suggesting it as possible optimal
choice for its predecessors.

If it has not increased above the best neighbor measure of predecessor w
there is no reason to update w since it already has a successor that represents
a better (or as good as) choice than v. The same applies if the predecessor
has priority 0, it then will reset its counter anyways so there is no reason
why it should especially pick v as successor, any will be optimal.
But whenever predecessor w ∈ V1, it will pick v as optimal successor if
the progress measure of v has increased above the current best neighbor
measure of w because w then represents a move by Spoiler who wants to
increase the progress measure. If now w ∈ V0 and v previously belonged to
the best choices for w its counter of neighbors that have the best progress
measure needs to be decreased. This is because v increased its measure and
w, which represents a move by Duplicator, wants to build a path that has
a low progress measure. However, if w only had v as best choice w needs to
be updated since the increased progress measure of v will still be the best
choice for w.

Everytime we put a predecessor w in the working list it represents that
w will choose v as optimal successor that suits his needs as Duplicator, if
w ∈ V0, or Spoiler, if w ∈ V1. If a vertex reaches progress measure ∞ it
means that his path visits vertices with priority 1 inﬁnity times while not
visiting priority 0 that often. Whenever a progress measure reaches ∞ it
will be passed through all predecessors to all members on that path since
∀i ∈ {0, 1, . . . , n} : i < ∞.

For the algorithm we can assume that as soon as we count n + 1 occurences
of vertices with priority 1 while not visiting priority 0 we have built a path
that can visit such vertices inﬁnite times. Because of that we assign ∞ as
progress measure whenever increasing a measure that is n. Note that the
size of ∞ can be optimized by analyzing the graph, e.g. by using SCC as
seen in Section 5.

33

3.4 Illustration

Section 3

3.4.1 Examples
To properly understand the algorithm we take a closer look on three exam-
ples.

Fig. 7: The game graph from Fig. 6, with similar notation, after the algo-
rithm has terminated. The additional tuples indicate the values of
the vertex datastructures (best-nghb-ms, nghb-cnt, µ). The bold edges
are the outgoing edges of v(q0,q1), they indicate the calculation of the
best-nghb-ms of v(q0,q1) in the ﬁrst and only round.

The ﬁrst is from Fig. 6, in Section 2.4.1 we already saw that Spoiler can
not win the game, no matter where the starting position is. Thus and be-
cause of Theorem 4 q0 (cid:22)f q1 and q1 (cid:22)f q0. Hence we already know the
correct result, after program termination every vertex must have a progress
measure lower than inﬁnity. We also know the amount of vertices with a
priority of 1, it is n = 1. This means as soon as a the progress measure µ of
a vertex v that has µ(v) = 1 should be increased it reachs inﬁnity.

Looking at Fig. 7 we see the game graph after the algorithm has termi-
nated. In this example the program will only make one iteration and then
terminate. First we notice the default values of a vertex, for best-nghb-ms it
is 0, nghb-cnt is the amount of successors and µ also is 0. The vertex (q0, q1)
initially also had these default values, (0, 2, 0).

The working list of the algorithm is initialized with (q0, q1) since this is the
only vertex that has a priority of 1. In lines 6-22 the ﬁrst iteration starts

34

3.4 Illustration

Section 3

with v = (q0, q1) now. In line 10 the best-nghb-ms of v gets calculated based
on its succeeding vertices. v has a priority of 1 and is in V1, this means it is
Spoiler’s turn to make a move. Because of that he is looking for the successor
with the highest progress measure, both successors have a progress measure
of 0 so any will be optimal. Therefore the best-nghb-ms of v currently is 0
and there are two successors having that measure, nghb-ms remains 2.

Line 12 updates the progress measure of v based on its best-nghb-ms.
Since the priority of v is 1 and the best-nghb-ms is 0 the progress measure
gets increased from 0 to 1. The program now would inform the predecessors
of v about the update but since v has no predecessors the iteration ends.
The working list is empty and the algorithm terminates. (q0, q1) managed
to increase its progress measure from 0 to 1 but not to ∞, which would only
be one additional update away. (q0, q1) has a progress measure below ∞
thus q1 (cid:22)f q0 follows, analogously q1 (cid:22)f q0 follows from (q1, q0).

The basic concept is to update the data structures of a vertex based on
its successors and then inform its predecessors about the update, maybe
add them to the working list. If, for example, q 6(cid:22)f q0 then the algorithm
will reversly build the path
 = v0 → v1 → . . . →

}
|
v(q,q0) → . . . → pred(pred(v(q,q0))) → pred(v(q,q0)) → v(q,q0)

{z

→ . . .

loop

by increasing the progress measure of v(q,q0), adding a predecessor to the
working list which also adds a predecessor to the working list and so on.
This continues and v(q,q0) gets visited again through one of its successors,
a loop is created, and it increases its progress measure again. The process
repeats until the progress measure of v(q,q0) reaches ∞, now all vertices on
the loop also reach ∞ and the loop is completely processed.

This creates the path  reversly because we are informing predecessors.
v0, v1 . . . may be vertices that are predecessors of a vertex that is involved
in the loop. The created path has a lasso-type structure, ﬁrst a chain of
vertices and then a loop.

Next the second example which has more iterations.
Fig. 8 shows an automaton with language {bω}. The language already tells
that the two states can not be merged or the new language will be {(ab)ω}.
However, q1 is of course redundant as it can not reach a ﬁnal state. Note
that the presented algorithm is not able to remove q1 as it is not part of a

35

3.4 Illustration

Section 3

Fig. 8: An automaton A and its game graph Gf

Fig. 6. No states can be merged, we have q1 (cid:22)f q0 and q0 6(cid:22)f q1.

A,A with the notation of

mutually fair simulation.
In Fig. 9 the sequence of iterations the algorithm performs can be seen.
∞ comes after increasing beyond n = 1 because there is only one vertex with
a priority of 1. The working list gets initialized with v = (q0, q1), v has two
successors and both have the same progress measure, 0. Since v has a priority
of 1 its progress measure gets increased to 1 and lines 13-22 work through
the predecessors of v. There is only one predecessor, w = (q0, q1, b), and
w is in V0 which means this vertex represents a move by Duplicator. Since
Duplicator does not want to increase the progress measure of its vertices he
seeks for another possibility to move at instead of v. But w has no better
alternative, there is no other successor of w with a smaller progress measure,
the nghb-cnt of w is 1. Therefore line 21 resolves to true and w gets added
to the working list.

In the second iteration the working vertex is v = (q0, q1, b). For v the
best-nghb-ms is the smallest progress measure of its successors since it is in
V0. However, v has only one successor, it has a progress measure of 1 so v
must increase its progress measure to 2. We are again in lines 13-22 and
work through the predecessors of v. There is only w = (q0, q1) ∈ V1 and line
16 resolves to true, w is added to the working list.
This process repeats until v = (q0, q1) reaches a progress measure of ∞ in
the fourth iteration. It then again forces Duplicator’s vertex w = (q0, q1, b)
to be added into the working list. After the ﬁfth iteration the cycle ends

36

3.4 Illustration

Section 3

Fig. 9: An excerpt of game graph from Fig. 8, with similar notation, illus-
trating the six iterations of the algorithm. From the current working
vertex bold dashed edges are outgoing and bold solid edges are in-
coming edges indicating the successors of interest for the best-nghb-ms
and the predecessors for update notiﬁcation.

37

3.4 Illustration

Section 3

because line 15 resolves to false for w. The reason why is that the progress
measure of v has not increased in this round, the best-nghb-ms of w already
is ∞ from the last iteration thus µ(v) 6> B(w).
The program terminates because the working list is empty and we obtain
two vertices with a progress measure of ∞, (q0, q1) and (q0, q1, b). We follow
q0 6(cid:22)f q1 but q1 (cid:22)f q0 since the vertex (q1, q0) has a progress measure of 0.
Note that if (q0, q1) would have another predecessor u it would pass its ∞,
after creating the loop with (q0, q1, b), through u. Of course this can only
be the case if u, which then would represent a move of Duplicator, has no
better alternative to move at.

The third and last example demonstrates, the possibility of Duplicator to
evade an update notiﬁcation by choosing a better alternative.

Fig. 10: A theoretical game graph before and after the algorithm was applied
with the notation of Fig. 6. The ﬁgure demonstrates the possibil-
ity of Duplicator for (q0, q3, a) to evade an update notiﬁcation by
choosing another edge.

If we apply the algorithm to the game graph from Fig. 10 we initially have

38

Section 4

a working list of {(q0, q1), (q0, q2)}. We ﬁrst work with v = (q0, q2) which
increases its progress measure to 1. Next v notiﬁes w = (q0, q3, a) about
its update but Duplicator has no interest in increasing the progress mea-
sure thus it chooses the vertex (q0, q1) as a better successor than v. This
event corresponds to line 19, w decreases its nghb-cnt to 1 since it now only
has one neighbor with its current optimal best-nghb-ms of 0 and w gets not
added to the working list.

Next its v = (q0, q1) turn and he also increases its progress measure to 1.
Its predecessor (q0, q1, a) gets added to the working list. The other predeces-
sor w = (q0, q3, a) now also gets added since both of its successors currently
have a progress measure of 1. For w there is no better alternative to move at
as to v or (q0, q2). This represents line 21 in the algorithm and the nghb-cnt
of w was previously decreased from 2 to 1 thus w gets added to the working
list.

Now working (q0, q3, a) will increase its progress measure to 1, set its best-

nghb-ms to 1 and nghb-cnt to 2.

As next step working (q0, q1, a) increases its progress measure and adds
(q0, q1) again which, when worked, increases its progress measure to 2. v =
(q0, q1) now tries to notify w = (q0, q3, a) a second time to pass its progress
measure of 2. Although line 18 resolves to true, since v represented one
of the optimal choices to move at in the last round, w gets not added to
the working list again because Duplicator better moves to (q0, q2). This is
represented by line 19 and the nghb-cnt of w gets decreased to 1 again.
The vertex v = (q0, q1) together with (q0, q1, a) will create a loop and
increase their progress measures to ∞. In every iteration v tries to notify
w = (q0, q3, a) about the update but the best-nghb-ms of w is still only 1,
representing (q0, q2) as optimal choice, thus line 18 resolves to false (more
precisely: t 6= B(w)) in every following iteration.
The program terminates after v = (q0, q1) and (q0, q1, a) have reached a
progress measure of ∞ and they could not pass ∞ to w = (q0, q3, a). w
prefers to move to (q0, q2) and accepts its progress measure of 1 which is far
better than ∞ for Duplicator.

4 Minimization using fair simulation
In this section we see how to reduce the size of a Büchi automaton using
fair simulation. For this we use two techniques, the ﬁrst allows us to merge
pairs of states and the second technique removes transitions. First the chain
of proof that connects merging and transition removal to fair simulation is

39

4.1 Language preservation

Section 4

constructed. After that we present the complete minimization algorithm.

In order to reduce the size of a Büchi automaton A we need to modify
it, merge states or remove transitions. Let A0 be the automaton received
after applying the desired modiﬁcations. We then evaluate if the language of
the automaton did change. If it does not, L(A) = L(A0), the modiﬁcations
are executed and A := A0.

Merging of two states q1 and q2 is achieved by adding transitions and then
removing one of the states from the automaton. Section 4.3 describes this
process in detail.

Both of our techniques are achieved by adding or removing transitions

and then checking if the language did change.

4.1 Language preservation
This section shows how fair simulation is used for merging two states and
the removal of a transition such that it preserves the language.
Deﬁnition 21. We deﬁne that two states q and q0 of a Büchi automaton
A = hΣ, Q, Q0, ∆, Fi have the same in- and outgoing possibilities iﬀ the

following holds.

∃a ∈ Σ, q0 ∈ Q : (q1, a, q0) ∈ ∆ ⇒ ∃(q2, a, q0) ∈ ∆
∧ ∃a ∈ Σ, q0 ∈ Q : (q0, a, q1) ∈ ∆ ⇒ ∃(q0, a, q2) ∈ ∆
∧ ∃a ∈ Σ, q0 ∈ Q : (q2, a, q0) ∈ ∆ ⇒ ∃(q1, a, q0) ∈ ∆
∧ ∃a ∈ Σ, q0 ∈ Q : (q0, a, q2) ∈ ∆ ⇒ ∃(q0, a, q1) ∈ ∆



Next we deﬁne the relation ∼ between states to hold iﬀ both states have the
same in- and outgoing possibilities.
Lemma 8. Given two states q1, q2 ∈ Q of a Büchi automaton A =
hΣ, Q, Q0, ∆, Fi where A0 is the automaton obtained by removing q2 (or q1
if q2 ∈ F ∧ q1 /∈ F) and all its in- and outgoing transitions, i.e. merging
states q1 and q2. the following holds.

q1 ∼ q2 ⇒ L(A) = L(A0)

I.e. merging q1 and q2 does not change the language if they have the same
in- and outgoing possibilities.
Proof. We proof by contradiction, assuming L(A) 6= L(A0).

40

4.1 Language preservation

Section 4

0a1q0

2a3q0

1a2q0

1. L(A) ⊃ L(A0) ⇒ ∃w = a1a2a3 . . . : w ∈ L(A) ∧ w /∈ L(A0)

Let π = q0
3 . . . be an arbitrary run that corresponds to w
and w.l.o.g. the states where merged by removing q2. We construct
π0 from π by exchanging q2 with q1. π0 is still a valid run since if π
uses (q0, a, q2) or (q2, a, q0) it follows that the transition (q0, a, q1) or
(q1, a, q0) does also exist by the left hand side of the lemma. But q1
and its transitions do also exist in A0 because we only removed q2. We
follow that π0 corresponds to w, forms an accepting run and w ∈ L(A0).
(cid:18)2. L(A) ⊂ L(A0) ⇒ ∃w = a1a2a3 . . . : w /∈ L(A) ∧ w ∈ L(A0)

2a3q0

1a2q0

0a1q0

Let π0 = q0
3 . . . be an arbitrary run that corresponds to w
and w.l.o.g. the states where merged by removing q2. We immediately
see that π = π0 forms an accepting run in A because every existing
transition or state from A0 also exists in A. We follow that w ∈ L(A).
(cid:18)

This follows L(A) = L(A0), the language did not change.

Using Lemma 8 we can safely merge two states if both have the same in-
and outgoing possibilities (Deﬁnition 21). But what if this is not the case?
For example if there is a transition (q1, a, q3) and the corresponding transi-
tion (q2, a, q3) does not exist. We need to add (q2, a, q3) to the automaton
and check wether this changed the language. This is where the correlation
to simulation shows.

So far fair simulation was only used for states from one automaton.
If
two automata A and A0 only diﬀer in their set of transitions we now use fair
simulation between two automata. For example q (cid:22)f q0 where q is a state
from A and q0 a state from A0. Recalling Deﬁnition 5, fair simulation is
easily extended by letting the left hand side of the implications use transi-
tions of A and the right hand side transitions from A0.

Using this we deﬁne fair simulation between automata.
Deﬁnition 22. Given two Büchi automata A = hΣ, Q, Q0, ∆, Fi and A0 =
hΣ, Q, Q0

0, ∆0, Fi where Q0 = Q0

0 we say

A0 fairly simulates A iﬀ ∀q ∈ Q0∃q0 ∈ Q0

0 : q (cid:22)f q0

41

4.1 Language preservation

Section 4

Next we see how fair simulation between automata preserves language.
Colorally 2. Given a Büchi automaton A = hΣ, Q, Q0, ∆, Fi and two states
q, q0 ∈ Q it holds that q (cid:22)f q0 ⇒ L(Aq) ⊆ L(Aq0)
Proof. Follows directly from the deﬁnition of fair simulation as described in
Deﬁnition 5.

Lemma 9. Given two Büchi automata A = hΣ, Q, Q0, ∆, Fi, A0 =
hΣ, Q, Q0

0, ∆0, Fi where Q0 = Q0

0, the following holds

A0 fairly simulates A ⇒ L(A) ⊆ L(A0)

Proof. Since A0 fairly simulates A we know that there exists a q0 ∈ Q0
each q ∈ Q0 so that q (cid:22)f q0. With Corollary 2 L(Aq) ⊆ L(A0q0) follows.

0 for

L(A0q0) = L(A0).

L(A) = [

L(Aq) ⊆ [

q∈Q0

q0∈Q0
0

Theorem 5. A = hΣ, Q, Q0, ∆, Fi, A0 = hΣ, Q, Q0
automata and Q0 = Q0
their language is the same.

0, ∆0, Fi are two Büchi
0. Then, if both automata fairly simulate each other,

(A0 fairly simulates A ∧ A fairly simulates A0) ⇒ L(A) = L(A0)

Proof. L(A) ⊆ L(A0) ∧ L(A) ⊇ L(A0) ⇒ L(A) = L(A0). Using Lemma 9
we are done.

For language equality we need inclusion in both directions, L(A) ⊆ L(A0)
and L(A) ⊇ L(A0). So if we add transitions for an attempted merge we need
to check if A fairly simulates A0 and if also A0 fairly simulates A. The same
applies if we want to remove transitions, language does not change if we
have fair simulation in both directions between the automaton before and
after the modiﬁcation.

42

4.2 Modiﬁng the game graph

Section 4

4.2 Modiﬁng the game graph
For checking language inclusion we use a method that allows us to eﬃciently
modify the game graph.

We present tools for game graph manipulation and in the next section

take a closer look on how they are used to compute language inclusion.
Deﬁnition 23. For a given Büchi automaton A = hΣ, Q, Q0, ∆, Fi, a game
A,A0 = hV0, V1, E, pi and a set of transitions T ⊆ Q × Σ × Q, we
graph Gf
make the following four deﬁnitions.

1. rem(A, T) = hΣ, Q, Q0, ∆ \ T, Fi is the automaton without transitions

in T.

2. rem(Gf

{z

E0 = E \ { (cid:16)
A,A0, T) is the game graph hV0, V1, E0, pi where
|
(q0, a, ˜q) ∈ T}.

|v(q,q0,a) ∈ V0, v(q,˜q) ∈ V1,

transition of Duplicator

v(q,q0,a), v(q,˜q)

(cid:17)
}

3. add(A, T) = hΣ, Q, Q0, ∆∪ T, Fi is the automaton A additionally with

transitions in T.

4. add(Gf

E0 = E ∪ {(cid:16)
A,A0, T) is the game graph hV0, V1, E0, pi where
|

(cid:17)
}
transition for Spoiler
v(˜q,q0,a) ∈ V0, (q, a, ˜q) ∈ T}.

|v(q,q0) ∈ V1,

v(q,q0), v(˜q,q0,a)

{z

As we see rem removes transitions, given as set T, only from Duplicator’s
automaton and add adds transitions only to Spoiler’s automaton.
Lemma 10. Given two given Büchi automaton A = hΣ, Q, Q0, ∆, Fi and
A0 = hΣ, Q, Q0, ∆0, Fi, where T is a set of transitions. If ∆0 = ∆ \ T then
A,A0 = rem(Gf
Gf
Proof. Since add(A, T) = A0 we directly follow that the game graph con-
structed by Gf
A,A by using
A,A, T). This is because add only adds transitions to Spoiler, the same
add(Gf
transitions that would be generated by giving Spoiler the automaton A0 for
use from beginning.

A0,A is the same as that generated by modifying Gf

A,A, T). If ∆0 = ∆ ∪ T then Gf

A0,A = add(Gf

A,A, T).

43

4.3 Merge states

Section 4

Analogue for rem where Duplicator looses the same transitions that would

be left if he directly started with the modiﬁed automaton A0.

Colorally 3. Furthermore, given two Büchi automata A, A0 and two sets
of transitions T, T 0, we have

1. Gf

A,rem(A,T ) = rem(Gf

A,A, T) and

rem(rem(Gf

A,A, T), T 0) = rem(Gf

A,A, T ∪ T 0).

2. Gf

add(A,T ),A = add(Gf

A,A, T) and

add(add(Gf

A,A, T), T 0) = add(Gf
Proof. Directly follows from Lemma 10.

A,A, T ∪ T 0).

4.3 Merge states
We have seen that a pair of states (q, q0) can be merged without changing the
language of the automaton when they directly or delayedly simulate each
other. For fair simulation this is not the case. However, chances are high in
practice that such a pair can also be merged without changing the language.
We say (q, q0) is of interest for merging if the states fairly simulate each
other,

q (cid:22)f q0 ∧ q0 (cid:22)f q.

Given such a pair we construct the automaton A0 where both states have
the same in- and outgoing possibilites, i.e. q ∼ q0 (Deﬁnition 21).

In detail we deﬁne A0 as the automaton add(A, T) where

T = {(q, a, ˜q) /∈ ∆|(q0, a, ˜q) ∈ ∆}
∪{(˜q, a, q) /∈ ∆|(˜q, a, q0) ∈ ∆}
∪{(q0, a, ˜q) /∈ ∆|(q, a, ˜q) ∈ ∆}
∪{(˜q, a, q0) /∈ ∆|(˜q, a, q) ∈ ∆}.

Recalling Theorem 5 we need to compute if A0 fairly simulates A and if A
fairly simulates A0.

The ﬁrst computation is easy. We already know that A0 fairly simulates

44

4.3 Merge states

Section 4

For A0 to fairly simulate A we need to show ∀q ∈ Q0∃q0 ∈ Q0

A because A0 has more transitions than A. Hence it intuitively has more
possibilities.
0 : q (cid:22)f q0. We
simply select q0 = q and q (cid:22)f q0 holds because if q in A builds an accepting
run π then q0 in A0 can build the same run π0 = π. All transitions from A
are also available for q0 in A0.

The second computation is not trivial, to compute if A fairly simulates A0
we construct the game graph Gf
A, T). This is the game graph
A0,A = add(Gf
where Spoiler plays on A0 and Duplicator on A.
Theorem 6. Let µ be the progress measure function obtained by applying
Algorithm 1 to the graph without modiﬁcations Gf
A.

Also let µ0 be the progress measure function obtained by applying the algo-
A0,A, where T is a set of

rithm to the modiﬁed game graph add(Gf
transitions. Then the following holds.

A, T) = Gf

A fairly simulates A0 iﬀ ∀v ∈ V : (µ(v) 6= ∞ ⇒ µ0(v) 6= ∞)
∧(µ(v) = ∞ ⇒ µ0(v) = ∞)

Proof. If the right hand side holds we directly follow

∀q0 ∈ Q0

0∃q ∈ Q0 : q0 (cid:22)f q

Deﬁnition 22

=⇒ A fairly simulates A0

A and also in Gf

If A fairly simulates A0 we have ∀q0 ∈ Q0

since we trivially have qi (cid:22)f qi∀i in Gf
q = q0.

A0,A, we simply select
0∃q ∈ Q0 : q0 (cid:22)f q, i.e. the trivial
i = qi. Since (cid:22)f transitive, which easily can be seen,
pairs q0
we build all other elements ˜q (cid:22)f qi of the simulation relation with ˜q (cid:22)f q0
by using

i (cid:22)f qi where q0

i

˜q (cid:22)f q0

i ∧ q0

i (cid:22)f qi ⇒ ˜q (cid:22)f qi.

We see that if we apply Algorithm 1 to Gf
A0,A and the obtained simulation
relation is the same as after running the algorithm on Gf
A, A fairly simulates
A0. Together with the trivial statement that A0 fairly simulates A we receive
language equivalence L(A) = L(A0) by Theorem 5. Both states then have

45

4.4 Remove redundant transitions

Section 4

the same in- and outgoing possibilities, we apply Lemma 8 and merge the
two states without changing the language.
Summarized we ﬁrst search for pairs (q, q0) where q (cid:22)f q0 and q0 (cid:22)f q.
A0,A and run Algorithm 1 on it. We compare results
Then we construct Gf
and if both simulation relations are equal the merge is accepted and does
not change the language of the automaton.

4.4 Remove redundant transitions
A transition (q, a, q0) is of interest for removal if

∃˜q ∈ Q : (q, a, ˜q) ∈ ∆ ∧ q0 (cid:22)f ˜q.

In practice chances are high that such transitions do not change the language
when removed, compared to arbitrary transitions. Given such a transition
we construct the automaton A0 where this transition was removed. In detail
A0 = rem(Gf

A, T) where T = {(q, a, q0)}.

We again recall Theorem 5 and compute if A0 fairly simulates A and A

fairly simulates A0.

For A to fairly simulate A0 we need to show ∀q0 ∈ Q0

This time the second computation is easy. If we remove transitions from
A we already know that A fairly simulates the received automaton A0 be-
cause A0 intuitively has less possibilities.
0∃q ∈ Q0 : q0 (cid:22)f q.
We select q = q0 and q0 (cid:22)f q holds because if q0 in A0 builds an accepting
run π0 then q in A can build the same path π = π0. All transitions from A0
are also available for q in A, i.e. for all transitions (q0, a, ˜q) in A0 there does
also exist the transition (q, a, ˜q) in A, analogously for transitions (˜q, a, q0) in
A0 there exists the transition (˜q, a, q) in A.

The ﬁrst computation is not trivial, we proceed likewise to Section 4.3.
In order to compute if A0 fairly simulates A, we consruct the game graph
A,A0 = rem(Gf
A, T) . In this game graph Spoiler plays on A and Duplicator
Gf
on the modiﬁed automaton A0.
Theorem 7. Let µ be the progress measure function obtained by applying
Algorithm 1 to the graph without modiﬁcations Gf
A.

Also let µ0 be the progress measure function obtained by applying the algo-
A,A0, where T is a set of

rithm to the modiﬁed game graph rem(Gf

A, T) = Gf

46

4.5 Algorithm

Section 4

transitions. Then the following holds.

A0 fairly simulates A iﬀ ∀v ∈ V : (µ0(v) 6= ∞ ⇒ µ(v) 6= ∞)
∧(µ0(v) = ∞ ⇒ µ(v) = ∞)

Proof. Analogously as for Theorem 6.

If both simulation relations are the same we receive that A0 fairly simulates
A, together with A fairly simulates A0 we now obtain language equivalence,
L(A) = L(A0) for removing the transition.

Summarized we ﬁrst search for transitions of interest (q, a, q0). Then we
A,A0 and run Algorithm 1 on it. We compare results and if
construct Gf
both simulation relations are equal the transition removal is accepted and
does not change the language of the automaton.

4.5 Algorithm
Take a look at Algorithm 3, ﬁrst presented in [7], the complete minimiza-
tion algorithm that uses the introduced techniques to reduce the size of a
Büchi automaton using fair simulation.

Lines 1-3 construct the game graph and apply the initial run of Algo-
rithm 1.

In lines 4-10 we compute the states of interest for merging and store it
in L1. We store the transitions of interest for removal in L2. As speciﬁed in
Section 4.3 and Section 4.4.

Lines 11-25 check if merging or transition removal would change the
language of the automaton.
If a merge would not change the language
the pair gets stored in S1, and S2 stores the transitions that would not
In lines 13-16 the set T describes the
change the language if removed.
transitions that need to be added for q and q0 to have the same in- and
outgoing possibilities as seen in Section 4.3. Line 18 and 24 represent
Theorem 6 and Theorem 7 respectively.

Lines 26-29 merge pairs of states and remove transitions that do not

change the language if merged or removed.

47

4.5 Algorithm

Section 4

A);

A := hV0, V1, E, pi;

Algorithm 3: Complete algorithm for minimization of Büchi au-
tomaton A = hΣ, Q, Q0, ∆, Fi using fair simulation.
1 Gf
2 V := V0 ∪ V1;
3 µ := Algorithm 1(Gf
4 L1 := ∅;
5 for v(q,q0) ∈ V : µ(v(q,q0)) < ∞ do
6
7
8 L2 := ∅;

9 for (q, a, q0) ∈ ∆ :(cid:16)∃˜q ∈ Q : (q, a, ˜q) ∈ ∆ ∧ µ(v(q0,˜q)) < ∞(cid:17) do

if µ(v(q0,q)) < ∞ ∧ v(q0,q) /∈ L1 then

L1 := L1 ∪ v(q,q0);

L2 := L2 ∪ (q, a, q0);

10
11 S1 := ∅;
12 for v(q,q0) ∈ L1 do
13
14
15
16
17
18

T := {(q, a, ˜q) /∈ ∆|(q0, a, ˜q) ∈ ∆};
∪{(˜q, a, q) /∈ ∆|(˜q, a, q0) ∈ ∆};
∪{(q0, a, ˜q) /∈ ∆|(q, a, ˜q) ∈ ∆};
∪{(˜q, a, q0) /∈ ∆|(˜q, a, q) ∈ ∆};
A, T));

µ0 := Algorithm 1(add(Gf
if ∀v ∈ V : (µ0(v) 6= ∞ ⇒ µ(v) 6= ∞)

S1 := S1 ∪ v(q,q0);

19
20 S2 := ∅;
21 for (q, a, q0) ∈ L2 do
T := {(q, a, q0)};
22
µ0 := Algorithm 1(rem(Gf
23
if ∀v ∈ V : (µ0(v) 6= ∞ ⇒ µ(v) 6= ∞)
24

A, T));

∧ (µ0(v) = ∞ ⇒ µ(v) = ∞) then

∧ (µ0(v) = ∞ ⇒ µ(v) = ∞) then

25

S2 := S2 ∪ (q, a, q0);

A:= merge(q, q0, A);

26 for v(q,q0) ∈ S1 do
27
28 for (q, a, q0) ∈ S2 do
29
30 return A;

A:= remove((q, a, q0), A);

48

4.5 Algorithm

Section 4

4.5.1 Complexity
Before we start to analyze the complexity of the minimization algorithm let
us establish some assumptions. We assume that checking the conditions in
lines 5, 6, 9, 18, 24 can be done in constant time. Most of them can
be checked while proccessing Algorithm 1 and, for example, L1 can be
implemented as Hashset which allows membership test in constant time.
Also we assume that we only hold one game graph in the memory.

If
we need to change the game graph, in lines 17, 23, we do not create a
new game graph and instead modify the original graph. If the modiﬁcation
changes the language we undo the changes, this is described in Section 5
in more detail.
Theorem 8. Given a Büchi automaton A = hΣ, Q, Q0, ∆, Fi Algorithm 3
runs in O(|Q|4 · |∆|2) time and O(|Q| · |∆|) space.
Proof. Let us ﬁrst analyze the space complexity. Theorem 1 states that
Algorithm 1 runs in O(|Q| · |∆|) space. But we ﬁrst need to construct the
game graph and hold it in memory. However, the game graph also has a
size of |Q| · |∆| as we know from Lemma 4. It will not increase the space
complexity.
Lists L1, L2, S1, S2 store vertices and transitions which are of interest.
Their size depends on the size of the game graph, |Q| · |∆|. The progress
measure function µ needs to be holded in memory the whole time.
Its
domain is V , the vertices of the game graph, but |V | ∈ O(|Q| · |∆|). So in
total we have a space complexity of O(|Q| · |∆|).
For the time complexity we ﬁrst spot Algorithm 1 runs in O(|Q|3 · |∆|)

For constructing the initial game graph Gf

time as Theorem 1 states.
A we need to iterate over each
state and each transition especially to create vertices v(q,q0,a) ∈ V0. Therefore
we have a time complexity of O(|Q| · |∆|) for line 1.
Last we need to know how often we apply Algorithm 1 in lines 17,
23, let us refer with k to this amount. Obviously k is proportional to the
number of attempted merges and transition removals. Those are dependent
on the amount of simulation relation elements (cid:22)f and transitions ∆. Since
(cid:22)f: Q × Q we follow k ∈ O(|Q|2 + |∆|) ⊆ O(2 · |Q| · |∆|) because |Q|2 ≤
|Q| · |∆| ∧ ∆ ≤ |Q| · |∆| as we know by Lemma 4.
In total we have a time complexity of O(|Q|3 · |∆| · k) ⊆ O(|Q|4 · |∆|2).

49

4.6 Examples

Section 4

4.6 Examples
Let us consider two examples. The ﬁrst example is the automaton of Fig. 2.
We see its game graph after the initial run of Algorithm 1 in Fig. 7. The
algorithm yields q0 (cid:22)f q1 and q1 (cid:22)f q0 so this pair is of interest for merging.
Next we need to compute T, the set of transitions that need to be added for
q0 and q1 to have the same in- and outgoing possibilities. q0 has predecessors
q0 and q1 both with letter a. q1 now also needs this predecessors, we add
(q0, a, q1) and (q1, a, q1) to T. q0 has successors q0, with a, and q1, with
b. q1 already has both required transitions. Now we move to q1, it has
two predecessors q0 and q1 both with letter b, we need to add (q0, b, q0) and
(q1, b, q0) to T. Since q0 already has all transitions required by the successors
of q1 we are done and

T = {(q0, a, q1), (q1, a, q1), (q0, b, q0), (q1, b, q0)}.

A, T) creates the game graph seen in Fig. 11. When running
Using add(Gf
Algorithm 1 on the modiﬁed game graph every vertex reaches a progress
measure of ∞. The resulting simulation relation (cid:22)f has no elements, there
is no fair simulation anymore. By Theorem 6 we know this means the
language changes if we merge q0 and q1.

Algorithm 3 does not accept the attempted merge. Since there are no
more merge candidates and no candidates for transition removal the pro-
gram terminates.

In the next example we see the successful removal of a transition.
Looking at Fig. 12 we have an automaton with q1 (cid:22)f q2, q3 (cid:22)f q0 and
q3 (cid:22)f q2 which clearly can be seen. Although there is no pair of states for
merging we can remove a transition.
In line 9 of Algorithm 3 we ﬁnd the transition (q0, a, q1) since there
does exist transition (q0, a, q2) and q1 (cid:22)f q2. When building the game graph
rem(Gf

A,{(q0, a, q1)}) in line 23 we remove the edges

(v(q1,q0,a), v(q1,q1)), (v(q2,q0,a), v(q2,q1)) and (v(q3,q0,a), v(q3,q1))

from the original graph Gf
Duplicator that would use the removed transition (q0, a, q1).

A. As we see those edges are exactly the edges of

If we now apply Algorithm 1 on the modiﬁed game graph the resulting
simulation relation is the same as before. By Theorem 7 this means the
language does not change if (q0, a, q1) is removed from the automaton. The

50

4.6 Examples

Section 4

Fig. 11: The game graph add(Gf

A, T) where A is from Fig. 2 and T the
transitions left for q0 and q1 to have the same in- and outgoing
possibilities with the notation of Fig. 6. The dashed edges indicate
the loop, starting at (q0, q1) which increases the progress measure
for every vertex to ∞.

attempted removal is accepted and the program terminates.

51

Section 5

Fig. 12: An automaton where q1 (cid:22)f q2 , if Algorithm 3 is applied, leads
to the removal of transition (q0, a, q1) because (q0, a, q2) exists. The
attempted removal does not change the language and gets accepted.

5 Optimization
This section presents some optimizations for the algorithm.

Reuse
When using Algorithm 1 in line 3 of Algorithm 3 in order to compute
the simulation relation, we can reuse information for future runs of the
algorithm in lines 17, 23. In practice modifcations on the game graph are
small and most progress measures of vertices will not change.

Instead of initializing the progress measure of vertices or the arrays B and
C with the default assignment, we can reuse information gathered from the
ﬁrst run of Algorithm 1 in line 3. The following lemma examines this
more closely.
Lemma 11. For the progress measures functions µ and µ0 received from Gf
and add(Gf

A, T), where T is a set of transitions, the following holds.

A

∀v ∈ V : µ(v) ≤ µ0(v)

The same applies to rem(Gf

A, T). I.e.

the progress measure can only get

52

Section 5

greater after modifying the graph.
Proof. The only changes made to the game graph were adding transitions
to vertices v ∈ V1 that belong to Spoiler. Since Spoiler always chooses a
successor that increases the progress measure, if possible, the modiﬁcation
can only increase the progress measure of a vertex. This is because Spoiler
has more possibilities to choose from after the modiﬁcation.

If the progress measure is unchanged the modiﬁcation did not give Spoiler

a better choice than before, if it increased it did create a better choice.

Analogue for rem(Gf

A, T) were Duplicator can only loose and not gain
opportunities to decrease the measure. The functions add and rem make
the game harder to win for Duplicator.

Lemma 11 allows us to initialize the data structures of every following run
of Algorithm 1 with the values they had in the end of the ﬁrst run. This
can be done because we already know that Spoiler is capable of progressing
to this progress measures. It can only happen that he progresses further.
By doing so we reduce the running time by the part where the algorithm
progresses to this state of progress measure.

In combination with the optimization game graph history we are even
able to reuse the information gathered from the last successful modiﬁcation
instead only from the initial run of Algorithm 1.

However, we need to take a closer look on the working list of the algorithm.
Normally it gets initialized with vertices which have a priority of 1 but it
can happen that we miss parts of the game graph. The modiﬁcation, for
example adding transitions, may lead to the creation of new vertices v ∈ V0
in the game graph. Imagine the addition of transition (q, a, q0), this may
create vertices v(q,˜q,a) if there was no from q outgoing transition labeled with
a before. If such a newly created vertex has a priority not equal to 0 we also
need to add it to the working list.

Preprocessing
A requirement of Algorithm 1 is that the input automaton neither has
dead ends. Since they do not contribute to the language of the automaton
we safely remove them before applying the algorithm by a linear search.

Furthermore this observation allows us to remove non live states [18] that

do not contribute to the language of a Büchi automaton too.

53

Section 5

Deﬁnition 24. Given a Büchi automaton A a state q is live iﬀ

∃w ∈ L(A)∃ corresponding run π : q ∈ π

else q is called a non live state. I.e. q occurs in an accepting run on some
word.

By doing so we reduce the size of the Büchi automaton and so the size of
the game graph which often is a bottleneck.

Depending on the type of input automaton removing non live states may
not always be a good idea, especially when the costs for removing them is
greater than the beneﬁt of a smaller game graph.

Fair-direct simulation
Merging two states q, q0 is always possible without changing the language
if they directly simulate each other (see [6]). This also applies to delayed
simulation.

The idea for this optimization is to use delayed or direct simulation prior
to fair simulation. Although delayed simulation, in contrast to direct sim-
ulation, yields more merge-equivalent pairs, the costs for creating the huge
game graph are high. However, the game graph for direct simulation can be
generated out of the graph for fair simulation by omitting some edges, as
seen in Deﬁnition 9.

We generate the game graph for fair simulation Gf

A and mark the edges
needed to omit for a direct game graph. Then we easily transform it to a
A, the costs for the transformation are in O(1). Next we
direct game graph Gdi
apply direct simulation by using Algorithm 1(Gdi
A) and receive the relation
(cid:22)di. After that we transform the graph back to Gf
A, again the costs are in
O(1) only. Now we start Algorithm 3. As we reach line 12, where we
check if we can merge the states q and q0 without changing the language,
we ﬁrst check if they directly simulate each other, i.e. q (cid:22)di q0 ∧ q0 (cid:22)di q. If
that is the case, we already know that merging them does not change the
language. We skip applying an additional run of Algorithm 1 and directly
add the pair to S1.
We can do likewise for transition removal. It holds that a transition of
interest for removal (q, a, q0) can safely be removed without changing the
language if ∃˜q ∈ Q : (q, a, ˜q) ∈ ∆ ∧ q0 (cid:22)di ˜q, compare to Section 4.4. I.e. if
the required relation is direct simulation, this was proven in [7].

54

This optimization is more useful if more pairs of directly simulating ver-

tices exist.

Section 5

Strongly connected components
As we have seen Algorithm 1 computes a bound, denoted by ∞, for the
progress measure. When a vertex reaches this bound one can be sure that
there does not exist a winning strategy for Duplicator when starting at this
vertex.

Normally this bound is set to n+1 where n is the amount of vertices with
a priority of 1. When increasing to a progress measure of n + 1 we have
visited n + 1 vertices with priority 1 without visiting priority 0. Then we
are visiting at least one vertex with priority 1 more than only once.

However, we can improve that bound for vertices locally. If, for example,
we already know that a vertex can only reach 5 vertices with priority 1
where there are 30 in total, why not setting the local bound for this vertex
to 6 instead of 31. The computation for vertices would ﬁnish much faster in
many applications.

This is where we use strongly connected components, shortened to SCCs,

lets take a look at the following deﬁnition.
Deﬁnition 25. A SCC is a directed graph GS = hV, Ei, where V is the set
of vertices and E the set of edges, that is strongly connected. GS is strongly
connected iﬀ

∀v ∈ V ∀v0 ∈ V : v reachable from v0,

i.e. every vertex in the SCC can be reached from every other vertex.

We can use algorithms that work in linear time, for example Tarjan’s algo-
rithm [16], to compute every SCC of our game graph Gf
A before we apply
Algorithm 1. Now we compute for every vertex the local optimal bound
which is the number of vertices with priority 1 that are in the SCC. Next
we can use Algorithm 1 on each SCC separately.

However, the SCCs need to propagate progress measure updates among

themselves.

As Algorithm 3 uses Algorithm 1 multiple times while modiﬁng the
game graph and therefore calculating the SCCs each time from scratch we
may reuse information. Since the game graph gets only slightly changed,

55

Section 5

we may already know how the SCCs change. If adding edges between SCCs
they may merge to one SCC, if removing edges in a SCC it may split into
several SCCs.

We can either disable the SCC optimization on following runs of Algo-
rithm 1 and only use it on the ﬁrst run or we maintain SCCs of SCCs, i.e.
calculating which SCCs can be reached from other SCCs. If we have a SCC
that contains several SCCs, we can merge them to one SCC. As there are
far less SCCs than vertices in the game graph, the SCC calculation of SCCs
may be fast, dependent on the type of input automaton.

Order of vertex processing
Algorithm 1 maintains the working list L, it contains vertices that need to
be processed by the algorithm. We can speed up the program by optimizing
the order vertices get processed. The algorithm obviously terminates the
fastest if all vertices reach a progress measure of ∞ as fast as possible, if
they can. Therefore implementing the working list with a priority queue
that ﬁrst processes vertices with a higher progress measure will signiﬁcantly
speed up the process.

If we detect that vertices frequently get added to the working list we
should prioritize them over others since chances are high they are part of a
smaller loop which increases the progress measure faster to ∞ than bigger
loops.

Game graph history
When implementing line 17, 23 of Algorithm 3 we should modify the
original game graph instead of creating a new game graph, since their size
is big. However, if an attempted merge or transition removal changes the
language, we must be able to revert changes to the game graph. Making a
backup of the original graph may not be a good idea, since they consume
much space. But we can also memorize made changes and implement an
undo method.

Note that when using the optimization reuse, we must also be able to
revert changes to the data structures of Algorithm 1 before reusing them in
future runs of the algorithm. Creating backups of the data structures needs
space in the size of the game graph, O(|V |). We should only memorize the
exact changes that where made. For many vertices their value in the data
structures will remain unchanged since the game graph gets only slightly
modiﬁed.

56

Section 5

When a modifcation does not change the language we keep the modiﬁed
graph and use this graph for next modiﬁcations. This may slightly fasten
the detection of future failing modiﬁcations, since the progress measure of
vertices may be greater than in the unmodiﬁed game graph and reach ∞
faster.

Smart initialization
When applying Algorithm 1 to a game graph we may already know that
a state q0 does not fairly simulate q. We then know for the vertex v(q,q0)
or v(q,q0,a) that it will reach ∞, we can speed the algorithm up by directly
initializing µ(v(q,q0)) with ∞ and adding it to the working list to faster spread
the progress measure in the game graph.
That is the case for vertices v(q,q0,a) ∈ V0 if they are dead ends, they
represent the position before Duplicator’s turn in the corresponding parity
game. Having no successor means loosing the game because Duplicator
can not match the previous turn of Spoiler. Note that there do not exist
dead end vertices v(q,q0) ∈ V1 because the algorithm requires the input Büchi
automaton to have no dead ends.

This optimization has great potential since many applications where the
size of Büchi automata needs to be reduced already have knownledge about
simulation relation elements from the context. For example the context may
yield equivalence classes of states where simulation between elements from
diﬀerent classes is impossible.

Not reachable
After removing edges in a game graph, there may exist vertices v(q,q0,a) ∈ V0
that have no predecessors. Those vertices are obsolete for the algorithm and
can be removed to optimize future runs of the algorithm.
Note that vertices v(q,q0) ∈ V1 should not get removed. Although they are
not reachable from other vertices, they represent a possible element of the
simulation relation.

Fast detection
This optimization speeds up the compution if a modiﬁcation changes the
language, i.e. when using Algorithm 1 in line 17, 23 of Algorithm 3.
We can directly abort the computation of Algorithm 1 as soon as one
vertex reaches a progress measure of ∞, while it has not reached it in the
ﬁrst run of Algorithm 1. Then the simulation results of before and after

57

the modiﬁcation already diﬀer. We do not need to compute the rest of the
simulation relation and directly know the modiﬁcation changes the language.

Section 6

Equivalence classes
In lines 12-19 of Algorithm 3 when checking if a desired merge does
change the language we may often skip the process by using equivalence
classes.

Take a look at the following example. We already know that the pair q
and q0 and the pair q0 and ˜q can be merged without changing the language.
When now attempting the merge for q and ˜q we can skip computing if it does
change the language because it will not. The state ˜q can be merged with
q0, which can be merged with q. Therefore ˜q and q will also be mergeable
without changing the language.

We detect such an equivalence class with a union-ﬁnd data structure.
In this structure initially every vertex has its own set. When a pair of
states q and q0 is mergeable without changing the language we union their
sets. Before attempting a merge we then check if both states are already in
the same set, if so we abort the process and already know they are safely
mergeable.

6 Experimental results
In this section we present experimental results for Algorithm 3. The re-
sults are compared with minimization techniques based on direct or delayed
simulation and two other minimization approaches.
Results where computed by a machine with an Intel Core i5-3570K (4 ×
3.40GHz) CPU. The algorithms where written in Java, the maximal heap
size of the virtual machine was restricted to 10GB.

We have implemented those methods in the AutomataLibrary of the UL-
TIMATE Project [11], which is a program analysis framework. Fair simu-
lation minimization was implemented as described in Section 4 using some
optimizations of Section 5. The implementation of direct and delayed sim-
ulation minimization is similar to the approach shown in [6]. The other two
techniques are called MinimizeSevpa and ShrinkNwa. They are based on
Hopcroft’s algorithm and are described in [14] in more detail. Further, we
distinguish between fair simulation minimization and fair-direct simulation
minimization. Fair-direct simulation is described in Section 5.

58

6.1 Random automata

Section 6

As before A = hΣ, Q, Q0, ∆, Fi is a Büchi automaton and GA =

hV0, V1, E, pi a game graph of A where V = V0 ∪ V1. Further, ∞ = |{v ∈ V :
p(v) = 1}|+1 as deﬁned in Section 3.1. The amount of states an algorithm
has removed from the automaton is referred by s. Analogously t refers to
the amount of removed transitions. The running time of an algorithm is
listed in the column time and is measured in seconds.

6.1 Random automata
The automata set consists of 1000 uniform distributed, random, connected
automata. The algorithm used for automata generation is desribed in [1].
They have 100 states, an alphabet of size 5 and 10 ﬁnal states.

method

Fair

Fair-Direct
Delayed
Direct

MinimizeSevpa

ShrinkNwa

time |Q|
100
0.349
0.736
100
100
0.09
100
0.065
100
0.001
0.001
100

|∆|
100
100
100
100
100
100

|V |
22 878
22 878
38 800
27 724

–
–

|E| ∞ s
21
11 976
11 976
21
21
22 963
0
18 020
20
20

901
901
9 001
1

–
–

–
–

t
0
0
–
–
–
–

method

Table 1: Experimental results averaged over 1000 uniform distributed, ran-
dom, connected automata. The alphabet size is 5, the totality 5%
and there are 10 ﬁnal states.
|∆|
250
250
250
250
250
250

|E| ∞ s
1
34 801
1
34 801
1
67 101
45 496
0
1
1

time |Q|
100
0.125
100
0.329
100
0.546
0.151
100
100
0.001
0.001
100

Fair-Direct
Delayed
Direct

|V |
29 701
29 701
57 884
44 641

MinimizeSevpa

ShrinkNwa

901
901
9 001
1

t
0
0
–
–
–
–

Fair

–
–

–
–

–
–

Table 2: Experimental results averaged over 1000 uniform distributed, ran-
dom, connected automata. The alphabet size is 5, the totality 50%
and there are 10 ﬁnal states.

In the ﬁrst setup the totality of the automata is 5%, for the second it is 50%.
An automaton is total iﬀ every state has an outgoing transition for every

59

6.1 Random automata

Section 6

letter of the alphabet, i.e. ∀q ∈ Q∀a ∈ Σ∃q0 ∈ Q : (q, a, q0) ∈ ∆. Table 1
and Table 2 show the results.

By comparing the results, it strikes that fair simulation has the lowest
running time for a totatility of 50%, but turns out to be fairly bad for 5%.
This is attributed to the size of the game graph which is far bigger for direct
or delayed simulation than for fair simulation. Additionally, there are less
mergeable states when increasing the totatility. Therefore, fair simulation
minimization does apply Algorithm 1 fewer times for checking if a merge
changes the language. As the game graph for fair simulation is small com-
pared to the others, a single run of Algorithm 1 is very fast. The running
time for fair simulation grows the more often Algorithm 1 needs to be
applied.

Further, this setup shows that fair simulation in general does not remove
more states than delayed simulation for random automata. But fair simula-
tion is a fast simulation based minimization solution for random automata
with high totatility.

method

Fair

Fair-Direct
Delayed
Direct

MinimizeSevpa

ShrinkNwa

time |Q|
100
0.15
0.365
100
100
0.281
100
0.159
0.001
100
100
0.001

|∆|
300
300
300
300
300
300

|V |
39 107
39 107
74 480
65 176

–
–

|E| ∞ s
2
33 064
33 064
2
2
60 128
0
50 350
1
1

1 601
1 601
8 001
1

–
–

–
–

t
0
0
–
–
–
–

Table 3: Experimental results averaged over 1000 uniform distributed, ran-
dom, connected automata. The alphabet size is 30, the totality
10% and there are 20 ﬁnal states.

In a third setup the size of the alphabet is 30, the totatility 10% and the
amount of ﬁnal states is 20. Table 3 shows the results.

Again, fair simulation is a good simulation based minimization strategy.
The reason is the same as before, there are not many states to remove and
the game graph of fair simulation is much smaller than for direct or delayed
simulation.

When increasing the size of the alphabet for random automata there are

less states to remove, fair simulation beneﬁts from this.

60

6.2 Program analysis automata

Section 6

6.2 Program analysis automata
The next set consists of automata obtained by applying termination analysis
with the Ultimate Büchi automizer [8] to C-programs from the benchmark
set of the software veriﬁcation competition SV-COMP 2016 [4]. In total
the set has 485 automata.

method

Fair

Fair-Direct
Delayed
Direct

MinimizeSevpa

ShrinkNwa

time |Q|
1.503
125
125
0.652
125
0.322
0.329
125
125
0.002
0.001
125

|∆|
189
189
189
189
189
189

|V |
63 086
63 086
102 668
101 506

–
–

|E| ∞ s
40 461
35
35
40 461
33
43 425
77 770
33
33
33

641
641
1 729
1

–
–

–
–

t
0
0
–
–
–
–

Table 4: Experimental results averaged over 114 automata derived by the
anaylsis of diﬀerent programs. The automata have a size greater
than 20 and the set does not contain automata where no states can
be removed.

The ﬁrst setup is a subset which does not contain automata with a size
smaller than 20 and automata where no states can be removed. The resulting
set contains 114 automata, the outcome is shown in Table 4.

The fair simulation minimization algorithm is slow on this set. The reason
is the same as in Section 6.1. There are many states to remove, thus fair
simulation often applies Algorithm 1 and the running time increases.

Though fair simulation is slow, the fair-direct optimization speeds up fair
simulation signiﬁcantly. This is because 33 of the removed 35 states are
direct simulation-equivalent states. As direct simulation minimization is
computed in 0.329 seconds, the remaining fair simulation is computed in
0.652−0.329 = 0.323 seconds when using the fair-direct optimization instead
of 1.503 seconds.

The beneﬁt of fair-direct simulation becomes more signiﬁcant if there are

more direct simulation-equivalent states.
The second subset only contains the automata where no states can be re-
moved by neither of the applied methods. These are 112 automata in total,
The results are shown in Table 5.

Fair simulation has the smallest running time of all simulation based meth-
ods that where applied. The reason why is the same as in Section 6.1. The

61

6.2 Program analysis automata

Section 6

method

Fair

Fair-Direct
Delayed
Direct

MinimizeSevpa

ShrinkNwa

time |Q|
0.053
72
72
0.142
72
0.805
72
0.077
0.001
72
72
0.001

|∆|
79
79
79
79
79
79

|V |
19 239
19 239
36 951
27 790

–
–

|E| ∞ s
11 669
0
0
11 669
0
21 515
0
18 400
0
0

858
858
7 944
1

–
–

–
–

t
0
0
–
–
–
–

Table 5: Experimental results averaged over 112 automata derived by the
anaylsis of diﬀerent programs. The set does only contain automata
where no states can be removed.

size of the fair simulation game graph and ∞ is much smaller than for de-
layed simulation.

method

Fair

Fair-Direct
Delayed
Direct

MinimizeSevpa

ShrinkNwa

time |Q|
135
0.223
0.586
135
135
0.456
135
0.452
135
0.003
0.001
135

|∆|
196
196
196
196
196
196

|V |
67 195
67 195
108 673
107 779

–
–

|E| ∞ s
1
43 089
43 089
1
0
46 868
0
83 044
0
0

317
317
2 393
1

–
–

–
–

t
0
0
–
–
–
–

Table 6: Experimental results averaged over 485 automata derived by the
anaylsis of diﬀerent programs. The method MinimizeSevpa was
applied on all automata prior to this experiment.

A similar result is yielded by the third subset. It contains all automata of
the current set after MinimizeSevpa was applied on them. This setup is
represented by Table 6.

As the size of the automata was already reduced by a minimization method,
there are not many removable states anymore. Fair simulation beneﬁts from
this and provides a fast simulation based technique for reducing the size of
automaton even further. For 12 automata in this set, fair simulation even
removed 40 to 50 states.

This setup shows that using a fast, coarser minimization technique be-
fore using fair simulation is a good strategy. Moreover, it creates excellent
prerequisites for the fair simulation algorithm.

62

6.3 Complemented automata

Section 6

6.3 Complemented automata
The automata sets in this subsection contain automata which are results of
complementation algorithms.

Initially, we use the set of automata that was used in the following publi-
cation [5]. Then, for the results of Table 7, the algorithm ReducedOutdegree
is used on the set. It is a rank-based complementation algorithm which uses
the reduced average outdegree optimization that is described in Section 4
of [12].

The results of Table 8 are derived analogously by using the algorithm
Elastic. Elastic is a yet unpublished Büchi complementation algorithm that
is available in the AutomataLibrary of the ULTIMATE Project [11].

method

Fair

Fair-Direct
Delayed
Direct

MinimizeSevpa

ShrinkNwa

time |Q|
19
0.237
19
0.345
0.042
19
19
0.011
19
0.001
0.001
19

|∆|
184
184
184
184
184
184

|V |
1 785
1 785
3 056
4 396

–
–

|E| ∞ s
5
6 071
5
6 071
10 192
4
3
8 144
3
–
–
3

120
120
306
1

–
–

t
31
31
–
–
–
–

Table 7: Experimental results averaged over 104 automata derived by the

complementation algorithm ReducedOutdegree.

method

Fair

Fair-Direct
Delayed
Direct

MinimizeSevpa

ShrinkNwa

time |Q|
0.099
16
16
0.159
16
0.032
16
0.01
0.003
16
16
0.001

|∆|
146
146
146
146
146
146

|V |
1 326
1 326
2 434
3 148

–
–

|E| ∞ s
4 123
4
4
4 123
3
7 104
3
5 564
4
4

93
93
269
1
–
–

–
–

t
17
17
–
–
–
–

Table 8: Experimental results averaged over 102 automata derived by the

complementation algorithm Elastic.

Though fair simulation is 3 to 5 times slower than direct or delayed simula-
tion, it removes many transitions of the automata. This may even lead to
states that become unreachable after the transition removal. Those states
can also be removed, therefore reducing the size of the automaton even fur-

63

6.4 Summary

ther.

Section 7

6.4 Summary
The results show that for automata in general, one can not assume that
minimization based on fair simulation is faster than based on direct or de-
layed simulation. However, if the automata have a small size or the expected
amount of removed states is small, fair simulation turns out to be the fastest,
presented, simulation based method.

There are automata sets where fair simulation minimization can remove
much more states than direct or delayed simulation minimization. Addition-
ally to the other methods, it also removes transitions. For special automata
sets, as seen in Section 6.3, this is particularly eﬀective.

Moreover, the space needed for fair simulation is much smaller compared
to direct or delayed simulation. This is attributed to the size of the game
graph and can be seen in all experiments of this section. Thus the presented
algorithm can handle bigger automata where direct or delayed simulation
methods run out of space.

7 Conclusion
The presented algorithm reduces the size of Büchi automata based on fair
simulation. We have seen that it is capable of merging states and even
removing redundant transitions. We also have seen that existing approaches
using other simulation relations are limited in their optimization capabilities,
remove less redundancies and may even be more complex in time or space
for the case of delayed simulation.

A detailed description of the algorithm was presented as Algorithm 3
which allowed us to develop optimization techniques as shown in Section 5.
Images and examples coming with the thesis illustrate sections which are
more diﬃcult to understand. The thesis should made the algorithm com-
prehensible and the theory behind parity games and the game graph be clear.

An aim for the future is to extend the algorithm for Nested Word automata,
presented in [3]. An equivalent, more easy to understand model are Visibly
Pushdown automata, as seen in [2].

This automata have a regular, a call and a return alphabet. Additionally
they use a stack to remember the call levels.
If they, for example, use a
transition call a they can use the transition return a after that. If using

64

Section 7

transitions call a, call a, call b they may use return b, return a, return a and
so on. Transitions of the regular alphabet can be used at anytime. Nested
Word automata model this behavior without the use of a stack by making
the structure of words, the nested words, more complex.

The ability for an automaton to use diﬀerent levels makes deﬁning simula-
tion relations and the construction of a correct game graph tricky. However,
also being able to reduce the size of Nested Word automata would be a
great beneﬁt for the ULTIMATE Project [11] and others as those automata
describe the behavior of programs closer than Büchi automata.

65

Section 7

References
[1] Marco Almeida, Nelma Moreira, and Rogério Reis. Aspects of enumer-
ation and generation with a string automata representation. CoRR,
abs/0906.3853, 2009.

[2] Rajeev Alur and P. Madhusudan. Visibly pushdown languages.

In
Proceedings of the Thirty-sixth Annual ACM Symposium on Theory of
Computing, STOC ’04, pages 202–211, New York, NY, USA, 2004.
ACM.

[3] Rajeev Alur and P. Madhusudan. Adding nesting structure to words.

J. ACM, 56(3):16:1–16:43, May 2009.

[4] Dirk Beyer.

Reliable and reproducible competition results with
benchexec and witnesses (report on sv-comp 2016). In TACAS, Lecture
Notes in Computer Science. Springer, 2016.

[5] Frantisek Blahoudek, Matthias Heizmann, Sven Schewe, Jan Strejcek,
and Ming-Hsien Tsai. Complementing semi-deterministic büchi au-
tomata. In TACAS, Lecture Notes in Computer Science. Springer, 2016.
[6] Kousha Etessami, Thomas Wilke, and Rebecca A. Schuller. Fair sim-
ulation relations, parity games, and state space reduction for büchi
automata. SIAM J. Comput., 34(5):1159–1175, May 2005.

[7] Sankar Gurumurthy, Roderick Bloem, and Fabio Somenzi. Fair simula-
tion minimization. In Proceedings of the 14th International Conference
on Computer Aided Veriﬁcation, CAV ’02, pages 610–624, London, UK,
UK, 2002. Springer-Verlag.

[8] Matthias Heizmann, Jochen Hoenicke, and Andreas Podelski. Termina-
tion analysis by learning terminating programs. In CAV, volume 8559
of Lecture Notes in Computer Science, pages 797–813. Springer, 2014.
[9] Marcin Jurdziński. Small progress measures for solving parity games.
In Horst Reichel and Sophie Tison, editors, STACS 2000, volume 1770
of Lecture Notes in Computer Science, pages 290–301. Springer Berlin
Heidelberg, 2000.

[10] Richard Mayr and Lorenzo Clemente. Advanced automata minimiza-
tion. In Proceedings of the 40th Annual ACM SIGPLAN-SIGACT Sym-
posium on Principles of Programming Languages, POPL ’13, pages 63–
74, New York, NY, USA, 2013. ACM.

66

References

Section 7

[11] Software Engineering University of Freiburg. ULTIMATE - a program
analysis framework. https://ultimate.informatik.uni-freiburg.
de, feb 2013.

[12] Sven Schewe. Büchi complementation made tight. In STACS, volume 3
of LIPIcs, pages 661–672. Schloss Dagstuhl - Leibniz-Zentrum fuer In-
formatik, Germany, 2009.

[13] Sven Schewe. Minimisation of deterministic parity and buchi automata
and relative minimisation of deterministic ﬁnite automata. CoRR,
abs/1007.1333, 2010.

[14] Christian Schilling. Minimization of nested word automata. Master’s

thesis, University of Freiburg, Germany, 2013.

[15] Fabio Somenzi and Roderick Bloem. Eﬃcient büchi automata from
In Proceedings of the 12th International Conference on
ltl formulae.
Computer Aided Veriﬁcation, CAV ’00, pages 248–263, London, UK,
UK, 2000. Springer-Verlag.

[16] Robert Tarjan. Depth-ﬁrst search and linear graph algorithms. SIAM

Journal on Computing, 1(2):146–160, 1972.

[17] Alfred Tarski. A lattice-theoretical ﬁxpoint theorem and its applica-

tions. Paciﬁc J. Math., 5(2):285–309, 1955.

[18] Ming-Hsien Tsai, Seth Fogarty, Moshe Y. Vardi, and Yih-Kuen Tsay.
Implementation and Application of Automata: 15th International Con-
ference, CIAA 2010, Winnipeg, MB, Canada, August 12-15, 2010. Re-
vised Selected Papers, chapter State of Büchi Complementation, pages
261–271. Springer Berlin Heidelberg, Berlin, Heidelberg, 2011.

67

